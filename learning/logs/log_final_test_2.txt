=======================================
Simulation: 1
Iteration: 1
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 3
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 4
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 5
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: -8
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 7
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 8
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 10
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.42911
New value of Value function: 1.42911
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 17
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.41482
New value of Value function: 6.41482
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 18
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.35067
New value of Value function: 1.42911
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 19
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.95507
New value of Value function: 6.41482
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 20
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.36946
New value of Value function: 6.36946
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 21
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.41482
New value of Value function: 6.41482
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 22
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.38382
New value of Value function: 1.38382
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 23
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 6.41482
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 24
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.97
New value of Value function: 4.97
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.95399
New value of Value function: 2.95399
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 26
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.93779
New value of Value function: 4.93779
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.9212
New value of Value function: 2.9212
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 28
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.91134
New value of Value function: 4.91134
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 2.89483
New value of Value function: 2.89483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 30
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.88861
New value of Value function: 4.88861
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 2.89483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 32
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 6.86588
New value of Value function: 6.86588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 33
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.80636
New value of Value function: 2.89483
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 34
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 6.86588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 35
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 40
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -7
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 41
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 42
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 43
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 44
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 45
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 46
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 47
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 7.68504
New value of Value function: 7.68504
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 48
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 6.86588
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 49
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -3.13412
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 2.87233
New value of Value function: 2.87233
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 51
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 4.86849
New value of Value function: 4.86849
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 2.85248
New value of Value function: 2.85248
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 53
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 4.8503
New value of Value function: 4.8503
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 2.90463
New value of Value function: 2.90463
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 56
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 57
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 58
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 59
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 60
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.198198
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 61
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 4.85986
New value of Value function: 4.85986
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 2.87351
New value of Value function: 2.87351
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 64
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 65
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 66
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 67
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 68
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.155225
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 69
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 2.8977
New value of Value function: 2.8977
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 71
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 72
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.40543
New value of Value function: 1.40543
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 73
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.79722
New value of Value function: 2.79722
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.86789
New value of Value function: 6.86789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.86872
New value of Value function: 2.8977
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 3.34806
New value of Value function: 3.34806
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 77
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.775625
New value of Value function: 0.775625
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 3.46925
New value of Value function: 3.46925
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.605089
New value of Value function: 0.605089
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 3.50524
New value of Value function: 3.50524
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 81
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0934063
New value of Value function: 0.605089
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 83
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.40096
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.544762
New value of Value function: 0.544762
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 3.35685
New value of Value function: 3.35685
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.35067
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 87
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 6.41482
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 88
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 91
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 3.08921
New value of Value function: 3.08921
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 94
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.38312
New value of Value function: 6.38312
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 95
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 1.35155
New value of Value function: 1.35155
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 96
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.34626
New value of Value function: 6.36946
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 97
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.33269
New value of Value function: 6.34626
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 98
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.14813
New value of Value function: 7.14813
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 99
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.22859
New value of Value function: 5.22859
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 100
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 3.31023
New value of Value function: 3.31023
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 101
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.19841
New value of Value function: 5.19841
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 102
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.17241
New value of Value function: 5.17241
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 103
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.31137
New value of Value function: 5.31137
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 104
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 0.435502
New value of Value function: 0.435502
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 3.34046
New value of Value function: 3.34046
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 106
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.386955
New value of Value function: 0.386955
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.76925
New value of Value function: 7.76925
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 108
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 2.79863
New value of Value function: 2.79863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 6.86789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 110
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.79921
New value of Value function: 1.79921
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 111
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.25951
New value of Value function: 6.86789
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 112
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -1.05
New value of Value function: 1.79921
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 113
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.60819
New value of Value function: 5.60819
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.13483
New value of Value function: 6.13483
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 115
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.55211
New value of Value function: 2.55211
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 116
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.52299
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 117
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.10416
New value of Value function: 6.10416
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 118
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 6.10416
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 119
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.52659
New value of Value function: 7.52659
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 120
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 2
New value of Q matrix: -6.53553
New value of Value function: 2.55211
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 121
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.9205
New value of Value function: 7.9205
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 122
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 3.72295
New value of Value function: 3.72295
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.85763
New value of Value function: 6.10416
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 124
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -2.36634
New value of Value function: 2.55211
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 125
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 3.72295
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 6.8413
New value of Value function: 6.8413
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.46159
New value of Value function: 8.46159
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 128
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.9078
New value of Value function: 3.9078
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.74029
New value of Value function: 6.74029
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 130
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.9304
New value of Value function: 1.9304
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 131
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.81002
New value of Value function: 6.81002
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 132
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.82158
New value of Value function: 1.82158
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 133
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.80751
New value of Value function: 6.80751
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 134
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 1.78051
New value of Value function: 1.78051
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 135
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.79166
New value of Value function: 6.79166
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 136
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.20423
New value of Value function: 1.78051
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 137
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.78201
New value of Value function: 6.78201
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 138
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 1.75085
New value of Value function: 1.75085
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 139
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.76662
New value of Value function: 6.76662
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 140
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 1.72966
New value of Value function: 1.72966
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 141
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 5.46551
New value of Value function: 5.46551
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 142
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.56607
New value of Value function: 9.56607
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 143
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 6.42786
New value of Value function: 6.42786
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 144
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 9.65283
New value of Value function: 9.65283
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 3.54874
New value of Value function: 7.76925
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 146
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 10.6722
New value of Value function: 10.6722
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.77023
New value of Value function: 7.77023
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 148
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.69253
New value of Value function: 2.79863
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.77047
New value of Value function: 7.77047
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 150
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 4.97342
New value of Value function: 4.97342
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 151
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 9.89024
New value of Value function: 9.89024
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 152
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 5.38237
New value of Value function: 5.38237
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 10.6261
New value of Value function: 10.6261
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 154
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.73162
New value of Value function: 7.73162
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 155
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.893
New value of Value function: 8.893
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 156
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 4.2191
New value of Value function: 4.2191
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 4.4301
New value of Value function: 4.4301
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 158
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.10123
New value of Value function: 10.6261
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 159
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 5.05927
New value of Value function: 5.05927
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 160
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 9.7004
New value of Value function: 9.7004
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 161
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 4.78424
New value of Value function: 4.78424
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 9.35958
New value of Value function: 9.35958
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 163
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 5.24703
New value of Value function: 5.24703
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.03397
New value of Value function: 5.03397
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 165
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 4.69052
New value of Value function: 4.69052
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 166
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 10.5077
New value of Value function: 10.5077
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 167
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 9.42436
New value of Value function: 9.42436
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 168
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.85048
New value of Value function: 5.24703
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.43762
New value of Value function: 9.42436
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 170
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.53025
New value of Value function: 9.42436
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 171
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.33012
New value of Value function: 9.42436
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 172
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.71547
New value of Value function: 9.71547
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 173
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 5.65561
New value of Value function: 5.65561
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 11.4914
New value of Value function: 11.4914
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 175
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 10.0279
New value of Value function: 10.0279
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 176
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 6.22923
New value of Value function: 6.22923
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 11.0921
New value of Value function: 11.0921
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 178
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 6.04404
New value of Value function: 6.04404
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 5.21741
New value of Value function: 5.21741
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 180
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 10.7721
New value of Value function: 10.7721
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 181
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -1.74174
New value of Value function: 6.04404
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.34723
New value of Value function: 5.34723
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 183
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 2.69942
New value of Value function: 2.69942
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.4993
New value of Value function: 10.4993
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 185
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 6.23107
New value of Value function: 6.23107
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 11.7767
New value of Value function: 11.7767
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 187
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 5.60384
New value of Value function: 10.4993
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 188
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 12.4763
New value of Value function: 12.4763
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 189
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.55078
New value of Value function: 10.0279
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 190
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.29376
New value of Value function: 8.29376
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 191
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.38709
New value of Value function: 6.38709
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 192
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 4.10881
New value of Value function: 4.10881
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 9.99444
New value of Value function: 9.99444
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 194
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 10.3658
New value of Value function: 10.3658
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 195
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -0.988702
New value of Value function: 6.23107
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 196
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.48145
New value of Value function: 7.48145
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 197
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 5.39268
New value of Value function: 5.39268
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 198
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 12
New value of Q matrix: 6.84319
New value of Value function: 6.84319
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 12.9374
New value of Value function: 12.9374
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 200
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 8.74794
New value of Value function: 8.74794
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 201
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.77476
New value of Value function: 1.77476
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 202
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 13
New value of Q matrix: 7.38814
New value of Value function: 7.38814
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 203
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 12.5316
New value of Value function: 12.5316
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 204
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 14
New value of Q matrix: 7.66025
New value of Value function: 7.66025
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 205
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 12.3017
New value of Value function: 12.3017
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 206
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 15
New value of Q matrix: 7.79411
New value of Value function: 7.79411
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 207
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 12.1637
New value of Value function: 12.1637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 208
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 16
New value of Q matrix: 7.85609
New value of Value function: 7.85609
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 209
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 19
New value of Q matrix: 12.0751
New value of Value function: 12.0751
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 210
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 17
New value of Q matrix: 7.87992
New value of Value function: 7.87992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 211
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 12.0138
New value of Value function: 12.0138
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 212
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 18
New value of Q matrix: 7.88317
New value of Value function: 7.88317
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 213
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 11.9681
New value of Value function: 11.9681
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 214
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 19
New value of Q matrix: 7.8752
New value of Value function: 7.8752
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 215
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 10.6439
New value of Value function: 10.6439
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 216
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.4972
New value of Value function: 2.4972
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 217
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.66047
New value of Value function: 7.8752
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 218
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 9.91665
New value of Value function: 9.91665
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 219
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 20
New value of Q matrix: 7.57607
New value of Value function: 7.57607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 220
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 23
New value of Q matrix: 11.3056
New value of Value function: 11.3056
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 221
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 8.09097
New value of Value function: 9.91665
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 222
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 5.58599
New value of Value function: 5.58599
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 223
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 24
New value of Q matrix: 11.3454
New value of Value function: 11.3454
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 224
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 21
New value of Q matrix: 7.50097
New value of Value function: 7.50097
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 225
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 11.3615
New value of Value function: 11.3615
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 226
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 22
New value of Q matrix: 7.44701
New value of Value function: 7.44701
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 227
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 11.3637
New value of Value function: 11.3637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 228
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 7.25583
New value of Value function: 7.25583
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 229
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.25003
New value of Value function: 6.25003
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 230
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.8831
New value of Value function: 11.3637
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 231
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.20583
New value of Value function: 6.20583
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 232
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 6.23135
New value of Value function: 6.23135
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 233
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 11.3289
New value of Value function: 11.3289
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 234
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 7.23811
New value of Value function: 7.23811
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 235
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 6.35179
New value of Value function: 6.35179
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 236
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 2.37658
New value of Value function: 2.37658
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 237
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 3.57415
New value of Value function: 6.35179
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 238
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.27115
New value of Value function: 2.27115
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 239
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 7.24815
New value of Value function: 7.24815
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 240
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.74725
New value of Value function: 5.74725
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 241
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 242
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 6.68978
New value of Value function: 6.68978
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 243
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.44219
New value of Value function: 5.58599
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 244
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 245
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 246
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 247
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 248
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 249
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 0.216425
New value of Value function: 0.216425
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 250
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.45456
New value of Value function: 5.45456
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 251
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.215607
New value of Value function: 0.215607
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 252
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.214845
New value of Value function: 0.214845
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 253
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.400019
New value of Value function: 0.400019
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 254
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.43505
New value of Value function: 5.44219
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 255
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.391354
New value of Value function: 0.391354
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 256
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.42149
New value of Value function: 5.43505
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 257
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.05216
New value of Value function: 3.05216
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 258
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.97836
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 259
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.15044
New value of Value function: 3.05216
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 260
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.02608
New value of Value function: 4.02608
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 261
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 262
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 263
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 264
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 265
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 266
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 267
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 268
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 269
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 270
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 271
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 272
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 273
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 274
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 275
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 276
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 277
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 278
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 279
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 4.96
New value of Value function: 4.96
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 280
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.96
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 281
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.93664
New value of Value function: 3.96
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 282
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.932
New value of Value function: 4.932
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 283
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.932
New value of Value function: 3.93664
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 284
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 3.90549
New value of Value function: 3.932
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 285
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.9093
New value of Value function: 4.9093
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 286
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.9093
New value of Value function: 3.9093
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 287
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.88975
New value of Value function: 3.90549
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 288
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.44774
New value of Value function: 4.44774
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 289
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.886421
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 290
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 4.18499
New value of Value function: 4.18499
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 291
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.02622
New value of Value function: 5.02622
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 292
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 4.51363
New value of Value function: 4.51363
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 293
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -0.104159
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 294
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.14857
New value of Value function: 4.51363
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 295
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 4.69368
New value of Value function: 4.69368
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 296
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.750212
New value of Value function: 0.750212
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 297
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 4.71102
New value of Value function: 4.71102
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 298
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.20383
New value of Value function: 3.20383
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 299
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 300
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 301
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 302
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 303
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 304
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 305
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.757206
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 306
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.10191
New value of Value function: 4.10191
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 307
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 308
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 3
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.97879
New value of Value function: 2.97879
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.99103
New value of Value function: 2.99103
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 312
----------
State: 4061
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.336094
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 313
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 5.82764
New value of Value function: 5.82764
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 314
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 4.10191
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 315
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.06089
New value of Value function: 6.06089
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 316
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 2.7147
New value of Value function: 2.7147
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 317
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 318
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.36416
New value of Value function: 1.36416
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 319
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.31073
New value of Value function: 5.31073
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 320
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 321
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 322
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 323
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 324
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.257622
New value of Value function: 0.257622
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 325
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.27858
New value of Value function: 5.27858
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 326
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.235116
New value of Value function: 0.235116
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 327
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.25567
New value of Value function: 5.25567
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 328
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.03
New value of Value function: 0.235116
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 329
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.13439
New value of Value function: 3.13439
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 330
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.216641
New value of Value function: 0.216641
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 331
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.23725
New value of Value function: 5.23725
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 332
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.500427
New value of Value function: 0.216641
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 333
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 2.01467
New value of Value function: 2.01467
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 334
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.0388761
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.96112
New value of Value function: 2.99103
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.09383
New value of Value function: 2.99103
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.97608
New value of Value function: 2.97608
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 5.56692
New value of Value function: 5.56692
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 339
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.51125
New value of Value function: 5.82764
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 6.87431
New value of Value function: 6.87431
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 341
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 5.24209
New value of Value function: 5.24209
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 342
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 5.54653
New value of Value function: 5.54653
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 343
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 5.01565
New value of Value function: 5.01565
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 344
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.99453
New value of Value function: 6.99453
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 345
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3.21447
New value of Value function: 3.21447
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 346
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.39168
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 347
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.32312
New value of Value function: 6.32312
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 348
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.14039
New value of Value function: 5.14039
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 349
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.0468125
New value of Value function: 0.0468125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 350
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.11169
New value of Value function: 3.11169
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 351
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.10485
New value of Value function: 5.10485
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 352
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.0636916
New value of Value function: 0.0636916
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 353
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.0858
New value of Value function: 3.0858
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 354
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.09007
New value of Value function: 5.09007
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 355
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 356
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 357
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 358
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.67956
New value of Value function: 2.67956
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 6.41261
New value of Value function: 6.41261
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 360
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.06576
New value of Value function: 3.06576
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 6.96163
New value of Value function: 6.96163
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 362
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 5.64111
New value of Value function: 5.64111
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 363
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.46289
New value of Value function: 4.46289
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 364
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.0597778
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 365
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.05494
New value of Value function: 3.0858
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 366
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.75156
New value of Value function: 3.0858
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 367
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.261
New value of Value function: 2.261
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 368
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 1.90162
New value of Value function: 1.90162
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 369
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.5579
New value of Value function: 6.5579
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 370
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.89295
New value of Value function: 2.89295
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 371
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 5.58452
New value of Value function: 6.5579
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 372
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 2.12488
New value of Value function: 2.12488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 373
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 6.45471
New value of Value function: 6.45471
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 374
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 28
New value of Q matrix: 10.3415
New value of Value function: 10.3415
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 375
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.10363
New value of Value function: 2.12488
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 376
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 2.14284
New value of Value function: 2.14284
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 377
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 7.276
New value of Value function: 7.276
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 378
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 5.09206
New value of Value function: 6.45471
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 379
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 1.50975
New value of Value function: 7.276
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 380
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 6.5416
New value of Value function: 6.5416
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 381
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.78619
New value of Value function: 7.276
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 382
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 27
New value of Q matrix: 7.07624
New value of Value function: 7.07624
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 383
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.22169
New value of Value function: 10.3415
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 384
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 6.10349
New value of Value function: 6.10349
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 385
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 29
New value of Q matrix: 10.4648
New value of Value function: 10.4648
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 386
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 28
New value of Q matrix: 6.94091
New value of Value function: 6.94091
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 387
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 30
New value of Q matrix: 10.539
New value of Value function: 10.539
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 388
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 29
New value of Q matrix: 6.84671
New value of Value function: 6.84671
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 389
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 31
New value of Q matrix: 10.582
New value of Value function: 10.582
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 390
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 30
New value of Q matrix: 6.77906
New value of Value function: 6.77906
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 391
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 10.4628
New value of Value function: 10.582
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 392
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 5.9295
New value of Value function: 5.9295
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 393
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 32
New value of Q matrix: 11.1539
New value of Value function: 11.1539
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 394
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 10.4144
New value of Value function: 10.4144
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 395
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 31
New value of Q matrix: 6.82636
New value of Value function: 6.82636
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 396
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 33
New value of Q matrix: 11.085
New value of Value function: 11.085
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 397
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 32
New value of Q matrix: 6.85249
New value of Value function: 6.85249
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 398
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 34
New value of Q matrix: 11.0334
New value of Value function: 11.0334
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 399
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 33
New value of Q matrix: 6.86478
New value of Value function: 6.86478
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 400
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 35
New value of Q matrix: 10.9933
New value of Value function: 10.9933
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 5.64109
New value of Value function: 5.64109
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 2
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4949
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 3
----------
State: 4949
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 4
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 5
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 6
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 7
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 11
----------
State: 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5061
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 12
----------
State: 5061
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 13
----------
State: 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 14
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 15
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4385
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 4385
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 17
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 18
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 19
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 20
----------
State: 3657
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 21
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4329
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 22
----------
State: 4329
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3545
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 23
----------
State: 3545
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 24
----------
State: 2757
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3541
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 25
----------
State: 3541
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 26
----------
State: 2757
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 27
----------
State: 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 28
----------
State: 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 29
----------
State: 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2021
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 30
----------
State: 2021
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1965
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 31
----------
State: 1965
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1909
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 32
----------
State: 1909
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2022
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 98
New value of Visit matrix: 1
New value of Q matrix: 98
New value of Value function: 98
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 1
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 2
----------
State: 8541
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 3
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 4
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 5
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.58468
New value of Value function: 2.58468
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.62325
New value of Value function: 5.62325
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 6.32479
New value of Value function: 6.32479
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 8
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 9
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.915
New value of Value function: 4.96464
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 10
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.98506
New value of Value function: 4.98506
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 11
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 12
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 13
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 12.377
New value of Value function: 12.377
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 14
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.41274
New value of Value function: 8.41274
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 15
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 8.25321
New value of Value function: 8.41274
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 16
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 12.3428
New value of Value function: 12.3428
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 17
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.32861
New value of Value function: 8.41274
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 18
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 8.22927
New value of Value function: 8.41274
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 19
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 12.3346
New value of Value function: 12.3346
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 20
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.32861
New value of Value function: 8.41274
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 21
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.64073
New value of Value function: 8.64073
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 22
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 4.13569
New value of Value function: 4.13569
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 23
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.41004
New value of Value function: 6.41004
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 24
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.76213
New value of Value function: 6.41004
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 25
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 5.89165
New value of Value function: 5.89165
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 26
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.8327
New value of Value function: 10.8327
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 27
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 7.09555
New value of Value function: 7.09555
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 28
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.54041
New value of Value function: 8.32861
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 29
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 1
New value of Q matrix: 15.0246
New value of Value function: 15.0246
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 30
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 6.75276
New value of Value function: 6.75276
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 31
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.4355
New value of Value function: 11.4355
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 32
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 6.64809
New value of Value function: 6.64809
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 33
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 10.7484
New value of Value function: 10.7484
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 34
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.28053
New value of Value function: 8.28053
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 35
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.23912
New value of Value function: 8.23912
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 36
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.20228
New value of Value function: 8.22927
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 37
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.1797
New value of Value function: 8.22927
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 38
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 8.21887
New value of Value function: 8.21887
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 39
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0647935
New value of Value function: 12.3346
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 40
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.96013
New value of Value function: 4.96013
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 41
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.93795
New value of Value function: 4.93795
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 42
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 0.880799
New value of Value function: 4.915
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 43
----------
State: 10053
	Distance: 12
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 44
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 1
New value of Q matrix: 17.1367
New value of Value function: 17.1367
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 45
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 8.21506
New value of Value function: 8.21506
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 46
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 12.2338
New value of Value function: 12.2338
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 47
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 8.16871
New value of Value function: 8.1797
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 48
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 12.173
New value of Value function: 12.173
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 49
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.14878
New value of Value function: 8.16871
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 50
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 8.05127
New value of Value function: 8.16871
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 51
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 12.1379
New value of Value function: 12.1379
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 52
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 8.10658
New value of Value function: 8.14878
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 53
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.0165
New value of Value function: 12.1379
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 54
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 12.1112
New value of Value function: 12.1112
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 55
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.11997
New value of Value function: 8.11997
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 56
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.09291
New value of Value function: 8.10658
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 57
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 8.07159
New value of Value function: 8.10658
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 58
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 8.06255
New value of Value function: 8.07159
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 59
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.113837
New value of Value function: 12.1112
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 60
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.88024
New value of Value function: 4.88024
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 61
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.85207
New value of Value function: 4.85207
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 62
----------
State: 8485
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 16.9653
New value of Value function: 16.9653
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 63
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 2
New value of Q matrix: 17.0336
New value of Value function: 17.0336
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 64
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 8.61514
New value of Value function: 8.61514
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 65
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 14.0462
New value of Value function: 14.0462
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 66
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 10.6387
New value of Value function: 10.6387
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 67
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 7.96014
New value of Value function: 8.61514
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 68
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.32757
New value of Value function: 7.32757
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 69
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 8.59027
New value of Value function: 8.59027
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 70
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 8.56645
New value of Value function: 8.56645
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 71
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -9
New value of Visit matrix: 2
New value of Q matrix: 7.91832
New value of Value function: 8.56645
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 72
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 3
New value of Q matrix: 14.7593
New value of Value function: 14.7593
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 73
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.33511
New value of Value function: 4.33511
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 74
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 7.55146
New value of Value function: 7.55146
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 75
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 8.54355
New value of Value function: 8.54355
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 76
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 8.5215
New value of Value function: 8.5215
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 77
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 8.71406
New value of Value function: 8.71406
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 78
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 2
New value of Q matrix: 0.942748
New value of Value function: 4.33511
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 79
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 8
New value of Q matrix: 12.5286
New value of Value function: 12.5286
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 80
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 4.80086
New value of Value function: 4.80086
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 81
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -8
New value of Visit matrix: 19
New value of Q matrix: 7.1739
New value of Value function: 7.1739
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 82
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 13.6269
New value of Value function: 14.0462
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 83
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 8.69293
New value of Value function: 8.69293
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 84
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 8.67244
New value of Value function: 8.67244
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 85
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 8.65254
New value of Value function: 8.65254
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 86
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 8.63319
New value of Value function: 8.63319
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 87
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 8.61435
New value of Value function: 8.61435
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 88
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 8.67647
New value of Value function: 8.67647
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 89
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.7495
New value of Value function: 13.7495
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 90
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.2932
New value of Value function: 11.2932
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 91
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 7.9377
New value of Value function: 7.9377
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 92
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 5.01912
New value of Value function: 8.67647
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 93
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 13.9649
New value of Value function: 13.9649
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 94
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.9321
New value of Value function: 11.9321
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 95
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 10.5897
New value of Value function: 10.5897
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 96
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 8.65838
New value of Value function: 8.65838
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 97
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 8.6407
New value of Value function: 8.6407
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 98
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 8.62342
New value of Value function: 8.62342
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 99
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 8.60651
New value of Value function: 8.60651
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 100
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 8.58995
New value of Value function: 8.58995
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 101
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 8.57371
New value of Value function: 8.57371
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 102
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 8.55779
New value of Value function: 8.55779
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 103
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 8.54217
New value of Value function: 8.54217
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 104
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 8.52683
New value of Value function: 8.52683
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 105
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 8.51175
New value of Value function: 8.51175
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 106
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 8.49694
New value of Value function: 8.49694
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 107
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.20333
New value of Value function: 8.49694
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 108
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 8.48236
New value of Value function: 8.48236
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 109
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 6.45769
New value of Value function: 8.48236
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 110
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 14.3441
New value of Value function: 14.3441
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 111
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 13.2745
New value of Value function: 13.2745
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 112
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 10.5897
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 113
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.21371
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 114
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 3
New value of Q matrix: 5.45761
New value of Value function: 5.45761
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 115
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 14.0556
New value of Value function: 14.0556
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 116
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 2
New value of Q matrix: 7.48617
New value of Value function: 7.9377
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 117
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 13.4033
New value of Value function: 14.3441
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 118
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 12.4849
New value of Value function: 12.4849
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 119
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 8.46803
New value of Value function: 8.46803
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 120
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 8.45391
New value of Value function: 8.45391
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 121
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 7.42747
New value of Value function: 8.45391
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 122
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 15.3937
New value of Value function: 15.3937
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 123
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.4669
New value of Value function: 14.0556
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 124
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 7.67031
New value of Value function: 7.67031
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 125
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.0562
New value of Value function: 2.0562
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 126
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 7.93569
New value of Value function: 7.93569
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 127
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 12.8269
New value of Value function: 12.8269
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 128
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 8.44002
New value of Value function: 8.44002
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 129
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 8.65298
New value of Value function: 8.65298
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 130
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 10.2397
New value of Value function: 10.2397
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 131
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 7
New value of Q matrix: 15.5686
New value of Value function: 15.5686
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 132
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.69246
New value of Value function: 7.93569
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 133
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 4
New value of Q matrix: -0.899943
New value of Value function: 2.0562
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 134
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 8.63913
New value of Value function: 8.63913
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 135
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 8.62547
New value of Value function: 8.62547
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 136
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 8.612
New value of Value function: 8.612
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 137
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 8.59871
New value of Value function: 8.59871
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 138
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 8.5856
New value of Value function: 8.5856
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 139
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.6703
New value of Value function: 11.6703
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 140
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 3
New value of Q matrix: 3.63835
New value of Value function: 10.2397
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 141
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 17.0861
New value of Value function: 17.0861
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 142
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 15.6145
New value of Value function: 15.6145
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 143
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 12.8362
New value of Value function: 12.8362
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 144
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.0857125
New value of Value function: 7.93569
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 145
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 16.8834
New value of Value function: 16.8834
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 146
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 36
New value of Q matrix: 11.5461
New value of Value function: 11.5461
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 147
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 10.7837
New value of Value function: 10.7837
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 148
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.99297
New value of Value function: 6.86478
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 149
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.65628
New value of Value function: 6.5416
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 150
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.99132
New value of Value function: 8.99132
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 151
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 6.86903
New value of Value function: 6.86903
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 152
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 10.5298
New value of Value function: 10.5298
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 153
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 7.02308
New value of Value function: 7.02308
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 154
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 10.8464
New value of Value function: 10.8464
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 155
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 34
New value of Q matrix: 6.86571
New value of Value function: 6.86571
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 156
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 6.06344
New value of Value function: 6.06344
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 157
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 11.4307
New value of Value function: 11.5461
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 158
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 37
New value of Q matrix: 11.423
New value of Value function: 11.4307
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 159
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 5.76205
New value of Value function: 6.86571
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 160
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 11.0769
New value of Value function: 11.0769
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 161
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 5.29084
New value of Value function: 6.86571
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 162
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 11.2467
New value of Value function: 11.2467
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 163
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 35
New value of Q matrix: 6.94188
New value of Value function: 6.94188
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 164
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.3498
New value of Value function: 11.423
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 165
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 38
New value of Q matrix: 11.3337
New value of Value function: 11.3498
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 166
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 36
New value of Q matrix: 6.99096
New value of Value function: 6.99096
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 167
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 11.2843
New value of Value function: 11.3337
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 168
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 39
New value of Q matrix: 11.2676
New value of Value function: 11.2843
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 169
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 37
New value of Q matrix: 7.02063
New value of Value function: 7.02063
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 170
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.2279
New value of Value function: 11.2676
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 171
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 40
New value of Q matrix: 11.2174
New value of Value function: 11.2279
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 172
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 38
New value of Q matrix: 7.03604
New value of Value function: 7.03604
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 173
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 11.1777
New value of Value function: 11.2174
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 174
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 41
New value of Q matrix: 11.1781
New value of Value function: 11.1781
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 175
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 39
New value of Q matrix: 7.04089
New value of Value function: 7.04089
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 176
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 42
New value of Q matrix: 11.1461
New value of Value function: 11.1777
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 177
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 40
New value of Q matrix: 7.04484
New value of Value function: 7.04484
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 178
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.7043
New value of Value function: 11.1777
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 179
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 6.06407
New value of Value function: 6.06407
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 180
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 10.1126
New value of Value function: 11.1777
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 181
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 5.71448
New value of Value function: 6.06407
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 182
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 41
New value of Q matrix: 7.03838
New value of Value function: 7.03838
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 183
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.66844
New value of Value function: 6.06407
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 184
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.403033
New value of Value function: 6.68978
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 185
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.51574
New value of Value function: 5.45761
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 186
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 5.24662
New value of Value function: 5.24662
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 187
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.68424
New value of Value function: 2.0562
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 188
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 2.33909
New value of Value function: 2.33909
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 189
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 7.80642
New value of Value function: 7.80642
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 190
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.46885
New value of Value function: 2.46885
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 191
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 7.73247
New value of Value function: 7.73247
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 192
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 2.52776
New value of Value function: 2.52776
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 193
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 7.68647
New value of Value function: 7.68647
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 194
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.52014
New value of Value function: 2.52014
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 195
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.14693
New value of Value function: 2.52014
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 196
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 26
New value of Q matrix: 7.69066
New value of Value function: 7.69066
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 197
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 12.7691
New value of Value function: 12.7691
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 198
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 10.9892
New value of Value function: 10.9892
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 199
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 9
New value of Q matrix: 7.94516
New value of Value function: 11.6703
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 200
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 5
New value of Q matrix: 18.0034
New value of Value function: 18.0034
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 201
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.1673
New value of Value function: 10.1673
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 202
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 8.08097
New value of Value function: 8.08097
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 203
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.28503
New value of Value function: 11.6703
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 204
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 7.3173
New value of Value function: 7.3173
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 205
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 11.1283
New value of Value function: 11.1283
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 206
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 15.6235
New value of Value function: 15.6235
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 207
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.6414
New value of Value function: 12.7691
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 208
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 12.682
New value of Value function: 12.682
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 209
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 10
New value of Q matrix: 16.6531
New value of Value function: 16.6531
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 210
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 4
New value of Q matrix: 9.73789
New value of Value function: 9.73789
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 211
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 11
New value of Q matrix: 16.9508
New value of Value function: 16.9508
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 212
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 11.2044
New value of Value function: 11.2044
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 213
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 11.3949
New value of Value function: 11.3949
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 214
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 16.5479
New value of Value function: 16.5479
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 215
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 12.5804
New value of Value function: 12.682
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 216
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 12.1942
New value of Value function: 12.682
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 217
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 6.96648
New value of Value function: 6.96648
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 218
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 6
New value of Q matrix: 10.0523
New value of Value function: 10.0523
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 219
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 16.2726
New value of Value function: 16.2726
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 220
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.2093
New value of Value function: 13.2093
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 221
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 11.2726
New value of Value function: 11.2726
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 222
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 11.2872
New value of Value function: 11.2872
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 223
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 13.3727
New value of Value function: 16.2726
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 224
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 13.315
New value of Value function: 13.315
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 225
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 16.1099
New value of Value function: 16.2726
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 226
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 16.2204
New value of Value function: 16.2204
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 227
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 14.5289
New value of Value function: 14.5289
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 228
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 11.945
New value of Value function: 11.945
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 229
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 10
New value of Q matrix: 8.22288
New value of Value function: 11.2872
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 230
----------
State: 9997
	Distance: 12
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 6
New value of Q matrix: 18.8897
New value of Value function: 18.8897
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 231
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 11.2062
New value of Value function: 11.2062
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 232
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 15
New value of Q matrix: 17.1512
New value of Value function: 17.1512
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 233
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 9
New value of Q matrix: 10.9566
New value of Value function: 10.9566
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 234
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 16
New value of Q matrix: 17.5752
New value of Value function: 17.5752
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 235
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.6325
New value of Value function: 11.6325
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 236
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 11.1689
New value of Value function: 11.1689
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 237
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 11.558
New value of Value function: 11.558
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 238
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 17.5287
New value of Value function: 17.5287
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 239
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 15.3402
New value of Value function: 15.3402
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 240
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 12.1782
New value of Value function: 12.1782
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 241
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 11.7978
New value of Value function: 11.7978
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 242
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.2441
New value of Value function: 17.5287
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 243
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.24413
New value of Value function: 7.3173
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 244
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 7.03222
New value of Value function: 7.24413
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 245
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 11.7638
New value of Value function: 11.7638
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 246
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 11.7311
New value of Value function: 11.7311
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 247
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 11.8974
New value of Value function: 11.8974
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 248
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 18
New value of Q matrix: 18.1245
New value of Value function: 18.1245
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 249
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 12.6402
New value of Value function: 12.6402
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 250
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 11.8667
New value of Value function: 11.8667
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 251
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 12.1359
New value of Value function: 12.1359
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 252
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 18.1388
New value of Value function: 18.1388
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 253
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 16.1617
New value of Value function: 16.1617
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 254
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 13
New value of Q matrix: 11.8961
New value of Value function: 11.8961
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 255
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 20
New value of Q matrix: 18.5051
New value of Value function: 18.5051
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 256
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 14
New value of Q matrix: 11.4749
New value of Value function: 11.4749
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 257
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 12.5979
New value of Value function: 18.5051
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 258
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 6.52411
New value of Value function: 7.24413
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 259
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 10.8802
New value of Value function: 10.8802
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 260
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.19291
New value of Value function: 7.19291
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 261
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.15138
New value of Value function: 7.15138
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 262
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.11562
New value of Value function: 7.11562
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 263
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 7.0704
New value of Value function: 7.0704
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 264
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 12.4231
New value of Value function: 12.4231
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 265
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 18.6131
New value of Value function: 18.6131
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 266
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 16.8048
New value of Value function: 16.8048
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 267
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 17.0124
New value of Value function: 17.0124
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 268
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 11.132
New value of Value function: 11.1461
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 269
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 43
New value of Q matrix: 11.7543
New value of Value function: 11.7543
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 270
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 9.40312
New value of Value function: 9.40312
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 271
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 10.8448
New value of Value function: 10.8448
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 272
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.79338
New value of Value function: 9.79338
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 273
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 5.38338
New value of Value function: 5.38338
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 274
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 10.5132
New value of Value function: 10.5132
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 275
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 7.54288
New value of Value function: 7.54288
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 276
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 42
New value of Q matrix: 7.1307
New value of Value function: 7.1307
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 277
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 44
New value of Q matrix: 11.6495
New value of Value function: 11.6495
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 278
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 43
New value of Q matrix: 7.19206
New value of Value function: 7.19206
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 279
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 45
New value of Q matrix: 11.5706
New value of Value function: 11.5706
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 280
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.34699
New value of Value function: 7.19206
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 281
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 44
New value of Q matrix: 7.16362
New value of Value function: 7.16362
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 282
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 6.16178
New value of Value function: 6.16178
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 283
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 46
New value of Q matrix: 11.8269
New value of Value function: 11.8269
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 284
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 10.0044
New value of Value function: 10.0044
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 285
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 45
New value of Q matrix: 7.15416
New value of Value function: 7.15416
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 286
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.10016
New value of Value function: 6.16178
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 287
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 6.29442
New value of Value function: 6.29442
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 288
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 47
New value of Q matrix: 12.1299
New value of Value function: 12.1299
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 289
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 9.98254
New value of Value function: 9.98254
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 290
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 6
New value of Q matrix: 9.78132
New value of Value function: 9.98254
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 291
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: 2.06824
New value of Value function: 6.29442
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 292
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.68308
New value of Value function: 9.68308
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 293
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 7.07281
New value of Value function: 7.07281
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 294
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 6.46276
New value of Value function: 6.46276
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 295
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 48
New value of Q matrix: 11.2627
New value of Value function: 11.2627
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 296
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.12276
New value of Value function: 2.12276
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 297
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 46
New value of Q matrix: 7.15356
New value of Value function: 7.15356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 298
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 11.1388
New value of Value function: 11.2627
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 299
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 49
New value of Q matrix: 11.637
New value of Value function: 11.637
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 300
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 9.36831
New value of Value function: 9.78132
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 301
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 2.10988
New value of Value function: 2.10988
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 302
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.08202
New value of Value function: 7.15356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 303
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 5.51525
New value of Value function: 7.15356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 304
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 8.92685
New value of Value function: 9.36831
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 305
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.6875
New value of Value function: 11.637
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 306
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 4
New value of Q matrix: 2.82725
New value of Value function: 6.46276
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 307
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.022
New value of Value function: 11.022
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 308
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 7.26064
New value of Value function: 7.26064
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 309
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.44793
New value of Value function: 6.44793
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 310
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.30048
New value of Value function: 6.44793
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 311
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 5.9694
New value of Value function: 6.44793
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 312
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 50
New value of Q matrix: 11.8686
New value of Value function: 11.8686
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 313
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 9.34877
New value of Value function: 9.34877
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 314
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 8.51073
New value of Value function: 9.34877
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 315
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 51
New value of Q matrix: 11.7584
New value of Value function: 11.7584
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 316
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.08202
New value of Value function: 7.15356
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 317
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 47
New value of Q matrix: 7.18709
New value of Value function: 7.18709
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 318
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 6.49107
New value of Value function: 6.49107
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 319
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 52
New value of Q matrix: 10.9722
New value of Value function: 11.1388
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 320
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 2.11149
New value of Value function: 2.11149
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 321
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 48
New value of Q matrix: 7.16405
New value of Value function: 7.16405
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 322
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 11.0995
New value of Value function: 11.0995
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 323
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.999
New value of Value function: 11.0995
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 324
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 6.10712
New value of Value function: 6.49107
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 325
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 6.3814
New value of Value function: 6.3814
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 326
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 11.0625
New value of Value function: 11.0625
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 327
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 11.0275
New value of Value function: 11.0275
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 328
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 10.9942
New value of Value function: 10.999
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 329
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 10.9574
New value of Value function: 10.9942
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 330
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 10.9625
New value of Value function: 10.9722
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 331
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 53
New value of Q matrix: 10.9887
New value of Value function: 10.9887
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 332
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 49
New value of Q matrix: 7.1233
New value of Value function: 7.1233
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 333
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 54
New value of Q matrix: 10.3221
New value of Value function: 10.9625
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 334
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 2.09434
New value of Value function: 2.10363
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 335
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 50
New value of Q matrix: 7.15078
New value of Value function: 7.15078
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 336
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 6.26871
New value of Value function: 6.30048
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 337
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 10.9321
New value of Value function: 10.9574
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 338
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.0564
New value of Value function: 11.0564
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 339
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.2641
New value of Value function: 6.26871
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 340
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 4.33023
New value of Value function: 6.26871
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 341
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 7.23333
New value of Value function: 7.23333
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 342
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 5.07764
New value of Value function: 6.26871
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 343
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 7.22112
New value of Value function: 7.22112
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 344
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 6.2014
New value of Value function: 6.2641
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 345
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.1048
New value of Value function: 11.1048
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 346
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.23278
New value of Value function: 6.23278
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 347
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.20491
New value of Value function: 6.20491
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 348
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.17958
New value of Value function: 6.2014
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 349
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 6.15901
New value of Value function: 6.17958
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 350
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.1089
New value of Value function: 11.1089
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 351
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.15622
New value of Value function: 6.15901
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 352
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 6.12677
New value of Value function: 6.15622
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 353
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 55
New value of Q matrix: 10.7176
New value of Value function: 11.1089
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 354
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 9.90613
New value of Value function: 9.90613
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 355
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 51
New value of Q matrix: 7.14292
New value of Value function: 7.14292
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 356
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.13446
New value of Value function: 6.13446
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 357
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.11401
New value of Value function: 6.12677
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 358
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 26
New value of Q matrix: 6.10147
New value of Value function: 6.11401
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 359
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 11.092
New value of Value function: 11.092
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 360
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.09467
New value of Value function: 6.10712
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 361
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.08949
New value of Value function: 6.10147
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 362
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 6.08973
New value of Value function: 6.09467
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 363
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 28
New value of Q matrix: 6.0692
New value of Value function: 6.09467
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 364
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 11.0752
New value of Value function: 11.0752
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 365
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 6.0763
New value of Value function: 6.08949
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 366
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 6.0845
New value of Value function: 6.0845
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 367
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 52
New value of Q matrix: 7.12638
New value of Value function: 7.12638
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 368
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.06823
New value of Value function: 6.0763
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 369
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.05876
New value of Value function: 6.0692
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 370
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 6.05793
New value of Value function: 6.06823
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 371
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.05257
New value of Value function: 6.05876
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 372
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.04195
New value of Value function: 6.05793
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 373
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 5.57359
New value of Value function: 6.05793
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 374
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.06649
New value of Value function: 7.12638
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 375
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.35262
New value of Value function: 7.12638
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 376
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.08876
New value of Value function: 2.09434
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 377
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 2.08346
New value of Value function: 2.08876
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 378
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 53
New value of Q matrix: 7.10866
New value of Value function: 7.10866
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 379
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 30
New value of Q matrix: 6.04086
New value of Value function: 6.05257
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 380
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 11.0521
New value of Value function: 11.0521
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 381
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 5.48254
New value of Value function: 6.05257
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 382
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 7.1276
New value of Value function: 7.1276
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 383
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.02861
New value of Value function: 6.05257
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 384
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 6.03744
New value of Value function: 6.04086
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 385
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 31
New value of Q matrix: 6.02303
New value of Value function: 6.03744
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 386
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.8057
New value of Value function: 11.0521
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 387
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 6.02279
New value of Value function: 6.02861
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 388
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.01305
New value of Value function: 6.02303
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 389
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 32
New value of Q matrix: 6.00863
New value of Value function: 6.02279
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 390
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 11.0282
New value of Value function: 11.0282
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 391
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 6.03342
New value of Value function: 6.03342
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 392
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.0767
New value of Value function: 2.08346
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 393
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 2.07119
New value of Value function: 2.0767
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 394
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 54
New value of Q matrix: 7.09021
New value of Value function: 7.09021
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 395
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.01958
New value of Value function: 6.01958
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 396
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 6.00612
New value of Value function: 6.01305
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 397
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.99801
New value of Value function: 6.00863
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 398
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.99817
New value of Value function: 6.00612
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 399
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.99301
New value of Value function: 5.99817
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 400
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.98789
New value of Value function: 5.99801
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 1
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.92542
New value of Value function: 3.92542
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 2
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 7.92409
New value of Value function: 7.92409
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 3
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 55
New value of Q matrix: 7.06969
New value of Value function: 7.06969
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 4
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.98347
New value of Value function: 5.99301
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 5
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 6.39191
New value of Value function: 6.39191
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 6
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 2.14299
New value of Value function: 2.14299
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 7
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.06632
New value of Value function: 2.07119
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 8
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.05494
New value of Value function: 8.05494
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 9
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.2973
New value of Value function: 3.0858
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 10
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.05494
New value of Value function: 8.05494
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 11
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.05494
New value of Value function: 3.0858
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 12
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 3.06676
New value of Value function: 3.06676
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 13
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.72005
New value of Value function: 5.72005
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 14
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 15
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 16
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.64948
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 17
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.69131
New value of Value function: 2.69131
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 18
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.11848
New value of Value function: 6.11848
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 19
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 20
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 21
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 22
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 23
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 24
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 25
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.85386
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 26
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.16365
New value of Value function: 3.16365
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 6.32479
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 28
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 29
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 30
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 31
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 32
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.72043
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 33
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.3743
New value of Value function: 3.3743
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 34
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.37824
New value of Value function: 6.37824
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 35
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 36
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 37
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 38
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 39
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 40
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 41
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -1.28466
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 42
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.20743
New value of Value function: 3.20743
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 6.28165
New value of Value function: 6.28165
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 44
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 3.21209
New value of Value function: 3.21209
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 6.9204
New value of Value function: 6.9204
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 46
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 6.41136
New value of Value function: 6.41136
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 47
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 4.37719
New value of Value function: 4.37719
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 48
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 6.3653
New value of Value function: 6.3653
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 49
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 4.33942
New value of Value function: 4.33942
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 50
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.97439
New value of Value function: 6.3653
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 51
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 3.61132
New value of Value function: 8.05494
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 52
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 53
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 54
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 55
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 56
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 57
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 58
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 59
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4169
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 60
----------
State: 4169
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 61
----------
State: 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4169
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 62
----------
State: 4169
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.47982
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 63
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: -1.05235
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 64
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 3.45365
New value of Value function: 3.45365
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.8405
New value of Value function: 6.9204
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.71442
New value of Value function: 6.9204
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.90191
New value of Value function: 6.90191
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 7.53329
New value of Value function: 7.53329
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 69
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.45796
New value of Value function: 6.41136
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 7.98678
New value of Value function: 7.98678
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 71
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 6.28126
New value of Value function: 6.28126
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 72
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 7.15286
New value of Value function: 7.15286
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 73
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 6.22964
New value of Value function: 6.22964
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 74
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.39022
New value of Value function: 8.39022
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 75
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 2.92347
New value of Value function: 4.33942
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 76
----------
State: 4057
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 3.96745
New value of Value function: 3.96745
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.45832
New value of Value function: 7.98678
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 7.96741
New value of Value function: 7.96741
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 8.25024
New value of Value function: 8.25024
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 80
----------
State: 4845
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 6.74624
New value of Value function: 6.74624
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 81
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.24229
New value of Value function: 3.24229
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 82
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 10.3063
New value of Value function: 10.3063
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 83
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 8.20325
New value of Value function: 8.39022
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 84
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 10.3063
New value of Value function: 10.3063
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 85
----------
State: 5685
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.30004
New value of Value function: 8.30004
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 86
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.20987
New value of Value function: 3.24229
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 87
----------
State: 4901
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 3.95171
New value of Value function: 3.95171
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 88
----------
State: 4957
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 2.62061
New value of Value function: 2.62061
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 89
----------
State: 4113
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.35218
New value of Value function: 2.35218
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 90
----------
State: 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 91
----------
State: 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.30165
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 92
----------
State: 5741
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 7.35952
New value of Value function: 7.35952
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 93
----------
State: 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.7461
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 94
----------
State: 5797
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 4.98
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 95
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 96
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 97
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 98
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.87844
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 99
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.45754
New value of Value function: 2.14299
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 100
----------
State: 6637
	Distance: 8
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.22284
New value of Value function: 3.22284
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 101
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 102
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 103
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 104
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 105
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 106
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5965
	Distance: 7
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 107
----------
State: 5965
	Distance: 7
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6021
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 108
----------
State: 6021
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5293
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 109
----------
State: 5293
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4505
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 110
----------
State: 4505
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4505
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 111
----------
State: 4505
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4561
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 112
----------
State: 4561
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4561
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 113
----------
State: 4561
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 114
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.16773
New value of Value function: 5.16773
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 8.21945
New value of Value function: 8.21945
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 116
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.14618
New value of Value function: 5.14618
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 8.19156
New value of Value function: 8.19156
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 118
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.12509
New value of Value function: 5.12509
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 8.16587
New value of Value function: 8.16587
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 120
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.08421
New value of Value function: 5.12509
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 8.14625
New value of Value function: 8.14625
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 122
----------
State: 4617
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.09494
New value of Value function: 5.09494
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5405
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 7.07318
New value of Value function: 7.07318
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 124
----------
State: 5405
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.00245
New value of Value function: 4.00245
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.77248
New value of Value function: 7.07318
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 7.05874
New value of Value function: 7.05874
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5405
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 7.03948
New value of Value function: 7.03948
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 128
----------
State: 5405
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5405
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.96243
New value of Value function: 4.00245
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 129
----------
State: 5405
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.97886
New value of Value function: 3.97886
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.90479
New value of Value function: 7.03948
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 6.24727
New value of Value function: 6.77248
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 132
----------
State: 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.70475
New value of Value function: 3.70475
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.73861
New value of Value function: 6.73861
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.70848
New value of Value function: 6.70848
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 6.32312
New value of Value function: 6.70848
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.68109
New value of Value function: 6.68109
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.55568
New value of Value function: 6.68109
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.65584
New value of Value function: 6.65584
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.63231
New value of Value function: 6.63231
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.6102
New value of Value function: 6.6102
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.5893
New value of Value function: 6.5893
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 6.56943
New value of Value function: 6.56943
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.17013
New value of Value function: 6.56943
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.55046
New value of Value function: 6.55046
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 6.35371
New value of Value function: 6.55046
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.5323
New value of Value function: 6.5323
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.51484
New value of Value function: 6.51484
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.49802
New value of Value function: 6.49802
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 6.48177
New value of Value function: 6.48177
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.13384
New value of Value function: 6.48177
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 6.36545
New value of Value function: 6.48177
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 6.46605
New value of Value function: 6.46605
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 6.45081
New value of Value function: 6.45081
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.43601
New value of Value function: 6.43601
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 6.42162
New value of Value function: 6.42162
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.22511
New value of Value function: 6.42162
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 6.40761
New value of Value function: 6.40761
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.39395
New value of Value function: 6.39395
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.38061
New value of Value function: 6.38061
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 6.36759
New value of Value function: 6.36759
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 6.35485
New value of Value function: 6.36545
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 6.34445
New value of Value function: 6.36545
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 6.35383
New value of Value function: 6.35383
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 6.34242
New value of Value function: 6.34445
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 6.33224
New value of Value function: 6.34242
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 6.33121
New value of Value function: 6.33224
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 6.32027
New value of Value function: 6.33121
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 6.32018
New value of Value function: 6.32027
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 6.30853
New value of Value function: 6.32018
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 6.30935
New value of Value function: 6.30935
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 6.29868
New value of Value function: 6.30853
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 6.29702
New value of Value function: 6.29868
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 6.28818
New value of Value function: 6.29702
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 6.28571
New value of Value function: 6.28818
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 6.27503
New value of Value function: 6.28818
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 6.27785
New value of Value function: 6.27785
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 6.26766
New value of Value function: 6.27503
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.22026
New value of Value function: 6.27503
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.93477
New value of Value function: 6.27503
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.19121
New value of Value function: 6.27503
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.07352
New value of Value function: 6.27503
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 6.26411
New value of Value function: 6.26766
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 6.25762
New value of Value function: 6.26411
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 6.25336
New value of Value function: 6.25762
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 6.24773
New value of Value function: 6.25336
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 6.24279
New value of Value function: 6.24773
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 6.23797
New value of Value function: 6.24279
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 6.22908
New value of Value function: 6.24279
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 6.23239
New value of Value function: 6.23239
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.20251
New value of Value function: 6.23239
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 6.22214
New value of Value function: 6.22908
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 6.21958
New value of Value function: 6.22214
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 6.21059
New value of Value function: 6.22214
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.17721
New value of Value function: 6.22214
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 6.21205
New value of Value function: 6.21205
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 6.2021
New value of Value function: 6.21059
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.16549
New value of Value function: 6.21059
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 6.20133
New value of Value function: 6.20251
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.18184
New value of Value function: 6.2021
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.16863
New value of Value function: 6.2021
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 6.19229
New value of Value function: 6.20133
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 6.19219
New value of Value function: 6.19229
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 6.18262
New value of Value function: 6.19219
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 6.18316
New value of Value function: 6.18316
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 6.17423
New value of Value function: 6.18262
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 6.17308
New value of Value function: 6.17423
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 6.16541
New value of Value function: 6.17308
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.09044
New value of Value function: 6.17308
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.14503
New value of Value function: 6.17308
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 6.15136
New value of Value function: 6.17308
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 6.16367
New value of Value function: 6.16541
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 6.15669
New value of Value function: 6.16367
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 6.15438
New value of Value function: 6.15669
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 6.14807
New value of Value function: 6.15438
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.13447
New value of Value function: 6.15438
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 6.1452
New value of Value function: 6.14807
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 6.13955
New value of Value function: 6.1452
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 6.13614
New value of Value function: 6.14503
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.1233
New value of Value function: 6.13955
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 6.13111
New value of Value function: 6.13614
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 6.12719
New value of Value function: 6.13447
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.11745
New value of Value function: 6.13111
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.10472
New value of Value function: 6.13111
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 6.12277
New value of Value function: 6.12719
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.0947
New value of Value function: 6.12719
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 6.0875
New value of Value function: 6.12719
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 6.11835
New value of Value function: 6.1233
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.10289
New value of Value function: 6.12277
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 6.11451
New value of Value function: 6.11835
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 6.10685
New value of Value function: 6.11835
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 6.10961
New value of Value function: 6.10961
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.07332
New value of Value function: 6.10961
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 6.10097
New value of Value function: 6.10685
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 6.09876
New value of Value function: 6.10289
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.08359
New value of Value function: 6.10097
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 6.09242
New value of Value function: 6.09876
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 6.09075
New value of Value function: 6.09242
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 6.08398
New value of Value function: 6.09075
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 6.08282
New value of Value function: 6.0875
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 6.07274
New value of Value function: 6.08398
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 6.07562
New value of Value function: 6.08359
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 6.07507
New value of Value function: 6.08359
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 6.06837
New value of Value function: 6.08359
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6133
	Distance: 7
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 5.15385
New value of Value function: 6.07562
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 245
----------
State: 6133
	Distance: 7
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -2.3323
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 246
----------
State: 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.21693
New value of Value function: 3.21693
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 6.06735
New value of Value function: 6.07332
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.05037
New value of Value function: 6.07274
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 6.05843
New value of Value function: 6.06837
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 6.06066
New value of Value function: 6.06735
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.04655
New value of Value function: 6.06735
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 6.05917
New value of Value function: 6.06066
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 6.05127
New value of Value function: 6.06066
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.03258
New value of Value function: 6.06066
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 6.05303
New value of Value function: 6.05303
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.39595
New value of Value function: 6.05303
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.5614
New value of Value function: 6.05303
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 6.04546
New value of Value function: 6.05127
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 6.06274
New value of Value function: 6.06274
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 260
----------
State: 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.0929
New value of Value function: 3.0929
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 6.05528
New value of Value function: 6.05528
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 5.68201
New value of Value function: 6.05127
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 263
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.06197
New value of Value function: 8.06197
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 264
----------
State: 6189
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 3.04183
New value of Value function: 3.04183
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 6.04326
New value of Value function: 6.04655
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 6.03303
New value of Value function: 6.04326
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 6.03532
New value of Value function: 6.03532
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.71754
New value of Value function: 6.03532
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 6.02746
New value of Value function: 6.03303
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 6.01987
New value of Value function: 6.03258
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.01247
New value of Value function: 6.02746
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 6.01968
New value of Value function: 6.01987
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 6.012
New value of Value function: 6.01987
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.00703
New value of Value function: 6.01247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.74581
New value of Value function: 6.01247
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.99346
New value of Value function: 6.012
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 6.00436
New value of Value function: 6.00703
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.76985
New value of Value function: 6.00703
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.99451
New value of Value function: 6.00436
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.9968
New value of Value function: 5.9968
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.98274
New value of Value function: 5.9968
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.9893
New value of Value function: 5.99346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.97289
New value of Value function: 5.99346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.96517
New value of Value function: 5.99346
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.97539
New value of Value function: 5.9893
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.95829
New value of Value function: 5.9893
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.78879
New value of Value function: 5.9893
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.98187
New value of Value function: 5.98187
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.65779
New value of Value function: 5.98187
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.97451
New value of Value function: 5.97539
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.95814
New value of Value function: 5.97451
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.72414
New value of Value function: 5.97451
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.96721
New value of Value function: 5.96721
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.80278
New value of Value function: 5.96721
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.95997
New value of Value function: 5.95997
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.9528
New value of Value function: 5.95829
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.94703
New value of Value function: 5.95814
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.93803
New value of Value function: 5.95814
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.94161
New value of Value function: 5.9528
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.94568
New value of Value function: 5.94568
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.93863
New value of Value function: 5.94161
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.92573
New value of Value function: 5.93863
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.93163
New value of Value function: 5.93803
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.92719
New value of Value function: 5.93163
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.92469
New value of Value function: 5.92719
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.91654
New value of Value function: 5.92573
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.91043
New value of Value function: 5.92469
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.89919
New value of Value function: 5.92469
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.9178
New value of Value function: 5.9178
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.91097
New value of Value function: 5.91654
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.80917
New value of Value function: 5.91654
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.90608
New value of Value function: 5.91097
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.90419
New value of Value function: 5.90608
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.8958
New value of Value function: 5.90419
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.89746
New value of Value function: 5.89919
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.88488
New value of Value function: 5.89746
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.89078
New value of Value function: 5.8958
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.88569
New value of Value function: 5.89078
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.88415
New value of Value function: 5.88569
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.8712
New value of Value function: 5.88569
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.87574
New value of Value function: 5.88415
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.87757
New value of Value function: 5.87757
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.87104
New value of Value function: 5.87574
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.86595
New value of Value function: 5.8712
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.74623
New value of Value function: 5.8712
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 5.7623
New value of Value function: 5.8712
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.80956
New value of Value function: 5.8712
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.86458
New value of Value function: 5.8712
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.85773
New value of Value function: 5.86595
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.85631
New value of Value function: 5.86458
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.85814
New value of Value function: 5.85814
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.85175
New value of Value function: 5.85773
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.84463
New value of Value function: 5.85631
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.8468
New value of Value function: 5.85175
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.8454
New value of Value function: 5.8468
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.83744
New value of Value function: 5.8454
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.8391
New value of Value function: 5.84463
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.83187
New value of Value function: 5.8391
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.83284
New value of Value function: 5.83744
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.80604
New value of Value function: 5.83744
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.82821
New value of Value function: 5.83284
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.82662
New value of Value function: 5.83187
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.81944
New value of Value function: 5.82821
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.81911
New value of Value function: 5.82662
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.80879
New value of Value function: 5.82662
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 5.80053
New value of Value function: 5.82662
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.82044
New value of Value function: 5.82044
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.81431
New value of Value function: 5.81911
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.81013
New value of Value function: 5.81431
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.8019
New value of Value function: 5.81431
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.80821
New value of Value function: 5.80821
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.80216
New value of Value function: 5.80604
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.79938
New value of Value function: 5.80216
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.79614
New value of Value function: 5.8019
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.79315
New value of Value function: 5.80053
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.78893
New value of Value function: 5.79938
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.78544
New value of Value function: 5.79938
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.79277
New value of Value function: 5.79614
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 5.75661
New value of Value function: 5.79614
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.79016
New value of Value function: 5.79277
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.78621
New value of Value function: 5.79016
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.78422
New value of Value function: 5.78893
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.77879
New value of Value function: 5.78893
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.77758
New value of Value function: 5.78621
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.7797
New value of Value function: 5.78544
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.77691
New value of Value function: 5.7797
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.77302
New value of Value function: 5.7797
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.77324
New value of Value function: 5.77758
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.76646
New value of Value function: 5.77691
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 5.74801
New value of Value function: 5.77691
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 5.74156
New value of Value function: 5.77691
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.76848
New value of Value function: 5.77324
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.76083
New value of Value function: 5.77324
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 5.73587
New value of Value function: 5.77324
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.75436
New value of Value function: 5.77324
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.76682
New value of Value function: 5.77302
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.76719
New value of Value function: 5.76719
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.76139
New value of Value function: 5.76682
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.76045
New value of Value function: 5.76646
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.75556
New value of Value function: 5.76139
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.75563
New value of Value function: 5.76045
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.75413
New value of Value function: 5.75563
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.7499
New value of Value function: 5.75556
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.74488
New value of Value function: 5.75436
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.74788
New value of Value function: 5.75436
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.7361
New value of Value function: 5.75436
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.74465
New value of Value function: 5.75436
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 5.72755
New value of Value function: 5.75436
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.73993
New value of Value function: 5.75436
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.74622
New value of Value function: 5.74788
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.74164
New value of Value function: 5.74622
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.7276
New value of Value function: 5.74622
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.73817
New value of Value function: 5.74164
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.73447
New value of Value function: 5.74164
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.73545
New value of Value function: 5.73817
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.73022
New value of Value function: 5.73545
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.7293
New value of Value function: 5.73447
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.72887
New value of Value function: 5.73022
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.71793
New value of Value function: 5.73022
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.72235
New value of Value function: 5.7293
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.7155
New value of Value function: 5.7293
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.72319
New value of Value function: 5.72887
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.71772
New value of Value function: 5.72887
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.72331
New value of Value function: 5.72755
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 5.7156
New value of Value function: 5.72331
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.71778
New value of Value function: 5.71793
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 5.16128
New value of Value function: 5.71793
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 8
----------
State: 7701
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 9
----------
State: 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 10
----------
State: 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: 1.98135
New value of Value function: 1.98135
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 11
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.00497
New value of Value function: 8.00497
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 12
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 7.96154
New value of Value function: 8.00497
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 13
----------
State: 6917
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: 1.94145
New value of Value function: 1.94145
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 14
----------
State: 6973
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.97389
New value of Value function: 7.96154
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 15
----------
State: 7757
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.63847
New value of Value function: 2.63847
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.70798
New value of Value function: 5.71778
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.71227
New value of Value function: 5.71772
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.7117
New value of Value function: 5.7155
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.7061
New value of Value function: 5.7155
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.70779
New value of Value function: 5.71227
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.7068
New value of Value function: 5.70798
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.69819
New value of Value function: 5.70779
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.70033
New value of Value function: 5.70779
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.70016
New value of Value function: 5.7068
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.70136
New value of Value function: 5.70136
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.69595
New value of Value function: 5.70033
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.69442
New value of Value function: 5.70016
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.69261
New value of Value function: 5.69819
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.68856
New value of Value function: 5.69595
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.69057
New value of Value function: 5.69442
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.68854
New value of Value function: 5.69261
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.25616
New value of Value function: 5.69261
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.68312
New value of Value function: 5.69261
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 5.33059
New value of Value function: 5.69261
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.68514
New value of Value function: 5.69057
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.67844
New value of Value function: 5.69057
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.68521
New value of Value function: 5.68856
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.67908
New value of Value function: 5.68521
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.67989
New value of Value function: 5.68312
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.67732
New value of Value function: 5.67989
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.67459
New value of Value function: 5.67908
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.66974
New value of Value function: 5.67908
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.67173
New value of Value function: 5.67908
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.66974
New value of Value function: 5.67844
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.6711
New value of Value function: 5.67173
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.66392
New value of Value function: 5.67173
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 5.38533
New value of Value function: 5.67173
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.66086
New value of Value function: 5.67173
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 5.42874
New value of Value function: 5.67173
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.666
New value of Value function: 5.66974
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.6645
New value of Value function: 5.666
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 5.46227
New value of Value function: 5.666
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.66031
New value of Value function: 5.6645
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.65928
New value of Value function: 5.66392
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.65673
New value of Value function: 5.66086
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.6518
New value of Value function: 5.66031
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 5.4881
New value of Value function: 5.66031
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.65465
New value of Value function: 5.65928
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.64403
New value of Value function: 5.65928
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.65409
New value of Value function: 5.65673
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.6496
New value of Value function: 5.65465
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.64902
New value of Value function: 5.65409
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.64893
New value of Value function: 5.6496
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.64254
New value of Value function: 5.64902
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.64343
New value of Value function: 5.64893
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.6438
New value of Value function: 5.64403
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.63522
New value of Value function: 5.6438
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.63869
New value of Value function: 5.64343
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.63787
New value of Value function: 5.64254
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.63554
New value of Value function: 5.63869
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.62705
New value of Value function: 5.63869
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.6336
New value of Value function: 5.63787
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.63234
New value of Value function: 5.63554
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.62861
New value of Value function: 5.6336
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.62854
New value of Value function: 5.63234
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.62684
New value of Value function: 5.62861
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.62173
New value of Value function: 5.62854
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 5.50321
New value of Value function: 5.62854
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.61573
New value of Value function: 5.62854
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.62351
New value of Value function: 5.62705
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.61847
New value of Value function: 5.62684
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.62138
New value of Value function: 5.62351
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.6185
New value of Value function: 5.62138
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.61594
New value of Value function: 5.6185
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.61351
New value of Value function: 5.61847
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.61
New value of Value function: 5.61594
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.61054
New value of Value function: 5.61573
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.60897
New value of Value function: 5.61351
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.60855
New value of Value function: 5.61054
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.60517
New value of Value function: 5.61
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.60164
New value of Value function: 5.60897
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.60227
New value of Value function: 5.60855
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.59439
New value of Value function: 5.60855
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.60361
New value of Value function: 5.60517
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.59982
New value of Value function: 5.60361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.59486
New value of Value function: 5.60361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.59039
New value of Value function: 5.60361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.59577
New value of Value function: 5.60361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.5987
New value of Value function: 5.5987
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.59381
New value of Value function: 5.59577
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.58918
New value of Value function: 5.59439
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.58623
New value of Value function: 5.59381
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.58894
New value of Value function: 5.59039
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.58278
New value of Value function: 5.59039
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.58422
New value of Value function: 5.59039
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.58514
New value of Value function: 5.58623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.58001
New value of Value function: 5.58623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.57956
New value of Value function: 5.58623
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.57817
New value of Value function: 5.58278
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.57629
New value of Value function: 5.58001
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.57046
New value of Value function: 5.58001
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.5748
New value of Value function: 5.57956
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.57476
New value of Value function: 5.57629
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 5.57011
New value of Value function: 5.57629
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.56985
New value of Value function: 5.5748
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 5.50601
New value of Value function: 5.5748
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.56319
New value of Value function: 5.5748
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.55701
New value of Value function: 5.5748
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.56963
New value of Value function: 5.57011
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.56535
New value of Value function: 5.56985
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.56346
New value of Value function: 5.56963
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.56448
New value of Value function: 5.56535
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 5.56062
New value of Value function: 5.56448
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.55935
New value of Value function: 5.56346
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.55712
New value of Value function: 5.56062
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 5.5559
New value of Value function: 5.55935
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.55426
New value of Value function: 5.55712
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.55083
New value of Value function: 5.55701
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.5493
New value of Value function: 5.5559
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 5.5512
New value of Value function: 5.55426
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.54919
New value of Value function: 5.5512
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.54194
New value of Value function: 5.5512
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 5.54653
New value of Value function: 5.55083
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 5.50415
New value of Value function: 5.55083
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.54458
New value of Value function: 5.54919
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.54414
New value of Value function: 5.54653
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 5.54187
New value of Value function: 5.54458
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.53838
New value of Value function: 5.54414
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.53912
New value of Value function: 5.54194
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 5.50113
New value of Value function: 5.54194
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.5344
New value of Value function: 5.54187
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 5.53724
New value of Value function: 5.53912
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 5.53278
New value of Value function: 5.53912
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 5.49819
New value of Value function: 5.53912
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.53413
New value of Value function: 5.53838
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 5.52865
New value of Value function: 5.53838
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.53223
New value of Value function: 5.5344
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.52693
New value of Value function: 5.53413
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.52916
New value of Value function: 5.53223
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.52612
New value of Value function: 5.52916
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.52421
New value of Value function: 5.52865
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 5.52407
New value of Value function: 5.52693
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.51955
New value of Value function: 5.52612
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.52006
New value of Value function: 5.52421
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 5.51953
New value of Value function: 5.52421
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.51929
New value of Value function: 5.52006
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.51403
New value of Value function: 5.51955
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.51224
New value of Value function: 5.51953
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 5.51499
New value of Value function: 5.51929
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.5144
New value of Value function: 5.51499
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 5.51047
New value of Value function: 5.5144
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.50952
New value of Value function: 5.51403
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.50523
New value of Value function: 5.51403
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.50805
New value of Value function: 5.51047
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 5.50597
New value of Value function: 5.50952
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.50467
New value of Value function: 5.50805
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.50211
New value of Value function: 5.50597
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 5.50149
New value of Value function: 5.50523
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.49806
New value of Value function: 5.50467
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.49984
New value of Value function: 5.50211
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.49621
New value of Value function: 5.50149
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.49518
New value of Value function: 5.50149
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 5.49703
New value of Value function: 5.49819
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 5.48902
New value of Value function: 5.49806
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.49097
New value of Value function: 5.49703
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 5.49259
New value of Value function: 5.49621
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.49035
New value of Value function: 5.49518
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.4904
New value of Value function: 5.49259
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 5.48816
New value of Value function: 5.49097
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.48394
New value of Value function: 5.4904
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.48564
New value of Value function: 5.49035
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 5.48022
New value of Value function: 5.49035
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.48454
New value of Value function: 5.48816
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 5.48375
New value of Value function: 5.48564
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.4809
New value of Value function: 5.48454
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.47649
New value of Value function: 5.48454
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.47875
New value of Value function: 5.48394
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.47697
New value of Value function: 5.48375
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 5.47936
New value of Value function: 5.48022
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.47048
New value of Value function: 5.48022
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 5.47133
New value of Value function: 5.47936
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 5.47499
New value of Value function: 5.47875
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.47301
New value of Value function: 5.47649
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 5.47179
New value of Value function: 5.47499
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 5.47063
New value of Value function: 5.47301
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 5.46283
New value of Value function: 5.47301
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.4673
New value of Value function: 5.47179
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.46712
New value of Value function: 5.47063
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.46366
New value of Value function: 5.47063
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.46198
New value of Value function: 5.47063
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 5.46629
New value of Value function: 5.46712
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 5.46247
New value of Value function: 5.46629
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 5.46197
New value of Value function: 5.46366
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.45688
New value of Value function: 5.46283
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 5.45419
New value of Value function: 5.46247
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 5.45783
New value of Value function: 5.46198
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.45634
New value of Value function: 5.46197
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 5.45767
New value of Value function: 5.45783
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 5.45322
New value of Value function: 5.45767
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 5.45338
New value of Value function: 5.45688
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.45016
New value of Value function: 5.45634
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.45075
New value of Value function: 5.45419
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.44553
New value of Value function: 5.45419
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 5.44568
New value of Value function: 5.45338
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 5.44911
New value of Value function: 5.45322
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 5.44517
New value of Value function: 5.45322
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 5.44863
New value of Value function: 5.45016
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.44351
New value of Value function: 5.44863
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 5.44405
New value of Value function: 5.44568
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 5.43964
New value of Value function: 5.44568
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 5.43727
New value of Value function: 5.44553
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.44
New value of Value function: 5.44517
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 5.44093
New value of Value function: 5.44351
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.4369
New value of Value function: 5.44093
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 5.43671
New value of Value function: 5.44
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.43451
New value of Value function: 5.43964
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 5.4351
New value of Value function: 5.43727
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 5.42898
New value of Value function: 5.4369
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.43036
New value of Value function: 5.43671
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.42926
New value of Value function: 5.43671
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 5.4325
New value of Value function: 5.4351
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 5.43059
New value of Value function: 5.4325
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 5.42831
New value of Value function: 5.43059
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 5.4261
New value of Value function: 5.43036
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.42387
New value of Value function: 5.42926
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.42383
New value of Value function: 5.42898
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 5.42419
New value of Value function: 5.42898
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 5.4208
New value of Value function: 5.4261
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 5.42162
New value of Value function: 5.42419
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.41747
New value of Value function: 5.42419
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 5.42003
New value of Value function: 5.42383
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.41183
New value of Value function: 5.42383
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.41844
New value of Value function: 5.42162
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.41338
New value of Value function: 5.42162
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 5.41716
New value of Value function: 5.4208
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 5.41272
New value of Value function: 5.42003
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 5.41588
New value of Value function: 5.41716
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 5.41273
New value of Value function: 5.41588
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 5.41175
New value of Value function: 5.41338
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.40805
New value of Value function: 5.41273
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 5.40831
New value of Value function: 5.41272
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 5.40771
New value of Value function: 5.41272
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 5.40474
New value of Value function: 5.41183
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.40549
New value of Value function: 5.40831
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.39953
New value of Value function: 5.40831
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 5.4039
New value of Value function: 5.40805
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.40275
New value of Value function: 5.40771
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 5.40361
New value of Value function: 5.40474
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 5.39685
New value of Value function: 5.4039
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 5.39952
New value of Value function: 5.40361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 5.39548
New value of Value function: 5.40361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.39756
New value of Value function: 5.40361
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 5.39953
New value of Value function: 5.39953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.39251
New value of Value function: 5.39953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 5.39146
New value of Value function: 5.39953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 5.39546
New value of Value function: 5.39953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 5.38945
New value of Value function: 5.39953
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.3933
New value of Value function: 5.39546
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 5.3914
New value of Value function: 5.3933
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.38711
New value of Value function: 5.39251
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.38158
New value of Value function: 5.39251
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.37671
New value of Value function: 5.39251
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.38729
New value of Value function: 5.39146
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 5.38713
New value of Value function: 5.3914
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 5.38736
New value of Value function: 5.38945
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 5.38175
New value of Value function: 5.38736
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 5.38333
New value of Value function: 5.38729
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.38211
New value of Value function: 5.38713
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 5.38281
New value of Value function: 5.38333
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 5.37932
New value of Value function: 5.38281
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 5.37852
New value of Value function: 5.38211
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.37695
New value of Value function: 5.38175
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 5.37414
New value of Value function: 5.37932
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 5.37532
New value of Value function: 5.37852
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 5.37157
New value of Value function: 5.37852
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 5.37424
New value of Value function: 5.37695
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.37183
New value of Value function: 5.37671
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.37066
New value of Value function: 5.37424
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 5.36998
New value of Value function: 5.37414
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 5.36661
New value of Value function: 5.37183
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 5.36762
New value of Value function: 5.37183
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 5.36588
New value of Value function: 5.37183
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.36673
New value of Value function: 5.37066
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 5.36202
New value of Value function: 5.37066
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.35972
New value of Value function: 5.37066
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 5.35848
New value of Value function: 5.37066
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.36466
New value of Value function: 5.36762
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 5.36366
New value of Value function: 5.36673
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.36166
New value of Value function: 5.36466
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.3587
New value of Value function: 5.36366
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 5.35972
New value of Value function: 5.36166
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.35661
New value of Value function: 5.35972
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 5.35236
New value of Value function: 5.35972
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 5.35579
New value of Value function: 5.3587
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.35278
New value of Value function: 5.35848
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 5.35428
New value of Value function: 5.35661
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.34732
New value of Value function: 5.35661
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.3516
New value of Value function: 5.35579
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 5.34554
New value of Value function: 5.35579
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.3424
New value of Value function: 5.35579
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 5.35187
New value of Value function: 5.35428
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 5.3501
New value of Value function: 5.35187
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 5.34797
New value of Value function: 5.3516
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.34661
New value of Value function: 5.3501
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 5.34594
New value of Value function: 5.34797
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 5.34408
New value of Value function: 5.34661
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.34164
New value of Value function: 5.34594
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 5.34179
New value of Value function: 5.34554
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 5.33833
New value of Value function: 5.34408
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 5.3402
New value of Value function: 5.3424
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.33661
New value of Value function: 5.34179
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 5.33766
New value of Value function: 5.34164
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.3367
New value of Value function: 5.3402
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.33211
New value of Value function: 5.3402
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 5.33634
New value of Value function: 5.33833
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.33104
New value of Value function: 5.33833
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 5.3312
New value of Value function: 5.33766
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 5.33354
New value of Value function: 5.33634
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 5.33249
New value of Value function: 5.33354
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 5.32943
New value of Value function: 5.33249
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 5.32865
New value of Value function: 5.33211
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.32722
New value of Value function: 5.3312
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 5.32414
New value of Value function: 5.33104
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 5.32547
New value of Value function: 5.33104
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.32532
New value of Value function: 5.32865
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 5.32482
New value of Value function: 5.32722
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 5.32118
New value of Value function: 5.32722
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.32236
New value of Value function: 5.32547
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 5.3214
New value of Value function: 5.32532
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.31964
New value of Value function: 5.32414
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 5.31755
New value of Value function: 5.32414
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 5.31715
New value of Value function: 5.32236
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.31752
New value of Value function: 5.32118
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 5.31738
New value of Value function: 5.31964
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.314
New value of Value function: 5.31755
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 5.3135
New value of Value function: 5.31752
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.31271
New value of Value function: 5.31738
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 5.31359
New value of Value function: 5.31715
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.31022
New value of Value function: 5.314
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 5.30951
New value of Value function: 5.314
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.3084
New value of Value function: 5.31359
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 5.30981
New value of Value function: 5.31271
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.30791
New value of Value function: 5.31022
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.30335
New value of Value function: 5.31022
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 5.30337
New value of Value function: 5.30981
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 5.30605
New value of Value function: 5.30951
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 5.3055
New value of Value function: 5.3084
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.30284
New value of Value function: 5.30605
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 5.3023
New value of Value function: 5.3055
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 5.3015
New value of Value function: 5.30337
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 5.29658
New value of Value function: 5.30335
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.29861
New value of Value function: 5.30284
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.29731
New value of Value function: 5.3023
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 5.29856
New value of Value function: 5.3015
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 5.29751
New value of Value function: 5.29861
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 5.29483
New value of Value function: 5.29861
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.29389
New value of Value function: 5.29751
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 5.29354
New value of Value function: 5.29731
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.29182
New value of Value function: 5.29658
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 5.28985
New value of Value function: 5.29483
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 5.29112
New value of Value function: 5.29389
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.28919
New value of Value function: 5.29354
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 5.28959
New value of Value function: 5.29182
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 5.28746
New value of Value function: 5.29182
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.28475
New value of Value function: 5.29182
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.28636
New value of Value function: 5.28985
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 5.28319
New value of Value function: 5.28959
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 5.28564
New value of Value function: 5.28746
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.28105
New value of Value function: 5.28746
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 5.28185
New value of Value function: 5.28746
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 5.28377
New value of Value function: 5.28475
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 5.27678
New value of Value function: 5.28475
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.28009
New value of Value function: 5.28377
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 5.28009
New value of Value function: 5.28185
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 5.27793
New value of Value function: 5.28105
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.27566
New value of Value function: 5.28009
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.27546
New value of Value function: 5.28009
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 5.27642
New value of Value function: 5.27793
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 5.27403
New value of Value function: 5.27678
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 5.27034
New value of Value function: 5.27678
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 5.27023
New value of Value function: 5.27642
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 5.27276
New value of Value function: 5.27566
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 5.26441
New value of Value function: 5.27566
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 5.26931
New value of Value function: 5.27566
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.2703
New value of Value function: 5.27546
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.26549
New value of Value function: 5.27546
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.27085
New value of Value function: 5.27085
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.26627
New value of Value function: 5.27034
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 5.26647
New value of Value function: 5.26931
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 5.26281
New value of Value function: 5.26931
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 1
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 12.6597
New value of Value function: 12.6597
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 2
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 18.8314
New value of Value function: 18.8314
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 3
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 15.6431
New value of Value function: 16.8048
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 4
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 18.9993
New value of Value function: 18.9993
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 5
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.0237
New value of Value function: 16.8048
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 6
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 11.7934
New value of Value function: 11.7934
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 7
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.6755
New value of Value function: 12.6597
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 8
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 12.4579
New value of Value function: 12.4579
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 9
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 12.6307
New value of Value function: 12.6307
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 10
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 12.8942
New value of Value function: 12.8942
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 11
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 13.8399
New value of Value function: 18.9993
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 12
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 14.6701
New value of Value function: 14.6701
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 13
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 19.1294
New value of Value function: 19.1294
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 14
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 17.9811
New value of Value function: 17.9811
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 15
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 16.9579
New value of Value function: 16.9579
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 16
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 11.1056
New value of Value function: 11.1056
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 17
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 4.01653
New value of Value function: 5.98789
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 18
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 14.9117
New value of Value function: 14.9117
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 19
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 11.4051
New value of Value function: 11.4051
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 20
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 4
New value of Q matrix: 16.9762
New value of Value function: 16.9762
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 21
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 10.7699
New value of Value function: 10.9321
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 22
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 15.18
New value of Value function: 15.18
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 23
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 11.5846
New value of Value function: 11.5846
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 24
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 16.9076
New value of Value function: 16.9076
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 25
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 10.5118
New value of Value function: 10.9321
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 26
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 15.3467
New value of Value function: 15.3467
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 27
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 11.6474
New value of Value function: 11.6474
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 28
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 6
New value of Q matrix: 16.873
New value of Value function: 16.873
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 29
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 10.9029
New value of Value function: 10.9029
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 30
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: 7.27614
New value of Value function: 10.9029
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 31
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 15.0039
New value of Value function: 15.0039
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 32
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 5.93877
New value of Value function: 5.98789
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 33
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 10.63
New value of Value function: 10.9029
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 34
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 15.7938
New value of Value function: 15.7938
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 35
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 10.8747
New value of Value function: 10.8747
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 36
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 10.8475
New value of Value function: 10.8475
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 37
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 56
New value of Q matrix: 11.1305
New value of Value function: 11.1305
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 38
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.67892
New value of Value function: 9.90613
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 39
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 8.01355
New value of Value function: 9.90613
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 40
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 57
New value of Q matrix: 11.485
New value of Value function: 11.485
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 41
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9713
	Distance: 12
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 6.92491
New value of Value function: 8.53025
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 42
----------
State: 9713
	Distance: 12
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 43
----------
State: 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8201
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 44
----------
State: 8201
	Distance: 10
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.37015
New value of Value function: 6.37015
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 45
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 58
New value of Q matrix: 11.611
New value of Value function: 11.611
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 46
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.4876
New value of Value function: 8.4876
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 47
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.44964
New value of Value function: 8.44964
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 48
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.41515
New value of Value function: 8.41515
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 49
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.38334
New value of Value function: 8.38334
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 50
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.3537
New value of Value function: 8.3537
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 51
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.32586
New value of Value function: 8.32586
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 52
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 8.29953
New value of Value function: 8.29953
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 53
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.2745
New value of Value function: 8.2745
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 54
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 8.25062
New value of Value function: 8.25062
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 55
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 8.22774
New value of Value function: 8.22774
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 56
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.70458
New value of Value function: 8.22774
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 57
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 12.3247
New value of Value function: 12.3247
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 58
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.39484
New value of Value function: 10.5132
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 59
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 12.8664
New value of Value function: 12.8664
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 60
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 5.6075
New value of Value function: 6.39484
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 61
----------
State: 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 62
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 63
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8033
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 64
----------
State: 8033
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 65
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 66
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 67
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 68
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 69
----------
State: 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8985
	Distance: 11
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -2.53553
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 70
----------
State: 8985
	Distance: 11
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 10.6359
New value of Value function: 10.6359
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 71
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 15.4388
New value of Value function: 15.7938
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 72
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 11.6431
New value of Value function: 11.6431
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 73
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8985
	Distance: 11
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 15.607
New value of Value function: 15.607
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 74
----------
State: 8985
	Distance: 11
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 10.6359
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 75
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 76
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 77
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 78
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 79
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 80
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 9.8539
New value of Value function: 9.8539
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 81
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 14.8539
New value of Value function: 15.0039
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 82
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.0563
New value of Value function: 15.0039
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 83
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: 1.72097
New value of Value function: 7.1276
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 84
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 13.0018
New value of Value function: 13.0018
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 85
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.34885
New value of Value function: 12.8942
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 86
----------
State: 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 87
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 88
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 89
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 90
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 91
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 92
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 93
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 94
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 95
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 96
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 97
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 98
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 99
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 100
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 101
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.35
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 102
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.6614
New value of Value function: 1.6614
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 103
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.65639
New value of Value function: 1.65639
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 104
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.65161
New value of Value function: 1.65161
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 105
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 106
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.01655
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 107
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.56642
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 108
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 109
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -10
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 110
----------
State: 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 111
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 112
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 113
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 114
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 115
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 116
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 117
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 118
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 119
----------
State: 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 120
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.0176777
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 121
----------
State: 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 122
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7753
	Distance: 9
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -11
New value of Visit matrix: 1
New value of Q matrix: -11
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 123
----------
State: 7753
	Distance: 9
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 11
New value of Visit matrix: 1
New value of Q matrix: 11
New value of Value function: 11
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 124
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7753
	Distance: 9
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -11
New value of Visit matrix: 1
New value of Q matrix: -0.11
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 125
----------
State: 7753
	Distance: 9
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 11
New value of Visit matrix: 2
New value of Q matrix: 11
New value of Value function: 11
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 126
----------
State: 6129
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 127
----------
State: 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 128
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 129
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 130
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 131
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 1
New value of Q matrix: -4.05
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 132
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 133
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 134
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 2.79014
New value of Value function: 2.79014
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 135
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.42911
New value of Value function: 1.42911
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 136
----------
State: 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 137
----------
State: 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.8019
New value of Value function: 5.8019
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 138
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.42086
New value of Value function: 1.42086
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 139
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 1.08237
New value of Value function: 1.08237
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 140
----------
State: 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.93673
New value of Value function: 5.93673
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 141
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.990687
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 142
----------
State: 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.51781
New value of Value function: 5.51781
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 143
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.01
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 144
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.964645
New value of Value function: 0.990687
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 145
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.38112
New value of Value function: 6.38112
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 146
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 1.16816
New value of Value function: 1.16816
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 147
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 2.62748
New value of Value function: 2.62748
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 148
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 149
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8425
	Distance: 10
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 2
New value of Q matrix: -7.55018
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 150
----------
State: 8425
	Distance: 10
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 151
----------
State: 7697
	Distance: 9
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 152
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.93148
New value of Value function: 5.93148
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 153
----------
State: 7641
	Distance: 9
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.28066
New value of Value function: 6.28066
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 154
----------
State: 6857
	Distance: 8
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.31222
New value of Value function: 1.16816
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 155
----------
State: 6913
	Distance: 8
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: -7.46447
New value of Value function: 5.93148
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 156
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 157
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 158
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 159
----------
State: 6185
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 160
----------
State: 6969
	Distance: 8
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.21662
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 5.26567
New value of Value function: 5.26627
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.2617
New value of Value function: 5.26567
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 5.26205
New value of Value function: 5.26549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 5.25916
New value of Value function: 5.26549
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.2602
New value of Value function: 5.26441
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 5.25797
New value of Value function: 5.26205
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 5.25843
New value of Value function: 5.2617
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.25715
New value of Value function: 5.2602
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.25494
New value of Value function: 5.25916
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 5.25532
New value of Value function: 5.25843
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 5.25483
New value of Value function: 5.25797
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 5.2516
New value of Value function: 5.25715
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.25263
New value of Value function: 5.25532
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 5.2515
New value of Value function: 5.25494
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.24971
New value of Value function: 5.25483
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 5.25124
New value of Value function: 5.25263
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 5.24813
New value of Value function: 5.2516
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 5.24528
New value of Value function: 5.2515
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 5.24769
New value of Value function: 5.25124
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 5.24766
New value of Value function: 5.24971
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.24451
New value of Value function: 5.24813
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.24364
New value of Value function: 5.24769
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 5.24389
New value of Value function: 5.24766
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.23965
New value of Value function: 5.24766
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 5.24409
New value of Value function: 5.24528
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 5.23901
New value of Value function: 5.24409
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 5.24012
New value of Value function: 5.24409
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 5.24053
New value of Value function: 5.24364
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 5.23918
New value of Value function: 5.24053
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 5.23698
New value of Value function: 5.24012
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 5.23635
New value of Value function: 5.23965
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.23452
New value of Value function: 5.23918
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 5.23473
New value of Value function: 5.23901
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 5.23279
New value of Value function: 5.23698
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.22964
New value of Value function: 5.23698
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 5.22711
New value of Value function: 5.23698
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 5.23344
New value of Value function: 5.23635
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 5.23259
New value of Value function: 5.23473
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 5.23031
New value of Value function: 5.23344
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 5.22173
New value of Value function: 5.23344
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 5.22991
New value of Value function: 5.23259
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 5.22885
New value of Value function: 5.23031
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 5.22591
New value of Value function: 5.22991
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 5.22639
New value of Value function: 5.22964
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.22457
New value of Value function: 5.22885
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 5.22511
New value of Value function: 5.22639
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 5.22289
New value of Value function: 5.22591
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 5.21614
New value of Value function: 5.22591
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 5.22152
New value of Value function: 5.22511
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 5.22139
New value of Value function: 5.22457
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.21951
New value of Value function: 5.22289
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 5.21089
New value of Value function: 5.22289
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 5.21939
New value of Value function: 5.22152
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 5.21715
New value of Value function: 5.22139
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 5.21768
New value of Value function: 5.21951
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.21449
New value of Value function: 5.21939
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 5.2159
New value of Value function: 5.21768
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.2098
New value of Value function: 5.21768
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 5.21398
New value of Value function: 5.21715
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 5.21281
New value of Value function: 5.2159
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 5.20873
New value of Value function: 5.2159
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 5.20501
New value of Value function: 5.2159
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 5.21242
New value of Value function: 5.21398
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 5.21029
New value of Value function: 5.21242
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 5.20677
New value of Value function: 5.21242
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 5.20896
New value of Value function: 5.21089
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 5.20491
New value of Value function: 5.2098
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.20483
New value of Value function: 5.20896
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 5.2055
New value of Value function: 5.20677
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.20007
New value of Value function: 5.20677
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 5.20213
New value of Value function: 5.20677
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 5.2031
New value of Value function: 5.20501
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 5.20071
New value of Value function: 5.20491
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 5.19898
New value of Value function: 5.2031
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 5.19945
New value of Value function: 5.20213
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 5.1987
New value of Value function: 5.20071
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 5.19328
New value of Value function: 5.20071
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 5.19644
New value of Value function: 5.20007
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.19516
New value of Value function: 5.19945
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 5.19581
New value of Value function: 5.1987
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 5.18804
New value of Value function: 5.1987
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 5.19238
New value of Value function: 5.1987
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 5.19527
New value of Value function: 5.19644
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 5.19218
New value of Value function: 5.19527
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 5.18896
New value of Value function: 5.19527
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 5.18304
New value of Value function: 5.19527
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 5.19185
New value of Value function: 5.19516
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.19027
New value of Value function: 5.19218
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 5.18846
New value of Value function: 5.19218
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 5.18794
New value of Value function: 5.19027
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.18541
New value of Value function: 5.18896
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 5.18536
New value of Value function: 5.18846
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 5.18506
New value of Value function: 5.18794
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 5.18372
New value of Value function: 5.18541
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.18058
New value of Value function: 5.18536
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 5.18176
New value of Value function: 5.18506
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 5.18168
New value of Value function: 5.18372
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 5.17952
New value of Value function: 5.18304
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 5.17728
New value of Value function: 5.18176
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 5.17818
New value of Value function: 5.18168
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.17587
New value of Value function: 5.18168
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 5.17829
New value of Value function: 5.17952
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 5.17533
New value of Value function: 5.17829
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 5.17492
New value of Value function: 5.17818
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 5.17139
New value of Value function: 5.17818
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 5.1746
New value of Value function: 5.17728
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 5.17157
New value of Value function: 5.17587
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.17108
New value of Value function: 5.17492
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 5.17156
New value of Value function: 5.1746
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 5.17104
New value of Value function: 5.17157
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 5.16589
New value of Value function: 5.17156
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 5.16821
New value of Value function: 5.17139
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 5.16723
New value of Value function: 5.17108
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 5.16749
New value of Value function: 5.17108
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 5.1634
New value of Value function: 5.17108
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 5.16505
New value of Value function: 5.17108
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.16632
New value of Value function: 5.16749
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 5.16187
New value of Value function: 5.16749
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 5.16395
New value of Value function: 5.16632
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 5.15951
New value of Value function: 5.16632
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.16159
New value of Value function: 5.16589
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 5.16025
New value of Value function: 5.16395
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 5.16042
New value of Value function: 5.16187
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 5.157
New value of Value function: 5.16187
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.1569
New value of Value function: 5.16187
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 5.15855
New value of Value function: 5.16025
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 5.15466
New value of Value function: 5.15951
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 5.15541
New value of Value function: 5.15855
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 5.15523
New value of Value function: 5.157
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 5.15349
New value of Value function: 5.1569
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.15221
New value of Value function: 5.15541
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 5.15132
New value of Value function: 5.15523
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 5.15193
New value of Value function: 5.15466
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 5.1491
New value of Value function: 5.15349
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 5.14999
New value of Value function: 5.15221
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.14755
New value of Value function: 5.15193
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 5.14863
New value of Value function: 5.15132
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 5.14724
New value of Value function: 5.14999
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 5.1465
New value of Value function: 5.1491
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 5.14358
New value of Value function: 5.14863
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 5.14534
New value of Value function: 5.14755
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 5.14291
New value of Value function: 5.14724
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 5.14218
New value of Value function: 5.14724
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 5.14319
New value of Value function: 5.1465
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 5.14303
New value of Value function: 5.14358
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 5.13835
New value of Value function: 5.14358
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 5.1381
New value of Value function: 5.14319
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 5.13915
New value of Value function: 5.14303
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 5.13956
New value of Value function: 5.14218
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 5.13891
New value of Value function: 5.13956
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 5.1328
New value of Value function: 5.13956
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 5.1361
New value of Value function: 5.13915
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 5.13512
New value of Value function: 5.13891
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 5.13564
New value of Value function: 5.13835
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 5.13375
New value of Value function: 5.1361
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 5.13265
New value of Value function: 5.13564
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 5.13239
New value of Value function: 5.13512
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 5.13111
New value of Value function: 5.13375
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 5.12918
New value of Value function: 5.1328
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 5.12725
New value of Value function: 5.1328
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 5.12494
New value of Value function: 5.1328
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 5.1211
New value of Value function: 5.1328
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 5.12739
New value of Value function: 5.13265
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 5.12922
New value of Value function: 5.13239
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 5.12914
New value of Value function: 5.12922
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 5.12579
New value of Value function: 5.12914
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 5.1259
New value of Value function: 5.12739
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 5.12202
New value of Value function: 5.12725
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 5.12327
New value of Value function: 5.1259
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 5.12268
New value of Value function: 5.12579
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 5.12237
New value of Value function: 5.12327
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 5.1193
New value of Value function: 5.12268
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 5.11945
New value of Value function: 5.12237
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 5.11897
New value of Value function: 5.12202
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.11668
New value of Value function: 5.1211
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 5.11659
New value of Value function: 5.11945
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 5.11624
New value of Value function: 5.1193
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 5.11559
New value of Value function: 5.1193
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 5.11535
New value of Value function: 5.11668
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 5.11137
New value of Value function: 5.11659
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 5.11211
New value of Value function: 5.11624
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 5.11304
New value of Value function: 5.11559
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 5.1122
New value of Value function: 5.11535
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 5.11142
New value of Value function: 5.11304
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 5.10888
New value of Value function: 5.11304
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 5.10762
New value of Value function: 5.11304
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 5.10578
New value of Value function: 5.11304
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 5.10984
New value of Value function: 5.11211
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 5.10764
New value of Value function: 5.11137
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 5.10675
New value of Value function: 5.11137
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 5.1061
New value of Value function: 5.10764
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 5.10319
New value of Value function: 5.10762
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 5.10362
New value of Value function: 5.10762
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 5.10372
New value of Value function: 5.1061
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 5.10086
New value of Value function: 5.10578
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 5.10242
New value of Value function: 5.10372
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 5.09982
New value of Value function: 5.10362
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 5.09881
New value of Value function: 5.10362
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 5.10045
New value of Value function: 5.10242
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 5.09614
New value of Value function: 5.10242
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 5.09907
New value of Value function: 5.10086
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 5.09565
New value of Value function: 5.10045
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 5.09454
New value of Value function: 5.10045
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 5.09729
New value of Value function: 5.09907
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 5.0925
New value of Value function: 5.09907
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 5.09573
New value of Value function: 5.09729
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 5.09413
New value of Value function: 5.09573
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 5.09109
New value of Value function: 5.09573
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 5.0924
New value of Value function: 5.09565
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 5.09025
New value of Value function: 5.09565
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 5.09048
New value of Value function: 5.0925
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 5.08909
New value of Value function: 5.0925
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 5.08865
New value of Value function: 5.09109
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 5.08795
New value of Value function: 5.09048
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 5.08495
New value of Value function: 5.09048
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 5.08586
New value of Value function: 5.09048
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 5.08534
New value of Value function: 5.09025
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 5.08589
New value of Value function: 5.08795
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 5.08481
New value of Value function: 5.08589
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 5.08154
New value of Value function: 5.08586
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 5.08256
New value of Value function: 5.08534
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 5.08023
New value of Value function: 5.08495
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 5.08113
New value of Value function: 5.08481
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 5.0756
New value of Value function: 5.08481
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 5.08169
New value of Value function: 5.08256
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 5.07926
New value of Value function: 5.08169
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 5.07858
New value of Value function: 5.08154
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 5.07722
New value of Value function: 5.08113
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 5.0711
New value of Value function: 5.08113
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 5.07324
New value of Value function: 5.08113
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 5.06961
New value of Value function: 5.08113
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 5.07732
New value of Value function: 5.07926
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 5.07598
New value of Value function: 5.07858
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 5.07547
New value of Value function: 5.07732
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 5.07353
New value of Value function: 5.07598
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 5.0727
New value of Value function: 5.07547
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 5.07237
New value of Value function: 5.07353
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 5.06974
New value of Value function: 5.0727
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 5.06943
New value of Value function: 5.07237
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 5.06927
New value of Value function: 5.0711
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 1
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.04153
New value of Value function: 7.04153
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 2
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 4
New value of Q matrix: 4.58086
New value of Value function: 7.04153
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 3
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 12
New value of Q matrix: 13.0333
New value of Value function: 13.0333
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 4
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 0.494937
New value of Value function: 0.494937
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 5
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 4.06501
New value of Value function: 4.06501
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 6
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 13.4063
New value of Value function: 13.4063
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 7
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 12.6928
New value of Value function: 12.6928
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 8
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.01492
New value of Value function: 7.03222
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 9
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 7.25007
New value of Value function: 7.25007
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 10
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 12.6657
New value of Value function: 12.6657
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 11
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 12.5639
New value of Value function: 12.5639
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 12
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 8.20283
New value of Value function: 8.20283
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 13
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 13.6371
New value of Value function: 13.6371
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 14
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 12.5383
New value of Value function: 12.5383
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 15
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 10.9661
New value of Value function: 12.5383
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 16
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 13.8064
New value of Value function: 13.8064
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 17
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 12.5132
New value of Value function: 12.5132
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 18
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 8.39067
New value of Value function: 12.5132
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 19
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 9.35799
New value of Value function: 9.35799
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 20
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 13.9304
New value of Value function: 13.9304
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 21
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 12.4887
New value of Value function: 12.4887
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 22
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 10.0863
New value of Value function: 12.4887
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 23
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 10.1274
New value of Value function: 10.1274
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 24
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 14.0208
New value of Value function: 14.0208
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 25
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 12.977
New value of Value function: 12.977
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 26
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 10.656
New value of Value function: 10.656
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 27
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 8.62574
New value of Value function: 14.0208
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 28
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.49712
New value of Value function: 10.656
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 29
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 2.97945
New value of Value function: 10.656
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 30
----------
State: 6861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 9.54944
New value of Value function: 9.54944
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 31
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 11.0095
New value of Value function: 11.0095
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 32
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 14.1895
New value of Value function: 14.1895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 33
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 11.6985
New value of Value function: 12.977
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 34
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 11.2974
New value of Value function: 11.2974
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 35
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 13.9885
New value of Value function: 13.9885
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 36
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 11.4447
New value of Value function: 11.4447
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 37
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 13.8594
New value of Value function: 13.8594
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 38
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 11.516
New value of Value function: 11.516
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 39
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 13.7711
New value of Value function: 13.7711
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 40
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 10.3931
New value of Value function: 10.3931
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 41
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 5.33206
New value of Value function: 5.33206
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 42
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.9856
New value of Value function: 13.7711
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 43
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 6.21439
New value of Value function: 6.21439
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 44
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.69778
New value of Value function: 13.7711
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 45
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 13.9745
New value of Value function: 13.9745
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 46
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 9.22806
New value of Value function: 12.977
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 47
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 8
New value of Visit matrix: 28
New value of Q matrix: 13.1991
New value of Value function: 13.1991
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 48
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 5
New value of Q matrix: 1.7686
New value of Value function: 6.21439
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 49
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 13.1746
New value of Value function: 13.1746
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 50
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 9.79674
New value of Value function: 13.1746
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 51
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 10.2753
New value of Value function: 13.1746
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 52
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 13.1505
New value of Value function: 13.1505
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 53
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 13.1269
New value of Value function: 13.1269
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 54
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 13.1037
New value of Value function: 13.1037
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 55
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 8.42793
New value of Value function: 13.1037
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 56
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.2543
New value of Value function: 13.0333
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 57
----------
State: 7645
	Distance: 9
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 10.0094
New value of Value function: 10.0094
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 58
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 10.6688
New value of Value function: 13.1037
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 59
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 13.0809
New value of Value function: 13.0809
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 60
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 13.0585
New value of Value function: 13.0585
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 61
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 13.4355
New value of Value function: 13.4355
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 62
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 8.30117
New value of Value function: 10.3931
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 63
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 13.4131
New value of Value function: 13.4131
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 64
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 13.3911
New value of Value function: 13.3911
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 65
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 13.3694
New value of Value function: 13.3694
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 66
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 13.6768
New value of Value function: 13.6768
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 67
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 10.7427
New value of Value function: 10.7427
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 68
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 13.7258
New value of Value function: 13.7258
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 69
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 10.9421
New value of Value function: 10.9421
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 70
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 13.5628
New value of Value function: 13.5628
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 71
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.3647
New value of Value function: 10.9421
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 72
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 11.0534
New value of Value function: 11.0534
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 73
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 13.9179
New value of Value function: 13.9179
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 74
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 11.0832
New value of Value function: 13.6768
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 75
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 13.6551
New value of Value function: 13.6551
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 76
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 14.0124
New value of Value function: 14.0124
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 77
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 9.22408
New value of Value function: 11.0534
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 78
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 11.2156
New value of Value function: 11.2156
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 79
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 11.5228
New value of Value function: 13.9179
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 80
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.77339
New value of Value function: 13.9179
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 81
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.7892
New value of Value function: 11.7892
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 82
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 7.26644
New value of Value function: 7.26644
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 83
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 59
New value of Q matrix: 11.6806
New value of Value function: 11.6806
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 84
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 8.20575
New value of Value function: 8.20575
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 85
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 8.18456
New value of Value function: 8.18456
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 86
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 8.1641
New value of Value function: 8.1641
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 87
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 8.1443
New value of Value function: 8.1443
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 88
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 8.1251
New value of Value function: 8.1251
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 89
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 8.10646
New value of Value function: 8.10646
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 90
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 8.08833
New value of Value function: 8.08833
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 91
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 8.07068
New value of Value function: 8.07068
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 92
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 7.87133
New value of Value function: 8.07068
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 93
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 60
New value of Q matrix: 11.7206
New value of Value function: 11.7206
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 94
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 8.05348
New value of Value function: 8.05348
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 95
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 8.03668
New value of Value function: 8.03668
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 96
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 7.92002
New value of Value function: 8.03668
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 97
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 56
New value of Q matrix: 7.141
New value of Value function: 7.141
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 98
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 61
New value of Q matrix: 11.6372
New value of Value function: 11.6372
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 99
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 57
New value of Q matrix: 7.19131
New value of Value function: 7.19131
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 100
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 10.7002
New value of Value function: 11.6372
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 101
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 35
New value of Q matrix: 6.07797
New value of Value function: 6.07797
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 102
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 62
New value of Q matrix: 11.5715
New value of Value function: 11.5715
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 103
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 58
New value of Q matrix: 7.22603
New value of Value function: 7.22603
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 104
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 63
New value of Q matrix: 11.5188
New value of Value function: 11.5188
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 105
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 59
New value of Q matrix: 7.19884
New value of Value function: 7.19884
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 106
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 36
New value of Q matrix: 6.13225
New value of Value function: 6.13225
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 107
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 64
New value of Q matrix: 11.4698
New value of Value function: 11.4698
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 108
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 60
New value of Q matrix: 7.21902
New value of Value function: 7.21902
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 109
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 65
New value of Q matrix: 11.4298
New value of Value function: 11.4298
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 110
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.26837
New value of Value function: 7.21902
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 111
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -8
New value of Visit matrix: 2
New value of Q matrix: -2.99605
New value of Value function: 7.92409
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 112
----------
State: 8037
	Distance: 10
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.78585
New value of Value function: 6.78585
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 113
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 114
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 115
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 116
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 117
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 118
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5629
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 2.6906
New value of Value function: 2.6906
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 119
----------
State: 5629
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.94168
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 120
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 9
New value of Visit matrix: 4
New value of Q matrix: 6.04461
New value of Value function: 6.04461
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 121
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 122
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.84485
New value of Value function: 5.84485
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 123
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.47763
New value of Value function: 9.47763
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 124
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -8
New value of Visit matrix: 3
New value of Q matrix: 1.27504
New value of Value function: 3.92542
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 125
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1.8453
New value of Value function: 1.8453
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 126
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 127
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 128
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.568205
New value of Value function: 0.568205
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 129
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 5.94722
New value of Value function: 5.94722
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 130
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 1.71884
New value of Value function: 1.71884
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 131
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.565364
New value of Value function: 0.565364
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 132
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.562835
New value of Value function: 0.562835
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 133
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.02038
New value of Value function: 2.02038
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 5.06607
New value of Value function: 5.06974
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 5.06622
New value of Value function: 5.06974
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 5.0662
New value of Value function: 5.06974
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 5.06335
New value of Value function: 5.06974
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 5.06598
New value of Value function: 5.06961
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 5.06143
New value of Value function: 5.06961
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 5.06249
New value of Value function: 5.06961
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 5.05726
New value of Value function: 5.06961
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 5.06534
New value of Value function: 5.0662
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 5.06295
New value of Value function: 5.06534
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 5.05986
New value of Value function: 5.06534
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 5.06109
New value of Value function: 5.06335
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 5.06028
New value of Value function: 5.06249
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 5.05874
New value of Value function: 5.06109
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 5.0567
New value of Value function: 5.06109
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 5.05519
New value of Value function: 5.06109
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 5.05727
New value of Value function: 5.06109
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 143
New value of Q matrix: 5.056
New value of Value function: 5.05727
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 152
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.887749
New value of Value function: 2.02038
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 153
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.37709
New value of Value function: 6.37709
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 154
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.0107
New value of Value function: 2.0107
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 5.05421
New value of Value function: 5.05726
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 5.05232
New value of Value function: 5.0567
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 5.05158
New value of Value function: 5.0567
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 5.05348
New value of Value function: 5.056
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 5.05178
New value of Value function: 5.05421
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 5.05116
New value of Value function: 5.05348
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 5.05026
New value of Value function: 5.05232
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 5.04742
New value of Value function: 5.05178
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 5.04759
New value of Value function: 5.05158
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 5.04788
New value of Value function: 5.05116
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 5.04442
New value of Value function: 5.05116
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 5.04812
New value of Value function: 5.05026
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 5.04522
New value of Value function: 5.05026
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 5.04706
New value of Value function: 5.04759
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 5.40062
New value of Value function: 5.40062
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 170
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.31332
New value of Value function: 6.37709
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 171
----------
State: 7197
	Distance: 9
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.60897
New value of Value function: 6.60897
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 172
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.14572
New value of Value function: 2.0107
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 173
----------
State: 6413
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.20464
New value of Value function: 2.20464
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 147
New value of Q matrix: 5.34297
New value of Value function: 5.34297
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 175
----------
State: 7253
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.42066
New value of Value function: 5.42066
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 176
----------
State: 6469
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.93238
New value of Value function: 6.93238
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 177
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.82904
New value of Value function: 9.47763
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 178
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.72096
New value of Value function: 9.47763
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 179
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 8.22978
New value of Value function: 9.47763
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 180
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 61
New value of Q matrix: 7.20006
New value of Value function: 7.20006
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 181
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 37
New value of Q matrix: 6.16237
New value of Value function: 6.16237
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 182
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 66
New value of Q matrix: 11.3926
New value of Value function: 11.3926
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 183
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 62
New value of Q matrix: 7.21005
New value of Value function: 7.21005
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 184
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 67
New value of Q matrix: 11.4637
New value of Value function: 11.4637
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 185
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.63876
New value of Value function: 4.63876
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 186
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 63
New value of Q matrix: 7.19628
New value of Value function: 7.19628
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 187
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 38
New value of Q matrix: 6.19266
New value of Value function: 6.19266
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 188
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 68
New value of Q matrix: 11.5234
New value of Value function: 11.5234
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 189
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 8.02028
New value of Value function: 8.02028
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 190
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 7.73169
New value of Value function: 8.02028
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 191
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 9.23633
New value of Value function: 11.5234
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 192
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 12.4082
New value of Value function: 12.4082
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 193
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 69
New value of Q matrix: 11.5736
New value of Value function: 11.5736
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 194
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 12
New value of Q matrix: 7.65264
New value of Value function: 8.02028
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 195
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 70
New value of Q matrix: 11.6174
New value of Value function: 11.6174
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 196
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 8.00424
New value of Value function: 8.00424
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 197
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 7.98854
New value of Value function: 7.98854
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 198
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 7.97317
New value of Value function: 7.97317
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 199
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 13
New value of Q matrix: 7.61065
New value of Value function: 7.97317
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 200
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 9.39252
New value of Value function: 11.6174
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 201
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 202
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 203
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 204
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 205
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 206
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 207
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 208
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 209
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 11.1938
New value of Value function: 11.1938
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 210
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 7.21846
New value of Value function: 7.21846
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 211
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 39
New value of Q matrix: 6.24207
New value of Value function: 6.24207
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 212
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 71
New value of Q matrix: 11.6502
New value of Value function: 11.6502
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 213
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 7.9581
New value of Value function: 7.9581
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 214
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 7.94332
New value of Value function: 7.94332
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 215
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 7.92882
New value of Value function: 7.92882
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 216
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 5.53356
New value of Value function: 7.92882
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 217
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 5.40426
New value of Value function: 8.22978
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 218
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 7.5464
New value of Value function: 7.5464
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 219
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 7.91458
New value of Value function: 7.92002
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 220
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.29177
New value of Value function: 7.92002
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 221
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.73979
New value of Value function: 3.73979
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 222
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 8.72913
New value of Value function: 8.72913
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 223
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 5.33708
New value of Value function: 7.19628
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 224
----------
State: 6525
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 3.57751
New value of Value function: 3.57751
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 225
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 8.44673
New value of Value function: 8.44673
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 226
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 64
New value of Q matrix: 7.23845
New value of Value function: 7.23845
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 227
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 10.7479
New value of Value function: 11.6502
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 228
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 40
New value of Q matrix: 6.28817
New value of Value function: 6.28817
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 229
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 72
New value of Q matrix: 11.5931
New value of Value function: 11.5931
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 230
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 65
New value of Q matrix: 7.26806
New value of Value function: 7.26806
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 231
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 73
New value of Q matrix: 11.7159
New value of Value function: 11.7159
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 232
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 9.38419
New value of Value function: 9.38419
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 233
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 66
New value of Q matrix: 7.30876
New value of Value function: 7.30876
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 234
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 74
New value of Q matrix: 11.66
New value of Value function: 11.66
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 235
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 67
New value of Q matrix: 7.33743
New value of Value function: 7.33743
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 236
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 75
New value of Q matrix: 11.6143
New value of Value function: 11.6143
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 237
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 68
New value of Q matrix: 7.35692
New value of Value function: 7.35692
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 238
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 76
New value of Q matrix: 11.5763
New value of Value function: 11.5763
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 239
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 69
New value of Q matrix: 7.3694
New value of Value function: 7.3694
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 240
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 10.9962
New value of Value function: 11.5763
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 241
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 77
New value of Q matrix: 11.5444
New value of Value function: 11.5444
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 242
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.1811
New value of Value function: 7.3694
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 243
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 70
New value of Q matrix: 7.37651
New value of Value function: 7.37651
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 244
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 78
New value of Q matrix: 11.1093
New value of Value function: 11.1093
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 245
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 3.98601
New value of Value function: 3.98601
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 246
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 9.92615
New value of Value function: 9.92615
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 247
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 5.72974
New value of Value function: 7.37651
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 248
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 10.3601
New value of Value function: 10.3601
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 249
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 71
New value of Q matrix: 7.35857
New value of Value function: 7.35857
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 250
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 5.89173
New value of Value function: 6.28817
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 251
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 72
New value of Q matrix: 7.34286
New value of Value function: 7.34286
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 252
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 41
New value of Q matrix: 6.2429
New value of Value function: 6.2429
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 253
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 10.2602
New value of Value function: 11.1093
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 254
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.82988
New value of Value function: 12.4082
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 255
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 8.93106
New value of Value function: 12.4082
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 256
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 13.7739
New value of Value function: 13.7739
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 257
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.04326
New value of Value function: 11.2156
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 258
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.37297
New value of Value function: 8.37297
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 259
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 13.1673
New value of Value function: 13.1673
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 260
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.28924
New value of Value function: 8.37297
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 261
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 5.93613
New value of Value function: 8.28924
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 262
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 6.68463
New value of Value function: 6.68463
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 263
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 4
New value of Q matrix: 10.9598
New value of Value function: 13.1673
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 264
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 7.2058
New value of Value function: 7.2058
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 265
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 42
New value of Q matrix: 6.20515
New value of Value function: 6.20515
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 266
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 10.9967
New value of Value function: 11.1093
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 267
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 79
New value of Q matrix: 11.4634
New value of Value function: 11.4634
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 268
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 8.32857
New value of Value function: 10.3601
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 269
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 10.1061
New value of Value function: 10.1061
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 270
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -7
New value of Visit matrix: 6
New value of Q matrix: 2.91487
New value of Value function: 3.61132
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 271
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 8.64065
New value of Value function: 8.64065
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 272
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 73
New value of Q matrix: 7.31948
New value of Value function: 7.31948
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 273
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 43
New value of Q matrix: 6.22705
New value of Value function: 6.22705
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 274
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 80
New value of Q matrix: 11.4391
New value of Value function: 11.4391
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 275
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.28708
New value of Value function: 7.31948
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 276
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 10.4844
New value of Value function: 10.4844
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 277
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 74
New value of Q matrix: 7.32009
New value of Value function: 7.32009
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 278
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 11.072
New value of Value function: 11.4391
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 279
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 81
New value of Q matrix: 11.4178
New value of Value function: 11.4178
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 280
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 75
New value of Q matrix: 7.31819
New value of Value function: 7.31819
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 281
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 82
New value of Q matrix: 10.9934
New value of Value function: 11.072
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 282
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 3.26975
New value of Value function: 3.26975
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 283
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 76
New value of Q matrix: 7.27725
New value of Value function: 7.27725
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 284
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 9.79768
New value of Value function: 11.072
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 285
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 77
New value of Q matrix: 7.26443
New value of Value function: 7.26443
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 286
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 44
New value of Q matrix: 6.18698
New value of Value function: 6.18698
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 287
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 11.0472
New value of Value function: 11.0472
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 288
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 83
New value of Q matrix: 11.3651
New value of Value function: 11.3651
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 289
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.1438
New value of Value function: 10.4844
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 290
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 78
New value of Q matrix: 7.24865
New value of Value function: 7.24865
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 291
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 6.00785
New value of Value function: 6.18698
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 292
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 79
New value of Q matrix: 7.23475
New value of Value function: 7.23475
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 293
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 45
New value of Q matrix: 6.19659
New value of Value function: 6.19659
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 294
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 84
New value of Q matrix: 11.694
New value of Value function: 11.694
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 295
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 10.0932
New value of Value function: 10.0932
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 296
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 3.68752
New value of Value function: 3.68752
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 297
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 10.4481
New value of Value function: 10.4481
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 298
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 80
New value of Q matrix: 7.27303
New value of Value function: 7.27303
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 299
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 85
New value of Q matrix: 11.6405
New value of Value function: 11.6405
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 300
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 81
New value of Q matrix: 7.30092
New value of Value function: 7.30092
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 301
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 86
New value of Q matrix: 11.596
New value of Value function: 11.596
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 302
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.66025
New value of Value function: 7.30092
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 303
----------
State: 6581
	Distance: 8
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 3.34349
New value of Value function: 3.34349
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 304
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 82
New value of Q matrix: 7.28256
New value of Value function: 7.28256
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 305
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 6.08416
New value of Value function: 6.19659
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 306
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 83
New value of Q matrix: 7.30423
New value of Value function: 7.30423
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 307
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 87
New value of Q matrix: 11.8906
New value of Value function: 11.8906
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 308
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 6.95265
New value of Value function: 10.4481
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 309
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 4.09244
New value of Value function: 8.64065
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 310
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 7
New value of Visit matrix: 10
New value of Q matrix: 9.66032
New value of Value function: 9.66032
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 311
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 6.16261
New value of Value function: 7.30423
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 312
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 10.7495
New value of Value function: 10.7495
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 313
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 5.79712
New value of Value function: 7.30423
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 314
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 8.77613
New value of Value function: 8.77613
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 315
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.2035
New value of Value function: 7.30423
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 316
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 84
New value of Q matrix: 7.28573
New value of Value function: 7.28573
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 317
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 46
New value of Q matrix: 6.28138
New value of Value function: 6.28138
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 318
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 88
New value of Q matrix: 11.8183
New value of Value function: 11.8183
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 319
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 85
New value of Q matrix: 7.33068
New value of Value function: 7.33068
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 320
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 89
New value of Q matrix: 12.1176
New value of Value function: 12.1176
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 321
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 11.0008
New value of Value function: 11.0008
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 322
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 86
New value of Q matrix: 7.40247
New value of Value function: 7.40247
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 323
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 90
New value of Q matrix: 12.0344
New value of Value function: 12.0344
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 324
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 87
New value of Q matrix: 7.45732
New value of Value function: 7.45732
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 325
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 91
New value of Q matrix: 11.9661
New value of Value function: 11.9661
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 326
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 88
New value of Q matrix: 7.49881
New value of Value function: 7.49881
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 327
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 92
New value of Q matrix: 11.9096
New value of Value function: 11.9096
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 328
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 89
New value of Q matrix: 7.52972
New value of Value function: 7.52972
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 329
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 93
New value of Q matrix: 11.8624
New value of Value function: 11.8624
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 330
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 90
New value of Q matrix: 7.55229
New value of Value function: 7.55229
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 331
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 11.1992
New value of Value function: 11.8624
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 332
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 10.7181
New value of Value function: 11.8624
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 333
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 12.6455
New value of Value function: 12.6455
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 334
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 94
New value of Q matrix: 12.1747
New value of Value function: 12.1747
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 335
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 11.2434
New value of Value function: 11.2434
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 336
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 91
New value of Q matrix: 7.60477
New value of Value function: 7.60477
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 337
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 95
New value of Q matrix: 12.1085
New value of Value function: 12.1085
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 338
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 92
New value of Q matrix: 7.64466
New value of Value function: 7.64466
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 339
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 96
New value of Q matrix: 12.0533
New value of Value function: 12.0533
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 340
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 93
New value of Q matrix: 7.67454
New value of Value function: 7.67454
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 341
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 97
New value of Q matrix: 12.0071
New value of Value function: 12.0071
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 342
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.36447
New value of Value function: 7.67454
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 343
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 94
New value of Q matrix: 7.69646
New value of Value function: 7.69646
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 344
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 98
New value of Q matrix: 11.9679
New value of Value function: 11.9679
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 345
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 95
New value of Q matrix: 7.71203
New value of Value function: 7.71203
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 346
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 99
New value of Q matrix: 11.9345
New value of Value function: 11.9345
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 347
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 96
New value of Q matrix: 7.66166
New value of Value function: 7.66166
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 348
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 47
New value of Q matrix: 6.35923
New value of Value function: 6.35923
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 349
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 100
New value of Q matrix: 11.8995
New value of Value function: 11.8995
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 350
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 97
New value of Q matrix: 7.67373
New value of Value function: 7.67373
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 351
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 101
New value of Q matrix: 11.8694
New value of Value function: 11.8694
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 352
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 98
New value of Q matrix: 7.68151
New value of Value function: 7.68151
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 353
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 11.3168
New value of Value function: 11.8694
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 354
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 10.8878
New value of Value function: 11.8694
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 355
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 7.37811
New value of Value function: 7.37811
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 356
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 102
New value of Q matrix: 12.1924
New value of Value function: 12.1924
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 357
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 11.4643
New value of Value function: 11.4643
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 358
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 99
New value of Q matrix: 7.7206
New value of Value function: 7.7206
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 359
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 103
New value of Q matrix: 12.1383
New value of Value function: 12.1383
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 360
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 100
New value of Q matrix: 7.75023
New value of Value function: 7.75023
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 361
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 104
New value of Q matrix: 12.0926
New value of Value function: 12.0926
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 362
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 101
New value of Q matrix: 7.70499
New value of Value function: 7.70499
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 363
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 48
New value of Q matrix: 6.44763
New value of Value function: 6.44763
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 364
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 105
New value of Q matrix: 12.0473
New value of Value function: 12.0473
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 365
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 102
New value of Q matrix: 7.72696
New value of Value function: 7.72696
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 366
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 106
New value of Q matrix: 12.0087
New value of Value function: 12.0087
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 367
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 103
New value of Q matrix: 7.74288
New value of Value function: 7.74288
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 368
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 107
New value of Q matrix: 11.9755
New value of Value function: 11.9755
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 369
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 104
New value of Q matrix: 7.75394
New value of Value function: 7.75394
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 370
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 11.4292
New value of Value function: 11.9755
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 371
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 11.005
New value of Value function: 11.9755
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 372
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 12.7669
New value of Value function: 12.7669
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 373
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 108
New value of Q matrix: 11.9467
New value of Value function: 11.9467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 374
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 105
New value of Q matrix: 7.7611
New value of Value function: 7.7611
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 375
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 109
New value of Q matrix: 12.2726
New value of Value function: 12.2726
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 376
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 8.79241
New value of Value function: 11.4643
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 377
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 11.0147
New value of Value function: 12.2726
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 378
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 13.6312
New value of Value function: 13.6312
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 379
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 8
New value of Visit matrix: 42
New value of Q matrix: 14.1058
New value of Value function: 14.1058
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 380
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.81075
New value of Value function: 6.68463
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 381
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 8.77041
New value of Value function: 11.2156
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 382
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 14.4105
New value of Value function: 14.4105
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 383
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 11.2765
New value of Value function: 11.2765
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 384
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 12.3279
New value of Value function: 13.6312
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 385
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 13.0523
New value of Value function: 13.0523
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 386
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.23063
New value of Value function: 8.23063
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 387
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 8.18311
New value of Value function: 8.18311
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 388
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.14219
New value of Value function: 8.14219
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 389
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 8.42895
New value of Value function: 8.42895
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 390
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 13.0709
New value of Value function: 13.0709
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 391
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 11.2048
New value of Value function: 11.2048
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 392
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 13.0745
New value of Value function: 13.0745
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 393
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.96272
New value of Value function: 11.2048
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 394
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 11.1504
New value of Value function: 11.1504
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 395
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 13.0687
New value of Value function: 13.0687
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 396
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 11.107
New value of Value function: 11.107
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 397
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 12.6325
New value of Value function: 12.6325
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 398
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 9.35791
New value of Value function: 9.35791
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 399
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 12.4162
New value of Value function: 12.4162
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 400
----------
State: 6805
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 9.26635
New value of Value function: 9.35791
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 5.33858
New value of Value function: 5.33858
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 5.0704
New value of Value function: 5.33858
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 5.33421
New value of Value function: 5.33421
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 5.14362
New value of Value function: 5.14362
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 5
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.09218
New value of Value function: 2.09218
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 4.96917
New value of Value function: 5.0704
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 7
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 8
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -9
New value of Visit matrix: 1
New value of Q matrix: -9
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 9
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.07126
New value of Value function: 7.07126
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 10
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.92275
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 11
----------
State: 5569
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.0197
New value of Value function: 2.0197
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 5.06552
New value of Value function: 5.06552
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 5.06067
New value of Value function: 5.06067
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 5.05585
New value of Value function: 5.05585
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 5.05105
New value of Value function: 5.05105
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 5.04628
New value of Value function: 5.04706
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 5.04386
New value of Value function: 5.04628
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 5.04153
New value of Value function: 5.04522
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 5.04219
New value of Value function: 5.04442
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 5.04074
New value of Value function: 5.04386
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 5.04067
New value of Value function: 5.04219
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 5.03687
New value of Value function: 5.04219
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 5.03917
New value of Value function: 5.04074
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 5.03708
New value of Value function: 5.04067
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.97089
New value of Value function: 5.04067
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 5.03749
New value of Value function: 5.03917
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 5.03616
New value of Value function: 5.03749
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 5.03431
New value of Value function: 5.03708
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 5.03342
New value of Value function: 5.03687
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 5.03217
New value of Value function: 5.03616
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 5.03316
New value of Value function: 5.03431
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 5.03115
New value of Value function: 5.03342
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 5.02978
New value of Value function: 5.03316
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 5.03016
New value of Value function: 5.03217
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 5.0275
New value of Value function: 5.03115
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 5.02319
New value of Value function: 5.03115
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 5.02799
New value of Value function: 5.03016
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 5.02717
New value of Value function: 5.02978
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 5.02615
New value of Value function: 5.02799
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 5.02484
New value of Value function: 5.02717
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 5.02419
New value of Value function: 5.02615
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 5.02253
New value of Value function: 5.02484
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 5.0217
New value of Value function: 5.02419
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 5.02121
New value of Value function: 5.02319
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 5.01856
New value of Value function: 5.02253
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 5.01893
New value of Value function: 5.0217
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.97093
New value of Value function: 5.0217
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 5.01857
New value of Value function: 5.02121
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 5.01824
New value of Value function: 5.01893
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 5.01533
New value of Value function: 5.01857
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.97073
New value of Value function: 5.01857
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 5.01544
New value of Value function: 5.01856
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 5.01396
New value of Value function: 5.01824
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 5.01528
New value of Value function: 5.01544
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 5.01233
New value of Value function: 5.01533
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.97028
New value of Value function: 5.01533
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 5.01175
New value of Value function: 5.01528
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 5.00843
New value of Value function: 5.01528
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 5.00535
New value of Value function: 5.01528
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 5.0025
New value of Value function: 5.01528
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 5.01232
New value of Value function: 5.01396
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 5.00938
New value of Value function: 5.01233
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 5.00922
New value of Value function: 5.01232
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 5.00938
New value of Value function: 5.00938
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 5.00483
New value of Value function: 5.00938
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 5.00613
New value of Value function: 5.00938
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 5.00643
New value of Value function: 5.00643
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 5.0035
New value of Value function: 5.00613
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 5.00041
New value of Value function: 5.00613
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 5.00304
New value of Value function: 5.0035
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 4.99618
New value of Value function: 5.0035
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 5.00057
New value of Value function: 5.00304
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.9689
New value of Value function: 5.00304
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.99995
New value of Value function: 5.0025
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.99896
New value of Value function: 5.00057
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.99765
New value of Value function: 4.99995
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.99687
New value of Value function: 4.99896
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.99544
New value of Value function: 4.99765
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.99474
New value of Value function: 4.99687
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.9938
New value of Value function: 4.99618
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.96709
New value of Value function: 4.99618
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 4.99169
New value of Value function: 4.99544
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.99192
New value of Value function: 4.99474
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.99183
New value of Value function: 4.9938
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.96524
New value of Value function: 4.9938
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.99074
New value of Value function: 4.99192
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.98842
New value of Value function: 4.99183
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.98893
New value of Value function: 4.99169
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 4.98723
New value of Value function: 4.99074
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.98769
New value of Value function: 4.98893
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.98603
New value of Value function: 4.98842
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.98493
New value of Value function: 4.98769
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.96307
New value of Value function: 4.98769
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.98464
New value of Value function: 4.98723
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 4.98279
New value of Value function: 4.98603
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.98314
New value of Value function: 4.98493
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.98144
New value of Value function: 4.98464
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.9816
New value of Value function: 4.98314
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 4.9784
New value of Value function: 4.98314
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.98026
New value of Value function: 4.9816
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.97798
New value of Value function: 4.9816
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.97857
New value of Value function: 4.98026
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.97739
New value of Value function: 4.97857
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.97456
New value of Value function: 4.97857
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.97555
New value of Value function: 4.9784
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 4.974
New value of Value function: 4.97739
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.96026
New value of Value function: 4.97739
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.97452
New value of Value function: 4.97555
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.97253
New value of Value function: 4.97456
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.97112
New value of Value function: 4.97452
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.96791
New value of Value function: 4.97452
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.97165
New value of Value function: 4.974
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.96961
New value of Value function: 4.974
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 4.96962
New value of Value function: 4.97165
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.9688
New value of Value function: 4.96962
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 4.96526
New value of Value function: 4.96961
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.9646
New value of Value function: 4.96961
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.9666
New value of Value function: 4.9688
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.96595
New value of Value function: 4.9666
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.96104
New value of Value function: 4.9666
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.96361
New value of Value function: 4.96595
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.96311
New value of Value function: 4.9646
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.96118
New value of Value function: 4.96361
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.96062
New value of Value function: 4.96311
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.96027
New value of Value function: 4.96118
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.95777
New value of Value function: 4.96104
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.95672
New value of Value function: 4.96062
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.95764
New value of Value function: 4.96027
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.95635
New value of Value function: 4.96027
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.95744
New value of Value function: 4.95777
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.95438
New value of Value function: 4.95764
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.95467
New value of Value function: 4.95744
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.95461
New value of Value function: 4.95672
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.95242
New value of Value function: 4.95635
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.95246
New value of Value function: 4.95467
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.9517
New value of Value function: 4.95461
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.95179
New value of Value function: 4.95438
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.95099
New value of Value function: 4.95246
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.94902
New value of Value function: 4.95246
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.94858
New value of Value function: 4.95242
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 4.94814
New value of Value function: 4.9517
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.94874
New value of Value function: 4.95099
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.94413
New value of Value function: 4.95099
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.94761
New value of Value function: 4.94902
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.94621
New value of Value function: 4.94874
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.94579
New value of Value function: 4.94858
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.94354
New value of Value function: 4.94858
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.94301
New value of Value function: 4.94858
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.94472
New value of Value function: 4.94761
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.94425
New value of Value function: 4.94472
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.94087
New value of Value function: 4.94425
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.94089
New value of Value function: 4.94413
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.93776
New value of Value function: 4.94413
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.93989
New value of Value function: 4.94354
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.94075
New value of Value function: 4.94301
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.93477
New value of Value function: 4.94301
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.9372
New value of Value function: 4.94301
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.93809
New value of Value function: 4.94301
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.94007
New value of Value function: 4.94007
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.9318
New value of Value function: 4.94007
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.93714
New value of Value function: 4.93989
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.93567
New value of Value function: 4.93809
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.93531
New value of Value function: 4.9372
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.93338
New value of Value function: 4.93714
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.93422
New value of Value function: 4.93567
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.93146
New value of Value function: 4.93531
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.93253
New value of Value function: 4.93422
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.9313
New value of Value function: 4.93338
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.92957
New value of Value function: 4.93253
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.92976
New value of Value function: 4.9318
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.92842
New value of Value function: 4.9318
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.92848
New value of Value function: 4.93146
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.92728
New value of Value function: 4.92976
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.92332
New value of Value function: 4.92976
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.927
New value of Value function: 4.92957
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.92578
New value of Value function: 4.92848
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.92221
New value of Value function: 4.92848
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.92518
New value of Value function: 4.92842
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.92551
New value of Value function: 4.927
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.9227
New value of Value function: 4.927
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.92424
New value of Value function: 4.92518
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.91995
New value of Value function: 4.92518
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.92188
New value of Value function: 4.92424
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.92148
New value of Value function: 4.92332
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.91918
New value of Value function: 4.92221
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.91844
New value of Value function: 4.92188
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.91876
New value of Value function: 4.92188
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.91859
New value of Value function: 4.91995
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.91707
New value of Value function: 4.91918
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.91505
New value of Value function: 4.91876
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.91429
New value of Value function: 4.91876
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.91125
New value of Value function: 4.91876
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.91602
New value of Value function: 4.91859
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.91531
New value of Value function: 4.91844
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.91469
New value of Value function: 4.91602
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.91328
New value of Value function: 4.91531
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.90749
New value of Value function: 4.91531
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.91148
New value of Value function: 4.91531
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.91066
New value of Value function: 4.91531
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.9082
New value of Value function: 4.91531
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.90884
New value of Value function: 4.91531
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.91204
New value of Value function: 4.91469
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.90895
New value of Value function: 4.91469
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.91096
New value of Value function: 4.91096
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.90723
New value of Value function: 4.90895
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.9057
New value of Value function: 4.90884
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.90598
New value of Value function: 4.9082
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.90359
New value of Value function: 4.9082
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.90548
New value of Value function: 4.90749
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.90341
New value of Value function: 4.90598
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.90248
New value of Value function: 4.90598
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.89957
New value of Value function: 4.90598
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.90279
New value of Value function: 4.90598
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.90313
New value of Value function: 4.90359
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.8999
New value of Value function: 4.90313
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.90028
New value of Value function: 4.90279
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.90008
New value of Value function: 4.90248
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.89925
New value of Value function: 4.90028
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.89744
New value of Value function: 4.90008
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.89738
New value of Value function: 4.8999
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 4.89622
New value of Value function: 4.89957
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.89553
New value of Value function: 4.89925
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.89602
New value of Value function: 4.89744
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.89264
New value of Value function: 4.89744
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.89461
New value of Value function: 4.89738
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.89469
New value of Value function: 4.89602
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.89281
New value of Value function: 4.89553
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.8915
New value of Value function: 4.89469
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.892
New value of Value function: 4.89461
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.89178
New value of Value function: 4.89281
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.8896
New value of Value function: 4.89264
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.88898
New value of Value function: 4.892
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.88931
New value of Value function: 4.89178
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.88896
New value of Value function: 4.8915
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.88749
New value of Value function: 4.8896
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.88641
New value of Value function: 4.88931
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.88663
New value of Value function: 4.88898
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.88409
New value of Value function: 4.88898
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.88534
New value of Value function: 4.88896
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.88615
New value of Value function: 4.88749
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.8835
New value of Value function: 4.88641
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.88322
New value of Value function: 4.88615
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.88176
New value of Value function: 4.88615
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.88334
New value of Value function: 4.88409
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.88142
New value of Value function: 4.8835
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.87827
New value of Value function: 4.8835
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.87953
New value of Value function: 4.88334
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.88054
New value of Value function: 4.88322
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.88004
New value of Value function: 4.88142
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.87875
New value of Value function: 4.88054
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.87775
New value of Value function: 4.88004
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.87687
New value of Value function: 4.87953
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.87557
New value of Value function: 4.87875
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.87188
New value of Value function: 4.87875
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.8761
New value of Value function: 4.87827
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.87467
New value of Value function: 4.87775
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.87353
New value of Value function: 4.87775
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.86843
New value of Value function: 4.87775
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.87496
New value of Value function: 4.87687
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.87371
New value of Value function: 4.87496
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.87218
New value of Value function: 4.87467
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.87107
New value of Value function: 4.87371
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.87056
New value of Value function: 4.87353
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.86948
New value of Value function: 4.87353
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.87089
New value of Value function: 4.87107
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.86473
New value of Value function: 4.87107
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.86749
New value of Value function: 4.87089
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.86824
New value of Value function: 4.87056
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.86741
New value of Value function: 4.86948
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.86671
New value of Value function: 4.86824
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.86403
New value of Value function: 4.86824
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.86561
New value of Value function: 4.86749
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.86147
New value of Value function: 4.86749
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.86392
New value of Value function: 4.86741
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.86428
New value of Value function: 4.86561
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.85895
New value of Value function: 4.86561
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.86298
New value of Value function: 4.86473
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.86083
New value of Value function: 4.86428
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.86115
New value of Value function: 4.86392
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.86037
New value of Value function: 4.86298
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.86035
New value of Value function: 4.86115
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.85688
New value of Value function: 4.86115
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.85803
New value of Value function: 4.86083
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.85695
New value of Value function: 4.86035
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.85773
New value of Value function: 4.85895
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.8562
New value of Value function: 4.85803
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.85343
New value of Value function: 4.85803
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.85513
New value of Value function: 4.85803
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.85492
New value of Value function: 4.85695
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.85309
New value of Value function: 4.8562
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.85346
New value of Value function: 4.85513
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.85252
New value of Value function: 4.85492
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.85182
New value of Value function: 4.85346
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.85072
New value of Value function: 4.85343
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.84991
New value of Value function: 4.85309
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.84924
New value of Value function: 4.85252
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.84992
New value of Value function: 4.85182
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.84873
New value of Value function: 4.85072
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.848
New value of Value function: 4.84992
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.84732
New value of Value function: 4.84991
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.84538
New value of Value function: 4.84991
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.84486
New value of Value function: 4.84991
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.8464
New value of Value function: 4.84924
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.84288
New value of Value function: 4.84924
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.84052
New value of Value function: 4.84924
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.8425
New value of Value function: 4.84924
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.84541
New value of Value function: 4.84873
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.83827
New value of Value function: 4.84873
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 4.84564
New value of Value function: 4.8464
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.84261
New value of Value function: 4.8464
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.8429
New value of Value function: 4.84541
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.84159
New value of Value function: 4.8429
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.83941
New value of Value function: 4.84261
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 4.83954
New value of Value function: 4.8425
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.83992
New value of Value function: 4.84159
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.83778
New value of Value function: 4.83992
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.83734
New value of Value function: 4.83954
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 4.83648
New value of Value function: 4.83941
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.83487
New value of Value function: 4.83941
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.83254
New value of Value function: 4.83941
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.83412
New value of Value function: 4.83941
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.83594
New value of Value function: 4.83827
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.83557
New value of Value function: 4.83648
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.83018
New value of Value function: 4.83648
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 4.83343
New value of Value function: 4.83594
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.83248
New value of Value function: 4.83557
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.83287
New value of Value function: 4.83412
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.83035
New value of Value function: 4.83343
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.82909
New value of Value function: 4.83343
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 4.83039
New value of Value function: 4.83287
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.83018
New value of Value function: 4.83039
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 4.82735
New value of Value function: 4.83035
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.82659
New value of Value function: 4.83018
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.82762
New value of Value function: 4.83018
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 4.8245
New value of Value function: 4.83018
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.8275
New value of Value function: 4.82909
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.82515
New value of Value function: 4.82909
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.82565
New value of Value function: 4.8275
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.82482
New value of Value function: 4.82659
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.82284
New value of Value function: 4.82565
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.82222
New value of Value function: 4.82515
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.82217
New value of Value function: 4.82515
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.81966
New value of Value function: 4.82515
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.8226
New value of Value function: 4.8245
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 4.82147
New value of Value function: 4.82284
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.81911
New value of Value function: 4.8226
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.82005
New value of Value function: 4.82222
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.8188
New value of Value function: 4.82147
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 4.81846
New value of Value function: 4.82005
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.81751
New value of Value function: 4.81966
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.817
New value of Value function: 4.81911
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.81539
New value of Value function: 4.8188
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.8154
New value of Value function: 4.81846
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 4.81546
New value of Value function: 4.81751
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.81437
New value of Value function: 4.81751
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.81497
New value of Value function: 4.81546
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.81246
New value of Value function: 4.8154
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.812
New value of Value function: 4.81539
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.81168
New value of Value function: 4.81497
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.81244
New value of Value function: 4.81437
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.81172
New value of Value function: 4.81246
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.80805
New value of Value function: 4.81246
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.80947
New value of Value function: 4.81244
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.80992
New value of Value function: 4.812
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.80468
New value of Value function: 4.812
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.80861
New value of Value function: 4.81172
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.80908
New value of Value function: 4.80992
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.8074
New value of Value function: 4.80947
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.80648
New value of Value function: 4.80908
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.80644
New value of Value function: 4.80861
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.80524
New value of Value function: 4.8074
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.80488
New value of Value function: 4.80648
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 4.80351
New value of Value function: 4.80644
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.80196
New value of Value function: 4.80644
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.80245
New value of Value function: 4.80644
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.80381
New value of Value function: 4.80468
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.80101
New value of Value function: 4.80381
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.79757
New value of Value function: 4.80381
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.80056
New value of Value function: 4.80381
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.80118
New value of Value function: 4.80245
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.79864
New value of Value function: 4.80245
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.79994
New value of Value function: 4.80118
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.79855
New value of Value function: 4.80056
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.79747
New value of Value function: 4.80056
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.79604
New value of Value function: 4.80056
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.7976
New value of Value function: 4.79864
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.7953
New value of Value function: 4.7976
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.79465
New value of Value function: 4.79757
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.79393
New value of Value function: 4.79747
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.79497
New value of Value function: 4.79604
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.79201
New value of Value function: 4.79604
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.79343
New value of Value function: 4.79497
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.78889
New value of Value function: 4.79497
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.79248
New value of Value function: 4.79465
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.7917
New value of Value function: 4.79393
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.79007
New value of Value function: 4.79393
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.79031
New value of Value function: 4.79343
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.79082
New value of Value function: 4.7917
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.78876
New value of Value function: 4.79082
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.78822
New value of Value function: 4.79031
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.7867
New value of Value function: 4.79007
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.78758
New value of Value function: 4.78889
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.78566
New value of Value function: 4.78889
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.78558
New value of Value function: 4.78876
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.78583
New value of Value function: 4.78758
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.78511
New value of Value function: 4.7867
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 4.7831
New value of Value function: 4.78583
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.78267
New value of Value function: 4.78583
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.77972
New value of Value function: 4.78583
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.78291
New value of Value function: 4.78566
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.78307
New value of Value function: 4.78558
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.78228
New value of Value function: 4.78307
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.78048
New value of Value function: 4.78291
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.77999
New value of Value function: 4.78267
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.7802
New value of Value function: 4.78228
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.77634
New value of Value function: 4.78228
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.77899
New value of Value function: 4.78048
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.7779
New value of Value function: 4.7802
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.7771
New value of Value function: 4.7802
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.77773
New value of Value function: 4.77899
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.77571
New value of Value function: 4.7779
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.77533
New value of Value function: 4.77773
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.77288
New value of Value function: 4.77773
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.77527
New value of Value function: 4.7771
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.77419
New value of Value function: 4.77634
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.77278
New value of Value function: 4.77571
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.76944
New value of Value function: 4.77571
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.77243
New value of Value function: 4.77527
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.77282
New value of Value function: 4.77419
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.7713
New value of Value function: 4.77288
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.77032
New value of Value function: 4.77282
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.77037
New value of Value function: 4.77243
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.76848
New value of Value function: 4.77243
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.76802
New value of Value function: 4.77243
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.76917
New value of Value function: 4.77032
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.7657
New value of Value function: 4.77032
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.76776
New value of Value function: 4.76944
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.76591
New value of Value function: 4.76917
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.76592
New value of Value function: 4.76848
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.7656
New value of Value function: 4.76776
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.76285
New value of Value function: 4.76776
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.7652
New value of Value function: 4.76592
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.76269
New value of Value function: 4.76592
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.76268
New value of Value function: 4.76591
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.76239
New value of Value function: 4.7657
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.7603
New value of Value function: 4.7657
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.76326
New value of Value function: 4.76326
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.76082
New value of Value function: 4.76285
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.75999
New value of Value function: 4.76268
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.75849
New value of Value function: 4.76268
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.75944
New value of Value function: 4.76239
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.75626
New value of Value function: 4.76239
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.75888
New value of Value function: 4.7603
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.75776
New value of Value function: 4.75999
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.75713
New value of Value function: 4.75944
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.75622
New value of Value function: 4.75888
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.75538
New value of Value function: 4.75776
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.75523
New value of Value function: 4.75713
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.75279
New value of Value function: 4.75713
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.75427
New value of Value function: 4.75626
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.75384
New value of Value function: 4.75622
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.753
New value of Value function: 4.75538
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.75189
New value of Value function: 4.75427
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.75143
New value of Value function: 4.75384
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.75142
New value of Value function: 4.753
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.7498
New value of Value function: 4.75279
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.75027
New value of Value function: 4.75189
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.74841
New value of Value function: 4.75143
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.74901
New value of Value function: 4.75143
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.74859
New value of Value function: 4.75027
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.74664
New value of Value function: 4.75027
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.74775
New value of Value function: 4.74901
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.7466
New value of Value function: 4.74859
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.74576
New value of Value function: 4.74841
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.74495
New value of Value function: 4.74775
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.74523
New value of Value function: 4.74664
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.74345
New value of Value function: 4.7466
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.7442
New value of Value function: 4.74576
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.74188
New value of Value function: 4.74576
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.74293
New value of Value function: 4.74523
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.74272
New value of Value function: 4.74495
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.7415
New value of Value function: 4.74345
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.74027
New value of Value function: 4.74293
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.74011
New value of Value function: 4.74272
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.73953
New value of Value function: 4.74272
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.73815
New value of Value function: 4.74272
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.74021
New value of Value function: 4.74027
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.73731
New value of Value function: 4.74027
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.73717
New value of Value function: 4.74027
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.73468
New value of Value function: 4.74027
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.73711
New value of Value function: 4.74021
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.73415
New value of Value function: 4.74021
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.73771
New value of Value function: 4.73815
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.73472
New value of Value function: 4.73771
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.73205
New value of Value function: 4.73771
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.73481
New value of Value function: 4.73771
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.72959
New value of Value function: 4.73771
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.73124
New value of Value function: 4.73771
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.73521
New value of Value function: 4.73521
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.72713
New value of Value function: 4.73521
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.73272
New value of Value function: 4.73481
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.73131
New value of Value function: 4.73481
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 4.73243
New value of Value function: 4.73272
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.73007
New value of Value function: 4.73272
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.73023
New value of Value function: 4.73131
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.7279
New value of Value function: 4.73124
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.7281
New value of Value function: 4.73023
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.7277
New value of Value function: 4.73023
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.72511
New value of Value function: 4.73023
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.72775
New value of Value function: 4.7279
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.72451
New value of Value function: 4.72775
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.72527
New value of Value function: 4.7277
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.72533
New value of Value function: 4.72713
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.72435
New value of Value function: 4.72533
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.72297
New value of Value function: 4.72527
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.7228
New value of Value function: 4.72511
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.72198
New value of Value function: 4.72451
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.72113
New value of Value function: 4.72435
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.72158
New value of Value function: 4.72297
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 4.7206
New value of Value function: 4.7228
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.72033
New value of Value function: 4.72198
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.71887
New value of Value function: 4.72158
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.71881
New value of Value function: 4.72113
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.71775
New value of Value function: 4.7206
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.71825
New value of Value function: 4.72033
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.71787
New value of Value function: 4.71887
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.71577
New value of Value function: 4.71881
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.71605
New value of Value function: 4.71825
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.71589
New value of Value function: 4.71787
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.7134
New value of Value function: 4.71787
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.71541
New value of Value function: 4.71775
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.7109
New value of Value function: 4.71775
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.71364
New value of Value function: 4.71775
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.7128
New value of Value function: 4.71775
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 233
New value of Q matrix: 4.81944
New value of Value function: 4.81944
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 136
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.3708
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 137
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 138
----------
State: 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 139
----------
State: 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 140
----------
State: 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 141
----------
State: 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 142
----------
State: 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 143
----------
State: 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 144
----------
State: 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 145
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 146
----------
State: 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 147
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 148
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 149
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 150
----------
State: 6633
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.85788
New value of Value function: 7.85788
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 151
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 152
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 153
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 154
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 155
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 156
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 157
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 2.97
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 158
----------
State: 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.42982
New value of Value function: 6.42982
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 159
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 160
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 161
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 162
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 163
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 164
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2869
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 165
----------
State: 2869
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3653
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 166
----------
State: 3653
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3709
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 167
----------
State: 3709
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 168
----------
State: 4441
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4497
	Distance: 5
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 169
----------
State: 4497
	Distance: 5
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5229
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 170
----------
State: 5229
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 12.8505
New value of Value function: 12.8505
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 171
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 8.36552
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 172
----------
State: 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 7.25005
New value of Value function: 7.25005
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 173
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 174
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.99
New value of Value function: 5.99
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 175
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.6215
New value of Value function: 7.6215
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 176
----------
State: 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3597
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 177
----------
State: 3597
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4333
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 178
----------
State: 4333
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.17755
New value of Value function: 2.17755
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 179
----------
State: 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.09008
New value of Value function: 8.09008
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 180
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.9301
New value of Value function: 5.99
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 181
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.8505
New value of Value function: 5.99
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 182
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 10.44
New value of Value function: 10.44
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 183
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.69737
New value of Value function: 5.9301
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 184
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 10.3356
New value of Value function: 10.44
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 185
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.6327
New value of Value function: 10.6327
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 186
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 5.32841
New value of Value function: 5.9301
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 187
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.7299
New value of Value function: 10.7299
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 188
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.88817
New value of Value function: 5.88817
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 189
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.85417
New value of Value function: 5.85417
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 190
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.8249
New value of Value function: 5.8249
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 191
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.79885
New value of Value function: 5.79885
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 192
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.77518
New value of Value function: 5.77518
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 193
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.75335
New value of Value function: 5.75335
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 194
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4445
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5.75335
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 195
----------
State: 4445
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.69582
New value of Value function: 8.69582
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 196
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.73301
New value of Value function: 5.73301
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 197
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 5.7139
New value of Value function: 5.7139
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 198
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 5.69583
New value of Value function: 5.69737
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 199
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 5.40042
New value of Value function: 5.69583
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 200
----------
State: 3657
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4385
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 201
----------
State: 4385
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.51131
New value of Value function: 2.51131
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 202
----------
State: 5173
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 10.6955
New value of Value function: 10.6955
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 203
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.67866
New value of Value function: 5.67866
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 204
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.00917
New value of Value function: 5.67866
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 205
----------
State: 5117
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 8.3279
New value of Value function: 8.3279
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 206
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 5.66226
New value of Value function: 5.66226
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 207
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.64656
New value of Value function: 5.64656
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 208
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.63147
New value of Value function: 5.63147
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 209
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 5.61693
New value of Value function: 5.61693
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 210
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 5.60289
New value of Value function: 5.60289
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 211
----------
State: 4389
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.10092
New value of Value function: 8.10092
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 212
----------
State: 3601
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.96586
New value of Value function: 8.96586
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 213
----------
State: 2813
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1909
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 75.0177
New value of Value function: 75.0177
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 214
----------
State: 1909
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1910
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 99.4142
New value of Value function: 99.4142
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 234
New value of Q matrix: 5.15814
New value of Value function: 5.15814
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 2
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.56068
New value of Value function: 3.56068
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.74545
New value of Value function: 5.15814
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 5.15477
New value of Value function: 5.15477
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.73374
New value of Value function: 5.15477
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 236
New value of Q matrix: 5.33673
New value of Value function: 5.33673
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 7
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 8
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 9
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.825498
New value of Value function: 0.825498
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 10
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 11
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 12
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 13
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 14
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 15
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 16
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 17
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 18
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 19
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 20
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6577
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 1.50756
New value of Value function: 1.50756
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 21
----------
State: 6577
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 22
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 23
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 24
----------
State: 7529
	Distance: 9
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.303798
New value of Value function: 0.303798
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 25
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 1.80925
New value of Value function: 1.80925
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 26
----------
State: 8369
	Distance: 10
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.30641
New value of Value function: 5.30641
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 27
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 28
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 29
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 30
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 31
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 32
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.73346
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 33
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 2.93735
New value of Value function: 2.93735
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 34
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 35
----------
State: 6801
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.739643
New value of Value function: -0.739643
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 36
----------
State: 7585
	Distance: 9
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 4.54335
New value of Value function: 4.54335
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 37
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 8.18413
New value of Value function: 8.18413
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 38
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.5032
New value of Value function: 1.5032
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 39
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.49904
New value of Value function: 1.49904
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 40
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.49503
New value of Value function: 1.49503
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 41
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.49117
New value of Value function: 1.49117
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 42
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.48744
New value of Value function: 1.48744
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 43
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.28336
New value of Value function: 2.28336
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 237
New value of Q matrix: 5.37786
New value of Value function: 5.37786
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 45
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.47184
New value of Value function: 3.47184
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 46
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2.80871
New value of Value function: 2.80871
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 47
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.977869
New value of Value function: 1.48744
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 48
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.62623
New value of Value function: 4.62623
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 49
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 2.80871
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 50
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.23853
New value of Value function: 5.23853
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 51
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 5.14249
New value of Value function: 5.14249
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 52
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.0956439
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 53
----------
State: 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 54
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 55
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 56
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 57
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.651
New value of Value function: 2.651
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 58
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.37551
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 59
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.31224
New value of Value function: 2.651
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 60
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.00719
New value of Value function: 4.00719
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 61
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.52743
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 62
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.48383
New value of Value function: 1.48383
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 63
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.48034
New value of Value function: 1.48034
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 64
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.47694
New value of Value function: 1.47694
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 65
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 66
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 67
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 68
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 69
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 70
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 71
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 72
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 73
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 74
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 75
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 76
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: -2.90893
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 77
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 8
New value of Visit matrix: 6
New value of Q matrix: 6.30906
New value of Value function: 6.30906
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 78
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -8
New value of Visit matrix: 2
New value of Q matrix: -2.09229
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 79
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.57125
New value of Value function: 6.30906
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 80
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.474922
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 81
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.39167
New value of Value function: 4.39167
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 82
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.652243
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 83
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.69584
New value of Value function: 4.69584
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 84
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 85
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 86
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 87
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 88
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.106512
New value of Value function: 0.106512
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 238
New value of Q matrix: 5.54459
New value of Value function: 5.54459
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 90
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.24613
New value of Value function: 2.24613
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 91
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.29783
New value of Value function: 1.29783
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 239
New value of Q matrix: 5.6807
New value of Value function: 5.6807
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 93
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.40646
New value of Value function: 5.40646
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 94
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.89086
New value of Value function: 1.89086
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 240
New value of Q matrix: 5.6285
New value of Value function: 5.6285
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 96
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.16902
New value of Value function: 2.16902
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 241
New value of Q matrix: 5.6505
New value of Value function: 5.6505
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 98
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -1.85267
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 99
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 2.32965
New value of Value function: 2.32965
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.80576
New value of Value function: 5.6505
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 5.64687
New value of Value function: 5.64687
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 243
New value of Q matrix: 5.66759
New value of Value function: 5.66759
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 103
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 104
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 105
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 106
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 107
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.8108
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 108
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 109
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 110
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 111
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 112
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 113
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 114
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8985
	Distance: 11
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.90998
New value of Value function: 3.90998
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 115
----------
State: 8985
	Distance: 11
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.87088
New value of Value function: 10.6359
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 116
----------
State: 7417
	Distance: 9
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 3.90998
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 117
----------
State: 7473
	Distance: 9
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.10228
New value of Value function: 3.10228
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 118
----------
State: 9041
	Distance: 11
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.5629
New value of Value function: 10.5629
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 119
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 11
New value of Q matrix: 7.61082
New value of Value function: 7.61082
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 120
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 110
New value of Q matrix: 12.2165
New value of Value function: 12.2165
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 121
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.03385
New value of Value function: 7.7611
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 122
----------
State: 7361
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.26965
New value of Value function: 2.26965
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 123
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.5036
New value of Value function: 4.5036
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 124
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 125
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 126
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 127
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 128
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 129
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 130
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 131
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 132
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 133
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.33252
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 134
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.977801
New value of Value function: 2.24613
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 135
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.66869
New value of Value function: 1.66869
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 136
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 6.74353
New value of Value function: 6.74353
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 137
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.71932
New value of Value function: 4.5036
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 138
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.7256
New value of Value function: 4.7256
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 139
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 140
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 141
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 142
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 143
----------
State: 6521
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -1.34026
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 144
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.33435
New value of Value function: 3.33435
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 145
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 146
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 147
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.699
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 148
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.07925
New value of Value function: 4.07925
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 149
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 150
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -9
New value of Visit matrix: 2
New value of Q matrix: -3.12188
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 151
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.18209
New value of Value function: 6.18209
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 152
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 2.42909
New value of Value function: 2.42909
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 244
New value of Q matrix: 5.49682
New value of Value function: 5.49682
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 154
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 155
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 156
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 157
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 158
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 159
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.17754
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 160
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.45514
New value of Value function: 4.45514
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 161
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 162
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.837981
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 163
----------
State: 6465
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.66108
New value of Value function: 4.66108
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 164
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -3.76402
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 165
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 2.43334
New value of Value function: 2.43334
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 245
New value of Q matrix: 5.3373
New value of Value function: 5.3373
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 167
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 168
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.29589
New value of Value function: 1.29589
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 169
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -9
New value of Visit matrix: 1
New value of Q matrix: -6.59099
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 170
----------
State: 5625
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 2.3861
New value of Value function: 2.3861
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 246
New value of Q matrix: 5.18828
New value of Value function: 5.18828
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 172
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -1.73691
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 173
----------
State: 5681
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.14795
New value of Value function: 3.14795
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 174
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 175
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 176
----------
State: 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 177
----------
State: 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 178
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -5.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 179
----------
State: 5737
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.85788
New value of Value function: 4.85788
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 180
----------
State: 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 3.07107
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 181
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 182
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 183
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 184
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 1.07911
New value of Value function: 1.07911
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 185
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 2.06832
New value of Value function: 2.97
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 186
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: -3.00802
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 187
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 188
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.53553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 189
----------
State: 6689
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 190
----------
State: 5905
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 191
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5061
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 192
----------
State: 5061
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 193
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 194
----------
State: 5793
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5005
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 195
----------
State: 5005
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4949
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 196
----------
State: 4949
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.07493
New value of Value function: 3.07493
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 197
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4053
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 198
----------
State: 4053
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4053
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 199
----------
State: 4053
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4053
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 200
----------
State: 4053
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.1364
New value of Value function: 2.1364
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 247
New value of Q matrix: 5.14577
New value of Value function: 5.14577
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 202
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4949
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 1.25185
New value of Value function: 1.25185
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 203
----------
State: 4949
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5005
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 3.07493
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 204
----------
State: 5005
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 205
----------
State: 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 206
----------
State: 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 207
----------
State: 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 208
----------
State: 4221
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 209
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2481
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 210
----------
State: 2481
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 211
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3.99
New value of Value function: 3.99
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 212
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 213
----------
State: 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.09431
New value of Value function: 2.09431
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 248
New value of Q matrix: 5.26035
New value of Value function: 5.26035
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 215
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3.99
New value of Value function: 3.99
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 216
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 2.19706
New value of Value function: 2.19706
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 217
----------
State: 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.17452
New value of Value function: 2.17452
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 249
New value of Q matrix: 5.1171
New value of Value function: 5.1171
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 219
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -1.84722
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 220
----------
State: 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.11183
New value of Value function: 2.11183
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 250
New value of Q matrix: 4.98321
New value of Value function: 4.98321
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 222
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.0499
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 223
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.67421
New value of Value function: 4.67421
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 224
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.17509
New value of Value function: 2.19706
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 225
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.62747
New value of Value function: 2.19706
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 226
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.62747
New value of Value function: 4.67421
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 227
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 228
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.93337
New value of Value function: 1.93337
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 251
New value of Q matrix: 4.97884
New value of Value function: 4.97884
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 230
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.93032
New value of Value function: 1.93032
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 252
New value of Q matrix: 4.97457
New value of Value function: 4.97457
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 232
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.92714
New value of Value function: 1.92714
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 253
New value of Q matrix: 4.97037
New value of Value function: 4.97037
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 234
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 235
----------
State: 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.92067
New value of Value function: 1.92067
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 254
New value of Q matrix: 4.97792
New value of Value function: 4.97792
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 237
----------
State: 2477
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.01999
New value of Value function: 2.01999
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 255
New value of Q matrix: 5.04005
New value of Value function: 5.04005
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 239
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.34454
New value of Value function: 4.34454
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 240
----------
State: 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.90146
New value of Value function: 1.92067
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 241
----------
State: 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2645
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 242
----------
State: 2645
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.98965
New value of Value function: 1.98965
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 256
New value of Q matrix: 4.91255
New value of Value function: 4.91255
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 244
----------
State: 2529
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2473
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 245
----------
State: 2473
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.17509
New value of Value function: 1.17509
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 246
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.58853
New value of Value function: 4.58853
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 247
----------
State: 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.30109
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 248
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.71142
New value of Value function: 4.71142
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 249
----------
State: 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 1.92067
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 250
----------
State: 3429
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 251
----------
State: 3373
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.66431
New value of Value function: 6.66431
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 252
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.80644
New value of Value function: 4.80644
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 253
----------
State: 2589
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.88019
New value of Value function: 1.90146
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.74128
New value of Value function: 4.91255
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 257
New value of Q matrix: 4.79325
New value of Value function: 4.80576
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 256
----------
State: 2529
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 4.59766
New value of Value function: 4.59766
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 257
----------
State: 3373
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.73083
New value of Value function: 6.73083
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 258
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.75838
New value of Value function: 4.80644
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 259
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.75838
New value of Value function: 4.80644
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 260
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.49041
New value of Value function: 4.80644
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 261
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 5.55892
New value of Value function: 5.55892
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 262
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.65257
New value of Value function: 4.80644
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 263
----------
State: 3377
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 6.04859
New value of Value function: 6.04859
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 264
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.74252
New value of Value function: 4.75838
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 265
----------
State: 3373
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.71926
New value of Value function: 6.71926
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 266
----------
State: 2533
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.84242
New value of Value function: 4.75838
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.80235
New value of Value function: 4.80235
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.79895
New value of Value function: 4.79895
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.71726
New value of Value function: 4.79895
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.79557
New value of Value function: 4.79557
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.79041
New value of Value function: 4.79557
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.71533
New value of Value function: 4.79557
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.7922
New value of Value function: 4.7922
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.71676
New value of Value function: 4.7922
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.78883
New value of Value function: 4.79041
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.71857
New value of Value function: 4.79041
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.78743
New value of Value function: 4.78883
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.78548
New value of Value function: 4.78743
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.78446
New value of Value function: 4.78548
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.78214
New value of Value function: 4.78446
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3265
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 371
New value of Q matrix: 4.62935
New value of Value function: 4.78446
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 282
----------
State: 3265
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 0.239332
New value of Value function: 0.239332
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 283
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 3.11593
New value of Value function: 3.11593
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 284
----------
State: 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 285
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.91523
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 286
----------
State: 4109
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3269
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: -0.464466
New value of Value function: 3.11593
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 287
----------
State: 3269
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.73662
New value of Value function: 1.73662
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3325
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 261
New value of Q matrix: 4.674
New value of Value function: 4.78214
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 289
----------
State: 3325
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 4.8805
New value of Value function: 4.8805
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 290
----------
State: 4165
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 291
----------
State: 3321
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2481
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.17157
New value of Value function: 4.67421
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 292
----------
State: 2481
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.73432
New value of Value function: 1.73432
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.77881
New value of Value function: 4.77881
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.74068
New value of Value function: 4.77881
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.77548
New value of Value function: 4.77548
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.63445
New value of Value function: 4.77548
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.77217
New value of Value function: 4.77217
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.73974
New value of Value function: 4.77217
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.76887
New value of Value function: 4.76887
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.76558
New value of Value function: 4.76558
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.71682
New value of Value function: 4.76558
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.73848
New value of Value function: 4.76558
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.7623
New value of Value function: 4.7623
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.67652
New value of Value function: 4.7623
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.75903
New value of Value function: 4.75903
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.75577
New value of Value function: 4.75577
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.63827
New value of Value function: 4.75577
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.75252
New value of Value function: 4.75252
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.64172
New value of Value function: 4.75252
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.74928
New value of Value function: 4.74928
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.71608
New value of Value function: 4.74928
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.74604
New value of Value function: 4.74604
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.74282
New value of Value function: 4.74282
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.73961
New value of Value function: 4.73961
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.73581
New value of Value function: 4.73961
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.73641
New value of Value function: 4.73641
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.73321
New value of Value function: 4.73581
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.73308
New value of Value function: 4.73321
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.73003
New value of Value function: 4.73308
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.71458
New value of Value function: 4.73308
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.73036
New value of Value function: 4.73036
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.72764
New value of Value function: 4.73003
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.72686
New value of Value function: 4.72764
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.64371
New value of Value function: 4.72764
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.72374
New value of Value function: 4.72764
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.72493
New value of Value function: 4.72493
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.72222
New value of Value function: 4.72374
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.71269
New value of Value function: 4.72374
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.72059
New value of Value function: 4.72222
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.71952
New value of Value function: 4.72059
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.71744
New value of Value function: 4.71952
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.71683
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.64508
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.71418
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.7106
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.64638
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.67613
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.64761
New value of Value function: 4.71744
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.7143
New value of Value function: 4.7143
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.71117
New value of Value function: 4.71418
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.71149
New value of Value function: 4.71149
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.70882
New value of Value function: 4.71117
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.70628
New value of Value function: 4.71117
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.70805
New value of Value function: 4.7106
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.70827
New value of Value function: 4.70827
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.70595
New value of Value function: 4.70805
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.70494
New value of Value function: 4.70628
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.70362
New value of Value function: 4.70595
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.67507
New value of Value function: 4.70595
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.70364
New value of Value function: 4.70494
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.70184
New value of Value function: 4.70364
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.70096
New value of Value function: 4.70364
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.69886
New value of Value function: 4.70364
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.70133
New value of Value function: 4.70133
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.69902
New value of Value function: 4.70096
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.67377
New value of Value function: 4.70096
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.69831
New value of Value function: 4.69902
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.69672
New value of Value function: 4.69886
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.69578
New value of Value function: 4.69831
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.69287
New value of Value function: 4.69831
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.69566
New value of Value function: 4.69672
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.69442
New value of Value function: 4.69566
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.69302
New value of Value function: 4.69442
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.69212
New value of Value function: 4.69302
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.69038
New value of Value function: 4.69287
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.67207
New value of Value function: 4.69287
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.6898
New value of Value function: 4.69212
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.68689
New value of Value function: 4.69212
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.68983
New value of Value function: 4.69038
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.68775
New value of Value function: 4.68983
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.68754
New value of Value function: 4.68775
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.67016
New value of Value function: 4.68775
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.68513
New value of Value function: 4.68754
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.68525
New value of Value function: 4.68689
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.68305
New value of Value function: 4.68689
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.68384
New value of Value function: 4.68513
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.68251
New value of Value function: 4.68384
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.68079
New value of Value function: 4.68305
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.68078
New value of Value function: 4.68251
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.67989
New value of Value function: 4.68079
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.67776
New value of Value function: 4.68078
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.6785
New value of Value function: 4.67989
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.64686
New value of Value function: 4.67989
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.64616
New value of Value function: 4.67989
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.67729
New value of Value function: 4.6785
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.67623
New value of Value function: 4.67776
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.66776
New value of Value function: 4.67776
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.67473
New value of Value function: 4.67729
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.67468
New value of Value function: 4.67623
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.66543
New value of Value function: 4.67623
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.67397
New value of Value function: 4.67473
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.67172
New value of Value function: 4.67468
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.6689
New value of Value function: 4.67468
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.67209
New value of Value function: 4.67397
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.67171
New value of Value function: 4.67209
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.6661
New value of Value function: 4.67209
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.64509
New value of Value function: 4.67209
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.66349
New value of Value function: 4.67209
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.6695
New value of Value function: 4.67171
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.64406
New value of Value function: 4.67171
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.66945
New value of Value function: 4.6695
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.66691
New value of Value function: 4.66945
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.6672
New value of Value function: 4.6672
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.66495
New value of Value function: 4.66691
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.66433
New value of Value function: 4.66543
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.66259
New value of Value function: 4.66495
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.6627
New value of Value function: 4.66433
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.66176
New value of Value function: 4.66349
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.6605
New value of Value function: 4.6627
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.66046
New value of Value function: 4.66259
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.65976
New value of Value function: 4.66176
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.65919
New value of Value function: 4.6605
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.65753
New value of Value function: 4.66046
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 4.65822
New value of Value function: 4.65976
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 4.65605
New value of Value function: 4.65976
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.65693
New value of Value function: 4.65919
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.65662
New value of Value function: 4.65753
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.65456
New value of Value function: 4.65693
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.65411
New value of Value function: 4.65662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.65406
New value of Value function: 4.65605
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 4.65382
New value of Value function: 4.65456
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 4.6516
New value of Value function: 4.65411
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.6513
New value of Value function: 4.65406
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.65151
New value of Value function: 4.65382
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 4.65159
New value of Value function: 4.6516
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.64864
New value of Value function: 4.65159
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 4.64937
New value of Value function: 4.65151
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.64896
New value of Value function: 4.6513
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 4.64586
New value of Value function: 4.6513
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.6485
New value of Value function: 4.64937
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 4.64715
New value of Value function: 4.64896
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 4.64312
New value of Value function: 4.64896
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.64642
New value of Value function: 4.6485
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 4.64499
New value of Value function: 4.6485
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.6457
New value of Value function: 4.64642
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.64388
New value of Value function: 4.6457
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.64291
New value of Value function: 4.64499
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.6414
New value of Value function: 4.64499
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.64173
New value of Value function: 4.64499
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.64025
New value of Value function: 4.64499
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 4.64278
New value of Value function: 4.64312
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 4.64019
New value of Value function: 4.64278
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 4.64057
New value of Value function: 4.64173
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 4.63736
New value of Value function: 4.64173
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.63937
New value of Value function: 4.6414
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.63888
New value of Value function: 4.64057
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 4.63836
New value of Value function: 4.64025
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.63747
New value of Value function: 4.63937
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.637
New value of Value function: 4.63888
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 4.63618
New value of Value function: 4.63888
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.63635
New value of Value function: 4.63747
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.6347
New value of Value function: 4.63736
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 4.63445
New value of Value function: 4.637
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.63464
New value of Value function: 4.63635
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.63383
New value of Value function: 4.63618
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 4.63398
New value of Value function: 4.6347
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.63193
New value of Value function: 4.63464
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.63228
New value of Value function: 4.63445
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.63004
New value of Value function: 4.63445
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.63135
New value of Value function: 4.63445
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.62792
New value of Value function: 4.63445
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 4.63154
New value of Value function: 4.63398
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 4.63178
New value of Value function: 4.63193
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.62918
New value of Value function: 4.63178
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 4.62959
New value of Value function: 4.63154
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 4.62864
New value of Value function: 4.63135
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.62574
New value of Value function: 4.63135
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 4.62748
New value of Value function: 4.63135
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.62885
New value of Value function: 4.62918
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 4.62538
New value of Value function: 4.62918
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.62642
New value of Value function: 4.62885
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.62634
New value of Value function: 4.62864
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 4.62574
New value of Value function: 4.62642
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.62368
New value of Value function: 4.62634
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.62385
New value of Value function: 4.62574
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 4.62286
New value of Value function: 4.62574
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.6234
New value of Value function: 4.62538
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 4.62319
New value of Value function: 4.62385
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.62135
New value of Value function: 4.62368
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.62094
New value of Value function: 4.6234
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.62107
New value of Value function: 4.62319
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 4.62101
New value of Value function: 4.62286
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 4.61892
New value of Value function: 4.62286
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.61894
New value of Value function: 4.62286
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 4.61998
New value of Value function: 4.62107
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.61874
New value of Value function: 4.62094
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.61821
New value of Value function: 4.61998
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.61558
New value of Value function: 4.61998
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.61652
New value of Value function: 4.61998
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 4.61711
New value of Value function: 4.61892
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 4.61675
New value of Value function: 4.61874
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 4.61435
New value of Value function: 4.61874
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.61641
New value of Value function: 4.61675
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 4.61458
New value of Value function: 4.61652
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.61404
New value of Value function: 4.61641
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 4.61409
New value of Value function: 4.61558
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.61286
New value of Value function: 4.61458
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 4.61242
New value of Value function: 4.61435
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 4.61149
New value of Value function: 4.61409
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.61177
New value of Value function: 4.61404
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.61022
New value of Value function: 4.61404
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.61156
New value of Value function: 4.61242
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 4.61025
New value of Value function: 4.61177
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.60946
New value of Value function: 4.61156
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.6091
New value of Value function: 4.61149
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 4.60864
New value of Value function: 4.61025
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 4.6059
New value of Value function: 4.61025
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 4.60809
New value of Value function: 4.61022
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.60751
New value of Value function: 4.60946
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.60715
New value of Value function: 4.6091
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.60663
New value of Value function: 4.60809
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 4.60594
New value of Value function: 4.60751
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.60481
New value of Value function: 4.60715
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.60484
New value of Value function: 4.60663
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.60222
New value of Value function: 4.60663
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.60417
New value of Value function: 4.60594
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.60181
New value of Value function: 4.60594
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 4.60379
New value of Value function: 4.6059
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 4.60306
New value of Value function: 4.60484
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.59968
New value of Value function: 4.60484
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 4.60254
New value of Value function: 4.60379
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 4.60164
New value of Value function: 4.60306
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 4.60024
New value of Value function: 4.60254
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.60024
New value of Value function: 4.60181
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.59936
New value of Value function: 4.60164
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 4.59949
New value of Value function: 4.60024
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 4.59742
New value of Value function: 4.60024
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.59794
New value of Value function: 4.59968
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.597
New value of Value function: 4.59949
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 4.59735
New value of Value function: 4.59936
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.59572
New value of Value function: 4.59936
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.59692
New value of Value function: 4.59742
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 4.5946
New value of Value function: 4.59735
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 4.59521
New value of Value function: 4.597
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.59433
New value of Value function: 4.59692
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.5918
New value of Value function: 4.59692
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 4.59315
New value of Value function: 4.59692
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.59448
New value of Value function: 4.59572
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.59344
New value of Value function: 4.5946
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 4.5918
New value of Value function: 4.59448
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 4.59108
New value of Value function: 4.59448
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.59204
New value of Value function: 4.59344
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.59115
New value of Value function: 4.59204
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.58961
New value of Value function: 4.5918
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.5873
New value of Value function: 4.5918
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 4.589
New value of Value function: 4.5918
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.58914
New value of Value function: 4.59115
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.58888
New value of Value function: 4.59108
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 4.58895
New value of Value function: 4.58914
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.58498
New value of Value function: 4.58914
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.58648
New value of Value function: 4.589
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.58661
New value of Value function: 4.589
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 4.5862
New value of Value function: 4.58895
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 4.58683
New value of Value function: 4.58683
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.58266
New value of Value function: 4.58683
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 4.58471
New value of Value function: 4.58661
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.58434
New value of Value function: 4.58648
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.58383
New value of Value function: 4.5862
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 4.58342
New value of Value function: 4.58471
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 4.58259
New value of Value function: 4.58434
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.58207
New value of Value function: 4.58383
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.58118
New value of Value function: 4.58342
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 4.58064
New value of Value function: 4.58266
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.58025
New value of Value function: 4.58259
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 4.58047
New value of Value function: 4.58207
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.57859
New value of Value function: 4.58207
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.57616
New value of Value function: 4.58207
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.57981
New value of Value function: 4.58064
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 4.57787
New value of Value function: 4.58047
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.57785
New value of Value function: 4.58047
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.57758
New value of Value function: 4.58047
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.57547
New value of Value function: 4.58047
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 4.57836
New value of Value function: 4.57836
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.57336
New value of Value function: 4.57836
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 4.57625
New value of Value function: 4.57787
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 4.5751
New value of Value function: 4.57785
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.57362
New value of Value function: 4.57785
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.57545
New value of Value function: 4.57625
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.57309
New value of Value function: 4.57625
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 4.57414
New value of Value function: 4.5751
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 4.57234
New value of Value function: 4.57414
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 4.57204
New value of Value function: 4.57362
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.571
New value of Value function: 4.57336
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.57111
New value of Value function: 4.57309
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.5707
New value of Value function: 4.57234
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 4.56959
New value of Value function: 4.57204
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 4.56994
New value of Value function: 4.57111
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.56839
New value of Value function: 4.57111
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.56886
New value of Value function: 4.5707
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.56831
New value of Value function: 4.56994
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 4.56784
New value of Value function: 4.56959
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 4.56684
New value of Value function: 4.56886
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.56662
New value of Value function: 4.56839
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.56447
New value of Value function: 4.56839
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.56578
New value of Value function: 4.56831
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.56592
New value of Value function: 4.56784
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 4.56416
New value of Value function: 4.56784
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 4.56575
New value of Value function: 4.56592
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 4.56154
New value of Value function: 4.56592
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 4.55907
New value of Value function: 4.56592
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.56231
New value of Value function: 4.56592
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.56354
New value of Value function: 4.56578
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.56317
New value of Value function: 4.56575
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 4.56366
New value of Value function: 4.56366
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 4.56157
New value of Value function: 4.56354
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.56117
New value of Value function: 4.56317
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.5589
New value of Value function: 4.56317
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.56057
New value of Value function: 4.56231
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.56008
New value of Value function: 4.56157
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.55803
New value of Value function: 4.56157
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.55793
New value of Value function: 4.56157
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 4.55949
New value of Value function: 4.55949
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 4.5574
New value of Value function: 4.55907
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 4.55635
New value of Value function: 4.5589
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.55653
New value of Value function: 4.55803
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.55544
New value of Value function: 4.55793
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.55571
New value of Value function: 4.5574
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 4.55533
New value of Value function: 4.55653
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 4.55331
New value of Value function: 4.55653
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.55417
New value of Value function: 4.55635
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.55352
New value of Value function: 4.55635
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 4.55364
New value of Value function: 4.55544
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.55286
New value of Value function: 4.55417
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.55181
New value of Value function: 4.55364
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.55033
New value of Value function: 4.55364
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 4.55125
New value of Value function: 4.55364
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 4.55093
New value of Value function: 4.55352
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.55131
New value of Value function: 4.55181
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.54946
New value of Value function: 4.55131
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.5491
New value of Value function: 4.55125
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 4.54918
New value of Value function: 4.55093
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 4.54823
New value of Value function: 4.55033
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 4.54717
New value of Value function: 4.55033
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 4.54525
New value of Value function: 4.55033
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.54776
New value of Value function: 4.54946
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.54528
New value of Value function: 4.54946
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.54711
New value of Value function: 4.5491
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.54487
New value of Value function: 4.5491
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.54294
New value of Value function: 4.5491
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.54689
New value of Value function: 4.54823
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.5427
New value of Value function: 4.54823
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 4.54553
New value of Value function: 4.54689
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.54469
New value of Value function: 4.54553
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 4.54285
New value of Value function: 4.54525
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 4.54319
New value of Value function: 4.54469
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.54249
New value of Value function: 4.54319
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 4.54113
New value of Value function: 4.54294
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.54031
New value of Value function: 4.54294
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.54038
New value of Value function: 4.54285
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 4.53915
New value of Value function: 4.54285
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 4.54017
New value of Value function: 4.5427
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.54036
New value of Value function: 4.54038
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.53783
New value of Value function: 4.54036
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.53803
New value of Value function: 4.54031
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.53812
New value of Value function: 4.54017
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.53542
New value of Value function: 4.54017
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 4.53749
New value of Value function: 4.53915
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.53308
New value of Value function: 4.53915
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.53576
New value of Value function: 4.53915
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.53088
New value of Value function: 4.53915
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 4.5371
New value of Value function: 4.53812
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.53593
New value of Value function: 4.53749
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.53352
New value of Value function: 4.53749
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 4.53482
New value of Value function: 4.5371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.53138
New value of Value function: 4.5371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 4.53229
New value of Value function: 4.5371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 4.53505
New value of Value function: 4.53593
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.53375
New value of Value function: 4.53505
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.52925
New value of Value function: 4.53505
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 4.53301
New value of Value function: 4.53375
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.53157
New value of Value function: 4.53301
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 4.52946
New value of Value function: 4.53301
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 4.53097
New value of Value function: 4.53229
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 4.52963
New value of Value function: 4.53097
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.52703
New value of Value function: 4.53097
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 4.52893
New value of Value function: 4.53088
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 4.52698
New value of Value function: 4.53088
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 4.52706
New value of Value function: 4.53088
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.52836
New value of Value function: 4.52946
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 4.52728
New value of Value function: 4.52836
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.52583
New value of Value function: 4.52728
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.52339
New value of Value function: 4.52728
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 4.52511
New value of Value function: 4.52706
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.52472
New value of Value function: 4.52706
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 4.52441
New value of Value function: 4.52698
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 4.52495
New value of Value function: 4.52511
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 4.52295
New value of Value function: 4.52495
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 4.5218
New value of Value function: 4.52495
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 4.52292
New value of Value function: 4.52472
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 4.51934
New value of Value function: 4.52472
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.52242
New value of Value function: 4.52339
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.52088
New value of Value function: 4.52295
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 4.52078
New value of Value function: 4.52292
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 4.52089
New value of Value function: 4.52242
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 4.51689
New value of Value function: 4.52242
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.52012
New value of Value function: 4.52089
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 4.51887
New value of Value function: 4.52088
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.51837
New value of Value function: 4.52078
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 4.51862
New value of Value function: 4.52012
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.51783
New value of Value function: 4.51887
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 4.51685
New value of Value function: 4.51862
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 4.51646
New value of Value function: 4.51837
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.51587
New value of Value function: 4.51783
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.51554
New value of Value function: 4.51689
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 4.51433
New value of Value function: 4.51689
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 4.51427
New value of Value function: 4.51685
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 4.51483
New value of Value function: 4.51587
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.51327
New value of Value function: 4.51587
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.51337
New value of Value function: 4.51483
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 4.51281
New value of Value function: 4.51433
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 4.51218
New value of Value function: 4.51427
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 4.51165
New value of Value function: 4.51337
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 4.50914
New value of Value function: 4.51337
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.51099
New value of Value function: 4.51337
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.51088
New value of Value function: 4.51281
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.5088
New value of Value function: 4.51281
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 503
New value of Q matrix: 4.5108
New value of Value function: 4.51218
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.5067
New value of Value function: 4.51218
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 4.51004
New value of Value function: 4.51088
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.50463
New value of Value function: 4.51088
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.50839
New value of Value function: 4.5108
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 4.50879
New value of Value function: 4.51004
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 4.50264
New value of Value function: 4.51004
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 4.50789
New value of Value function: 4.50914
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 4.50654
New value of Value function: 4.50879
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 4.50407
New value of Value function: 4.50879
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 505
New value of Q matrix: 4.50679
New value of Value function: 4.50839
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.50591
New value of Value function: 4.50789
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 4.50575
New value of Value function: 4.50679
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 4.50478
New value of Value function: 4.50591
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.50344
New value of Value function: 4.50575
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 4.50362
New value of Value function: 4.50478
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 507
New value of Q matrix: 4.50278
New value of Value function: 4.50407
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.501
New value of Value function: 4.50407
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 4.50148
New value of Value function: 4.50362
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 4.50149
New value of Value function: 4.50278
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 4.49942
New value of Value function: 4.50278
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 4.50078
New value of Value function: 4.50264
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.50037
New value of Value function: 4.50148
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 4.49889
New value of Value function: 4.501
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.49853
New value of Value function: 4.50078
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 4.49879
New value of Value function: 4.50037
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.49812
New value of Value function: 4.49942
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 4.49729
New value of Value function: 4.49889
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 4.49631
New value of Value function: 4.49879
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.49608
New value of Value function: 4.49879
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 4.4968
New value of Value function: 4.49812
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.49586
New value of Value function: 4.49729
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 4.49517
New value of Value function: 4.4968
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 4.49377
New value of Value function: 4.4968
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.49367
New value of Value function: 4.4968
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 4.49481
New value of Value function: 4.49586
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.49361
New value of Value function: 4.49517
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 4.49305
New value of Value function: 4.49481
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 4.49126
New value of Value function: 4.49481
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 4.49282
New value of Value function: 4.49367
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.49122
New value of Value function: 4.49361
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 4.49136
New value of Value function: 4.49305
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 4.49093
New value of Value function: 4.49282
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 4.48878
New value of Value function: 4.49282
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 4.49084
New value of Value function: 4.49136
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.48878
New value of Value function: 4.49136
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.48912
New value of Value function: 4.49093
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 4.48882
New value of Value function: 4.49084
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 4.48886
New value of Value function: 4.48912
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.48688
New value of Value function: 4.48886
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 4.48688
New value of Value function: 4.48882
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 4.48671
New value of Value function: 4.48878
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 4.48622
New value of Value function: 4.48878
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.48634
New value of Value function: 4.48688
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.48465
New value of Value function: 4.48688
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 4.4849
New value of Value function: 4.48671
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.48392
New value of Value function: 4.48671
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 4.48461
New value of Value function: 4.48622
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 4.48367
New value of Value function: 4.4849
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 4.48293
New value of Value function: 4.48465
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 4.48251
New value of Value function: 4.48465
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.48242
New value of Value function: 4.48392
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.48149
New value of Value function: 4.48367
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 4.48112
New value of Value function: 4.48293
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 4.48096
New value of Value function: 4.48251
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 4.48041
New value of Value function: 4.48242
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 4.4784
New value of Value function: 4.48242
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.48019
New value of Value function: 4.48149
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 4.47645
New value of Value function: 4.48149
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.47906
New value of Value function: 4.48112
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 4.47858
New value of Value function: 4.48096
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 4.47899
New value of Value function: 4.48019
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.47796
New value of Value function: 4.47906
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.47664
New value of Value function: 4.47899
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 4.47448
New value of Value function: 4.47899
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 4.47703
New value of Value function: 4.47858
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 4.47605
New value of Value function: 4.47796
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.47574
New value of Value function: 4.47703
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 4.47507
New value of Value function: 4.47664
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.47422
New value of Value function: 4.47605
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 4.47247
New value of Value function: 4.47605
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 4.47352
New value of Value function: 4.47574
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.47353
New value of Value function: 4.47507
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 4.47311
New value of Value function: 4.47422
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.47181
New value of Value function: 4.47353
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.47132
New value of Value function: 4.47352
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.47099
New value of Value function: 4.47311
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 4.47115
New value of Value function: 4.47247
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 4.47039
New value of Value function: 4.47181
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.4694
New value of Value function: 4.47132
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 4.46835
New value of Value function: 4.47132
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.46911
New value of Value function: 4.47115
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 4.4692
New value of Value function: 4.47099
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.46847
New value of Value function: 4.4694
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 4.46726
New value of Value function: 4.4694
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.467
New value of Value function: 4.46911
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.4669
New value of Value function: 4.46847
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.46596
New value of Value function: 4.46835
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.46477
New value of Value function: 4.46835
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 4.46627
New value of Value function: 4.46726
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.46461
New value of Value function: 4.46726
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 4.46531
New value of Value function: 4.46627
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 4.4642
New value of Value function: 4.46596
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.46345
New value of Value function: 4.46531
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 4.46337
New value of Value function: 4.46477
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 4.46148
New value of Value function: 4.46477
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.46258
New value of Value function: 4.46461
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.46222
New value of Value function: 4.4642
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 4.46213
New value of Value function: 4.46345
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.46095
New value of Value function: 4.46258
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.46038
New value of Value function: 4.46222
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.45983
New value of Value function: 4.46213
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 4.46006
New value of Value function: 4.46148
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 4.45955
New value of Value function: 4.46095
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.45845
New value of Value function: 4.46038
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.45819
New value of Value function: 4.46006
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 4.45763
New value of Value function: 4.46006
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 4.458
New value of Value function: 4.45983
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.45745
New value of Value function: 4.45845
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.45596
New value of Value function: 4.45819
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.45601
New value of Value function: 4.458
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 4.45594
New value of Value function: 4.45763
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 4.4557
New value of Value function: 4.45745
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.45507
New value of Value function: 4.45601
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.45383
New value of Value function: 4.45596
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.45347
New value of Value function: 4.45594
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.45175
New value of Value function: 4.45594
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 4.45388
New value of Value function: 4.4557
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 4.45376
New value of Value function: 4.45507
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.45269
New value of Value function: 4.45388
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 4.45184
New value of Value function: 4.45388
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.47181
New value of Value function: 4.47353
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.47132
New value of Value function: 4.47352
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 4.47117
New value of Value function: 4.47352
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 4.471
New value of Value function: 4.47247
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 4.47039
New value of Value function: 4.47181
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.4694
New value of Value function: 4.47132
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.4671
New value of Value function: 4.47132
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.46911
New value of Value function: 4.47117
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 4.46922
New value of Value function: 4.471
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 4.46848
New value of Value function: 4.47039
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 4.46831
New value of Value function: 4.46922
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.46481
New value of Value function: 4.46922
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 4.46627
New value of Value function: 4.46922
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 4.466
New value of Value function: 4.46922
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 4.46727
New value of Value function: 4.46911
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.46691
New value of Value function: 4.46727
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 4.46532
New value of Value function: 4.46691
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.4647
New value of Value function: 4.46627
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 4.4642
New value of Value function: 4.466
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 4.4635
New value of Value function: 4.46532
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 4.46338
New value of Value function: 4.46481
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.46242
New value of Value function: 4.4647
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.46251
New value of Value function: 4.4642
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 4.46213
New value of Value function: 4.4635
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 4.46099
New value of Value function: 4.46338
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 4.46143
New value of Value function: 4.46251
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.46031
New value of Value function: 4.46242
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.46003
New value of Value function: 4.46213
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 4.46006
New value of Value function: 4.46143
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 4.45949
New value of Value function: 4.46099
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 4.45849
New value of Value function: 4.46031
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.45812
New value of Value function: 4.46006
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 4.458
New value of Value function: 4.46003
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.45765
New value of Value function: 4.45949
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 4.45756
New value of Value function: 4.45849
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 4.456
New value of Value function: 4.45812
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.45594
New value of Value function: 4.458
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.45386
New value of Value function: 4.458
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 4.45594
New value of Value function: 4.45765
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.45527
New value of Value function: 4.45756
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 4.4536
New value of Value function: 4.45756
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 4.45562
New value of Value function: 4.45594
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 4.45388
New value of Value function: 4.45562
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 4.45123
New value of Value function: 4.45562
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 4.45369
New value of Value function: 4.45527
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 4.45189
New value of Value function: 4.45527
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.45289
New value of Value function: 4.45386
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 4.45177
New value of Value function: 4.45386
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 4.44993
New value of Value function: 4.45386
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.45168
New value of Value function: 4.45289
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.45052
New value of Value function: 4.45177
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.44822
New value of Value function: 4.45177
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 4.44984
New value of Value function: 4.45168
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 4.44796
New value of Value function: 4.45168
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 4.448
New value of Value function: 4.45168
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 4.44878
New value of Value function: 4.45168
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.4495
New value of Value function: 4.4495
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 4.44635
New value of Value function: 4.4495
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.44733
New value of Value function: 4.44822
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.44586
New value of Value function: 4.448
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 4.44607
New value of Value function: 4.44796
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 4.44591
New value of Value function: 4.44733
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.44517
New value of Value function: 4.44635
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 4.44388
New value of Value function: 4.44607
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 4.44388
New value of Value function: 4.44607
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 4.44416
New value of Value function: 4.44586
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.44351
New value of Value function: 4.44517
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.443
New value of Value function: 4.44416
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.44119
New value of Value function: 4.44416
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 4.44224
New value of Value function: 4.44388
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 4.44142
New value of Value function: 4.44388
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 4.44184
New value of Value function: 4.443
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 4.43986
New value of Value function: 4.443
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.44084
New value of Value function: 4.44224
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 4.44033
New value of Value function: 4.44142
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 4.43896
New value of Value function: 4.44119
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.43884
New value of Value function: 4.44084
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.43868
New value of Value function: 4.44033
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 4.43842
New value of Value function: 4.43986
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 4.43782
New value of Value function: 4.43896
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.43651
New value of Value function: 4.43896
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 4.43651
New value of Value function: 4.43868
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.43428
New value of Value function: 4.43868
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.43653
New value of Value function: 4.43842
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 4.43417
New value of Value function: 4.43842
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 4.43651
New value of Value function: 4.43782
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 4.43579
New value of Value function: 4.43653
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.43438
New value of Value function: 4.43651
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 4.4346
New value of Value function: 4.43579
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.4323
New value of Value function: 4.43579
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.43203
New value of Value function: 4.43579
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 4.43377
New value of Value function: 4.4346
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 4.43175
New value of Value function: 4.4346
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 4.4327
New value of Value function: 4.43377
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 4.43174
New value of Value function: 4.4327
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 4.4308
New value of Value function: 4.4323
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.43016
New value of Value function: 4.43203
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.4297
New value of Value function: 4.43175
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 4.42932
New value of Value function: 4.43174
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 4.42972
New value of Value function: 4.4308
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.42805
New value of Value function: 4.4308
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 4.4289
New value of Value function: 4.42972
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 4.42771
New value of Value function: 4.4297
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 4.42578
New value of Value function: 4.4297
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 4.42691
New value of Value function: 4.4297
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.42737
New value of Value function: 4.4289
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 546
New value of Q matrix: 4.42701
New value of Value function: 4.42805
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.42592
New value of Value function: 4.42737
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.42385
New value of Value function: 4.42737
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.42505
New value of Value function: 4.42701
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 547
New value of Q matrix: 4.42511
New value of Value function: 4.42691
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 4.42448
New value of Value function: 4.42578
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 548
New value of Q matrix: 4.42325
New value of Value function: 4.42578
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 4.42377
New value of Value function: 4.42505
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.42273
New value of Value function: 4.42448
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.42051
New value of Value function: 4.42448
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.41841
New value of Value function: 4.42448
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.42176
New value of Value function: 4.42448
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 4.42206
New value of Value function: 4.42377
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 4.42176
New value of Value function: 4.42325
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 4.42136
New value of Value function: 4.42206
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 4.41964
New value of Value function: 4.42176
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 4.41735
New value of Value function: 4.42176
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 4.41975
New value of Value function: 4.42176
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.41628
New value of Value function: 4.42176
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 4.41963
New value of Value function: 4.42136
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 550
New value of Q matrix: 4.41948
New value of Value function: 4.41975
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 4.41775
New value of Value function: 4.41963
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 4.41584
New value of Value function: 4.41963
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 4.41751
New value of Value function: 4.41948
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 4.41759
New value of Value function: 4.41759
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 4.4154
New value of Value function: 4.41759
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 4.41495
New value of Value function: 4.41759
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 552
New value of Q matrix: 4.41571
New value of Value function: 4.41628
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.41398
New value of Value function: 4.41584
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.41178
New value of Value function: 4.41584
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 4.41384
New value of Value function: 4.41571
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 4.4133
New value of Value function: 4.41571
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 4.4113
New value of Value function: 4.41571
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 553
New value of Q matrix: 4.41384
New value of Value function: 4.41495
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.40965
New value of Value function: 4.41495
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 4.41255
New value of Value function: 4.41384
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 4.41184
New value of Value function: 4.41384
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 4.41196
New value of Value function: 4.41255
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 4.41011
New value of Value function: 4.41255
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 4.41016
New value of Value function: 4.41184
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 4.40985
New value of Value function: 4.4113
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 4.40919
New value of Value function: 4.41016
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 4.40776
New value of Value function: 4.41011
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 4.40824
New value of Value function: 4.40985
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 4.40787
New value of Value function: 4.40965
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 4.40711
New value of Value function: 4.40965
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.40737
New value of Value function: 4.40824
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 4.40638
New value of Value function: 4.40787
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 4.40588
New value of Value function: 4.40776
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 4.40538
New value of Value function: 4.40737
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.40509
New value of Value function: 4.40711
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 4.40395
New value of Value function: 4.40711
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 558
New value of Q matrix: 4.40454
New value of Value function: 4.40711
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 4.40501
New value of Value function: 4.40538
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 4.403
New value of Value function: 4.40509
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 4.40202
New value of Value function: 4.40509
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.40281
New value of Value function: 4.40501
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 4.40291
New value of Value function: 4.40454
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 4.40268
New value of Value function: 4.403
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 4.40083
New value of Value function: 4.403
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 4.40062
New value of Value function: 4.40291
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 4.40082
New value of Value function: 4.40281
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.40053
New value of Value function: 4.40202
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 4.40005
New value of Value function: 4.40083
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.39828
New value of Value function: 4.40083
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 561
New value of Q matrix: 4.39897
New value of Value function: 4.40082
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 4.39873
New value of Value function: 4.40062
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 4.39825
New value of Value function: 4.40005
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.39611
New value of Value function: 4.40005
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 4.39807
New value of Value function: 4.39897
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 4.39712
New value of Value function: 4.39873
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 4.39664
New value of Value function: 4.39825
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 4.39588
New value of Value function: 4.39807
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 4.39363
New value of Value function: 4.39807
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 4.39151
New value of Value function: 4.39807
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 4.3961
New value of Value function: 4.39712
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 4.39526
New value of Value function: 4.39664
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 4.39455
New value of Value function: 4.39611
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 4.3894
New value of Value function: 4.39611
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.39384
New value of Value function: 4.3961
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 4.39413
New value of Value function: 4.39526
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 4.39341
New value of Value function: 4.39455
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 4.39247
New value of Value function: 4.39413
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 4.39217
New value of Value function: 4.39384
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.39159
New value of Value function: 4.39341
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 4.39156
New value of Value function: 4.39247
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 4.3904
New value of Value function: 4.39217
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 4.39021
New value of Value function: 4.39159
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 4.38831
New value of Value function: 4.39159
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.38933
New value of Value function: 4.39156
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 566
New value of Q matrix: 4.38972
New value of Value function: 4.3904
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 4.38832
New value of Value function: 4.38972
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 4.38788
New value of Value function: 4.3894
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.38709
New value of Value function: 4.3894
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 4.38705
New value of Value function: 4.38832
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 4.38625
New value of Value function: 4.38831
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 503
New value of Q matrix: 4.38635
New value of Value function: 4.38788
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 4.38603
New value of Value function: 4.38709
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.38484
New value of Value function: 4.38705
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 4.3847
New value of Value function: 4.38635
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 4.38245
New value of Value function: 4.38635
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 4.38419
New value of Value function: 4.38635
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 4.38222
New value of Value function: 4.38635
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 4.3844
New value of Value function: 4.38603
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 4.3842
New value of Value function: 4.38484
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 4.38239
New value of Value function: 4.38484
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 4.38028
New value of Value function: 4.38484
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.3826
New value of Value function: 4.3844
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 505
New value of Q matrix: 4.38245
New value of Value function: 4.3826
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 4.38012
New value of Value function: 4.3826
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 4.38056
New value of Value function: 4.3826
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.38037
New value of Value function: 4.38245
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 4.3805
New value of Value function: 4.38056
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 4.37873
New value of Value function: 4.3805
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 507
New value of Q matrix: 4.37855
New value of Value function: 4.38037
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.37813
New value of Value function: 4.38028
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 4.37823
New value of Value function: 4.38012
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 4.37779
New value of Value function: 4.37873
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 4.3769
New value of Value function: 4.37855
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 4.37661
New value of Value function: 4.37823
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 4.37617
New value of Value function: 4.37813
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.37591
New value of Value function: 4.37779
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.37546
New value of Value function: 4.3769
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 4.37468
New value of Value function: 4.3769
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 4.37507
New value of Value function: 4.37617
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 4.37412
New value of Value function: 4.37591
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 4.37328
New value of Value function: 4.37591
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.37368
New value of Value function: 4.37546
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 4.37155
New value of Value function: 4.37546
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.37314
New value of Value function: 4.37468
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 4.37275
New value of Value function: 4.37412
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 4.37207
New value of Value function: 4.37368
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.37146
New value of Value function: 4.37314
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 4.3698
New value of Value function: 4.37314
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.37082
New value of Value function: 4.37275
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 4.37081
New value of Value function: 4.37207
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 4.37003
New value of Value function: 4.37146
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.36925
New value of Value function: 4.37082
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.36851
New value of Value function: 4.37081
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 4.36888
New value of Value function: 4.37003
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 4.36798
New value of Value function: 4.3698
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 4.36798
New value of Value function: 4.36925
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.36703
New value of Value function: 4.36888
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 4.36695
New value of Value function: 4.36851
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.3662
New value of Value function: 4.36798
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 4.36595
New value of Value function: 4.36798
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.36399
New value of Value function: 4.36798
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 4.36616
New value of Value function: 4.36703
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.36482
New value of Value function: 4.36695
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 4.36503
New value of Value function: 4.36616
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 4.36392
New value of Value function: 4.36616
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 4.36435
New value of Value function: 4.36503
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 4.3631
New value of Value function: 4.36482
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.36173
New value of Value function: 4.36482
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.36262
New value of Value function: 4.36435
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 4.36254
New value of Value function: 4.36392
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 4.36079
New value of Value function: 4.36392
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 4.36189
New value of Value function: 4.3631
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.35951
New value of Value function: 4.3631
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 4.36118
New value of Value function: 4.36262
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.36042
New value of Value function: 4.36189
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 4.35986
New value of Value function: 4.36118
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 4.35926
New value of Value function: 4.36079
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 4.35741
New value of Value function: 4.36079
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 4.35898
New value of Value function: 4.36042
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 4.35563
New value of Value function: 4.36042
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.35822
New value of Value function: 4.35986
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 4.35783
New value of Value function: 4.35951
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 395
New value of Q matrix: 4.28988
New value of Value function: 4.35951
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 276
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 277
----------
State: 4897
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 5.61564
New value of Value function: 5.61564
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 278
----------
State: 4953
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4169
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 279
----------
State: 4169
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 280
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 281
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 282
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 283
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 284
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 285
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 286
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 287
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 288
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: -0.53386
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 289
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.40543
New value of Value function: 4.40543
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 290
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 291
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 292
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 293
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 294
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 295
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 296
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 297
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 298
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5177
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 299
----------
State: 5177
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 300
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 301
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 302
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 303
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5177
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: -0.0150756
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 304
----------
State: 5177
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 305
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4449
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 306
----------
State: 4449
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 307
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 308
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 309
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 310
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 311
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.638628
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 312
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.36137
New value of Value function: 4.40543
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 313
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.7487
New value of Value function: 4.7487
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 314
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 315
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 316
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 317
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 318
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.398321
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 319
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.60168
New value of Value function: 4.7487
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 320
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5177
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 4.7487
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 321
----------
State: 5177
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5965
	Distance: 7
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 322
----------
State: 5965
	Distance: 7
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5125
	Distance: 6
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 323
----------
State: 5125
	Distance: 6
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5069
	Distance: 6
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 324
----------
State: 5069
	Distance: 6
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 325
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 326
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 327
----------
State: 5853
	Distance: 7
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 328
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6693
	Distance: 8
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 329
----------
State: 6693
	Distance: 8
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 330
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 331
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 332
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6693
	Distance: 8
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 333
----------
State: 6693
	Distance: 8
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 334
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 335
----------
State: 5909
	Distance: 7
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.70122
New value of Value function: 9.70122
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 336
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.87435
New value of Value function: 4.87435
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 337
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 338
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 339
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 340
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 341
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 342
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 343
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 344
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 345
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 346
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 347
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 348
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.269035
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 349
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.37328
New value of Value function: 5.37328
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 350
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.0252583
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 351
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.62506
New value of Value function: 5.62506
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 352
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 353
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 354
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 355
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 356
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 357
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 358
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 359
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 360
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 361
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 362
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 363
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 364
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 365
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 366
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 367
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 1.68483
New value of Value function: 1.68483
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 368
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.17944
New value of Value function: 2.17944
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 369
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 1.42123
New value of Value function: 1.42123
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 370
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 2.31083
New value of Value function: 2.31083
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 371
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 1.36153
New value of Value function: 1.36153
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 372
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 2.32937
New value of Value function: 2.32937
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 373
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 1.33889
New value of Value function: 1.33889
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 374
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.06521
New value of Value function: 2.32937
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 375
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 376
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 377
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 4
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 378
----------
State: 3385
	Distance: 4
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 379
----------
State: 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 380
----------
State: 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 381
----------
State: 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 382
----------
State: 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 383
----------
State: 3441
	Distance: 4
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 384
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.90287
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 385
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 3.46725
New value of Value function: 3.46725
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 386
----------
State: 4225
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.02621
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 387
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 3.26995
New value of Value function: 3.26995
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 388
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 389
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 390
----------
State: 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 391
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 392
----------
State: 5849
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.475
New value of Value function: 7.475
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 393
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 3.03238
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 394
----------
State: 5009
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 4.36408
New value of Value function: 4.36408
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 395
----------
State: 5065
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 1.74812
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 396
----------
State: 5121
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.76299
New value of Value function: 5.76299
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 397
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.313065
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 398
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 399
----------
State: 4393
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2.70004
New value of Value function: 2.70004
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 400
----------
State: 4337
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4281
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 1
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 8.99115
New value of Value function: 8.99115
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 2
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 12.731
New value of Value function: 12.731
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 3
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 9.64326
New value of Value function: 9.64326
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 4
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 12.5468
New value of Value function: 12.731
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 5
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 10.7132
New value of Value function: 10.7132
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 6
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 39
New value of Q matrix: 10.8461
New value of Value function: 10.8461
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 7
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 13.0883
New value of Value function: 13.0883
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 8
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 7.31232
New value of Value function: 10.7132
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 9
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 13.284
New value of Value function: 13.284
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 10
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 10.5573
New value of Value function: 10.5573
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 11
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 13.3433
New value of Value function: 13.3433
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 12
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 10.4645
New value of Value function: 10.4645
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 13
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 16.4509
New value of Value function: 16.4509
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 14
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 15.4509
New value of Value function: 15.607
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 15
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 16.4657
New value of Value function: 16.4657
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 16
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 10.1257
New value of Value function: 12.2165
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 17
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 16.78
New value of Value function: 16.78
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 18
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 111
New value of Q matrix: 12.0333
New value of Value function: 12.0333
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 19
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 17.2721
New value of Value function: 17.2721
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 20
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 16.8395
New value of Value function: 16.8395
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 21
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 112
New value of Q matrix: 12.2888
New value of Value function: 12.2888
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 22
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 40
New value of Q matrix: 11.0443
New value of Value function: 11.0443
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 23
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 17.5024
New value of Value function: 17.5024
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 24
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.3832
New value of Value function: 16.8395
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 25
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 6.29605
New value of Value function: 6.44763
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 26
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 106
New value of Q matrix: 7.72439
New value of Value function: 7.72439
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 27
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 49
New value of Q matrix: 7.19384
New value of Value function: 7.19384
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 28
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 16.9728
New value of Value function: 16.9728
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 29
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 113
New value of Q matrix: 12.5377
New value of Value function: 12.5377
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 30
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 9.97075
New value of Value function: 11.0443
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 31
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 17.6527
New value of Value function: 17.6527
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 32
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.1393
New value of Value function: 15.4509
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 33
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 50
New value of Q matrix: 7.63261
New value of Value function: 7.63261
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 34
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.3417
New value of Value function: 15.4388
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 35
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 14.73
New value of Value function: 15.3417
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 36
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 17.6392
New value of Value function: 17.6392
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 37
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 13.0896
New value of Value function: 13.0896
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 38
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 11.2926
New value of Value function: 12.5377
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 39
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 13.2983
New value of Value function: 13.2983
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 40
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 51
New value of Q matrix: 7.56718
New value of Value function: 7.56718
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 41
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 13.3448
New value of Value function: 13.3448
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 42
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 114
New value of Q matrix: 12.4382
New value of Value function: 12.4382
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 43
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 17.9484
New value of Value function: 17.9484
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 44
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 115
New value of Q matrix: 12.671
New value of Value function: 12.671
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 45
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 19
New value of Q matrix: 4.8873
New value of Value function: 11.0443
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 46
----------
State: 9661
	Distance: 12
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 15.3598
New value of Value function: 15.3598
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 47
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 11.102
New value of Value function: 11.102
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 48
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 11.2946
New value of Value function: 11.2946
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 49
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 8
New value of Q matrix: 5.15857
New value of Value function: 7.72439
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 50
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 7
New value of Visit matrix: 16
New value of Q matrix: 11.9883
New value of Value function: 11.9883
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 51
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 107
New value of Q matrix: 8.05926
New value of Value function: 8.05926
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 52
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 15.2531
New value of Value function: 15.2531
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 53
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 15.1768
New value of Value function: 15.1768
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 54
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 16.7689
New value of Value function: 16.7689
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 55
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 17.8067
New value of Value function: 17.8067
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 56
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 15.8138
New value of Value function: 16.7689
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 57
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 16.6697
New value of Value function: 16.6697
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 58
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 17.6919
New value of Value function: 17.6919
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 59
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 14.2032
New value of Value function: 16.6697
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 60
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 52
New value of Q matrix: 7.564
New value of Value function: 7.564
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 61
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 116
New value of Q matrix: 12.6067
New value of Value function: 12.6067
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 62
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 108
New value of Q matrix: 8.0998
New value of Value function: 8.0998
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 63
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 11.6438
New value of Value function: 12.6067
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 64
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 117
New value of Q matrix: 12.8447
New value of Value function: 12.8447
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 65
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 14
New value of Q matrix: 9.18153
New value of Value function: 11.2946
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 66
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 53
New value of Q matrix: 7.58492
New value of Value function: 7.58492
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 67
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 118
New value of Q matrix: 12.7223
New value of Value function: 12.7223
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 68
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 17.6251
New value of Value function: 17.6251
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 69
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 16.0952
New value of Value function: 16.6697
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 70
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 15.8106
New value of Value function: 16.0952
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 71
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 8.82523
New value of Value function: 11.2946
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 72
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 9.22935
New value of Value function: 11.2946
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 73
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 11.5606
New value of Value function: 11.5606
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 74
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.61178
New value of Value function: 8.0998
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 75
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.75569
New value of Value function: 8.0998
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 76
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 109
New value of Q matrix: 8.14724
New value of Value function: 8.14724
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 77
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 119
New value of Q matrix: 12.6621
New value of Value function: 12.6621
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 78
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 110
New value of Q matrix: 8.18426
New value of Value function: 8.18426
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 79
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 120
New value of Q matrix: 12.9162
New value of Value function: 12.9162
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 80
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 11.7958
New value of Value function: 11.7958
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 81
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 111
New value of Q matrix: 8.21509
New value of Value function: 8.21509
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 82
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 54
New value of Q matrix: 7.61242
New value of Value function: 7.61242
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 83
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 121
New value of Q matrix: 12.845
New value of Value function: 12.845
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 84
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 112
New value of Q matrix: 8.26247
New value of Value function: 8.26247
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 85
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 122
New value of Q matrix: 12.7848
New value of Value function: 12.7848
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 86
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.08252
New value of Value function: 8.26247
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 87
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 9
New value of Q matrix: 5.06186
New value of Value function: 8.26247
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 88
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 7
New value of Visit matrix: 17
New value of Q matrix: 12.7624
New value of Value function: 12.7624
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 89
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 113
New value of Q matrix: 8.28823
New value of Value function: 8.28823
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 90
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 55
New value of Q matrix: 7.61842
New value of Value function: 7.61842
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 91
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 123
New value of Q matrix: 12.7325
New value of Value function: 12.7325
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 92
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.90557
New value of Value function: 8.28823
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 93
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 114
New value of Q matrix: 8.31202
New value of Value function: 8.31202
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 94
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 56
New value of Q matrix: 7.61665
New value of Value function: 7.61665
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 95
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 11.8361
New value of Value function: 12.7325
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 96
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 124
New value of Q matrix: 12.6873
New value of Value function: 12.6873
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 97
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 115
New value of Q matrix: 8.33518
New value of Value function: 8.33518
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 98
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 125
New value of Q matrix: 12.6483
New value of Value function: 12.6483
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 99
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 116
New value of Q matrix: 8.35252
New value of Value function: 8.35252
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 100
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 11.3782
New value of Value function: 12.6483
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 101
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 7.87919
New value of Value function: 7.87919
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 102
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 7.60656
New value of Value function: 7.60656
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 103
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 58
New value of Q matrix: 7.59544
New value of Value function: 7.59544
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 104
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 126
New value of Q matrix: 12.9182
New value of Value function: 12.9182
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 105
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 12.0179
New value of Value function: 12.0179
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 106
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 117
New value of Q matrix: 8.39287
New value of Value function: 8.39287
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 107
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 12.023
New value of Value function: 12.9182
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 108
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 12.1704
New value of Value function: 12.9182
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 109
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 127
New value of Q matrix: 12.8642
New value of Value function: 12.8642
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 110
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 8.26933
New value of Value function: 8.39287
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 111
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 9
New value of Q matrix: 17.9952
New value of Value function: 17.9952
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 112
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 128
New value of Q matrix: 13.1323
New value of Value function: 13.1323
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 113
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 12.2103
New value of Value function: 12.2103
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 114
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 118
New value of Q matrix: 8.40453
New value of Value function: 8.40453
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 115
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 59
New value of Q matrix: 7.64824
New value of Value function: 7.64824
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 116
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 129
New value of Q matrix: 13.3925
New value of Value function: 13.3925
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 117
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 46
New value of Q matrix: 12.374
New value of Value function: 12.374
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 118
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 119
New value of Q matrix: 8.48282
New value of Value function: 8.48282
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 119
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 11.5189
New value of Value function: 13.3925
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 120
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 13
New value of Q matrix: 8.26178
New value of Value function: 8.26178
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 121
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 130
New value of Q matrix: 13.3053
New value of Value function: 13.3053
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 122
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 8.06129
New value of Value function: 8.48282
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 123
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 120
New value of Q matrix: 8.54576
New value of Value function: 8.54576
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 124
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 131
New value of Q matrix: 13.2315
New value of Value function: 13.2315
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 125
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 121
New value of Q matrix: 8.54812
New value of Value function: 8.54812
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 126
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 60
New value of Q matrix: 8.07246
New value of Value function: 8.07246
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 127
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 16.0344
New value of Value function: 16.0344
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 128
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 15.9777
New value of Value function: 15.9777
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 129
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 15.9244
New value of Value function: 15.9244
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 130
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 15.8741
New value of Value function: 15.8741
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 131
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 12.5206
New value of Value function: 15.8741
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 132
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 61
New value of Q matrix: 8.41084
New value of Value function: 8.41084
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 133
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 15.8262
New value of Value function: 15.8262
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 134
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 16.4823
New value of Value function: 16.4823
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 135
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 132
New value of Q matrix: 13.4942
New value of Value function: 13.4942
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 136
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 12.356
New value of Value function: 12.356
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 137
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.075
New value of Value function: 12.356
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 138
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 122
New value of Q matrix: 8.62156
New value of Value function: 8.62156
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 139
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 133
New value of Q matrix: 13.4111
New value of Value function: 13.4111
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 140
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 123
New value of Q matrix: 8.68515
New value of Value function: 8.68515
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 141
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 62
New value of Q matrix: 8.77999
New value of Value function: 8.77999
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 142
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 16.4366
New value of Value function: 16.4366
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 143
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 16.3927
New value of Value function: 16.3927
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 144
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 16.3504
New value of Value function: 16.3504
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 145
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 16.3095
New value of Value function: 16.3095
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 146
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 16.2699
New value of Value function: 16.2699
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 147
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 16.2316
New value of Value function: 16.2316
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 148
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 15.5611
New value of Value function: 16.2316
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 149
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 12.3795
New value of Value function: 13.4111
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 150
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 134
New value of Q matrix: 13.3409
New value of Value function: 13.3409
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 151
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 124
New value of Q matrix: 8.73205
New value of Value function: 8.73205
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 152
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 135
New value of Q matrix: 13.281
New value of Value function: 13.281
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 153
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 125
New value of Q matrix: 8.76927
New value of Value function: 8.76927
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 154
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 10.8861
New value of Value function: 13.281
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 155
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 63
New value of Q matrix: 8.70039
New value of Value function: 8.70039
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 156
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 12.5223
New value of Value function: 13.281
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 157
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 136
New value of Q matrix: 13.2296
New value of Value function: 13.2296
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 158
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 126
New value of Q matrix: 8.61894
New value of Value function: 8.61894
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 159
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 11.8906
New value of Value function: 11.8906
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 160
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 8.62301
New value of Value function: 8.62301
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 161
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 64
New value of Q matrix: 8.9965
New value of Value function: 8.9965
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 162
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 16.1944
New value of Value function: 16.1944
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 163
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 16.1581
New value of Value function: 16.1581
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 164
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 16.1229
New value of Value function: 16.1229
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 165
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 16.3631
New value of Value function: 16.3631
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 166
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 137
New value of Q matrix: 13.17
New value of Value function: 13.17
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 167
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 127
New value of Q matrix: 8.7332
New value of Value function: 8.7332
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 168
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 65
New value of Q matrix: 8.87765
New value of Value function: 8.87765
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 169
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 138
New value of Q matrix: 13.4307
New value of Value function: 13.4307
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 170
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 12.5421
New value of Value function: 12.5421
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 171
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 128
New value of Q matrix: 8.78298
New value of Value function: 8.78298
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 172
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 11.4914
New value of Value function: 13.4307
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 173
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 66
New value of Q matrix: 8.80611
New value of Value function: 8.80611
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 174
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 139
New value of Q matrix: 13.3683
New value of Value function: 13.3683
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 175
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 5.64352
New value of Value function: 8.78298
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 176
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 5.88036
New value of Value function: 8.99115
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 177
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 9.08402
New value of Value function: 9.08402
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 178
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 12.7069
New value of Value function: 12.7069
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 179
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 6.556
New value of Value function: 8.78298
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 180
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 12.8466
New value of Value function: 12.8466
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 181
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 129
New value of Q matrix: 8.86531
New value of Value function: 8.86531
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 182
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 6.78959
New value of Value function: 8.80611
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 183
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 130
New value of Q matrix: 8.9401
New value of Value function: 8.9401
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 184
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 67
New value of Q matrix: 9.0985
New value of Value function: 9.0985
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 185
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 16.9274
New value of Value function: 16.9274
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 186
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 140
New value of Q matrix: 13.6514
New value of Value function: 13.6514
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 187
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 51
New value of Q matrix: 12.9872
New value of Value function: 12.9872
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 188
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 131
New value of Q matrix: 8.83801
New value of Value function: 8.83801
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 189
----------
State: 8205
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 12.7496
New value of Value function: 12.7496
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 190
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 132
New value of Q matrix: 8.89693
New value of Value function: 8.89693
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 191
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 141
New value of Q matrix: 13.9214
New value of Value function: 13.9214
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 192
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 13.101
New value of Value function: 13.101
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 193
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 133
New value of Q matrix: 8.99323
New value of Value function: 8.99323
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 194
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.64279
New value of Value function: 9.0985
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 195
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 68
New value of Q matrix: 9.06015
New value of Value function: 9.06015
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 196
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 10
New value of Q matrix: 11.5012
New value of Value function: 13.9214
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 197
----------
State: 9829
	Distance: 12
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 18.0438
New value of Value function: 18.0438
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 198
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 13.9589
New value of Value function: 13.9589
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 199
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 69
New value of Q matrix: 9.02669
New value of Value function: 9.02669
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 200
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 142
New value of Q matrix: 14.1773
New value of Value function: 14.1773
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 201
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 13.2112
New value of Value function: 13.2112
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 202
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 134
New value of Q matrix: 9.08327
New value of Value function: 9.08327
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 203
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 143
New value of Q matrix: 14.4199
New value of Value function: 14.4199
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 204
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 11.9546
New value of Value function: 13.2112
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 205
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.34204
New value of Value function: 9.08327
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 206
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 8.52979
New value of Value function: 9.08327
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 207
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 135
New value of Q matrix: 9.1859
New value of Value function: 9.1859
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 208
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 144
New value of Q matrix: 14.3094
New value of Value function: 14.3094
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 209
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 7.01524
New value of Value function: 9.1859
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 210
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 54
New value of Q matrix: 13.3314
New value of Value function: 13.3314
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 211
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.56091
New value of Value function: 9.1859
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 212
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 136
New value of Q matrix: 9.25025
New value of Value function: 9.25025
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 213
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 70
New value of Q matrix: 9.04338
New value of Value function: 9.04338
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 214
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 145
New value of Q matrix: 14.2138
New value of Value function: 14.2138
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 215
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 137
New value of Q matrix: 9.31029
New value of Value function: 9.31029
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 216
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 71
New value of Q matrix: 9.04674
New value of Value function: 9.04674
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 217
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 146
New value of Q matrix: 14.1313
New value of Value function: 14.1313
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 218
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 138
New value of Q matrix: 9.36815
New value of Value function: 9.36815
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 219
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 147
New value of Q matrix: 14.0606
New value of Value function: 14.0606
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 220
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 139
New value of Q matrix: 9.41496
New value of Value function: 9.41496
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 221
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 148
New value of Q matrix: 13.9998
New value of Value function: 13.9998
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 222
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 140
New value of Q matrix: 9.45256
New value of Value function: 9.45256
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 223
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 149
New value of Q matrix: 14.2618
New value of Value function: 14.2618
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 224
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 9.90018
New value of Value function: 13.3314
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 225
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 55
New value of Q matrix: 13.4698
New value of Value function: 13.4698
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 226
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 8.75951
New value of Value function: 9.45256
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 227
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 141
New value of Q matrix: 9.5087
New value of Value function: 9.5087
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 228
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 150
New value of Q matrix: 14.5128
New value of Value function: 14.5128
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 229
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 13.5959
New value of Value function: 13.5959
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 230
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 142
New value of Q matrix: 9.58078
New value of Value function: 9.58078
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 231
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 151
New value of Q matrix: 14.7526
New value of Value function: 14.7526
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 232
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 13.7137
New value of Value function: 13.7137
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 233
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 8.9534
New value of Value function: 9.58078
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 234
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 143
New value of Q matrix: 9.61218
New value of Value function: 9.61218
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 235
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 72
New value of Q matrix: 9.11254
New value of Value function: 9.11254
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 236
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 12.0078
New value of Value function: 14.7526
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 237
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 73
New value of Q matrix: 9.17019
New value of Value function: 9.17019
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 238
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 11.8134
New value of Value function: 14.7526
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 239
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 15
New value of Q matrix: 9.13478
New value of Value function: 9.13478
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 240
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 152
New value of Q matrix: 14.9817
New value of Value function: 14.9817
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 241
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 58
New value of Q matrix: 13.819
New value of Value function: 13.819
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 242
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 9.09867
New value of Value function: 9.61218
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 243
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 144
New value of Q matrix: 9.65104
New value of Value function: 9.65104
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 244
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 74
New value of Q matrix: 9.2471
New value of Value function: 9.2471
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 245
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 12.9439
New value of Value function: 14.9817
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 246
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 153
New value of Q matrix: 14.8663
New value of Value function: 14.8663
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 247
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 145
New value of Q matrix: 9.73962
New value of Value function: 9.73962
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 248
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 11.9614
New value of Value function: 14.8663
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 249
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 75
New value of Q matrix: 9.53705
New value of Value function: 9.53705
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 250
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 17.7329
New value of Value function: 17.7329
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 251
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 12.1329
New value of Value function: 14.8663
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 252
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 18.2833
New value of Value function: 18.2833
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 253
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 154
New value of Q matrix: 15.0931
New value of Value function: 15.0931
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 254
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 59
New value of Q matrix: 13.9262
New value of Value function: 13.9262
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 255
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 146
New value of Q matrix: 9.79772
New value of Value function: 9.79772
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 256
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 6.38795
New value of Value function: 9.53705
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 257
----------
State: 7477
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 16
New value of Q matrix: 9.58662
New value of Value function: 9.58662
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 258
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 155
New value of Q matrix: 15.3095
New value of Value function: 15.3095
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 259
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 60
New value of Q matrix: 14.0261
New value of Value function: 14.0261
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 260
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 9.24894
New value of Value function: 9.79772
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 261
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 9.97904
New value of Value function: 9.97904
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 262
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 10
New value of Q matrix: 18.9949
New value of Value function: 18.9949
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 263
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 156
New value of Q matrix: 15.5157
New value of Value function: 15.5157
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 264
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 14.1353
New value of Value function: 14.1353
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 265
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 9.66753
New value of Value function: 9.79772
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 266
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 15
New value of Q matrix: 9.74416
New value of Value function: 14.1353
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 267
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 157
New value of Q matrix: 15.7135
New value of Value function: 15.7135
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 268
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 14.207
New value of Value function: 14.207
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 269
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 8.97525
New value of Value function: 9.79772
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 270
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 18.8049
New value of Value function: 18.9949
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 271
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 12.8933
New value of Value function: 18.9949
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 272
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 9.50635
New value of Value function: 9.50635
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 273
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 14.2691
New value of Value function: 14.2691
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 274
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 6.17652
New value of Value function: 9.79772
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 275
----------
State: 7309
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.36845
New value of Value function: 9.50635
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 276
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 7
New value of Visit matrix: 18
New value of Q matrix: 13.6904
New value of Value function: 13.6904
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 277
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 9.50437
New value of Value function: 9.79772
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 278
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 14.3229
New value of Value function: 14.3229
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 279
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 147
New value of Q matrix: 9.85083
New value of Value function: 9.85083
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 280
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 76
New value of Q matrix: 9.65398
New value of Value function: 9.65398
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 281
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 13.4131
New value of Value function: 15.7135
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 282
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 12.4013
New value of Value function: 15.7135
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 283
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 17.2876
New value of Value function: 17.2876
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 284
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 9.64297
New value of Value function: 9.64297
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 285
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 78
New value of Q matrix: 9.92284
New value of Value function: 9.92284
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 286
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 18.1316
New value of Value function: 18.1316
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 287
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 158
New value of Q matrix: 15.9097
New value of Value function: 15.9097
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 288
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 65
New value of Q matrix: 14.3762
New value of Value function: 14.3762
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 289
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 148
New value of Q matrix: 10.007
New value of Value function: 10.007
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 290
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 159
New value of Q matrix: 15.7509
New value of Value function: 15.7509
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 291
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 9.42586
New value of Value function: 10.007
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 292
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 14.3585
New value of Value function: 14.3585
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 293
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 67
New value of Q matrix: 14.4255
New value of Value function: 14.4255
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 294
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 9.38574
New value of Value function: 10.007
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 295
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 68
New value of Q matrix: 14.4839
New value of Value function: 14.4839
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 296
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 149
New value of Q matrix: 10.0739
New value of Value function: 10.0739
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 297
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 79
New value of Q matrix: 9.99828
New value of Value function: 9.99828
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 298
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 160
New value of Q matrix: 15.9555
New value of Value function: 15.9555
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 299
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 69
New value of Q matrix: 14.5428
New value of Value function: 14.5428
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 300
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 150
New value of Q matrix: 10.2145
New value of Value function: 10.2145
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 301
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 161
New value of Q matrix: 15.8102
New value of Value function: 15.8102
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 302
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 151
New value of Q matrix: 10.3315
New value of Value function: 10.3315
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 303
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 162
New value of Q matrix: 15.6859
New value of Value function: 15.6859
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 304
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 9.09232
New value of Value function: 10.3315
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 305
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 70
New value of Q matrix: 14.6247
New value of Value function: 14.6247
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 306
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 12
New value of Q matrix: 6.28535
New value of Value function: 10.3315
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 307
----------
State: 8093
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 7
New value of Visit matrix: 6
New value of Q matrix: 11.3604
New value of Value function: 13.6904
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 308
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 152
New value of Q matrix: 10.3775
New value of Value function: 10.3775
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 309
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 9
New value of Q matrix: 6.86508
New value of Value function: 9.99828
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 310
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 9.30102
New value of Value function: 13.9589
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 311
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 8
New value of Q matrix: 14.6446
New value of Value function: 14.6446
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 312
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 80
New value of Q matrix: 10.0576
New value of Value function: 10.0576
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 313
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 163
New value of Q matrix: 15.5753
New value of Value function: 15.5753
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 314
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 9.41052
New value of Value function: 10.3775
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 315
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 71
New value of Q matrix: 14.7017
New value of Value function: 14.7017
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 316
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 153
New value of Q matrix: 10.4617
New value of Value function: 10.4617
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 317
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 164
New value of Q matrix: 15.4802
New value of Value function: 15.4802
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 318
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 9.21589
New value of Value function: 10.4617
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 319
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 72
New value of Q matrix: 14.7789
New value of Value function: 14.7789
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 320
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 9.34164
New value of Value function: 10.4617
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 321
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 73
New value of Q matrix: 14.8466
New value of Value function: 14.8466
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 322
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 9.58099
New value of Value function: 10.4617
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 323
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 154
New value of Q matrix: 10.5313
New value of Value function: 10.5313
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 324
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 165
New value of Q matrix: 15.3981
New value of Value function: 15.3981
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 325
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 155
New value of Q matrix: 10.5886
New value of Value function: 10.5886
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 326
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 166
New value of Q matrix: 15.3271
New value of Value function: 15.3271
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 327
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 156
New value of Q matrix: 10.6181
New value of Value function: 10.6181
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 328
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 81
New value of Q matrix: 10.0705
New value of Value function: 10.0705
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 329
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 167
New value of Q matrix: 15.264
New value of Value function: 15.264
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 330
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 157
New value of Q matrix: 10.6574
New value of Value function: 10.6574
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 331
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 168
New value of Q matrix: 15.5289
New value of Value function: 15.5289
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 332
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 12.7466
New value of Value function: 14.8466
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 333
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 74
New value of Q matrix: 14.9285
New value of Value function: 14.9285
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 334
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 9.80349
New value of Value function: 10.6574
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 335
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 158
New value of Q matrix: 10.7144
New value of Value function: 10.7144
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 336
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 169
New value of Q matrix: 15.458
New value of Value function: 15.458
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 337
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 159
New value of Q matrix: 10.7611
New value of Value function: 10.7611
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 338
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 170
New value of Q matrix: 15.3963
New value of Value function: 15.3963
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 339
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 160
New value of Q matrix: 10.7992
New value of Value function: 10.7992
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 340
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 171
New value of Q matrix: 15.3424
New value of Value function: 15.3424
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 341
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 161
New value of Q matrix: 10.8299
New value of Value function: 10.8299
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 342
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 12.6002
New value of Value function: 15.3424
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 343
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 7.71677
New value of Value function: 10.0705
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 344
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 10.0088
New value of Value function: 10.8299
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 345
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 162
New value of Q matrix: 10.8409
New value of Value function: 10.8409
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 346
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 10.0594
New value of Value function: 10.0594
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 347
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 11
New value of Q matrix: 8.03711
New value of Value function: 10.0594
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 348
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 75
New value of Q matrix: 15.0213
New value of Value function: 15.0213
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 349
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 163
New value of Q matrix: 10.8682
New value of Value function: 10.8682
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 350
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 172
New value of Q matrix: 15.298
New value of Value function: 15.298
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 351
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 164
New value of Q matrix: 10.8898
New value of Value function: 10.8898
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 352
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 173
New value of Q matrix: 15.5696
New value of Value function: 15.5696
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 353
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 76
New value of Q matrix: 15.1084
New value of Value function: 15.1084
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 354
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 165
New value of Q matrix: 10.8952
New value of Value function: 10.8952
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 355
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 83
New value of Q matrix: 10.0983
New value of Value function: 10.0983
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 356
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 12.2998
New value of Value function: 15.5696
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 357
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 14.4131
New value of Value function: 14.4131
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 358
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 17.348
New value of Value function: 17.348
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 359
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 84
New value of Q matrix: 10.3249
New value of Value function: 10.3249
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 360
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 16.8323
New value of Value function: 16.8323
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 361
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 85
New value of Q matrix: 10.4701
New value of Value function: 10.4701
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 362
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 16.4865
New value of Value function: 16.4865
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 363
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 86
New value of Q matrix: 10.464
New value of Value function: 10.464
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 364
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 174
New value of Q matrix: 15.5102
New value of Value function: 15.5102
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 365
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 166
New value of Q matrix: 10.9309
New value of Value function: 10.9309
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 366
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 12.5686
New value of Value function: 15.5102
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 367
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 13.7518
New value of Value function: 13.7518
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 368
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 16.228
New value of Value function: 16.228
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 369
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 87
New value of Q matrix: 10.1585
New value of Value function: 10.1585
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 370
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 9.44546
New value of Value function: 13.7518
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 371
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 13.0175
New value of Value function: 13.0175
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 372
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 11.5379
New value of Value function: 14.4105
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 373
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 14.6495
New value of Value function: 14.6495
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 374
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 9.54966
New value of Value function: 11.107
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 375
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 10.8092
New value of Value function: 10.8092
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 376
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 8.21379
New value of Value function: 8.21379
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 377
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 15.5947
New value of Value function: 17.9811
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 378
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 16.6449
New value of Value function: 17.9811
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 379
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 12.9687
New value of Value function: 12.9687
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 380
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 10.8724
New value of Value function: 10.8724
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 381
----------
State: 7533
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 8.12289
New value of Value function: 8.12289
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 382
----------
State: 9101
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 13.5077
New value of Value function: 13.5077
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 383
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 14.6277
New value of Value function: 14.6277
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 384
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 12.785
New value of Value function: 14.6277
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 385
----------
State: 7589
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -9
New value of Visit matrix: 6
New value of Q matrix: 3.35647
New value of Value function: 10.8724
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 386
----------
State: 8429
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 14.5443
New value of Value function: 14.5443
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 387
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 14.6061
New value of Value function: 14.6061
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 388
----------
State: 8373
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 47
New value of Q matrix: 14.5087
New value of Value function: 14.5087
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 389
----------
State: 9941
	Distance: 12
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 19.4638
New value of Value function: 19.4638
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 390
----------
State: 9885
	Distance: 12
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 4
New value of Q matrix: 19.2977
New value of Value function: 19.2977
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 391
----------
State: 9045
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 14.5367
New value of Value function: 14.5367
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 392
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 175
New value of Q matrix: 15.7708
New value of Value function: 15.7708
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 393
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 77
New value of Q matrix: 14.9599
New value of Value function: 14.9599
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 394
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 11
New value of Q matrix: 19.7843
New value of Value function: 19.7843
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 395
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 176
New value of Q matrix: 15.6062
New value of Value function: 15.6062
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 396
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 12
New value of Q matrix: 20.2652
New value of Value function: 20.2652
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 397
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 12.0443
New value of Value function: 15.6062
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 398
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 17.1721
New value of Value function: 17.1721
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 399
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 177
New value of Q matrix: 15.4901
New value of Value function: 15.4901
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 400
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 6
New value of Visit matrix: 13
New value of Q matrix: 20.562
New value of Value function: 20.562
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 1
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 178
New value of Q matrix: 15.739
New value of Value function: 15.739
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 2
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 78
New value of Q matrix: 15.0048
New value of Value function: 15.0048
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 3
----------
State: 9717
	Distance: 12
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 19.8773
New value of Value function: 19.8773
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 4
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 16.31
New value of Value function: 17.1721
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 5
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 17.9161
New value of Value function: 17.9161
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 6
----------
State: 8989
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 179
New value of Q matrix: 15.9719
New value of Value function: 15.9719
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 7
----------
State: 8149
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 79
New value of Q matrix: 15.0967
New value of Value function: 15.0967
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 8
----------
State: 7365
	Distance: 9
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 167
New value of Q matrix: 10.9406
New value of Value function: 10.9406
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 9
----------
State: 7421
	Distance: 9
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 5.79657
New value of Value function: 10.1585
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 10
----------
State: 9773
	Distance: 12
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 15.5824
New value of Value function: 16.31
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 11
----------
State: 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.30809
New value of Value function: 6.30809
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 12
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.39834
New value of Value function: 4.7256
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 13
----------
State: 8145
	Distance: 10
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.09921
New value of Value function: 7.09921
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 14
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.87238
New value of Value function: 2.87238
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 15
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.22321
New value of Value function: 7.22321
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 16
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 6.18048
New value of Value function: 6.18048
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 17
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.84365
New value of Value function: 7.84365
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 18
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.77008
New value of Value function: 2.87238
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 19
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.83187
New value of Value function: 2.83187
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 20
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.8153
New value of Value function: 7.8153
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 21
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 2.79838
New value of Value function: 2.79838
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 22
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.78937
New value of Value function: 7.78937
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 23
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.76941
New value of Value function: 2.77008
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 24
----------
State: 8089
	Distance: 10
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.76588
New value of Value function: 7.76588
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 25
----------
State: 7305
	Distance: 9
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8033
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: -3.05
New value of Value function: 2.77008
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 26
----------
State: 8033
	Distance: 10
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.32655
New value of Value function: 9.32655
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 27
----------
State: 7249
	Distance: 9
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7193
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 6.18048
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 28
----------
State: 7193
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.1203
New value of Value function: 11.1203
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 29
----------
State: 6409
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7193
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 6.11669
New value of Value function: 6.11669
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 30
----------
State: 7193
	Distance: 9
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.31591
New value of Value function: 11.1203
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.35722
New value of Value function: 4.35898
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 4.35718
New value of Value function: 4.35783
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 4.35581
New value of Value function: 4.35722
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 4.35385
New value of Value function: 4.35722
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 4.35199
New value of Value function: 4.35722
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.35493
New value of Value function: 4.35718
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.35277
New value of Value function: 4.35718
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 4.35537
New value of Value function: 4.35563
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 4.35372
New value of Value function: 4.35537
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 4.35358
New value of Value function: 4.35372
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 4.35181
New value of Value function: 4.35358
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 4.35178
New value of Value function: 4.35277
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.35049
New value of Value function: 4.35199
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 4.34998
New value of Value function: 4.35181
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.34828
New value of Value function: 4.35181
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 4.34991
New value of Value function: 4.35178
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 4.34805
New value of Value function: 4.35178
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.2908
New value of Value function: 4.35178
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 4.34998
New value of Value function: 4.34998
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 4.34819
New value of Value function: 4.34991
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.3461
New value of Value function: 4.34991
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.29159
New value of Value function: 4.34991
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 4.34801
New value of Value function: 4.34819
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 4.3464
New value of Value function: 4.34805
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.34393
New value of Value function: 4.34805
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 4.34468
New value of Value function: 4.34805
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 4.34604
New value of Value function: 4.34801
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 4.34412
New value of Value function: 4.34801
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 4.34611
New value of Value function: 4.34611
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 4.34295
New value of Value function: 4.34611
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 4.3413
New value of Value function: 4.34611
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 4.34421
New value of Value function: 4.34421
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 4.34232
New value of Value function: 4.34412
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 4.34212
New value of Value function: 4.34393
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.34167
New value of Value function: 4.34232
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 4.34042
New value of Value function: 4.34212
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 4.34012
New value of Value function: 4.34167
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.33941
New value of Value function: 4.3413
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 4.33952
New value of Value function: 4.34042
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 4.33853
New value of Value function: 4.34012
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 4.33813
New value of Value function: 4.33952
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 4.33774
New value of Value function: 4.33941
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.33716
New value of Value function: 4.33853
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 4.33665
New value of Value function: 4.33813
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 4.33614
New value of Value function: 4.33774
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 4.33596
New value of Value function: 4.33716
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.33491
New value of Value function: 4.33665
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.29167
New value of Value function: 4.33665
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 4.33417
New value of Value function: 4.33665
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 4.3323
New value of Value function: 4.33665
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 4.33051
New value of Value function: 4.33665
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 4.33476
New value of Value function: 4.33596
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 4.33419
New value of Value function: 4.33491
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 4.32873
New value of Value function: 4.33491
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.33267
New value of Value function: 4.33476
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 4.33288
New value of Value function: 4.33419
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 4.33241
New value of Value function: 4.33288
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.33044
New value of Value function: 4.33288
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.29157
New value of Value function: 4.33288
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 4.33101
New value of Value function: 4.33241
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 4.33064
New value of Value function: 4.33101
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 4.32913
New value of Value function: 4.33064
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 4.32684
New value of Value function: 4.33064
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 4.32888
New value of Value function: 4.33044
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.3282
New value of Value function: 4.32913
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 4.32726
New value of Value function: 4.32888
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 4.32711
New value of Value function: 4.3282
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.32597
New value of Value function: 4.32726
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 4.32488
New value of Value function: 4.32726
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 4.32538
New value of Value function: 4.32711
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 4.32535
New value of Value function: 4.32597
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 603
New value of Q matrix: 4.32361
New value of Value function: 4.32597
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.32374
New value of Value function: 4.32538
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 4.32352
New value of Value function: 4.32488
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 4.32291
New value of Value function: 4.32374
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.32152
New value of Value function: 4.32361
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 604
New value of Q matrix: 4.32185
New value of Value function: 4.32352
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 4.32165
New value of Value function: 4.32291
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 4.32094
New value of Value function: 4.32185
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 4.3198
New value of Value function: 4.32185
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 605
New value of Q matrix: 4.32009
New value of Value function: 4.32152
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.3193
New value of Value function: 4.32094
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 4.31897
New value of Value function: 4.32009
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 4.31706
New value of Value function: 4.32009
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 606
New value of Q matrix: 4.31834
New value of Value function: 4.3198
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 4.31794
New value of Value function: 4.3193
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.31708
New value of Value function: 4.31834
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 4.31609
New value of Value function: 4.31834
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 607
New value of Q matrix: 4.31659
New value of Value function: 4.31708
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.31487
New value of Value function: 4.31706
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 4.3151
New value of Value function: 4.31659
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 608
New value of Q matrix: 4.31484
New value of Value function: 4.31609
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 4.31424
New value of Value function: 4.3151
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 4.31242
New value of Value function: 4.3151
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 4.31314
New value of Value function: 4.31487
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.31266
New value of Value function: 4.31484
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 4.31126
New value of Value function: 4.31484
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 609
New value of Q matrix: 4.31309
New value of Value function: 4.31309
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 4.30939
New value of Value function: 4.31309
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 610
New value of Q matrix: 4.31134
New value of Value function: 4.31266
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.31046
New value of Value function: 4.31242
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 4.31057
New value of Value function: 4.31134
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 611
New value of Q matrix: 4.3096
New value of Value function: 4.31057
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 4.30872
New value of Value function: 4.31046
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.30826
New value of Value function: 4.3096
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 4.30785
New value of Value function: 4.30939
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.30612
New value of Value function: 4.30939
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 4.30745
New value of Value function: 4.30872
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 4.29027
New value of Value function: 4.30872
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 4.30688
New value of Value function: 4.30785
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 613
New value of Q matrix: 4.30611
New value of Value function: 4.30745
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 4.3055
New value of Value function: 4.30688
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.30397
New value of Value function: 4.30688
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.28895
New value of Value function: 4.30688
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 546
New value of Q matrix: 4.30503
New value of Value function: 4.30611
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 4.30438
New value of Value function: 4.3055
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.28763
New value of Value function: 4.3055
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 4.30356
New value of Value function: 4.30503
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 615
New value of Q matrix: 4.30267
New value of Value function: 4.30503
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 4.30168
New value of Value function: 4.30503
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 4.29989
New value of Value function: 4.30503
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 547
New value of Q matrix: 4.30319
New value of Value function: 4.30397
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.30178
New value of Value function: 4.30319
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 616
New value of Q matrix: 4.30095
New value of Value function: 4.30319
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 548
New value of Q matrix: 4.30136
New value of Value function: 4.30178
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.2996
New value of Value function: 4.30136
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 4.29952
New value of Value function: 4.30095
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 617
New value of Q matrix: 4.29922
New value of Value function: 4.29989
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 4.29796
New value of Value function: 4.2996
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.28608
New value of Value function: 4.2996
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 618
New value of Q matrix: 4.29751
New value of Value function: 4.2996
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.29742
New value of Value function: 4.29952
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 550
New value of Q matrix: 4.29769
New value of Value function: 4.29796
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 4.29603
New value of Value function: 4.29769
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 4.29586
New value of Value function: 4.29751
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 619
New value of Q matrix: 4.29578
New value of Value function: 4.29742
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.29524
New value of Value function: 4.29603
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 4.2941
New value of Value function: 4.29586
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 552
New value of Q matrix: 4.29403
New value of Value function: 4.29578
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 620
New value of Q matrix: 4.29406
New value of Value function: 4.29524
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.29307
New value of Value function: 4.2941
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 4.29217
New value of Value function: 4.29406
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 621
New value of Q matrix: 4.29233
New value of Value function: 4.29403
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 553
New value of Q matrix: 4.2922
New value of Value function: 4.29307
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 4.29041
New value of Value function: 4.29307
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.2909
New value of Value function: 4.29233
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 622
New value of Q matrix: 4.29061
New value of Value function: 4.29217
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 4.28867
New value of Value function: 4.29217
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 4.29025
New value of Value function: 4.2909
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.28873
New value of Value function: 4.29061
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 623
New value of Q matrix: 4.28889
New value of Value function: 4.29025
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 4.28833
New value of Value function: 4.28889
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 624
New value of Q matrix: 4.28718
New value of Value function: 4.28873
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.28657
New value of Value function: 4.28867
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 4.28685
New value of Value function: 4.28833
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 4.28641
New value of Value function: 4.28718
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 625
New value of Q matrix: 4.28546
New value of Value function: 4.28685
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 4.28503
New value of Value function: 4.28657
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 4.28442
New value of Value function: 4.28641
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 4.2845
New value of Value function: 4.28608
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.28395
New value of Value function: 4.28546
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.28189
New value of Value function: 4.28546
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 4.28375
New value of Value function: 4.28503
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 558
New value of Q matrix: 4.28322
New value of Value function: 4.2845
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.28227
New value of Value function: 4.2845
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 4.28258
New value of Value function: 4.28375
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 627
New value of Q matrix: 4.28204
New value of Value function: 4.28322
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 4.28141
New value of Value function: 4.28258
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.2798
New value of Value function: 4.28258
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 628
New value of Q matrix: 4.28035
New value of Value function: 4.28258
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 201
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 503
New value of Q matrix: 4.28067
New value of Value function: 4.28227
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.28012
New value of Value function: 4.28141
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 4.2788
New value of Value function: 4.28141
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 4.2796
New value of Value function: 4.28035
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 561
New value of Q matrix: 4.27782
New value of Value function: 4.28035
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.27771
New value of Value function: 4.28035
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 629
New value of Q matrix: 4.27864
New value of Value function: 4.28012
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 208
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.27797
New value of Value function: 4.2788
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 209
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 505
New value of Q matrix: 4.2769
New value of Value function: 4.27864
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 210
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.27586
New value of Value function: 4.27864
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 211
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 630
New value of Q matrix: 4.27694
New value of Value function: 4.27782
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 212
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 4.27602
New value of Value function: 4.27771
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 213
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.27559
New value of Value function: 4.27694
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 4.27524
New value of Value function: 4.2769
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 215
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 4.27499
New value of Value function: 4.27602
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 216
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 507
New value of Q matrix: 4.27314
New value of Value function: 4.27602
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 217
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 632
New value of Q matrix: 4.27357
New value of Value function: 4.27602
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 218
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 4.27422
New value of Value function: 4.27586
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 219
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 4.27373
New value of Value function: 4.27559
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 220
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 633
New value of Q matrix: 4.27195
New value of Value function: 4.27559
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 221
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.27348
New value of Value function: 4.27422
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 222
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 4.27242
New value of Value function: 4.27373
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 223
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.27159
New value of Value function: 4.27348
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 224
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 634
New value of Q matrix: 4.27031
New value of Value function: 4.27348
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 225
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.27137
New value of Value function: 4.27314
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 226
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 4.27125
New value of Value function: 4.27242
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 227
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 4.27062
New value of Value function: 4.27159
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 228
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.26946
New value of Value function: 4.27137
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 229
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.26926
New value of Value function: 4.27125
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 230
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 4.26935
New value of Value function: 4.27062
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 231
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 566
New value of Q matrix: 4.26882
New value of Value function: 4.27031
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 232
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 635
New value of Q matrix: 4.26862
New value of Value function: 4.26946
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 233
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.26734
New value of Value function: 4.26935
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 234
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 4.26746
New value of Value function: 4.26926
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 235
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.26716
New value of Value function: 4.26882
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 236
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 4.26703
New value of Value function: 4.26862
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 237
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 4.26692
New value of Value function: 4.26746
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 238
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 4.26557
New value of Value function: 4.26734
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 239
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.26521
New value of Value function: 4.26716
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 240
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.26319
New value of Value function: 4.26716
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 241
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 4.26376
New value of Value function: 4.26716
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 242
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.26506
New value of Value function: 4.26703
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 243
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 4.26524
New value of Value function: 4.26692
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 244
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 637
New value of Q matrix: 4.26523
New value of Value function: 4.26524
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 245
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.26117
New value of Value function: 4.26524
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 246
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 4.26345
New value of Value function: 4.26523
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 247
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 638
New value of Q matrix: 4.26354
New value of Value function: 4.26506
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 248
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 4.26173
New value of Value function: 4.26506
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 249
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.26296
New value of Value function: 4.26376
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 250
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 4.26188
New value of Value function: 4.26354
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 251
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 4.26186
New value of Value function: 4.26296
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 252
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.25915
New value of Value function: 4.26296
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 253
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.26087
New value of Value function: 4.26188
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 254
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 4.26
New value of Value function: 4.26186
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 255
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 4.2582
New value of Value function: 4.26186
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 256
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.25717
New value of Value function: 4.26186
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 257
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 4.26017
New value of Value function: 4.26173
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 258
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 4.25995
New value of Value function: 4.26087
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 259
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.25878
New value of Value function: 4.26017
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 260
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 641
New value of Q matrix: 4.25849
New value of Value function: 4.25995
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 261
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 4.25817
New value of Value function: 4.25878
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 262
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.25669
New value of Value function: 4.25849
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 263
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 642
New value of Q matrix: 4.25681
New value of Value function: 4.2582
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 264
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 4.25639
New value of Value function: 4.2582
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 265
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 4.25633
New value of Value function: 4.25717
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 266
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.25507
New value of Value function: 4.25681
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 267
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 643
New value of Q matrix: 4.25513
New value of Value function: 4.25669
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 268
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 4.25463
New value of Value function: 4.25669
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 269
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 4.25447
New value of Value function: 4.25669
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 270
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.25461
New value of Value function: 4.25513
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 271
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 644
New value of Q matrix: 4.25345
New value of Value function: 4.25507
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 272
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.25297
New value of Value function: 4.25463
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 273
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 4.25285
New value of Value function: 4.25461
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 274
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.25253
New value of Value function: 4.25447
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 275
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 4.2526
New value of Value function: 4.25345
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 276
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 645
New value of Q matrix: 4.25178
New value of Value function: 4.25297
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 277
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.25087
New value of Value function: 4.25285
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 278
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 4.25108
New value of Value function: 4.2526
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 279
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 4.24937
New value of Value function: 4.2526
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 280
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 4.24774
New value of Value function: 4.2526
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 281
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 4.25073
New value of Value function: 4.25253
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 282
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.25046
New value of Value function: 4.25178
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 283
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 4.24614
New value of Value function: 4.25178
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 284
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 646
New value of Q matrix: 4.25011
New value of Value function: 4.25087
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 285
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.24877
New value of Value function: 4.25073
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 286
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 4.24887
New value of Value function: 4.25046
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 287
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.24839
New value of Value function: 4.25011
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 288
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 647
New value of Q matrix: 4.24844
New value of Value function: 4.24887
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 289
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 4.24701
New value of Value function: 4.24877
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 290
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.24668
New value of Value function: 4.24844
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 291
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 648
New value of Q matrix: 4.24677
New value of Value function: 4.24839
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 292
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.24632
New value of Value function: 4.24701
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 293
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 4.24515
New value of Value function: 4.24677
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 294
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 649
New value of Q matrix: 4.2451
New value of Value function: 4.24668
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 295
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 650
New value of Q matrix: 4.2435
New value of Value function: 4.24668
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 296
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.2446
New value of Value function: 4.24632
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 297
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 4.24438
New value of Value function: 4.24632
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 298
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.24425
New value of Value function: 4.24515
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 299
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.24223
New value of Value function: 4.24515
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 300
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 4.24329
New value of Value function: 4.2446
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 301
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.24251
New value of Value function: 4.24438
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 302
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 4.24262
New value of Value function: 4.2435
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 303
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 651
New value of Q matrix: 4.24183
New value of Value function: 4.24329
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 304
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 652
New value of Q matrix: 4.24023
New value of Value function: 4.24329
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 305
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 4.24144
New value of Value function: 4.24262
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 306
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 653
New value of Q matrix: 4.23866
New value of Value function: 4.24262
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 307
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 4.24086
New value of Value function: 4.24251
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 308
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.24019
New value of Value function: 4.24251
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 309
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 654
New value of Q matrix: 4.23715
New value of Value function: 4.24251
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 310
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.24043
New value of Value function: 4.24144
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 311
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 4.23959
New value of Value function: 4.24086
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 312
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 4.23911
New value of Value function: 4.24043
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 313
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.23836
New value of Value function: 4.24019
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 314
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 4.2374
New value of Value function: 4.24019
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 315
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 4.23576
New value of Value function: 4.24019
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 316
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.23814
New value of Value function: 4.23959
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 317
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 4.23774
New value of Value function: 4.23836
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 318
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.23628
New value of Value function: 4.23814
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 319
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.23608
New value of Value function: 4.23774
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 320
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 4.23409
New value of Value function: 4.23774
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 321
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 4.23589
New value of Value function: 4.23715
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 322
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 655
New value of Q matrix: 4.2355
New value of Value function: 4.23628
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 323
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.23421
New value of Value function: 4.23608
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 324
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.23404
New value of Value function: 4.23589
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 325
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.23208
New value of Value function: 4.23589
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 326
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 4.23405
New value of Value function: 4.2355
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 327
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 656
New value of Q matrix: 4.23384
New value of Value function: 4.23421
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 328
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.23215
New value of Value function: 4.23409
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 329
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.23014
New value of Value function: 4.23409
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 330
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 4.23234
New value of Value function: 4.23405
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 331
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 4.23221
New value of Value function: 4.23384
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 332
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 657
New value of Q matrix: 4.23219
New value of Value function: 4.23234
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 333
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 4.2306
New value of Value function: 4.23221
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 334
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 4.22892
New value of Value function: 4.23221
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 335
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.23009
New value of Value function: 4.23221
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 336
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 4.23037
New value of Value function: 4.23219
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 337
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 658
New value of Q matrix: 4.23054
New value of Value function: 4.23054
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 338
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 659
New value of Q matrix: 4.22889
New value of Value function: 4.23037
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 339
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 4.22724
New value of Value function: 4.23037
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 340
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 4.22853
New value of Value function: 4.23014
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 341
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.2281
New value of Value function: 4.23009
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 342
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 4.22562
New value of Value function: 4.23009
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 343
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.22803
New value of Value function: 4.22889
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 660
New value of Q matrix: 4.22725
New value of Value function: 4.22853
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 345
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 4.2267
New value of Value function: 4.2281
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 346
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 4.22493
New value of Value function: 4.2281
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.22598
New value of Value function: 4.2281
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.22606
New value of Value function: 4.22725
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 4.2256
New value of Value function: 4.22606
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 350
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 4.22403
New value of Value function: 4.22598
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 351
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.22392
New value of Value function: 4.22562
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 352
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 4.22388
New value of Value function: 4.2256
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 662
New value of Q matrix: 4.22396
New value of Value function: 4.22493
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 4.22219
New value of Value function: 4.22493
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 355
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 4.22057
New value of Value function: 4.22493
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 356
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 4.2231
New value of Value function: 4.22403
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 4.22201
New value of Value function: 4.22396
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 4.22232
New value of Value function: 4.22392
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 4.21897
New value of Value function: 4.22392
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.22188
New value of Value function: 4.2231
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 4.22128
New value of Value function: 4.22232
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 4.21738
New value of Value function: 4.22232
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 664
New value of Q matrix: 4.22068
New value of Value function: 4.22201
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 4.21998
New value of Value function: 4.22188
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 4.21805
New value of Value function: 4.22188
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.21983
New value of Value function: 4.22128
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 4.21945
New value of Value function: 4.22068
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 4.21905
New value of Value function: 4.21983
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 4.21765
New value of Value function: 4.21983
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.21779
New value of Value function: 4.21905
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 666
New value of Q matrix: 4.21741
New value of Value function: 4.21805
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 4.21603
New value of Value function: 4.21779
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.21575
New value of Value function: 4.21765
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 4.21583
New value of Value function: 4.21741
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 4.21408
New value of Value function: 4.21741
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 667
New value of Q matrix: 4.21578
New value of Value function: 4.21738
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 4.21565
New value of Value function: 4.21583
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 4.21401
New value of Value function: 4.21578
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 4.21215
New value of Value function: 4.21578
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 668
New value of Q matrix: 4.21415
New value of Value function: 4.21575
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 669
New value of Q matrix: 4.21258
New value of Value function: 4.21575
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.21371
New value of Value function: 4.21565
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.21177
New value of Value function: 4.21565
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 4.21393
New value of Value function: 4.21401
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.20985
New value of Value function: 4.21401
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 386
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 4.2122
New value of Value function: 4.21393
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 387
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 4.21221
New value of Value function: 4.21258
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 388
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 4.21016
New value of Value function: 4.21258
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 389
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 4.2105
New value of Value function: 4.21258
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 390
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 670
New value of Q matrix: 4.21095
New value of Value function: 4.2122
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 391
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 4.21039
New value of Value function: 4.21095
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 392
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 671
New value of Q matrix: 4.20933
New value of Value function: 4.2105
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 393
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 4.20879
New value of Value function: 4.21039
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 394
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 4.20858
New value of Value function: 4.21016
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 395
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.20784
New value of Value function: 4.21016
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 396
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 672
New value of Q matrix: 4.20773
New value of Value function: 4.21016
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 397
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 4.20816
New value of Value function: 4.20879
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 398
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 4.20707
New value of Value function: 4.20858
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 399
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 4.20678
New value of Value function: 4.20816
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 400
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 4.20616
New value of Value function: 4.20784
New value of Policy matrix: 1

