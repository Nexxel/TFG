=======================================
Episode: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 0.457496
New value of Value function: 0.457496
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 6
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 7
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 12
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 13
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 14
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 15
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 16
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 17
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 18
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 19
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 20
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 21
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 22
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 23
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 24
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 25
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 26
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 27
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 28
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 29
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 30
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 31
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 32
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 33
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 34
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 35
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 36
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 37
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.47056
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 0.840793
New value of Value function: 0.840793
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 39
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 40
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.16762
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.114337
New value of Value function: 0.840793
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.839539
New value of Value function: 0.839539
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.15808
New value of Value function: 1.15808
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 44
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 45
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 46
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 47
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 48
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.8535
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 2.1459
New value of Value function: 2.1459
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 50
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.839492
New value of Value function: 0.839492
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.313231
New value of Value function: 2.1459
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.369817
New value of Value function: 2.1459
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 2.38913
New value of Value function: 2.38913
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 54
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.62041
New value of Value function: 0.839492
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.420646
New value of Value function: 2.38913
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 2.38572
New value of Value function: 2.38572
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 2.59013
New value of Value function: 2.59013
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 58
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.23002
New value of Value function: 3.23002
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 59
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.71473
New value of Value function: 3.71473
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 60
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.2365
New value of Value function: 2.2365
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 61
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 3.96443
New value of Value function: 3.96443
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 62
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.08065
New value of Value function: 2.08065
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 63
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 4.0071
New value of Value function: 4.0071
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 64
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.38622
New value of Value function: 3.38622
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 65
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 66
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 67
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 68
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 69
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 70
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 71
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 72
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 73
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 74
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 75
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 76
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 77
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 78
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 79
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 80
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 81
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 82
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 83
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 84
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.95
New value of Value function: 7.95
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 85
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.14315
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 86
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 87
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 88
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 89
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 90
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 91
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 92
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 93
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 94
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 95
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 96
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 97
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 98
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 99
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 100
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 101
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 102
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 103
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 104
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 105
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 106
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 107
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 108
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 109
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 110
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 111
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 112
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 113
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 114
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 115
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 116
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 117
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 118
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 119
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 120
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 121
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 122
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.435773
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 2.64752
New value of Value function: 2.64752
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 124
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 125
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.279676
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 2.6964
New value of Value function: 2.6964
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 127
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -0.141299
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 128
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 129
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 130
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.361378
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 2.7381
New value of Value function: 2.7381
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 132
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 133
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 134
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 135
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 136
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 137
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 138
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 139
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 140
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 141
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 142
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 143
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 144
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 145
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 146
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 147
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 148
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 149
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 150
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 151
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 152
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 153
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 154
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 155
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 156
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 0.424614
New value of Value function: 0.424614
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 157
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.579632
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 158
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 0.712307
New value of Value function: 0.712307
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 159
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.294816
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 160
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.264385
New value of Value function: 0.264385
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 2.80936
New value of Value function: 2.80936
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 162
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 0.564699
New value of Value function: 0.564699
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 163
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.440948
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 164
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 0.729227
New value of Value function: 0.729227
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 165
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.278065
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 166
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 0.394073
New value of Value function: 0.394073
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 2.83507
New value of Value function: 2.83507
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 168
----------
State: 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 169
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.73205
New value of Value function: 3.73205
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 170
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 171
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 172
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 173
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.69473
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 174
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 175
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 176
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 177
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 178
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 179
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 180
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 181
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 182
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 183
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 184
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 185
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 186
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 187
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.8805
New value of Value function: 1.8805
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 188
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 189
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.92015
New value of Value function: 4.92015
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 190
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.87375
New value of Value function: 1.87375
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 191
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.88758
New value of Value function: 4.88758
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 192
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.85351
New value of Value function: 1.85351
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 193
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.86406
New value of Value function: 4.86406
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 194
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.83446
New value of Value function: 1.83446
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 195
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.13205
New value of Value function: 6.13205
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 196
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.18388
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 197
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 198
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.193283
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.742384
New value of Value function: 2.83507
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 2.83128
New value of Value function: 2.83128
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 2.85363
New value of Value function: 2.85363
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 2
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 3
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 4
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.174909
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.679624
New value of Value function: 2.85363
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.484499
New value of Value function: 2.85363
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 2.87285
New value of Value function: 2.87285
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 3

=======================================
Episode: 3
Iteration: 9
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.155882
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.883347
New value of Value function: 2.87285
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 3.27606
New value of Value function: 3.27606
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 12
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.05072
New value of Value function: 1.05072
New value of Policy matrix: 3

=======================================
Episode: 3
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 3.37471
New value of Value function: 3.37471
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 14
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 1.05072
New value of Policy matrix: 3

=======================================
Episode: 3
Iteration: 15
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 5.04021
New value of Value function: 5.04021
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 16
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.17614
New value of Value function: 2.17614
New value of Policy matrix: 3

=======================================
Episode: 3
Iteration: 17
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.845624
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 2.58807
New value of Value function: 2.58807
New value of Policy matrix: 3

=======================================
Episode: 3
Iteration: 19
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 20
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 21
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.12132
New value of Value function: 2.12132
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 22
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 23
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 24
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 25
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 26
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 27
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 28
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 29
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 30
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 31
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.92507
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 32
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 33
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 34
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 35
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 36
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 37
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 38
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.340966
New value of Value function: 0.340966
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 3.52137
New value of Value function: 3.52137
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 40
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.38104
New value of Value function: 2.38104
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 41
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.40543
New value of Value function: 1.40543
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 42
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.64764
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.10011
New value of Value function: 3.38622
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 44
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.83206
New value of Value function: 2.83206
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 45
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.04504
New value of Value function: 4.04504
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 46
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 47
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 48
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 49
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 50
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.18644
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 51
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.40598
New value of Value function: 4.40598
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 52
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 53
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 54
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 55
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 56
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 57
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.869843
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 58
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.616
New value of Value function: 4.616
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 59
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 60
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 61
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 62
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 63
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 64
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.608628
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 65
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 1.7487
New value of Value function: 1.7487
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 66
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 67
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 68
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 69
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 70
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 71
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 72
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 73
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 74
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 75
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 76
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 77
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 78
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 79
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.486161
New value of Value function: 0.486161
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 3.51629
New value of Value function: 3.51629
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 81
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 0.8495
New value of Value function: 0.8495
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 82
----------
State: 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.481122
New value of Value function: 0.481122
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 3.45124
New value of Value function: 3.45124
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 84
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 85
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 86
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.535534
New value of Value function: 0.535534
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 87
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.46982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 88
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.02015
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 89
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.599638
New value of Value function: 0.599638
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 3.46904
New value of Value function: 3.46904
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 91
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1.03797
New value of Value function: 1.03797
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 92
----------
State: 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.448049
New value of Value function: 0.448049
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 3.41086
New value of Value function: 3.41086
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 94
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -1.84471
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 95
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 96
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 97
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 98
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 99
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 100
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 101
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 102
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 103
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 104
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 105
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 106
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 107
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.629929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 108
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.368321
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 109
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.05939
New value of Value function: 4.05939
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 110
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.75242
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 111
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 112
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 113
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 114
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 115
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 116
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 117
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 118
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 119
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 120
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.376754
New value of Value function: 0.376754
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 3.4062
New value of Value function: 3.4062
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 122
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.372138
New value of Value function: 0.376754
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 3.35658
New value of Value function: 3.35658
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 124
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.323009
New value of Value function: 0.323009
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 3.35211
New value of Value function: 3.35211
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 126
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.319779
New value of Value function: 0.323009
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 127
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -2.73382
New value of Value function: 0.319779
New value of Policy matrix: 4

=======================================
Episode: 3
Iteration: 128
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.31658
New value of Value function: 4.31658
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 129
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.317518
New value of Value function: 0.317518
New value of Policy matrix: 4

=======================================
Episode: 3
Iteration: 130
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.315685
New value of Value function: 0.315685
New value of Policy matrix: 4

=======================================
Episode: 3
Iteration: 131
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.314106
New value of Value function: 0.314106
New value of Policy matrix: 4

=======================================
Episode: 3
Iteration: 132
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 133
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 134
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.50186
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 135
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 136
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.02
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 137
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 138
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 139
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 140
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 141
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -0.997592
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 142
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.19283
New value of Value function: 6.19283
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 143
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 144
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 145
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 146
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 147
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 148
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.97
New value of Value function: 1.97
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 149
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 3.44274
New value of Value function: 3.44274
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 150
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.70711
New value of Value function: 1.70711
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 151
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 152
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 153
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.309964
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 154
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 1.87621
New value of Value function: 1.87621
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 155
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 156
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 157
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -2.0497
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 158
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 3.40543
New value of Value function: 3.40543
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 159
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 160
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 161
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 162
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 163
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 164
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 165
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 166
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.59169
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 167
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.02029
New value of Value function: 4.02029
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 168
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 1.9381
New value of Value function: 1.9381
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 169
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 170
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 171
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 172
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.03053
New value of Value function: 2.03053
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 173
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 174
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 175
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 176
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 177
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 178
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 179
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 180
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 181
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 182
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 183
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 184
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 185
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 186
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 187
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 188
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 189
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 190
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 191
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 192
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 193
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 194
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 195
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 196
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 197
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 198
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 199
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 2.97
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 200
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.864538
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 3.30972
New value of Value function: 3.30972
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 2
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.276626
New value of Value function: 0.276626
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.868331
New value of Value function: 3.30972
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 2.06776
New value of Value function: 3.30972
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 5
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.11641
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 6
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.55436
New value of Value function: 1.55436
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 3.45663
New value of Value function: 3.45663
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.0921
New value of Value function: 1.0921
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 71
New value of Q matrix: 3.53075
New value of Value function: 3.53075
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 10
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.866585
New value of Value function: 0.866585
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 3.56931
New value of Value function: 3.56931
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 12
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 1.28684
New value of Value function: 1.28684
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 13
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.05525
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 14
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.533613
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 3.65178
New value of Value function: 3.65178
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 16
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 1.06298
New value of Value function: 1.06298
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 74
New value of Q matrix: 3.69835
New value of Value function: 3.69835
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.36396
New value of Value function: 2.36396
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 19
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.661363
New value of Value function: 0.661363
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.11
New value of Value function: 3.69835
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 75
New value of Q matrix: 3.8899
New value of Value function: 3.8899
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 22
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.17404
New value of Value function: 2.17404
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 23
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.197715
New value of Value function: 4.0071
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 24
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.10501
New value of Value function: 4.10501
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 25
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.98254
New value of Value function: 3.98254
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 26
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.38739
New value of Value function: 2.38739
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 27
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.2025
New value of Value function: 4.2025
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 28
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 2.38739
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 29
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 30
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 31
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 32
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 33
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 34
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.50018
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 35
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.69583
New value of Value function: 4.69583
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 36
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.95718
New value of Value function: 4.95718
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 37
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.09708
New value of Value function: 3.09708
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 38
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.23082
New value of Value function: 4.616
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 39
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 5.05333
New value of Value function: 5.05333
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 40
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.3123
New value of Value function: 6.3123
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 41
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.71275
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 42
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.59265
New value of Value function: 5.59265
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.89731
New value of Value function: 5.89731
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 44
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 45
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 46
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 47
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 48
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 49
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 50
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 51
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 52
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 53
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 54
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 55
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 56
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 57
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 58
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 59
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 60
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 61
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 62
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 63
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 64
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 65
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 66
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 67
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 68
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 69
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 70
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 71
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.536728
New value of Value function: 0.536728
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 72
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.7155
New value of Value function: 5.7155
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 73
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 7.04534
New value of Value function: 7.04534
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 74
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.10895
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 75
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.87621
New value of Value function: 4.87621
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 76
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.15981
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 77
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 78
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 79
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 80
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 81
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 82
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.52139
New value of Value function: 5.52139
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 83
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.40007
New value of Value function: 3.40007
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 84
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.70711
New value of Value function: 2.70711
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 85
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 86
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 87
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 88
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.01023
New value of Value function: 4.01023
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 89
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.81128
New value of Value function: 0.81128
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 90
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 2.32497
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 91
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 0.556501
New value of Value function: 0.556501
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 92
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.11546
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 93
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 94
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 1.10011
New value of Value function: 1.10011
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 95
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 96
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 97
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 3.9403
New value of Value function: 3.9403
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 98
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.76496
New value of Value function: 2.76496
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 99
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.03091
New value of Value function: 4.03091
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 100
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.487063
New value of Value function: 0.487063
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 101
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.544553
New value of Value function: 1.10011
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 102
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.11239
New value of Value function: 0.544553
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 103
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 104
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 105
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 106
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 107
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -1.38104
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 108
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.53911
New value of Value function: 2.53911
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 109
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.542118
New value of Value function: 0.542118
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 110
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.539905
New value of Value function: 0.539905
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 111
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.537864
New value of Value function: 0.537864
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 112
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.535962
New value of Value function: 0.535962
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 113
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.534176
New value of Value function: 0.534176
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 114
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.532486
New value of Value function: 0.532486
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 115
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.530881
New value of Value function: 0.530881
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 116
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.529348
New value of Value function: 0.529348
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 117
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.26269
New value of Value function: 0.529348
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 118
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 2.76496
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 119
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.93557
New value of Value function: 6.93557
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 120
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.47259
New value of Value function: 3.47259
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 121
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.75655
New value of Value function: 4.75655
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 122
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.502165
New value of Value function: 0.502165
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 123
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.52788
New value of Value function: 0.52788
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 124
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.52647
New value of Value function: 0.52647
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 125
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.52511
New value of Value function: 0.52511
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 126
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.523797
New value of Value function: 0.523797
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 127
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.522527
New value of Value function: 0.522527
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 128
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.521295
New value of Value function: 0.521295
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 129
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.222329
New value of Value function: 0.521295
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 130
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.507425
New value of Value function: 0.507425
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 131
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.520099
New value of Value function: 0.520099
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 132
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.518936
New value of Value function: 0.518936
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 133
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.76733
New value of Value function: 0.518936
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 134
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.09079
New value of Value function: 4.09079
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 135
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.09008
New value of Value function: 5.09008
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 136
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.039182
New value of Value function: 0.507425
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 137
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.86622
New value of Value function: 5.09008
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 138
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.15627
New value of Value function: 8.15627
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 139
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.51492
New value of Value function: 4.51492
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 140
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.25839
New value of Value function: 5.25839
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 141
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.50966
New value of Value function: 0.50966
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 142
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.517804
New value of Value function: 0.517804
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 143
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.5167
New value of Value function: 0.5167
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 144
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.515623
New value of Value function: 0.515623
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 145
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.51457
New value of Value function: 0.51457
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 146
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.504564
New value of Value function: 0.51457
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 147
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.509582
New value of Value function: 0.509582
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 148
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.337519
New value of Value function: 0.51457
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 149
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.509532
New value of Value function: 0.509532
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 150
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.513541
New value of Value function: 0.513541
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 151
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.512534
New value of Value function: 0.512534
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 152
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.511548
New value of Value function: 0.511548
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 153
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.510581
New value of Value function: 0.510581
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 154
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.509633
New value of Value function: 0.509633
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 155
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.504474
New value of Value function: 0.509633
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 156
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.504437
New value of Value function: 0.509532
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 157
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.508026
New value of Value function: 0.508026
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 158
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.508702
New value of Value function: 0.508702
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 159
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.507789
New value of Value function: 0.507789
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 160
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.503591
New value of Value function: 0.507789
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 161
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 162
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1373
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 163
----------
State: 1373
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 164
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.09203
New value of Value function: 1.09203
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 165
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.553175
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 166
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 4.50463
New value of Value function: 4.50463
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 167
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.00638
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 168
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 4.78644
New value of Value function: 4.78644
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 169
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 2.41722
New value of Value function: 2.41722
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 170
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.53475
New value of Value function: 2.53475
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 171
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.98586
New value of Value function: 1.98586
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 172
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.97439
New value of Value function: 1.97439
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 173
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.96452
New value of Value function: 1.96452
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 174
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.95573
New value of Value function: 1.95573
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 175
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.94775
New value of Value function: 1.94775
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 176
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.94039
New value of Value function: 1.94039
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 177
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.93353
New value of Value function: 1.93353
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 178
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.92708
New value of Value function: 1.92708
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 179
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.60695
New value of Value function: 1.92708
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 180
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.11451
New value of Value function: 4.11451
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 181
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -2.23554
New value of Value function: 1.92708
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 182
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.29507
New value of Value function: 3.29507
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 183
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.92099
New value of Value function: 1.92099
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 184
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.9152
New value of Value function: 1.9152
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 185
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.90967
New value of Value function: 1.90967
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 186
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.90437
New value of Value function: 1.90437
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 187
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.89928
New value of Value function: 1.89928
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 188
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.89438
New value of Value function: 1.89438
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 189
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.88964
New value of Value function: 1.88964
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 190
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.88506
New value of Value function: 1.88506
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 191
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.88062
New value of Value function: 1.88062
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 192
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.8763
New value of Value function: 1.8763
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 193
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.87211
New value of Value function: 1.87211
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 194
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.86802
New value of Value function: 1.86802
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 195
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.86404
New value of Value function: 1.86404
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 196
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.86015
New value of Value function: 1.86015
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 197
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.793514
New value of Value function: 1.86015
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 198
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.06831
New value of Value function: 4.06831
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 199
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.85635
New value of Value function: 1.85635
New value of Policy matrix: 2

=======================================
Episode: 4
Iteration: 200
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 1.85264
New value of Value function: 1.85264
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.88544
New value of Value function: 3.88544
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 2.22102
New value of Value function: 3.88544
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.846584
New value of Value function: 0.846584
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 77
New value of Q matrix: 4.24766
New value of Value function: 4.24766
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 5
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.20519
New value of Value function: 4.10501
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 78
New value of Q matrix: 4.56655
New value of Value function: 4.56655
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 0.855157
New value of Value function: 1.20519
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 8
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.440544
New value of Value function: 0.846584
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 79
New value of Q matrix: 4.52453
New value of Value function: 4.52453
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 10
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.8828
New value of Value function: 0.855157
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 11
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.29397
New value of Value function: 1.29397
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 4.44874
New value of Value function: 4.44874
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 13
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.07932
New value of Value function: 1.07932
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 4.40649
New value of Value function: 4.40649
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 15
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 1.18633
New value of Value function: 1.18633
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 82
New value of Q matrix: 4.38087
New value of Value function: 4.38087
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 17
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.0028
New value of Value function: 8.0028
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 18
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 6.53554
New value of Value function: 6.53554
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 19
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 6.30196
New value of Value function: 6.30196
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 20
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 7.13778
New value of Value function: 7.13778
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 21
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 5.38616
New value of Value function: 5.38616
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 22
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.0817
New value of Value function: 11.0817
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 23
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.8705
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 24
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.67189
New value of Value function: 8.67189
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 25
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.0817
New value of Value function: 11.0817
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 26
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.56158
New value of Value function: 6.56158
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 27
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.98657
New value of Value function: 8.98657
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 28
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.09212
New value of Value function: 4.09212
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 29
----------
State: 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 30
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 31
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 32
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 33
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 34
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 35
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 36
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 37
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.98
New value of Value function: 6.98
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 38
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.25967
New value of Value function: 1.83446
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 39
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 2.91938
New value of Value function: 2.91938
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 41
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.948805
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 42
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.27408
New value of Value function: 5.27408
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 43
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 44
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.33706
New value of Value function: 1.33706
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 4.37459
New value of Value function: 4.37459
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 1.50571
New value of Value function: 1.50571
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.94595
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 48
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 2.25285
New value of Value function: 2.25285
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 49
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 51
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 53
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 54
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 55
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 56
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 57
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.899893
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 58
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 59
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 60
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 61
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 62
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 63
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.26683
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 64
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.58699
New value of Value function: 2.58699
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 65
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 66
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 67
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 68
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 69
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.59993
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 70
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.12132
New value of Value function: 4.12132
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 71
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 72
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.852855
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 73
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 2.7556
New value of Value function: 2.7556
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 74
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 75
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 76
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 77
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 78
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 79
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 80
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 81
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 82
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 83
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 84
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 85
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 86
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 87
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 88
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 89
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -4.40826
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 90
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 91
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 92
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.98
New value of Value function: 6.98
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 93
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 94
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 95
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 96
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 97
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 98
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 99
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 100
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 101
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.32017
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 102
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.08011
New value of Value function: 2.7556
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 103
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.47161
New value of Value function: 4.47161
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 104
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 3.59634
New value of Value function: 3.59634
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 105
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.39766
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 106
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.14315
New value of Value function: 4.14315
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 107
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.34164
New value of Value function: 3.34164
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 108
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 6
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.57012
New value of Value function: 4.37459
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 1.4536
New value of Value function: 4.37459
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 4.36982
New value of Value function: 4.36982
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 85
New value of Q matrix: 4.22124
New value of Value function: 4.22124
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 5
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 6.92277
New value of Value function: 6.92277
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 6
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 9.46199
New value of Value function: 9.46199
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 7
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 7.20262
New value of Value function: 7.20262
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 8
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.47891
New value of Value function: 5.38616
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 4.18071
New value of Value function: 5.38616
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 7.24363
New value of Value function: 7.24363
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 11
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 7.57744
New value of Value function: 7.57744
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 12
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 8.84452
New value of Value function: 8.84452
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 13
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 11.0817
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 8.9709
New value of Value function: 8.9709
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 15
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.3209
New value of Value function: 11.3209
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 16
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.73528
New value of Value function: 6.73528
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 17
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 20
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 22
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 23
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 24
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 25
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 26
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.17903
New value of Value function: 1.17903
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 4.08955
New value of Value function: 4.08955
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 28
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 29
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 30
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 31
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 32
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 33
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 34
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 35
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 36
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 37
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 38
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 39
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 40
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 41
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 42
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 43
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 44
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 45
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.42335
New value of Value function: 3.42335
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 46
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.500179
New value of Value function: 8.98657
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 47
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.3836
New value of Value function: 6.3836
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 48
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.4826
New value of Value function: 2.4826
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 49
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.7896
New value of Value function: 6.7896
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 50
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.17197
New value of Value function: 2.17197
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 51
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.91711
New value of Value function: 6.91711
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 52
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.448357
New value of Value function: 2.17197
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 53
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.04949
New value of Value function: 2.04949
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 54
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.9544
New value of Value function: 6.9544
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 55
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.99129
New value of Value function: 1.99129
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 56
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.95977
New value of Value function: 6.95977
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 57
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 1.95758
New value of Value function: 1.95758
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 58
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 2.16724
New value of Value function: 6.95977
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 59
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.04866
New value of Value function: 1.17903
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 87
New value of Q matrix: 4.18052
New value of Value function: 4.18052
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 61
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 1.93627
New value of Value function: 1.93627
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 62
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.94685
New value of Value function: 6.94685
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 63
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 1.91851
New value of Value function: 1.91851
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 64
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.88119
New value of Value function: 6.94685
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 65
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.88119
New value of Value function: 8.9709
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 66
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.20767
New value of Value function: 9.20767
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 67
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 11.2182
New value of Value function: 11.2182
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 68
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 9.13582
New value of Value function: 9.13582
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 69
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.4193
New value of Value function: 11.4193
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 70
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.60979
New value of Value function: 7.60979
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 71
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 6.93313
New value of Value function: 6.93313
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 72
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 1.90272
New value of Value function: 1.90272
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 73
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 6.91942
New value of Value function: 6.91942
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 74
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 1.88816
New value of Value function: 1.88816
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 75
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.04969
New value of Value function: 6.91942
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 76
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 8.85022
New value of Value function: 8.85022
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 77
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.46932
New value of Value function: 6.91942
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 78
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.9745
New value of Value function: 8.9709
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 79
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 80
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 81
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 82
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 83
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 84
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 85
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 86
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 87
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 88
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 89
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 90
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 91
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 7.88119
New value of Value function: 7.88119
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 92
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.8502
New value of Value function: 11.8502
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 93
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 5.64934
New value of Value function: 5.64934
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 94
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.15052
New value of Value function: 1.15052
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 88
New value of Q matrix: 4.65087
New value of Value function: 4.65087
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 96
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.79643
New value of Value function: 5.64934
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 97
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.14728
New value of Value function: 5.64934
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 98
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.59285
New value of Value function: 4.59285
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 99
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 5.96433
New value of Value function: 5.96433
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 100
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 1.62531
New value of Value function: 1.62531
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 101
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 6.12551
New value of Value function: 6.12551
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 102
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 1.48045
New value of Value function: 1.48045
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 103
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 6.20801
New value of Value function: 6.20801
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 104
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 1.39682
New value of Value function: 1.39682
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 105
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 6.05219
New value of Value function: 6.05219
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 106
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.87485
New value of Value function: 4.87485
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 107
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 6.12805
New value of Value function: 6.12805
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 108
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 1.31677
New value of Value function: 1.31677
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 109
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.25897
New value of Value function: 6.12805
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 110
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 6.1673
New value of Value function: 6.1673
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 111
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 1.267
New value of Value function: 1.267
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 112
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 6.18629
New value of Value function: 6.18629
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 113
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 1.23429
New value of Value function: 1.23429
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 114
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 5.60052
New value of Value function: 6.18629
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 115
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.337
New value of Value function: 11.337
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 116
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 6.1939
New value of Value function: 6.1939
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 117
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 1.21141
New value of Value function: 1.21141
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 118
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 6.19502
New value of Value function: 6.19502
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 119
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 1.19432
New value of Value function: 1.19432
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 120
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 6.19244
New value of Value function: 6.19244
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 121
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.587428
New value of Value function: 1.19432
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 122
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.82611
New value of Value function: 4.87485
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 123
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 5.02246
New value of Value function: 5.02246
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 124
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 6.1484
New value of Value function: 6.1484
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 125
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 5.05469
New value of Value function: 5.05469
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 126
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 6.12011
New value of Value function: 6.12011
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 127
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 5.05657
New value of Value function: 5.05657
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 128
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 6.09815
New value of Value function: 6.09815
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 129
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 5.04865
New value of Value function: 5.04865
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 130
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.37059
New value of Value function: 6.09815
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 131
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 5.04431
New value of Value function: 5.04431
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 132
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 6.07844
New value of Value function: 6.07844
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 133
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 5.03489
New value of Value function: 5.03489
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 134
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 6.061
New value of Value function: 6.061
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 135
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.4416
New value of Value function: 5.03489
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 89
New value of Q matrix: 5.11192
New value of Value function: 5.11192
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 137
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 6.08316
New value of Value function: 6.08316
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 138
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 1.15765
New value of Value function: 1.15765
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 139
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.87919
New value of Value function: 6.08316
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 140
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.1553
New value of Value function: 11.1553
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 141
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 6.09446
New value of Value function: 6.09446
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 142
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 1.13177
New value of Value function: 1.13177
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 143
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 6.09906
New value of Value function: 6.09906
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 144
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 1.11264
New value of Value function: 1.11264
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 145
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 6.09948
New value of Value function: 6.09948
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 146
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 1.09781
New value of Value function: 1.09781
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 147
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 6.09731
New value of Value function: 6.09731
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 148
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.29092
New value of Value function: 4.29092
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 149
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.56826
New value of Value function: 8.98657
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 150
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.40546
New value of Value function: 7.40546
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 151
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.53521
New value of Value function: 7.53521
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 152
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.50228
New value of Value function: 5.50228
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 153
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 4.70322
New value of Value function: 4.70322
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 154
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.18288
New value of Value function: 3.18288
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 155
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.81133
New value of Value function: 4.81133
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 156
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.84882
New value of Value function: 3.18288
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 90
New value of Q matrix: 5.22146
New value of Value function: 5.22146
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 158
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 4.22466
New value of Value function: 4.22466
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 159
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.86301
New value of Value function: 2.86301
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 91
New value of Q matrix: 5.42702
New value of Value function: 5.42702
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 161
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 4.7337
New value of Value function: 4.7337
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 162
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 2.53682
New value of Value function: 2.53682
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 163
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.355796
New value of Value function: 0.355796
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 164
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.80117
New value of Value function: 2.53682
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 165
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 166
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 167
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 168
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 169
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 0.511455
New value of Value function: 0.511455
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 170
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.52785
New value of Value function: 2.52785
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 171
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 1.56375
New value of Value function: 2.52785
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 172
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.505176
New value of Value function: 0.505176
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 173
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 36.3519
New value of Value function: 36.3519
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 174
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 99
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 6
Iteration: 175
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.42136
New value of Value function: 5.42136
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 93
New value of Q matrix: 6.14163
New value of Value function: 6.14163
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 9.87145
New value of Value function: 9.87145
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 7.92445
New value of Value function: 7.92445
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 7.18721
New value of Value function: 7.18721
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 3.51278
New value of Value function: 3.51278
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 7
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.64641
New value of Value function: 7.18721
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 8
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.29669
New value of Value function: 7.18721
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 9
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 10.3583
New value of Value function: 10.3583
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.18779
New value of Value function: 7.92445
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 11
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.5761
New value of Value function: 10.5761
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 12
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 8.26823
New value of Value function: 8.26823
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 13
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 6.9368
New value of Value function: 6.9368
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 14
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 8.43442
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 8.72389
New value of Value function: 8.72389
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 16
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 12.3756
New value of Value function: 12.3756
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 17
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.27472
New value of Value function: 8.27472
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 18
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 7.17278
New value of Value function: 7.17278
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 6.43331
New value of Value function: 6.43331
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 20
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 7.88722
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 6.15382
New value of Value function: 6.15382
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 22
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.24242
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 23
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.7518
New value of Value function: 8.7518
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 24
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 7.82603
New value of Value function: 7.82603
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 25
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 6.01278
New value of Value function: 6.01278
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 26
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.80287
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 27
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.57192
New value of Value function: 6.01278
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 28
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 5.93551
New value of Value function: 5.93551
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 29
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.0216
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 30
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.0321
New value of Value function: 9.0321
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 31
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.16849
New value of Value function: 6.16849
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 32
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 4.21387
New value of Value function: 4.21387
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 94
New value of Q matrix: 6.24788
New value of Value function: 6.24788
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 34
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 3.2861
New value of Value function: 3.2861
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 35
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.06074
New value of Value function: 6.06074
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 36
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.00014
New value of Value function: 4.7337
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 37
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 7.57665
New value of Value function: 7.57665
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 38
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 4.13958
New value of Value function: 4.13958
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 39
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 5.38683
New value of Value function: 5.38683
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 4.36204
New value of Value function: 4.36204
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 41
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.51219
New value of Value function: 6.51219
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 13.9657
New value of Value function: 13.9657
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 43
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 25.8637
New value of Value function: 25.8637
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 95
New value of Q matrix: 7.33317
New value of Value function: 7.33317
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 45
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.59799
New value of Value function: 13.9657
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 96
New value of Q matrix: 8.30203
New value of Value function: 8.30203
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 47
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 17.8782
New value of Value function: 17.8782
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 48
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 18.7748
New value of Value function: 18.7748
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 49
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 9.72689
New value of Value function: 9.72689
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 16.7121
New value of Value function: 16.7121
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 12.1359
New value of Value function: 12.1359
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.03765
New value of Value function: 16.7121
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 53
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.9834
New value of Value function: 11.9834
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 54
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 15.964
New value of Value function: 15.964
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 55
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 12.8821
New value of Value function: 12.8821
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 56
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.12641
New value of Value function: 15.964
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 57
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 13.2586
New value of Value function: 13.2586
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 39.4926
New value of Value function: 39.4926
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 59
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 8.2936
New value of Value function: 8.2936
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 8.81652
New value of Value function: 8.81652
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.46871
New value of Value function: 10.5761
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 10.8921
New value of Value function: 10.8921
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.78336
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.68621
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 11.0652
New value of Value function: 11.0652
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.54371
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 9.02299
New value of Value function: 9.02299
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 10
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 8.30171
New value of Value function: 8.30171
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.32036
New value of Value function: 9.02299
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 12
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.47726
New value of Value function: 11.0652
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 13
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 11.3719
New value of Value function: 11.3719
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 14
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 9.33172
New value of Value function: 9.33172
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 9.89619
New value of Value function: 9.89619
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 16
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.8627
New value of Value function: 12.8627
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 17
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.4967
New value of Value function: 8.7518
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 18
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 9.78929
New value of Value function: 9.78929
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 19
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 13.1461
New value of Value function: 13.1461
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 20
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.24979
New value of Value function: 9.24979
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 21
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 8.32747
New value of Value function: 8.32747
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 22
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.05899
New value of Value function: 5.93551
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 99
New value of Q matrix: 8.82252
New value of Value function: 8.82252
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 24
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 26
New value of Q matrix: 1.51875
New value of Value function: 5.93551
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 25
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 11.9418
New value of Value function: 11.9418
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 26
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.99523
New value of Value function: 8.99523
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 27
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.79333
New value of Value function: 9.79333
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 28
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.71087
New value of Value function: 5.71087
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 29
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 14.8635
New value of Value function: 14.8635
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 30
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.29265
New value of Value function: 11.9834
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 31
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 9.43224
New value of Value function: 9.43224
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 24.1214
New value of Value function: 24.1214
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 33
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 7.31711
New value of Value function: 39.4926
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 34
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 31.1841
New value of Value function: 31.1841
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 35
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 14.8922
New value of Value function: 39.4926
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 36
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 27.3559
New value of Value function: 27.3559
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 24.1316
New value of Value function: 24.1316
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 33.2012
New value of Value function: 33.2012
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 39
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 19.9147
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 40
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 30.3298
New value of Value function: 30.3298
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 41
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -2.3094
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 42
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.73429
New value of Value function: 5.73429
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.81035
New value of Value function: 8.82252
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 100
New value of Q matrix: 8.80796
New value of Value function: 8.80796
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 45
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.69374
New value of Value function: 5.69374
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 46
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.63681
New value of Value function: 5.69374
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 47
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.66087
New value of Value function: 5.66087
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 48
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.63257
New value of Value function: 5.63681
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 49
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.59695
New value of Value function: 5.63257
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 50
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.60738
New value of Value function: 5.60738
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 51
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.71988
New value of Value function: 5.71988
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 101
New value of Q matrix: 10.1918
New value of Value function: 10.1918
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 8.78508
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 54
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 26.3554
New value of Value function: 26.3554
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 55
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 48.1974
New value of Value function: 48.1974
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 56
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 10.1817
New value of Value function: 10.1817
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 103
New value of Q matrix: 10.1494
New value of Value function: 10.1494
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 3
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 9.28127
New value of Value function: 9.28127
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 11.6607
New value of Value function: 11.6607
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 9.9481
New value of Value function: 9.9481
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 6
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 11.2643
New value of Value function: 11.2643
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 7
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.4832
New value of Value function: 13.4832
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 8
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.71044
New value of Value function: 8.71044
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 9
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 10.8465
New value of Value function: 11.1553
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 10
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.18646
New value of Value function: 8.71044
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 11
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.6095
New value of Value function: 10.6095
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 12
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.62334
New value of Value function: 8.71044
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 13
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 8.43828
New value of Value function: 8.62334
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.9888
New value of Value function: 13.9888
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 15
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 8.74092
New value of Value function: 11.9418
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 16
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 6.55772
New value of Value function: 6.55772
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 17
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 9.33329
New value of Value function: 9.33329
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 7.2564
New value of Value function: 7.2564
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 19
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.632
New value of Value function: 10.632
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 20
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 25.6248
New value of Value function: 25.6248
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 21
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 27.5886
New value of Value function: 27.5886
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 22
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 26.1025
New value of Value function: 26.1025
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 23
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 27.6648
New value of Value function: 27.6648
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 24
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 31.9038
New value of Value function: 31.9038
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 25
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 38.4984
New value of Value function: 38.4984
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 104
New value of Q matrix: 12.5455
New value of Value function: 12.5455
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 31.5848
New value of Value function: 31.9038
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 34.0166
New value of Value function: 34.0166
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 34.6482
New value of Value function: 34.6482
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 30
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 17.6808
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 34.7512
New value of Value function: 34.7512
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 32
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 31.7563
New value of Value function: 31.7563
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 33
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 23.282
New value of Value function: 23.282
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 16.4458
New value of Value function: 31.7563
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 34.683
New value of Value function: 34.683
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 30.2927
New value of Value function: 30.2927
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 37
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 24.8513
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 46.0072
New value of Value function: 46.0072
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 39
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 5
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.10453
New value of Value function: 12.5455
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 12.5332
New value of Value function: 12.5332
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.40726
New value of Value function: 12.5332
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 12.5211
New value of Value function: 12.5211
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.51508
New value of Value function: 12.5211
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.27731
New value of Value function: 12.5211
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 107
New value of Q matrix: 12.0792
New value of Value function: 12.0792
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 8
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.79899
New value of Value function: 7.79899
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 12.5381
New value of Value function: 12.5381
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 10
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 11.1362
New value of Value function: 13.9888
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 11
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 13.5002
New value of Value function: 13.5002
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 12
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.56236
New value of Value function: 8.56236
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 13
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 9.34943
New value of Value function: 9.34943
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 15.256
New value of Value function: 15.256
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 15
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 4.08649
New value of Value function: 11.9418
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 16
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.41275
New value of Value function: 9.41275
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 109
New value of Q matrix: 12.7569
New value of Value function: 12.7569
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 18
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.62839
New value of Value function: 8.74092
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 19
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 10.3231
New value of Value function: 10.3231
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 20
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 14.6018
New value of Value function: 14.6018
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 21
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 9.29223
New value of Value function: 9.29223
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 22
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 7.2512
New value of Value function: 7.2512
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 23
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.3974
New value of Value function: 11.3974
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 24
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 17.4647
New value of Value function: 17.4647
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 25
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 12.6902
New value of Value function: 12.6902
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 26
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 17.3999
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 27
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.98896
New value of Value function: 27.6648
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 28
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 21.5392
New value of Value function: 21.5392
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 29
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 22.4584
New value of Value function: 22.4584
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 110
New value of Q matrix: 11.8266
New value of Value function: 11.8266
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 31
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 20.2339
New value of Value function: 20.2339
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 26.3074
New value of Value function: 26.3074
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 32.4148
New value of Value function: 32.4148
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 34
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 28.3876
New value of Value function: 28.3876
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 26.5832
New value of Value function: 31.5848
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 36
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 21.9602
New value of Value function: 21.9602
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 31.3614
New value of Value function: 31.3614
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 38
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 31.1804
New value of Value function: 31.1804
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 39
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 31.0245
New value of Value function: 31.0245
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 30.8857
New value of Value function: 30.8857
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 30.7596
New value of Value function: 30.7596
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 30.6434
New value of Value function: 30.6434
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 43
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 30.535
New value of Value function: 30.535
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 44
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.54847
New value of Value function: 30.535
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 111
New value of Q matrix: 13.8581
New value of Value function: 13.8581
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 31.0665
New value of Value function: 31.0665
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 38.6492
New value of Value function: 38.6492
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 112
New value of Q matrix: 15.7383
New value of Value function: 15.7383
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 49
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 33.1058
New value of Value function: 33.1058
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 36.1902
New value of Value function: 36.1902
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 21.8016
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 52
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 34.2281
New value of Value function: 34.2281
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 53
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 34.2727
New value of Value function: 34.2727
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 54
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 24.4792
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 55
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 31.6519
New value of Value function: 34.2281
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 56
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 34.748
New value of Value function: 34.748
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 57
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 6.65422
New value of Value function: 34.2727
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 11.9034
New value of Value function: 34.2727
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 59
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 32.7685
New value of Value function: 32.7685
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 60
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.1467
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 61
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 49.2478
New value of Value function: 49.2478
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 62
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 11
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 15.7235
New value of Value function: 15.7235
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 114
New value of Q matrix: 14.751
New value of Value function: 14.751
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.2639
New value of Value function: 4.2639
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 4
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1.33756
New value of Value function: 1.33756
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 5
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.72614
New value of Value function: 0.340966
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 6
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.28593
New value of Value function: 8.28593
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 115
New value of Q matrix: 13.7787
New value of Value function: 13.7787
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 8
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.65391
New value of Value function: 4.65391
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 9
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.33254
New value of Value function: 5.33254
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 116
New value of Q matrix: 12.9778
New value of Value function: 12.9778
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 11
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.71179
New value of Value function: 4.71179
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 12
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 8.59364
New value of Value function: 8.59364
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 13
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.71469
New value of Value function: 5.71469
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 14
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 6.25085
New value of Value function: 6.25085
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 15
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 16
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 17
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.52239
New value of Value function: 1.52239
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 18
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.21371
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 19
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.2153
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 20
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 21
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 22
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.86517
New value of Value function: 8.86517
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 23
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.16377
New value of Value function: 7.16377
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.09213
New value of Value function: 3.40007
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 25
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.76492
New value of Value function: 7.76492
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.51296
New value of Value function: 3.40007
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 27
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.03376
New value of Value function: 8.03376
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 28
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.295012
New value of Value function: 2.51296
New value of Policy matrix: 3

=======================================
Episode: 11
Iteration: 29
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 30
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 31
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 32
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.0795
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 33
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.49283
New value of Value function: 2.95
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 34
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.33198
New value of Value function: 4.33198
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 35
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.96536
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 36
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.4997
New value of Value function: 11.4997
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 37
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.33079
New value of Value function: 8.33079
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 38
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 39
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 40
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 41
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.644427
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 42
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.16673
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 43
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 44
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 45
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 46
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 47
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 48
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 49
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 50
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 51
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.856846
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 52
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 53
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 54
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 55
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.438423
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 56
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 57
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 58
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 59
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 60
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 61
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 62
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.8905
New value of Value function: 0.8905
New value of Policy matrix: 3

=======================================
Episode: 11
Iteration: 63
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 8.28167
New value of Value function: 8.28167
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 64
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.9428
New value of Value function: 8.9428
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 65
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.66193
New value of Value function: 9.66193
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 66
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.07471
New value of Value function: 8.15627
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 67
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.81302
New value of Value function: 8.81302
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 68
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.79697
New value of Value function: 4.79697
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 69
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.68303
New value of Value function: 6.68303
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 70
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.17614
New value of Value function: 3.17614
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 71
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 4.25413
New value of Value function: 4.25413
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 72
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 2.40282
New value of Value function: 2.40282
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 73
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 4.29568
New value of Value function: 4.29568
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 74
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 2.34609
New value of Value function: 2.34609
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 75
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.0984
New value of Value function: 5.0984
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 76
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 1.35646
New value of Value function: 1.35646
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 77
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.68866
New value of Value function: 2.34609
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 78
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 4.8645
New value of Value function: 4.8645
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 79
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 3.05207
New value of Value function: 3.05207
New value of Policy matrix: 0

=======================================
Episode: 11
Iteration: 80
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 1.35385
New value of Value function: 1.35385
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 81
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.324566
New value of Value function: 1.35385
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 82
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 3.65141
New value of Value function: 3.65141
New value of Policy matrix: 1

=======================================
Episode: 11
Iteration: 83
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 1.35129
New value of Value function: 1.35129
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 84
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 1.34879
New value of Value function: 1.34879
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 85
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 1.34632
New value of Value function: 1.34632
New value of Policy matrix: 2

=======================================
Episode: 11
Iteration: 86
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Episode: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 12.9658
New value of Value function: 12.9658
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 13.1111
New value of Value function: 13.1111
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.89503
New value of Value function: 11.6607
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 4
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 5.44497
New value of Value function: 5.44497
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 12.9658
New value of Value function: 12.9658
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 12.1663
New value of Value function: 12.1663
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.73861
New value of Value function: 8.73861
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.04464
New value of Value function: 9.28127
New value of Policy matrix: 3

=======================================
Episode: 12
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.71865
New value of Value function: 12.1663
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 119
New value of Q matrix: 12.3843
New value of Value function: 12.3843
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 11.6123
New value of Value function: 11.6123
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.7389
New value of Value function: 8.59364
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 9.66797
New value of Value function: 9.66797
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 10
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.00105
New value of Value function: 11.2643
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 11
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5.7155
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 12
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 13
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 14
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 15
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 16
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 17
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 18
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 19
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 20
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 21
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 22
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 23
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 24
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 25
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 26
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 27
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 28
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 29
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 30
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 31
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 32
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 33
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 34
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 35
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 36
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 37
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 38
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 39
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 40
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 41
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 42
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 43
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 44
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 45
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 46
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 47
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 48
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 49
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 50
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 51
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 52
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.28343
New value of Value function: 9.28343
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 53
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 6.99078
New value of Value function: 11.3974
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 54
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 11.1826
New value of Value function: 11.1826
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 55
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.28343
New value of Value function: 17.4647
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 56
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 14.842
New value of Value function: 14.842
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 57
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 19.6792
New value of Value function: 19.6792
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 58
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 25.8166
New value of Value function: 25.8166
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 59
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 30.4565
New value of Value function: 30.4565
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 60
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 34.8789
New value of Value function: 34.8789
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 61
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 36.2301
New value of Value function: 36.2301
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 62
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 15.4178
New value of Value function: 49.2478
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 63
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 44.6105
New value of Value function: 44.6105
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 64
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 38.1075
New value of Value function: 38.1075
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 65
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 42.0459
New value of Value function: 42.0459
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 66
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 39.1321
New value of Value function: 39.1321
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 67
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 40.5745
New value of Value function: 40.5745
New value of Policy matrix: 0

=======================================
Episode: 12
Iteration: 68
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 50.9753
New value of Value function: 50.9753
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 69
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.49988
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 12
Iteration: 70
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 28.1951
New value of Value function: 28.1951
New value of Policy matrix: 1

=======================================
Episode: 12
Iteration: 71
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 60.4989
New value of Value function: 60.4989
New value of Policy matrix: 2

=======================================
Episode: 12
Iteration: 72
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.84963
New value of Value function: 12.3843
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.1945
New value of Value function: 12.3843
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 12.373
New value of Value function: 12.373
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 121
New value of Q matrix: 12.3074
New value of Value function: 12.3074
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 5
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.48874
New value of Value function: 8.73861
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 122
New value of Q matrix: 12.5055
New value of Value function: 12.5055
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 11.9015
New value of Value function: 11.9015
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 10.4672
New value of Value function: 10.4672
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 10.2198
New value of Value function: 10.2198
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 10
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.87526
New value of Value function: 4.87526
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 11
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 11.3462
New value of Value function: 11.3462
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 12
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 10.918
New value of Value function: 10.918
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 13
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 14.0187
New value of Value function: 14.0187
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 14
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 8.87851
New value of Value function: 10.3231
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 15
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 14.3654
New value of Value function: 14.3654
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 16
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 10.6152
New value of Value function: 10.6152
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 17
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 10.364
New value of Value function: 10.364
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 2.02177
New value of Value function: 11.1826
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 19
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 6.44338
New value of Value function: 6.44338
New value of Policy matrix: 3

=======================================
Episode: 13
Iteration: 20
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 11.2552
New value of Value function: 11.2552
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 10.4108
New value of Value function: 10.4108
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 22
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.4144
New value of Value function: 11.4144
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 23
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 9.01632
New value of Value function: 11.2552
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 24
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 11.9355
New value of Value function: 11.9355
New value of Policy matrix: 1

=======================================
Episode: 13
Iteration: 25
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.06924
New value of Value function: 11.2552
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 26
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 11.8804
New value of Value function: 11.8804
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 27
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 11.0439
New value of Value function: 11.0439
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 28
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 17.7487
New value of Value function: 17.7487
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 29
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 22.4649
New value of Value function: 22.4649
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 30
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 21.493
New value of Value function: 21.493
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 31
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 12.5712
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 32
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 20.4887
New value of Value function: 20.4887
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 33
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 22.736
New value of Value function: 22.736
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 34
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 25.8996
New value of Value function: 25.8996
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 35
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 30.152
New value of Value function: 30.4565
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 36
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 31.9749
New value of Value function: 31.9749
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 32.5621
New value of Value function: 34.8789
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 38
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 32.0678
New value of Value function: 32.5621
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 39
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 28.0983
New value of Value function: 28.0983
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 32.4639
New value of Value function: 32.4639
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 32.3702
New value of Value function: 32.3702
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.96447
New value of Value function: 32.3702
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 7.81937
New value of Value function: 12.5055
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 44
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 28.9952
New value of Value function: 28.9952
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 45
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 32.4774
New value of Value function: 32.4774
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 32.2804
New value of Value function: 32.2804
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 47
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 32.1941
New value of Value function: 32.1941
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 48
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 32.111
New value of Value function: 32.111
New value of Policy matrix: 4

=======================================
Episode: 13
Iteration: 49
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 37.6959
New value of Value function: 37.6959
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 57.2585
New value of Value function: 57.2585
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 44.346
New value of Value function: 44.346
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 55.2817
New value of Value function: 55.2817
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.3568
New value of Value function: 44.346
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 123
New value of Q matrix: 15.607
New value of Value function: 15.607
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 55
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 46.5104
New value of Value function: 46.5104
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 56
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 28.3893
New value of Value function: 55.2817
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 57
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 48.065
New value of Value function: 48.065
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 54.3046
New value of Value function: 54.3046
New value of Policy matrix: 2

=======================================
Episode: 13
Iteration: 59
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 25.5549
New value of Value function: 48.065
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 60
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 61.1462
New value of Value function: 61.1462
New value of Policy matrix: 0

=======================================
Episode: 13
Iteration: 61
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 14
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 15.593
New value of Value function: 15.593
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 8.01478
New value of Value function: 15.593
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 3
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.05525
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 4
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 7.33165
New value of Value function: 7.33165
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 6.73349
New value of Value function: 6.73349
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 6
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.6826
New value of Value function: 10.6826
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 125
New value of Q matrix: 15.0629
New value of Value function: 15.0629
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.01873
New value of Value function: 8.01873
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 9
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 4.84347
New value of Value function: 4.84347
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 10
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.372
New value of Value function: 10.6826
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 8.36516
New value of Value function: 15.0629
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 12
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 9.63509
New value of Value function: 9.63509
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 13
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 5.53874
New value of Value function: 8.01873
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 14
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 10.6652
New value of Value function: 10.6652
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 15
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.7439
New value of Value function: 8.7439
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 16
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 5.04265
New value of Value function: 5.04265
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 17
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 11.9122
New value of Value function: 11.9122
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 126
New value of Q matrix: 14.4038
New value of Value function: 14.4038
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 19
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 3.67022
New value of Value function: 3.67022
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 20
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.93002
New value of Value function: 5.93002
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 21
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.65754
New value of Value function: 5.71469
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 22
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.69136
New value of Value function: 5.69136
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 23
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.76902
New value of Value function: 7.76902
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 24
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.49103
New value of Value function: 7.49103
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 25
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.24999
New value of Value function: 5.24999
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 26
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 11.4997
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 27
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 28
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 29
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 30
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 31
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 32
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 12.3847
New value of Value function: 12.3847
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 33
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.8586
New value of Value function: 12.8586
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 34
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 10.9307
New value of Value function: 10.9307
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 35
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.6934
New value of Value function: 11.6934
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 36
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.2316
New value of Value function: 9.2316
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 37
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.48457
New value of Value function: 5.48457
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.36605
New value of Value function: 7.36605
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 39
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 3.3356
New value of Value function: 3.3356
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 4.90984
New value of Value function: 4.90984
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 2.98829
New value of Value function: 2.98829
New value of Policy matrix: 0

=======================================
Episode: 14
Iteration: 42
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.5327
New value of Value function: 4.90984
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 43
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.16771
New value of Value function: 3.16771
New value of Policy matrix: 1

=======================================
Episode: 14
Iteration: 44
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 31.0196
New value of Value function: 31.0196
New value of Policy matrix: 2

=======================================
Episode: 14
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 98.5355
New value of Value function: 98.5355
New value of Policy matrix: 4

=======================================
Episode: 15
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 14.391
New value of Value function: 14.391
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 6.26437
New value of Value function: 14.391
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 128
New value of Q matrix: 14.1493
New value of Value function: 14.1493
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.21572
New value of Value function: 9.21572
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 5
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 8.02523
New value of Value function: 8.02523
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 129
New value of Q matrix: 13.9709
New value of Value function: 13.9709
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 7
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.59172
New value of Value function: 9.59172
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 8
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 1.66035
New value of Value function: 1.66035
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 9
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 5.64375
New value of Value function: 5.64375
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 10
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 1.63275
New value of Value function: 1.63275
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 11
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.75871
New value of Value function: 7.75871
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 130
New value of Q matrix: 13.3274
New value of Value function: 13.3274
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 13
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 5.24115
New value of Value function: 5.24115
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 14
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.06232
New value of Value function: 6.06232
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 11.5693
New value of Value function: 11.5693
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 16
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.62578
New value of Value function: 7.49103
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 17
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.41612
New value of Value function: 12.8586
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 18
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.51397
New value of Value function: 8.51397
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.9205
New value of Value function: 7.9205
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 20
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.65576
New value of Value function: 5.65576
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 21
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.2255
New value of Value function: 11.2255
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 22
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 8.03376
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 23
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 10.9534
New value of Value function: 10.9534
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 24
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.59132
New value of Value function: 7.59132
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 25
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.5154
New value of Value function: 5.5154
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 26
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.5522
New value of Value function: 7.5522
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.49201
New value of Value function: 2.49201
New value of Policy matrix: 3

=======================================
Episode: 15
Iteration: 28
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.52211
New value of Value function: 7.52211
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 29
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.46945
New value of Value function: 2.46945
New value of Policy matrix: 3

=======================================
Episode: 15
Iteration: 30
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 7.49633
New value of Value function: 7.49633
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 31
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.44476
New value of Value function: 2.46945
New value of Policy matrix: 3

=======================================
Episode: 15
Iteration: 32
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.49869
New value of Value function: 4.49869
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 7.23407
New value of Value function: 7.23407
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 34
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.38291
New value of Value function: 8.38291
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 131
New value of Q matrix: 12.8391
New value of Value function: 12.8391
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 36
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 14.4274
New value of Value function: 14.4274
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 24.0545
New value of Value function: 24.0545
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 8.94148
New value of Value function: 8.94148
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 20.6456
New value of Value function: 20.6456
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 40
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 11.8051
New value of Value function: 11.8051
New value of Policy matrix: 0

=======================================
Episode: 15
Iteration: 41
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.33437
New value of Value function: 20.6456
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 42
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 8.2582
New value of Value function: 8.2582
New value of Policy matrix: 1

=======================================
Episode: 15
Iteration: 43
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 20.4392
New value of Value function: 20.6456
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 44
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 41.1218
New value of Value function: 41.1218
New value of Policy matrix: 2

=======================================
Episode: 15
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 99.381
New value of Value function: 99.381
New value of Policy matrix: 4

=======================================
Episode: 16
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 12.8279
New value of Value function: 12.8279
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 133
New value of Q matrix: 12.7991
New value of Value function: 12.7991
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 10.7095
New value of Value function: 10.7095
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 4
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.76131
New value of Value function: 8.76131
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 134
New value of Q matrix: 12.8685
New value of Value function: 12.8685
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 6
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 10.5448
New value of Value function: 10.5448
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 7
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 4.75663
New value of Value function: 4.75663
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 8
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 7.61213
New value of Value function: 7.61213
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 9
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.77007
New value of Value function: 9.77007
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 9.5397
New value of Value function: 9.5397
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 11
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.8956
New value of Value function: 12.8956
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 12
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.8234
New value of Value function: 11.8234
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 13
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.42136
New value of Value function: 7.49633
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.1153
New value of Value function: 8.1153
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 15
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.14517
New value of Value function: 2.46945
New value of Policy matrix: 3

=======================================
Episode: 16
Iteration: 16
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.1617
New value of Value function: 12.1617
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 17
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 8.51954
New value of Value function: 8.51954
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 18
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 11.4453
New value of Value function: 11.4453
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 19
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 19.5721
New value of Value function: 19.5721
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.94665
New value of Value function: 41.1218
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 21
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.43993
New value of Value function: 8.2582
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.9234
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 23
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 17.8881
New value of Value function: 17.8881
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 36.3328
New value of Value function: 36.3328
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 25
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 23.5652
New value of Value function: 23.5652
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 26
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 33.7393
New value of Value function: 33.7393
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 27
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 25.6596
New value of Value function: 25.6596
New value of Policy matrix: 0

=======================================
Episode: 16
Iteration: 28
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.1569
New value of Value function: 33.7393
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 29
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 21.9626
New value of Value function: 21.9626
New value of Policy matrix: 1

=======================================
Episode: 16
Iteration: 30
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 29.6052
New value of Value function: 33.7393
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 31
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 49.7176
New value of Value function: 49.7176
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 32
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 30.505
New value of Value function: 99.381
New value of Policy matrix: 4

=======================================
Episode: 16
Iteration: 33
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 61.7185
New value of Value function: 61.7185
New value of Policy matrix: 2

=======================================
Episode: 16
Iteration: 34
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 99.6905
New value of Value function: 99.6905
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 12.8575
New value of Value function: 12.8575
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 136
New value of Q matrix: 12.9074
New value of Value function: 12.9074
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 11.4882
New value of Value function: 11.4882
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 4
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 7.86906
New value of Value function: 7.86906
New value of Policy matrix: 1

=======================================
Episode: 17
Iteration: 5
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 10.2304
New value of Value function: 10.2304
New value of Policy matrix: 1

=======================================
Episode: 17
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 6.51276
New value of Value function: 12.9074
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 137
New value of Q matrix: 12.7172
New value of Value function: 12.7172
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 8
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.81599
New value of Value function: 8.81599
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 138
New value of Q matrix: 12.2908
New value of Value function: 12.2908
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 10
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 5.95859
New value of Value function: 5.95859
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 10.7367
New value of Value function: 10.7367
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 12
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.3281
New value of Value function: 11.3281
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 13
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 10.6402
New value of Value function: 10.6402
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 14
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.72851
New value of Value function: 7.9205
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 15
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.3363
New value of Value function: 11.3363
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 16
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 12.718
New value of Value function: 12.718
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.59083
New value of Value function: 11.8234
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 18
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.8653
New value of Value function: 13.8653
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 19
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 12.3649
New value of Value function: 12.3649
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 20
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.85467
New value of Value function: 8.1153
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 21
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 7.91313
New value of Value function: 7.91313
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.63248
New value of Value function: 2.63248
New value of Policy matrix: 3

=======================================
Episode: 17
Iteration: 23
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 7.82451
New value of Value function: 7.85467
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.69112
New value of Value function: 2.69112
New value of Policy matrix: 3

=======================================
Episode: 17
Iteration: 25
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.80932
New value of Value function: 7.82451
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 26
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 7.78005
New value of Value function: 7.80932
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.70628
New value of Value function: 2.70628
New value of Policy matrix: 3

=======================================
Episode: 17
Iteration: 28
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.77027
New value of Value function: 7.78005
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 29
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 7.7531
New value of Value function: 7.77027
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 30
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 2.70143
New value of Value function: 2.70143
New value of Policy matrix: 3

=======================================
Episode: 17
Iteration: 31
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 7.24124
New value of Value function: 7.77027
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 32
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 12.4987
New value of Value function: 12.4987
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 33
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.73552
New value of Value function: 7.7531
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 34
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 7.73279
New value of Value function: 7.73552
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 35
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.68701
New value of Value function: 2.68701
New value of Policy matrix: 3

=======================================
Episode: 17
Iteration: 36
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 14.0401
New value of Value function: 14.0401
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 37
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 14.0444
New value of Value function: 14.0444
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.74653
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 39
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 4.65164
New value of Value function: 4.65164
New value of Policy matrix: 3

=======================================
Episode: 17
Iteration: 40
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 15.358
New value of Value function: 15.358
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 41
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 14.4946
New value of Value function: 14.4946
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 42
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.13929
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 43
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.5148
New value of Value function: 11.5148
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 44
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.05177
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 45
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.01885
New value of Value function: 7.01885
New value of Policy matrix: 1

=======================================
Episode: 17
Iteration: 46
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 25.5632
New value of Value function: 25.5632
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 47
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 54.2303
New value of Value function: 54.2303
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 48
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 32.3801
New value of Value function: 32.3801
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 49
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 49.9292
New value of Value function: 49.9292
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 50
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 9.25386
New value of Value function: 32.3801
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 51
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 36.1426
New value of Value function: 36.1426
New value of Policy matrix: 0

=======================================
Episode: 17
Iteration: 52
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 41.051
New value of Value function: 49.9292
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 53
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 16.5361
New value of Value function: 49.9292
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 54
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.5224
New value of Value function: 21.9626
New value of Policy matrix: 1

=======================================
Episode: 17
Iteration: 55
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.506492
New value of Value function: 21.9626
New value of Policy matrix: 1

=======================================
Episode: 17
Iteration: 56
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.506891
New value of Value function: 0.506891
New value of Policy matrix: 4

=======================================
Episode: 17
Iteration: 57
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.42804
New value of Value function: 8.42804
New value of Policy matrix: 2

=======================================
Episode: 17
Iteration: 58
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 44.979
New value of Value function: 44.979
New value of Policy matrix: 1

=======================================
Episode: 17
Iteration: 59
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1774
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 5
New value of Q matrix: 98.4873
New value of Value function: 98.4873
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 12.2804
New value of Value function: 12.2804
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.37141
New value of Value function: 12.2804
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 12.27
New value of Value function: 12.27
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 7.27953
New value of Value function: 12.27
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 12.3423
New value of Value function: 12.3423
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 6
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.86094
New value of Value function: 10.2304
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 142
New value of Q matrix: 12.0533
New value of Value function: 12.0533
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 8
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 5.82496
New value of Value function: 5.82496
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 9
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 9.29867
New value of Value function: 9.29867
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 10
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 10.0245
New value of Value function: 10.0245
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 11
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 10.8146
New value of Value function: 10.8146
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 12
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 9.62709
New value of Value function: 9.62709
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 13
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 11.1727
New value of Value function: 11.1727
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 14
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 9.62709
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 15
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.93281
New value of Value function: 8.93281
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 7.90697
New value of Value function: 12.0533
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 143
New value of Q matrix: 12.2473
New value of Value function: 12.2473
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 10.806
New value of Value function: 10.806
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 144
New value of Q matrix: 12.3682
New value of Value function: 12.3682
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 20
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 11.3571
New value of Value function: 11.3571
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 21
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 9.18599
New value of Value function: 11.9122
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 145
New value of Q matrix: 12.2372
New value of Value function: 12.2372
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 23
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 8.33991
New value of Value function: 8.33991
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 12.156
New value of Value function: 12.156
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 25
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.24353
New value of Value function: 8.33991
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 26
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 11.8647
New value of Value function: 11.8647
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 27
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 8.14659
New value of Value function: 8.14659
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 28
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 12.0651
New value of Value function: 12.0651
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 29
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 8.07922
New value of Value function: 8.07922
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 30
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 10.127
New value of Value function: 12.0651
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 31
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 12.1575
New value of Value function: 12.1575
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 32
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 6.80381
New value of Value function: 8.07922
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 33
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.0359
New value of Value function: 12.1575
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 34
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 14.061
New value of Value function: 14.061
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 35
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 11.1227
New value of Value function: 11.1227
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 36
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 10.2702
New value of Value function: 10.2702
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 147
New value of Q matrix: 12.549
New value of Value function: 12.549
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 38
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 13.4292
New value of Value function: 13.4292
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 39
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 10.1675
New value of Value function: 10.2702
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 40
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 9.95017
New value of Value function: 10.1675
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 148
New value of Q matrix: 12.8569
New value of Value function: 12.8569
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 42
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.2194
New value of Value function: 13.2194
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 43
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.0956
New value of Value function: 10.0956
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 44
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.87174
New value of Value function: 10.0956
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 8.55125
New value of Value function: 12.8569
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 12.8464
New value of Value function: 12.8464
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 9.10314
New value of Value function: 12.8464
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 13.111
New value of Value function: 13.111
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 49
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 13.107
New value of Value function: 13.107
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 50
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 9.21193
New value of Value function: 10.0956
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 51
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 9.15584
New value of Value function: 9.15584
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 52
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 10.0373
New value of Value function: 10.0373
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 53
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 9.91205
New value of Value function: 10.0373
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 54
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 9.11309
New value of Value function: 9.11309
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 55
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 6.85943
New value of Value function: 6.85943
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 56
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 12.5192
New value of Value function: 12.5192
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 57
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 13.5646
New value of Value function: 13.5646
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 58
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 14.6195
New value of Value function: 14.6195
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 59
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.4112
New value of Value function: 15.4112
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 60
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 10.7847
New value of Value function: 15.358
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 61
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.99171
New value of Value function: 10.7847
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 62
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 13.6768
New value of Value function: 13.6768
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 63
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 9.57387
New value of Value function: 10.7847
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 64
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 13.6768
New value of Value function: 13.6768
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 65
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 10.7439
New value of Value function: 10.7439
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 66
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 10.7059
New value of Value function: 10.7059
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 67
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 10.6703
New value of Value function: 10.6703
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 68
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 10.6365
New value of Value function: 10.6365
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 69
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 10.6044
New value of Value function: 10.6044
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 70
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 10.5738
New value of Value function: 10.5738
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 71
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 10.5445
New value of Value function: 10.5445
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 72
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 10.5163
New value of Value function: 10.5163
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 73
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.1317
New value of Value function: 10.5163
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 74
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.5235
New value of Value function: 13.5235
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 75
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 10.4892
New value of Value function: 10.4892
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 76
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 10.463
New value of Value function: 10.463
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 77
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 10.4376
New value of Value function: 10.4376
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 78
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 10.413
New value of Value function: 10.413
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 79
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 10.3891
New value of Value function: 10.3891
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 80
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 10.3659
New value of Value function: 10.3659
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 81
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 10.3432
New value of Value function: 10.3432
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 82
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 10.3212
New value of Value function: 10.3212
New value of Policy matrix: 4

=======================================
Episode: 18
Iteration: 83
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 12.1707
New value of Value function: 12.1707
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 84
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 11.0499
New value of Value function: 11.0499
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 85
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 5.37446
New value of Value function: 5.37446
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 86
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 10.6815
New value of Value function: 12.1707
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 87
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 12.5144
New value of Value function: 12.5144
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 88
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.57058
New value of Value function: 11.0499
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 89
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 14.7314
New value of Value function: 14.7314
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 90
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 9.82935
New value of Value function: 9.82935
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 91
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 5.95609
New value of Value function: 5.95609
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 92
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.39651
New value of Value function: 12.5144
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 93
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 7.90622
New value of Value function: 7.90622
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 94
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.82716
New value of Value function: 5.95609
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 95
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.47798
New value of Value function: 8.47798
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 96
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 6.35359
New value of Value function: 6.35359
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 97
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.1946
New value of Value function: 12.1946
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 98
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 9.60918
New value of Value function: 9.60918
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 99
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 6.39622
New value of Value function: 6.39622
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 100
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 9.50451
New value of Value function: 9.50451
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 101
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.37299
New value of Value function: 6.39622
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 102
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.16718
New value of Value function: 7.16718
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 12.8656
New value of Value function: 12.8656
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 104
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.65082
New value of Value function: 8.65082
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 152
New value of Q matrix: 12.76
New value of Value function: 12.76
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 106
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 9.14163
New value of Value function: 9.14163
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 153
New value of Q matrix: 12.7026
New value of Value function: 12.7026
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 108
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 9.33572
New value of Value function: 9.33572
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 154
New value of Q matrix: 12.6656
New value of Value function: 12.6656
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 110
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 9.41867
New value of Value function: 9.41867
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 155
New value of Q matrix: 12.6382
New value of Value function: 12.6382
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 112
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 9.45386
New value of Value function: 9.45386
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.4312
New value of Value function: 12.6382
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 156
New value of Q matrix: 11.8665
New value of Value function: 11.8665
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 115
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 116
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 117
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 118
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 119
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 120
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 7.3932
New value of Value function: 7.3932
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 121
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 8.31927
New value of Value function: 8.47798
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 122
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.3932
New value of Value function: 7.3932
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 123
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.90512
New value of Value function: 8.90512
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 124
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 6.57088
New value of Value function: 6.57088
New value of Policy matrix: 3

=======================================
Episode: 18
Iteration: 125
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 11.8979
New value of Value function: 11.8979
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 126
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.8414
New value of Value function: 9.50451
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 127
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.57648
New value of Value function: 9.50451
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 128
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 13.7981
New value of Value function: 13.7981
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 129
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.6788
New value of Value function: 11.6788
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 130
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 13.1151
New value of Value function: 13.1151
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 131
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.66457
New value of Value function: 25.5632
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 132
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.8595
New value of Value function: 16.8595
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 133
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 32.2102
New value of Value function: 32.2102
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 134
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 16.5551
New value of Value function: 44.979
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 135
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 36.8389
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 136
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 45.6587
New value of Value function: 45.6587
New value of Policy matrix: 1

=======================================
Episode: 18
Iteration: 137
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 47.3961
New value of Value function: 47.3961
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 138
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 38.2719
New value of Value function: 38.2719
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 139
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 18.3953
New value of Value function: 47.3961
New value of Policy matrix: 2

=======================================
Episode: 18
Iteration: 140
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 18.9446
New value of Value function: 38.2719
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 141
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 27.4169
New value of Value function: 38.2719
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 142
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 52.9398
New value of Value function: 52.9398
New value of Policy matrix: 0

=======================================
Episode: 18
Iteration: 143
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 99.1048
New value of Value function: 99.1048
New value of Policy matrix: 4

=======================================
Episode: 19
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 11.857
New value of Value function: 11.857
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 158
New value of Q matrix: 12.1847
New value of Value function: 12.1847
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 12.7006
New value of Value function: 13.107
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 13.031
New value of Value function: 13.031
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 5
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.98713
New value of Value function: 9.98713
New value of Policy matrix: 4

=======================================
Episode: 19
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 9.94246
New value of Value function: 9.94246
New value of Policy matrix: 4

=======================================
Episode: 19
Iteration: 7
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.90065
New value of Value function: 9.94246
New value of Policy matrix: 4

=======================================
Episode: 19
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 12.9542
New value of Value function: 12.9542
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 9
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 9.90187
New value of Value function: 9.91205
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 10
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 10.3045
New value of Value function: 10.3045
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 11
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 9.29422
New value of Value function: 9.29422
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 12
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 9.56934
New value of Value function: 9.56934
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 13
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 13.5254
New value of Value function: 13.5254
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 14
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.67789
New value of Value function: 13.5254
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 15
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 14.34
New value of Value function: 14.34
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 16
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.8151
New value of Value function: 13.8151
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 17
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 17.8438
New value of Value function: 17.8438
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 18
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 25.0632
New value of Value function: 25.0632
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 19
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.62585
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 20
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 10.3813
New value of Value function: 10.3813
New value of Policy matrix: 3

=======================================
Episode: 19
Iteration: 21
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 21.3362
New value of Value function: 21.3362
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 12.2589
New value of Value function: 12.2589
New value of Policy matrix: 3

=======================================
Episode: 19
Iteration: 23
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 19.4669
New value of Value function: 19.4669
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 16.3832
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 25
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 7.81062
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.52642
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 27
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 13.5178
New value of Value function: 13.5178
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 28
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.72729
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 29
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.31562
New value of Value function: 9.31562
New value of Policy matrix: 1

=======================================
Episode: 19
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 159
New value of Q matrix: 12.589
New value of Value function: 12.589
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 31
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 14.3969
New value of Value function: 14.3969
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 32
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 33.4705
New value of Value function: 33.4705
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.63141
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 34
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 20.5007
New value of Value function: 20.5007
New value of Policy matrix: 1

=======================================
Episode: 19
Iteration: 35
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 40.2893
New value of Value function: 40.2893
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 36
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 45.4619
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Episode: 19
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 48.8279
New value of Value function: 48.8279
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 51.4256
New value of Value function: 51.4256
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 49.6446
New value of Value function: 49.6446
New value of Policy matrix: 2

=======================================
Episode: 19
Iteration: 40
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 37.0085
New value of Value function: 51.4256
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 62.5362
New value of Value function: 62.5362
New value of Policy matrix: 0

=======================================
Episode: 19
Iteration: 42
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 7
New value of Q matrix: 98.3093
New value of Value function: 98.3093
New value of Policy matrix: 4

=======================================
Episode: 20
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 8.99749
New value of Value function: 12.589
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 160
New value of Q matrix: 12.6657
New value of Value function: 12.6657
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 3
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 13.1798
New value of Value function: 13.1798
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 12.7723
New value of Value function: 12.9542
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 13.0477
New value of Value function: 13.0477
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 10.6034
New value of Value function: 10.6034
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.10578
New value of Value function: 9.29422
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 8
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.20128
New value of Value function: 9.20128
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 9
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 10.0946
New value of Value function: 10.0946
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 10
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 13.6934
New value of Value function: 13.6934
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 11
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 15.1751
New value of Value function: 15.1751
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 12
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 18.2177
New value of Value function: 18.2177
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 13
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 16.5925
New value of Value function: 16.5925
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 12.4384
New value of Value function: 12.4384
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 15
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 19.4952
New value of Value function: 19.4952
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 16
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 19.3954
New value of Value function: 19.3954
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 11.0934
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 18
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 15.3594
New value of Value function: 15.3594
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 19
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.1018
New value of Value function: 19.3954
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 20
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.4931
New value of Value function: 16.4931
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 21
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 26.3457
New value of Value function: 26.3457
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 39.8864
New value of Value function: 40.2893
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 23
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 42.7188
New value of Value function: 42.7188
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 24
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 32.5455
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 25
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 26.9233
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 44.4865
New value of Value function: 44.4865
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 27
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 32.3428
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 28
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 45.7878
New value of Value function: 45.7878
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 29
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 45.8973
New value of Value function: 45.8973
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 30
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 52.4424
New value of Value function: 52.4424
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 31
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 29.5339
New value of Value function: 62.5362
New value of Policy matrix: 0

=======================================
Episode: 20
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 25.6556
New value of Value function: 52.4424
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 46.8547
New value of Value function: 46.8547
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 34
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 46.9025
New value of Value function: 46.9025
New value of Policy matrix: 1

=======================================
Episode: 20
Iteration: 35
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 62.0426
New value of Value function: 62.0426
New value of Policy matrix: 2

=======================================
Episode: 20
Iteration: 36
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 98.907
New value of Value function: 98.907
New value of Policy matrix: 4

=======================================
Episode: 21
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 12.6557
New value of Value function: 12.6557
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 162
New value of Q matrix: 12.912
New value of Value function: 12.912
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.81161
New value of Value function: 13.0477
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 13.2067
New value of Value function: 13.2067
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 5
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.043
New value of Value function: 11.043
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 6
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 9.8041
New value of Value function: 9.8041
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 7
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 11.2429
New value of Value function: 11.2429
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 8
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 10.4516
New value of Value function: 10.4516
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 9
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 11.8168
New value of Value function: 11.8168
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 5.44383
New value of Value function: 15.1751
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 11
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 17.7666
New value of Value function: 17.7666
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 12
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 16.5763
New value of Value function: 16.5763
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 13
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 17.1063
New value of Value function: 17.1063
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 15.6569
New value of Value function: 15.6569
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 15
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 19.1435
New value of Value function: 19.1435
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 11.6651
New value of Value function: 15.6569
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 17
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 17.3287
New value of Value function: 17.3287
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 18
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 28.268
New value of Value function: 28.268
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 19
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 44.4579
New value of Value function: 44.4579
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 20
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 38.804
New value of Value function: 38.804
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 21
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 42.8045
New value of Value function: 44.4579
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 14.8194
New value of Value function: 44.4579
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 23
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 33.8124
New value of Value function: 33.8124
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 48.8144
New value of Value function: 48.8144
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 25
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 62.3956
New value of Value function: 62.3956
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 26
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 61.933
New value of Value function: 61.933
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 62.5661
New value of Value function: 62.5661
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 28
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 61.5082
New value of Value function: 61.5082
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 29
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 69.9333
New value of Value function: 69.9333
New value of Policy matrix: 2

=======================================
Episode: 21
Iteration: 30
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 57.8931
New value of Value function: 98.907
New value of Policy matrix: 4

=======================================
Episode: 21
Iteration: 31
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 69.7257
New value of Value function: 69.7257
New value of Policy matrix: 0

=======================================
Episode: 21
Iteration: 32
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 9
New value of Q matrix: 98.2714
New value of Value function: 98.2714
New value of Policy matrix: 4

=======================================
Episode: 22
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 12.9018
New value of Value function: 12.9018
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 164
New value of Q matrix: 13.0487
New value of Value function: 13.0487
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 12.4002
New value of Value function: 12.4002
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 11.7884
New value of Value function: 11.7884
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 14.3854
New value of Value function: 14.3854
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 6
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 15.0452
New value of Value function: 15.0452
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 7
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 11.797
New value of Value function: 11.797
New value of Policy matrix: 1

=======================================
Episode: 22
Iteration: 8
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.4181
New value of Value function: 15.4181
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 9
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 12.4985
New value of Value function: 12.4985
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 10
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 12.9788
New value of Value function: 12.9788
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 11
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 18.9245
New value of Value function: 18.9245
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 12
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 13.9487
New value of Value function: 13.9487
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 13
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 21.2187
New value of Value function: 21.2187
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 14
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 25.2561
New value of Value function: 25.2561
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 15
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: -0.0906495
New value of Value function: 28.9952
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 16
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 18.3526
New value of Value function: 18.3526
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 17
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 31.0477
New value of Value function: 31.0477
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 18
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 34.0899
New value of Value function: 34.0899
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 19
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.83821
New value of Value function: 37.6959
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 165
New value of Q matrix: 15.1717
New value of Value function: 15.1717
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 21
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: 36.6278
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 22
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 35.0469
New value of Value function: 35.0469
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 23
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 33.1486
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 24
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.72113
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 17.0414
New value of Value function: 17.0414
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 26
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 10.7961
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 167
New value of Q matrix: 18.7608
New value of Value function: 18.7608
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 40.187
New value of Value function: 40.187
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 55.6958
New value of Value function: 55.6958
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 30
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 59.2588
New value of Value function: 59.2588
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 31
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 20.4877
New value of Value function: 55.6958
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 40.6577
New value of Value function: 40.6577
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 33
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 20.0741
New value of Value function: 55.6958
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 56.5242
New value of Value function: 56.5242
New value of Policy matrix: 2

=======================================
Episode: 22
Iteration: 35
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 16.5245
New value of Value function: 59.2588
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 36
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 12.6873
New value of Value function: 12.6873
New value of Policy matrix: 1

=======================================
Episode: 22
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 168
New value of Q matrix: 22.0711
New value of Value function: 22.0711
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 38
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 69.0643
New value of Value function: 69.0643
New value of Policy matrix: 0

=======================================
Episode: 22
Iteration: 39
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 9
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 23
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 10.7769
New value of Value function: 22.0711
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 22.0541
New value of Value function: 22.0541
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 170
New value of Q matrix: 21.3695
New value of Value function: 21.3695
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 4
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 13.7748
New value of Value function: 13.7748
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 171
New value of Q matrix: 20.5764
New value of Value function: 20.5764
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 6
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 8.57184
New value of Value function: 8.57184
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 7
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.2428
New value of Value function: 15.2428
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 172
New value of Q matrix: 19.8833
New value of Value function: 19.8833
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 9
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 11.0179
New value of Value function: 11.0179
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 173
New value of Q matrix: 19.5937
New value of Value function: 19.5937
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 11
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 13.5146
New value of Value function: 13.5146
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 12
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 10.2392
New value of Value function: 11.2429
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 13
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 13.7094
New value of Value function: 13.7094
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 14
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 11.5617
New value of Value function: 11.5617
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 15
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.10753
New value of Value function: 10.4516
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 16
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.0115
New value of Value function: 10.0115
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 17
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 12.7076
New value of Value function: 12.7076
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 18
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 17.2759
New value of Value function: 17.2759
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 20.5587
New value of Value function: 20.5587
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 20
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 18.952
New value of Value function: 19.1435
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 21
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 9.83329
New value of Value function: 19.1435
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 22
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 21.8413
New value of Value function: 21.8413
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 23
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 25.5871
New value of Value function: 25.5871
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 24
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 30.0445
New value of Value function: 30.0445
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 25
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 29.2125
New value of Value function: 29.2125
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 15.6121
New value of Value function: 48.8144
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 36.6773
New value of Value function: 36.6773
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 28
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 47.2371
New value of Value function: 47.2371
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 29
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 41.6681
New value of Value function: 41.6681
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 30
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 52.4493
New value of Value function: 52.4493
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 31
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 55.1425
New value of Value function: 69.9333
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 31.3105
New value of Value function: 69.9333
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 33
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 42.4265
New value of Value function: 42.4265
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 34
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 52.2419
New value of Value function: 52.2419
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 35
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 39.4895
New value of Value function: 46.9025
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 36
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 51.8336
New value of Value function: 51.8336
New value of Policy matrix: 1

=======================================
Episode: 23
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 70.13
New value of Value function: 70.13
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 69.2568
New value of Value function: 69.2568
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 70.2068
New value of Value function: 70.2068
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 40
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 68.9064
New value of Value function: 68.9064
New value of Policy matrix: 0

=======================================
Episode: 23
Iteration: 41
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 75.7915
New value of Value function: 75.7915
New value of Policy matrix: 2

=======================================
Episode: 23
Iteration: 42
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 10
New value of Q matrix: 98.818
New value of Value function: 98.818
New value of Policy matrix: 4

=======================================
Episode: 24
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 19.5789
New value of Value function: 19.5789
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 11.8974
New value of Value function: 19.5789
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 175
New value of Q matrix: 19.2285
New value of Value function: 19.2285
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 10.4399
New value of Value function: 11.9122
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 5
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 6.98445
New value of Value function: 6.98445
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 12.7378
New value of Value function: 12.7378
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 7
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 13.6589
New value of Value function: 13.6589
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 13.3184
New value of Value function: 13.3184
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 14.0652
New value of Value function: 14.0652
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 10
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.09282
New value of Value function: 10.918
New value of Policy matrix: 1

=======================================
Episode: 24
Iteration: 11
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 11.6651
New value of Value function: 11.6651
New value of Policy matrix: 1

=======================================
Episode: 24
Iteration: 12
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 15.4818
New value of Value function: 15.4818
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 13
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 12.5116
New value of Value function: 12.5116
New value of Policy matrix: 1

=======================================
Episode: 24
Iteration: 14
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 13.4499
New value of Value function: 13.4499
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 15
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 15.2132
New value of Value function: 15.2132
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 16
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 23.4869
New value of Value function: 23.4869
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 17
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 27.5117
New value of Value function: 27.5117
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 18
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 26.0444
New value of Value function: 26.0444
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 19
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.61295
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 20
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 12.4648
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 21
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 14.4085
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 22
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 28.7701
New value of Value function: 28.7701
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 23
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 37.2931
New value of Value function: 40.6577
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 24
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 39.0009
New value of Value function: 40.6577
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 25
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 40.9037
New value of Value function: 40.9037
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 26
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 37.6855
New value of Value function: 37.6855
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 27
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 33.1117
New value of Value function: 33.1117
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 41.3339
New value of Value function: 41.3339
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 37
New value of Q matrix: 49.868
New value of Value function: 49.868
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 7.1876
New value of Value function: 19.2285
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 19.214
New value of Value function: 19.214
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 177
New value of Q matrix: 21.0711
New value of Value function: 21.0711
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 12.5215
New value of Value function: 41.3339
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 178
New value of Q matrix: 22.7837
New value of Value function: 22.7837
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 43.1992
New value of Value function: 43.1992
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 13.1374
New value of Value function: 49.868
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 37
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 70.3737
New value of Value function: 70.3737
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 38
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 19.5559
New value of Value function: 69.0643
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 179
New value of Q matrix: 26.4155
New value of Value function: 26.4155
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 40
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 64.2132
New value of Value function: 64.2132
New value of Policy matrix: 0

=======================================
Episode: 24
Iteration: 41
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 58.6494
New value of Value function: 58.6494
New value of Policy matrix: 2

=======================================
Episode: 24
Iteration: 42
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 10
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 25
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 26.3958
New value of Value function: 26.3958
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 181
New value of Q matrix: 25.6656
New value of Value function: 25.6656
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 13.9315
New value of Value function: 13.9315
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.5585
New value of Value function: 11.5617
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 14.0801
New value of Value function: 14.0801
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 12.399
New value of Value function: 12.399
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 14.5157
New value of Value function: 14.5157
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 8
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 11.5592
New value of Value function: 17.7666
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 15.5578
New value of Value function: 15.5578
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.77827
New value of Value function: 17.2759
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 11
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 11.6987
New value of Value function: 17.2759
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 12
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 16.2795
New value of Value function: 16.2795
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 13
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 19.038
New value of Value function: 19.038
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 14
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 28.4828
New value of Value function: 28.4828
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 15
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 36.7132
New value of Value function: 36.7132
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 16
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 53.0566
New value of Value function: 53.0566
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 17
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 56.8305
New value of Value function: 56.8305
New value of Policy matrix: 1

=======================================
Episode: 25
Iteration: 18
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 74.8355
New value of Value function: 74.8355
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 19
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 26
New value of Q matrix: 69.5302
New value of Value function: 69.5302
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 79.5674
New value of Value function: 79.5674
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 21
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 23.6402
New value of Value function: 98.818
New value of Policy matrix: 4

=======================================
Episode: 25
Iteration: 22
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 61.4053
New value of Value function: 61.4053
New value of Policy matrix: 1

=======================================
Episode: 25
Iteration: 23
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 83.4445
New value of Value function: 83.4445
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 24
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 63.5088
New value of Value function: 98.818
New value of Policy matrix: 4

=======================================
Episode: 25
Iteration: 25
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.04485
New value of Value function: 69.5302
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 26
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 43.4906
New value of Value function: 43.4906
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 27
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 75.5538
New value of Value function: 75.5538
New value of Policy matrix: 0

=======================================
Episode: 25
Iteration: 28
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 37.5823
New value of Value function: 98.818
New value of Policy matrix: 4

=======================================
Episode: 25
Iteration: 29
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 65.6996
New value of Value function: 65.6996
New value of Policy matrix: 1

=======================================
Episode: 25
Iteration: 30
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 86.6314
New value of Value function: 86.6314
New value of Policy matrix: 2

=======================================
Episode: 25
Iteration: 31
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 11
New value of Q matrix: 97.6668
New value of Value function: 97.6668
New value of Policy matrix: 4

=======================================
Episode: 26
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 25.6466
New value of Value function: 25.6466
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 13.6393
New value of Value function: 25.6466
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 9.32695
New value of Value function: 25.6466
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 183
New value of Q matrix: 25.088
New value of Value function: 25.088
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 5
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 17.7352
New value of Value function: 17.7352
New value of Policy matrix: 1

=======================================
Episode: 26
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 9.44739
New value of Value function: 25.088
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 25.0695
New value of Value function: 25.0695
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 10.7604
New value of Value function: 25.0695
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 9
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 8.048
New value of Value function: 17.7352
New value of Policy matrix: 1

=======================================
Episode: 26
Iteration: 10
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 14.9787
New value of Value function: 14.9787
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 11
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 14.4115
New value of Value function: 14.4115
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 12
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 13.4604
New value of Value function: 13.4604
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 13
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 15.8737
New value of Value function: 15.8737
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 14
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 20.3433
New value of Value function: 20.3433
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 15
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 18.9729
New value of Value function: 18.9729
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 16
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 18.7893
New value of Value function: 18.7893
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 17
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 19.6004
New value of Value function: 19.6004
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 18
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 32.3612
New value of Value function: 32.3612
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 19
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 38.7236
New value of Value function: 38.7236
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 20
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.33015
New value of Value function: 42.4265
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 21
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 26.3713
New value of Value function: 26.3713
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 46.2527
New value of Value function: 46.2527
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 23
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 51.3297
New value of Value function: 51.3297
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 24
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 16.8408
New value of Value function: 41.6681
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 25
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 44.7423
New value of Value function: 44.7423
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 58.5342
New value of Value function: 58.5342
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 68.8373
New value of Value function: 86.6314
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 28
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 38.0136
New value of Value function: 86.6314
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 29
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 50.3822
New value of Value function: 50.3822
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 30
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 60.7091
New value of Value function: 60.7091
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 31
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 69.6418
New value of Value function: 69.6418
New value of Policy matrix: 1

=======================================
Episode: 26
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 85.0363
New value of Value function: 85.0363
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 33
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 27.4326
New value of Value function: 75.5538
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 34
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: 76.8072
New value of Value function: 76.8072
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 35
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 83.9158
New value of Value function: 83.9158
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 36
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 55.3053
New value of Value function: 76.8072
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 82.9866
New value of Value function: 82.9866
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 77.4292
New value of Value function: 77.4292
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 85.9076
New value of Value function: 85.9076
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 40
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 31
New value of Q matrix: 14.3333
New value of Value function: 97.6668
New value of Policy matrix: 4

=======================================
Episode: 26
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 51.9934
New value of Value function: 77.4292
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 42
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 22.1072
New value of Value function: 77.4292
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 43
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 62.0727
New value of Value function: 62.0727
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 44
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 81.4935
New value of Value function: 81.4935
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 48.3025
New value of Value function: 97.6668
New value of Policy matrix: 4

=======================================
Episode: 26
Iteration: 46
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 72.5002
New value of Value function: 72.5002
New value of Policy matrix: 1

=======================================
Episode: 26
Iteration: 47
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 44.6388
New value of Value function: 85.9076
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 48
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 84.7617
New value of Value function: 84.7617
New value of Policy matrix: 0

=======================================
Episode: 26
Iteration: 49
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 59.109
New value of Value function: 97.6668
New value of Policy matrix: 4

=======================================
Episode: 26
Iteration: 50
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 88.3429
New value of Value function: 88.3429
New value of Policy matrix: 2

=======================================
Episode: 26
Iteration: 51
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 12
New value of Q matrix: 98.3404
New value of Value function: 98.3404
New value of Policy matrix: 4

=======================================
Episode: 27
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 25.0511
New value of Value function: 25.0511
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 186
New value of Q matrix: 24.3344
New value of Value function: 24.3344
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 13.45
New value of Value function: 13.45
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 14.152
New value of Value function: 14.152
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 16.0634
New value of Value function: 16.0634
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 6
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 15.9736
New value of Value function: 15.9736
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 7
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.4118
New value of Value function: 15.4118
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 8
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 21.8804
New value of Value function: 21.8804
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 9
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 5.01035
New value of Value function: 15.2132
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 10
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 11.4943
New value of Value function: 21.8804
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 11
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 16.2921
New value of Value function: 16.2921
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 12
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 20.9706
New value of Value function: 20.9706
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 13
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 19.5788
New value of Value function: 19.5788
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 14
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 16.3831
New value of Value function: 27.5117
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 15
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 5.13415
New value of Value function: 19.5788
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 16
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 22.0239
New value of Value function: 22.0239
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 17
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 27.5903
New value of Value function: 27.5903
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 18
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 31.3059
New value of Value function: 31.3059
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 19
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 41.7274
New value of Value function: 41.7274
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 20
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 9.11203
New value of Value function: 43.1992
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 21
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 27.1719
New value of Value function: 27.1719
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 22
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 41.1294
New value of Value function: 41.1294
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 23
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 16.3267
New value of Value function: 33.1117
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 24
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 35.3996
New value of Value function: 35.3996
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 25
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 14.4509
New value of Value function: 41.7274
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 26
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 39.2571
New value of Value function: 39.2571
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 27
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 41.934
New value of Value function: 41.934
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 44.4065
New value of Value function: 44.4065
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 8.58834
New value of Value function: 58.6494
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 30
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 17.4619
New value of Value function: 17.4619
New value of Policy matrix: 1

=======================================
Episode: 27
Iteration: 31
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.5597
New value of Value function: 33.1117
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 32
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 8.91526
New value of Value function: 8.91526
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 33
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 44.0567
New value of Value function: 44.0567
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 39
New value of Q matrix: 51.4294
New value of Value function: 51.4294
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 35
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 17.5392
New value of Value function: 17.5392
New value of Policy matrix: 1

=======================================
Episode: 27
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 187
New value of Q matrix: 25.9891
New value of Value function: 25.9891
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 45.949
New value of Value function: 45.949
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 30.8911
New value of Value function: 51.4294
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 39
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 66.9777
New value of Value function: 66.9777
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 40
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 60.8749
New value of Value function: 60.8749
New value of Policy matrix: 0

=======================================
Episode: 27
Iteration: 41
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 59.7415
New value of Value function: 59.7415
New value of Policy matrix: 2

=======================================
Episode: 27
Iteration: 42
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 11
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Episode: 28
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 25.9702
New value of Value function: 25.9702
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 15.1849
New value of Value function: 25.9702
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 189
New value of Q matrix: 25.5765
New value of Value function: 25.5765
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 4
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 19.3564
New value of Value function: 19.3564
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 190
New value of Q matrix: 24.9737
New value of Value function: 24.9737
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 6
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 15.8796
New value of Value function: 15.8796
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 7
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.2944
New value of Value function: 19.3564
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 8
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 15.27
New value of Value function: 15.27
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 191
New value of Q matrix: 23.884
New value of Value function: 23.884
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 10
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 14.8912
New value of Value function: 14.8912
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 192
New value of Q matrix: 23.4408
New value of Value function: 23.4408
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 12
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 17.9599
New value of Value function: 17.9599
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 193
New value of Q matrix: 23.2493
New value of Value function: 23.2493
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 14
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 18.9884
New value of Value function: 18.9884
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 194
New value of Q matrix: 23.1451
New value of Value function: 23.1451
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 16
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 10.7208
New value of Value function: 18.9884
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 17
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 18.3525
New value of Value function: 18.3525
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 18
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 19.5422
New value of Value function: 19.5422
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 195
New value of Q matrix: 23.0036
New value of Value function: 23.0036
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 20
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.83902
New value of Value function: 18.3525
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 21
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 14.5907
New value of Value function: 14.5907
New value of Policy matrix: 1

=======================================
Episode: 28
Iteration: 22
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 16.2042
New value of Value function: 16.2042
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 23
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 13.451
New value of Value function: 14.4115
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 24
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 16.8919
New value of Value function: 16.8919
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 25
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 13.5198
New value of Value function: 14.4115
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 26
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 14.9231
New value of Value function: 14.9231
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 27
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 11.1662
New value of Value function: 13.4604
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 28
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 15.2853
New value of Value function: 15.2853
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 29
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 14.5589
New value of Value function: 14.5589
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 30
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 12.7692
New value of Value function: 15.8737
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 31
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 12.4134
New value of Value function: 15.8737
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 32
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 15.348
New value of Value function: 15.348
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 33
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 15.2891
New value of Value function: 15.2891
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 34
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 15.7817
New value of Value function: 15.7817
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 35
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 16.7418
New value of Value function: 16.7418
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 36
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 18.4397
New value of Value function: 18.4397
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 37
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.09937
New value of Value function: 18.9729
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 38
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 20.8625
New value of Value function: 20.8625
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 39
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 20.565
New value of Value function: 20.565
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 40
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 22.2178
New value of Value function: 22.2178
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 41
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 35.5295
New value of Value function: 35.5295
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 42
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 14.1332
New value of Value function: 38.7236
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 43
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 27.0602
New value of Value function: 27.0602
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 44
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 16.8793
New value of Value function: 38.7236
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 45
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 42.0599
New value of Value function: 42.0599
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 46
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 53.7654
New value of Value function: 53.7654
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 47
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 52.4538
New value of Value function: 52.4538
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 48
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 24.316
New value of Value function: 24.316
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 49
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 46.6147
New value of Value function: 46.6147
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 50
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 59.3926
New value of Value function: 59.3926
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 51
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 87.9725
New value of Value function: 87.9725
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 52
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 32
New value of Q matrix: 84.8202
New value of Value function: 84.8202
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 53
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 87.6709
New value of Value function: 87.6709
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 54
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 84.8157
New value of Value function: 84.8157
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 55
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 43.9108
New value of Value function: 87.6709
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 56
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 55.7161
New value of Value function: 55.7161
New value of Policy matrix: 0

=======================================
Episode: 28
Iteration: 57
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 64.8529
New value of Value function: 64.8529
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 58
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 89.8602
New value of Value function: 89.8602
New value of Policy matrix: 2

=======================================
Episode: 28
Iteration: 59
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 13
New value of Q matrix: 98.8007
New value of Value function: 98.8007
New value of Policy matrix: 4

=======================================
Episode: 29
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 22.9872
New value of Value function: 22.9872
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 197
New value of Q matrix: 22.6413
New value of Value function: 22.6413
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 16.1199
New value of Value function: 16.1199
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 16.4399
New value of Value function: 16.4399
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 18.0759
New value of Value function: 18.0759
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 23.4093
New value of Value function: 23.4093
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 22.5621
New value of Value function: 22.5621
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 18.237
New value of Value function: 18.237
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 9
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 14.5605
New value of Value function: 14.5605
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 18.0546
New value of Value function: 18.237
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 11
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 22.1493
New value of Value function: 22.1493
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 12
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 12.8265
New value of Value function: 27.0602
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 13
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 25.7734
New value of Value function: 25.7734
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 31.3409
New value of Value function: 31.3409
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 15
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 22.7324
New value of Value function: 42.0599
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 34.4155
New value of Value function: 34.4155
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 17
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 48.2873
New value of Value function: 48.2873
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 18
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 55.1597
New value of Value function: 64.8529
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 19
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 62.0768
New value of Value function: 62.0768
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 20
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 27.9181
New value of Value function: 46.6147
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 21
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 51.4489
New value of Value function: 51.4489
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 29.8035
New value of Value function: 62.0768
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 23
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 57.7847
New value of Value function: 57.7847
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 60.6594
New value of Value function: 60.6594
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 25
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 36.0556
New value of Value function: 51.4489
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 26
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 52.2068
New value of Value function: 52.2068
New value of Policy matrix: 3

=======================================
Episode: 29
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 58.8867
New value of Value function: 58.8867
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 28
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 39.1706
New value of Value function: 60.6594
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 29
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 59.6782
New value of Value function: 59.6782
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 30
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 45.1409
New value of Value function: 60.6594
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 31
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 60.2541
New value of Value function: 60.2541
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 32
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 66.0277
New value of Value function: 66.0277
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 33
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 16.1037
New value of Value function: 89.8602
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 34
----------
State: 2173
	Distance: 5
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 42.8044
New value of Value function: 42.8044
New value of Policy matrix: 3

=======================================
Episode: 29
Iteration: 35
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 53.2246
New value of Value function: 53.2246
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 36
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 55.7121
New value of Value function: 55.7121
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 37
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 85.9675
New value of Value function: 85.9675
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 63.298
New value of Value function: 84.8157
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 39
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 34
New value of Q matrix: 85.1837
New value of Value function: 85.1837
New value of Policy matrix: 0

=======================================
Episode: 29
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 46
New value of Q matrix: 91.7699
New value of Value function: 91.7699
New value of Policy matrix: 2

=======================================
Episode: 29
Iteration: 41
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 14
New value of Q matrix: 99.1212
New value of Value function: 99.1212
New value of Policy matrix: 4

=======================================
Episode: 30
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 16.1031
New value of Value function: 22.6413
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 22.6252
New value of Value function: 22.6252
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 16.8963
New value of Value function: 22.6252
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 22.6092
New value of Value function: 22.6092
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 200
New value of Q matrix: 22.5518
New value of Value function: 22.5518
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 6
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 17.7044
New value of Value function: 17.7044
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 7
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 19.3263
New value of Value function: 19.3263
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 201
New value of Q matrix: 22.409
New value of Value function: 22.409
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 9
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 18.6959
New value of Value function: 18.6959
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 10
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 14.0337
New value of Value function: 19.3263
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 11
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 18.5089
New value of Value function: 18.6959
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 12
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 19.2391
New value of Value function: 19.2391
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 13
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 19.2264
New value of Value function: 19.2264
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 202
New value of Q matrix: 22.3835
New value of Value function: 22.3835
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 15
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 19.5202
New value of Value function: 19.5202
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 16
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 19.1879
New value of Value function: 19.1879
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 203
New value of Q matrix: 22.3794
New value of Value function: 22.3794
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 18
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 19.6788
New value of Value function: 19.6788
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 19
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 19.1718
New value of Value function: 19.1718
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 204
New value of Q matrix: 22.3866
New value of Value function: 22.3866
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 21
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 19.774
New value of Value function: 19.774
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 22
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 11.7512
New value of Value function: 19.1718
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 23
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 19.98
New value of Value function: 19.98
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 24
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 16.7741
New value of Value function: 19.1718
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 25
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.5305
New value of Value function: 19.774
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 26
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 21.1752
New value of Value function: 21.1752
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 27
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 8.19369
New value of Value function: 23.4093
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 28
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 23.1864
New value of Value function: 23.1864
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 29
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 21.0192
New value of Value function: 21.0192
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 30
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 25.0424
New value of Value function: 25.0424
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 31
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 15.2923
New value of Value function: 15.2923
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 32
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 6.80637
New value of Value function: 6.80637
New value of Policy matrix: 3

=======================================
Episode: 30
Iteration: 33
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 3.85908
New value of Value function: 15.2923
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 34
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 11.3077
New value of Value function: 11.3077
New value of Policy matrix: 3

=======================================
Episode: 30
Iteration: 35
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 19.3565
New value of Value function: 19.3565
New value of Policy matrix: 0

=======================================
Episode: 30
Iteration: 36
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 19.1708
New value of Value function: 19.1708
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 37
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 12.6938
New value of Value function: 22.1493
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 38
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 16.6951
New value of Value function: 19.1708
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 39
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 7.64508
New value of Value function: 21.8413
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 40
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.66973
New value of Value function: 16.2795
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 41
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 15.7308
New value of Value function: 15.7308
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 42
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 19.3692
New value of Value function: 19.3692
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 43
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 18.8476
New value of Value function: 19.038
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 44
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 18.924
New value of Value function: 18.924
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 45
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 16.8722
New value of Value function: 16.8722
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 46
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 21.3561
New value of Value function: 21.3561
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 47
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 13.3438
New value of Value function: 26.3457
New value of Policy matrix: 1

=======================================
Episode: 30
Iteration: 48
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 37.5694
New value of Value function: 37.5694
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 49
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 93.427
New value of Value function: 93.427
New value of Policy matrix: 2

=======================================
Episode: 30
Iteration: 50
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 15
New value of Q matrix: 98.0571
New value of Value function: 98.0571
New value of Policy matrix: 4

=======================================
Episode: 31
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 22.371
New value of Value function: 22.371
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 206
New value of Q matrix: 22.1332
New value of Value function: 22.1332
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 16.8853
New value of Value function: 16.8853
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 17.2326
New value of Value function: 17.2326
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 20.0592
New value of Value function: 20.0592
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 24.6083
New value of Value function: 24.6083
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 21.6238
New value of Value function: 21.6238
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 25.4074
New value of Value function: 25.4074
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 9
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 35.9571
New value of Value function: 35.9571
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 10
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 39.3334
New value of Value function: 39.3334
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 11
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 17.5841
New value of Value function: 53.2246
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 12
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 41.7661
New value of Value function: 41.7661
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 13
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 55.2817
New value of Value function: 55.2817
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 59.5237
New value of Value function: 59.5237
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 15
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 55.5409
New value of Value function: 55.5409
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 16
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 53.4242
New value of Value function: 53.4242
New value of Policy matrix: 3

=======================================
Episode: 31
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 58.9414
New value of Value function: 58.9414
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 18
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 62.1089
New value of Value function: 62.1089
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 19
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 92.4029
New value of Value function: 92.4029
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 20
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 35
New value of Q matrix: 85.9097
New value of Value function: 85.9097
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 21
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 48.6314
New value of Value function: 92.4029
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 41.9771
New value of Value function: 58.9414
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 23
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 37.1114
New value of Value function: 58.9414
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 24
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 41.6671
New value of Value function: 53.4242
New value of Policy matrix: 3

=======================================
Episode: 31
Iteration: 25
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 53.3825
New value of Value function: 53.3825
New value of Policy matrix: 3

=======================================
Episode: 31
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 59.958
New value of Value function: 59.958
New value of Policy matrix: 0

=======================================
Episode: 31
Iteration: 27
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 67.36
New value of Value function: 67.36
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 28
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 93.7848
New value of Value function: 93.7848
New value of Policy matrix: 2

=======================================
Episode: 31
Iteration: 29
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 16
New value of Q matrix: 97.7928
New value of Value function: 97.7928
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 11.3168
New value of Value function: 22.1332
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 22.1179
New value of Value function: 22.1179
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 17.5213
New value of Value function: 22.1179
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 12.9691
New value of Value function: 22.1179
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 208
New value of Q matrix: 21.61
New value of Value function: 21.61
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 6
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 16.4954
New value of Value function: 16.4954
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 10.9646
New value of Value function: 21.61
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 21.595
New value of Value function: 21.595
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 210
New value of Q matrix: 21.6627
New value of Value function: 21.6627
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 10
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 19.2637
New value of Value function: 19.774
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 11
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 16.4414
New value of Value function: 19.2637
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 12
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 13.9461
New value of Value function: 13.9461
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 211
New value of Q matrix: 21.4288
New value of Value function: 21.4288
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 7.52277
New value of Value function: 15.4181
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 15
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 11.6327
New value of Value function: 19.2637
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 16
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 13.4698
New value of Value function: 14.152
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 17
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 19.1525
New value of Value function: 19.1525
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 18
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 19.0567
New value of Value function: 19.0567
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 19
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 18.9715
New value of Value function: 18.9715
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 20
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 18.894
New value of Value function: 18.894
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 21
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 9.71752
New value of Value function: 18.894
New value of Policy matrix: 4

=======================================
Episode: 32
Iteration: 22
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 14.4016
New value of Value function: 14.4016
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 23
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 14.9022
New value of Value function: 14.9022
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 24
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 16.5574
New value of Value function: 16.5574
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 25
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 11.1733
New value of Value function: 15.9736
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 26
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 15.9337
New value of Value function: 15.9337
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 27
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 15.9337
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 28
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 29
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 30
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 31
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 32
----------
State: 4173
	Distance: 10
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 33
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 34
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 35
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 36
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 37
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 38
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.63564
New value of Value function: 4.63564
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 39
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 40
----------
State: 3893
	Distance: 9
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.8905
New value of Value function: 2.8905
New value of Policy matrix: 3

=======================================
Episode: 32
Iteration: 41
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 6.45088
New value of Value function: 6.45088
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 42
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 10.4901
New value of Value function: 10.4901
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 16.5558
New value of Value function: 16.5558
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 44
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 12.4108
New value of Value function: 12.4108
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 45
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 16.9824
New value of Value function: 16.9824
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 46
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 6.27826
New value of Value function: 15.4118
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 47
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.78883
New value of Value function: 8.78883
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 48
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 8.25614
New value of Value function: 15.4118
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 49
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 8.78883
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 50
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.1525
New value of Value function: 11.1525
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 51
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 11.3689
New value of Value function: 11.3689
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 52
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 19.0708
New value of Value function: 19.0708
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 53
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 23.6444
New value of Value function: 23.6444
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 54
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 29.0887
New value of Value function: 29.0887
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 55
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 32.9105
New value of Value function: 32.9105
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 56
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 34.5814
New value of Value function: 39.2571
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 57
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 34.0071
New value of Value function: 34.0071
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 58
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 41.6763
New value of Value function: 41.6763
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 59
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 24
New value of Q matrix: 39.0694
New value of Value function: 39.0694
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 60
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 37.1526
New value of Value function: 37.1526
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 61
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 39
New value of Q matrix: 43.5201
New value of Value function: 43.5201
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 62
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 23.4096
New value of Value function: 33.1117
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 63
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 42.3095
New value of Value function: 42.3095
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 64
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 40.2725
New value of Value function: 40.2725
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 65
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 40
New value of Q matrix: 41.5058
New value of Value function: 41.5058
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 66
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 37.1856
New value of Value function: 37.1856
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 67
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 44.729
New value of Value function: 44.729
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 68
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 41
New value of Q matrix: 53.2794
New value of Value function: 53.2794
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 69
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 17.8768
New value of Value function: 17.8768
New value of Policy matrix: 1

=======================================
Episode: 32
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 212
New value of Q matrix: 23.2043
New value of Value function: 23.2043
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 71
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 46.429
New value of Value function: 46.429
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 72
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 54.6661
New value of Value function: 54.6661
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 73
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 59.0082
New value of Value function: 59.0082
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 74
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 55.5433
New value of Value function: 55.5433
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 75
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 57.7529
New value of Value function: 57.7529
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 76
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 56.0908
New value of Value function: 56.0908
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 77
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 34.7502
New value of Value function: 57.7529
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 78
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 45
New value of Q matrix: 56.5506
New value of Value function: 56.5506
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 79
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 41.1618
New value of Value function: 57.7529
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 80
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 26.7426
New value of Value function: 56.5506
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 81
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 33.5425
New value of Value function: 56.5506
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 82
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 48.3438
New value of Value function: 48.3438
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 83
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 46
New value of Q matrix: 56.9376
New value of Value function: 56.9376
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 84
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 57.062
New value of Value function: 57.062
New value of Policy matrix: 0

=======================================
Episode: 32
Iteration: 85
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 43.3634
New value of Value function: 56.9376
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 86
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 87.1978
New value of Value function: 87.1978
New value of Policy matrix: 2

=======================================
Episode: 32
Iteration: 87
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 12
New value of Q matrix: 99.134
New value of Value function: 99.134
New value of Policy matrix: 4

=======================================
Episode: 33
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 14.5126
New value of Value function: 23.2043
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 18.1974
New value of Value function: 23.2043
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 12.4774
New value of Value function: 23.2043
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 23.1884
New value of Value function: 23.1884
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 23.1726
New value of Value function: 23.1726
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 215
New value of Q matrix: 23.1163
New value of Value function: 23.1163
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 7
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 19.6506
New value of Value function: 19.6506
New value of Policy matrix: 1

=======================================
Episode: 33
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 216
New value of Q matrix: 22.4897
New value of Value function: 22.4897
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 9
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 15.0603
New value of Value function: 15.0603
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 10
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 18.267
New value of Value function: 18.267
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 11
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 21.5198
New value of Value function: 21.5198
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 12
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 13.9711
New value of Value function: 24.6083
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 13
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 5.2602
New value of Value function: 18.4397
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 14
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 17.722
New value of Value function: 17.722
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 15
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 20.4855
New value of Value function: 20.4855
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 16
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 24.073
New value of Value function: 24.073
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 35.7657
New value of Value function: 35.7657
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 18
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 46.4041
New value of Value function: 46.4041
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 19
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 11.0266
New value of Value function: 55.2817
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 20
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.73111
New value of Value function: 16.8722
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 21
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 20.3761
New value of Value function: 20.3761
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 22
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 24.4318
New value of Value function: 24.4318
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 23
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 37.9911
New value of Value function: 37.9911
New value of Policy matrix: 1

=======================================
Episode: 33
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 71.9216
New value of Value function: 71.9216
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 25
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 92.8325
New value of Value function: 92.8325
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 26
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 86.5755
New value of Value function: 86.5755
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 51
New value of Q matrix: 92.1151
New value of Value function: 92.1151
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 28
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 37
New value of Q matrix: 87.0059
New value of Value function: 87.0059
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 29
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 51.1926
New value of Value function: 92.1151
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 30
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 62.8481
New value of Value function: 62.8481
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 31
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 72.689
New value of Value function: 72.689
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 32
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 75.9811
New value of Value function: 75.9811
New value of Policy matrix: 1

=======================================
Episode: 33
Iteration: 33
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 93.4603
New value of Value function: 93.4603
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 34
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 74.8405
New value of Value function: 97.7928
New value of Policy matrix: 4

=======================================
Episode: 33
Iteration: 35
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 38
New value of Q matrix: 89.0838
New value of Value function: 89.0838
New value of Policy matrix: 0

=======================================
Episode: 33
Iteration: 36
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 73.3173
New value of Value function: 97.7928
New value of Policy matrix: 4

=======================================
Episode: 33
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 94.6079
New value of Value function: 94.6079
New value of Policy matrix: 2

=======================================
Episode: 33
Iteration: 38
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 17
New value of Q matrix: 98.3281
New value of Value function: 98.3281
New value of Policy matrix: 4

=======================================
Episode: 34
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 22.4744
New value of Value function: 22.4744
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 218
New value of Q matrix: 22.1211
New value of Value function: 22.1211
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 15.2669
New value of Value function: 15.2669
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 15.8127
New value of Value function: 15.8127
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 18.0806
New value of Value function: 18.0806
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 6
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 18.6082
New value of Value function: 18.6082
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 7
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 10.297
New value of Value function: 19.0708
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 8
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 14.1245
New value of Value function: 14.1245
New value of Policy matrix: 1

=======================================
Episode: 34
Iteration: 9
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 22.1832
New value of Value function: 22.1832
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 10
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 25.9737
New value of Value function: 25.9737
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 11
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 30.8468
New value of Value function: 30.8468
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 12
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 36.3758
New value of Value function: 36.3758
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 13
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 23.6101
New value of Value function: 40.2725
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 14
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 37.0072
New value of Value function: 42.3095
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 15
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 37.2822
New value of Value function: 37.2822
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 16
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 41.2843
New value of Value function: 41.2843
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 17
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 37.6795
New value of Value function: 37.6795
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 18
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 42.3193
New value of Value function: 42.3193
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 19
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 42.1528
New value of Value function: 42.1528
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 20
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 14.4202
New value of Value function: 48.3438
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 219
New value of Q matrix: 24.0631
New value of Value function: 24.0631
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 22
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 50.0058
New value of Value function: 50.0058
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 23
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 47
New value of Q matrix: 51.3598
New value of Value function: 51.3598
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 24
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 19.1942
New value of Value function: 19.1942
New value of Policy matrix: 1

=======================================
Episode: 34
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 220
New value of Q matrix: 25.9807
New value of Value function: 25.9807
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 26
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 37.1158
New value of Value function: 50.0058
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 50.5783
New value of Value function: 50.5783
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 28
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 48
New value of Q matrix: 52.3892
New value of Value function: 52.3892
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 29
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 55.6227
New value of Value function: 55.6227
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 30
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 31.3294
New value of Value function: 52.3892
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 31
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 49
New value of Q matrix: 53.0573
New value of Value function: 53.0573
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 32
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 26
New value of Q matrix: 54.6233
New value of Value function: 54.6233
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 33
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 50
New value of Q matrix: 53.4844
New value of Value function: 53.4844
New value of Policy matrix: 2

=======================================
Episode: 34
Iteration: 34
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 29.8013
New value of Value function: 54.6233
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 35
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 63.5759
New value of Value function: 63.5759
New value of Policy matrix: 0

=======================================
Episode: 34
Iteration: 36
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 13
New value of Q matrix: 99.3742
New value of Value function: 99.3742
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 25.9632
New value of Value function: 25.9632
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 222
New value of Q matrix: 25.4365
New value of Value function: 25.4365
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 9.20999
New value of Value function: 15.2669
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 19.7786
New value of Value function: 19.7786
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 223
New value of Q matrix: 25.1866
New value of Value function: 25.1866
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 6
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 18.8226
New value of Value function: 18.8226
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 7
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 18.7561
New value of Value function: 18.7561
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 8
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 18.6935
New value of Value function: 18.6935
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 9
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 18.6344
New value of Value function: 18.6344
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 10
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 18.5782
New value of Value function: 18.5782
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 11
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 18.5246
New value of Value function: 18.5246
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 12
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 18.4732
New value of Value function: 18.4732
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 13
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 18.4239
New value of Value function: 18.4239
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 14
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 18.3763
New value of Value function: 18.3763
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 15
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 18.3303
New value of Value function: 18.3303
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 16
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 18.2859
New value of Value function: 18.2859
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 17
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 18.2428
New value of Value function: 18.2428
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 18
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 18.2009
New value of Value function: 18.2009
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 19
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 8.90994
New value of Value function: 18.2009
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 20
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 23.4221
New value of Value function: 23.4221
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 21
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 18.2998
New value of Value function: 18.2998
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 22
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.4425
New value of Value function: 16.4425
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 23
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 14.4888
New value of Value function: 14.4888
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 24
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 24.8809
New value of Value function: 24.8809
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 25
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 9.81914
New value of Value function: 25.9737
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 26
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 25.4885
New value of Value function: 25.4885
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 27
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 22.2944
New value of Value function: 22.2944
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 28
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.8119
New value of Value function: 25.4885
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 29
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 13.8261
New value of Value function: 13.8261
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 30
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 8.68785
New value of Value function: 8.91526
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 31
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 13.8261
New value of Value function: 13.8261
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 32
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 20.8539
New value of Value function: 20.8539
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 33
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 44.0619
New value of Value function: 44.0619
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 34
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 46
New value of Q matrix: 48.2539
New value of Value function: 48.2539
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 35
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 41.9426
New value of Value function: 41.9426
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 36
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 39.6273
New value of Value function: 48.2539
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 49.3765
New value of Value function: 49.3765
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 51
New value of Q matrix: 48.796
New value of Value function: 48.796
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 39
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 20.313
New value of Value function: 20.313
New value of Policy matrix: 1

=======================================
Episode: 35
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 224
New value of Q matrix: 26.9703
New value of Value function: 26.9703
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 49.6553
New value of Value function: 49.6553
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 42
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 52
New value of Q matrix: 51.0348
New value of Value function: 51.0348
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 43
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: 60.7315
New value of Value function: 60.7315
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 44
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 34.7769
New value of Value function: 51.0348
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 45
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 37.7479
New value of Value function: 51.0348
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 50.208
New value of Value function: 50.208
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 53
New value of Q matrix: 52.558
New value of Value function: 52.558
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 48
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 58.7447
New value of Value function: 58.7447
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 49
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 54
New value of Q matrix: 53.5921
New value of Value function: 53.5921
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 50
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: 57.341
New value of Value function: 57.341
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 51
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 55
New value of Q matrix: 60.3056
New value of Value function: 60.3056
New value of Policy matrix: 2

=======================================
Episode: 35
Iteration: 52
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 53.7676
New value of Value function: 99.3742
New value of Policy matrix: 4

=======================================
Episode: 35
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 65.2507
New value of Value function: 65.2507
New value of Policy matrix: 0

=======================================
Episode: 35
Iteration: 54
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 14
New value of Q matrix: 99.5414
New value of Value function: 99.5414
New value of Policy matrix: 4

=======================================
Episode: 36
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 13.1635
New value of Value function: 26.9703
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 225
New value of Q matrix: 25.949
New value of Value function: 25.949
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 15.7141
New value of Value function: 15.7141
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 226
New value of Q matrix: 25.4279
New value of Value function: 25.4279
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 5
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 17.9972
New value of Value function: 17.9972
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 27.6224
New value of Value function: 27.6224
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 22.2157
New value of Value function: 22.2157
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 8
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 17.4096
New value of Value function: 17.4096
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 9
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 18.1306
New value of Value function: 18.1306
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 10
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 26.4948
New value of Value function: 26.4948
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 11
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 25.1793
New value of Value function: 25.1793
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 12
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 8.45583
New value of Value function: 22.2944
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 13
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 24.748
New value of Value function: 24.748
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 14
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 33.0301
New value of Value function: 33.0301
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 15
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 39.8482
New value of Value function: 39.8482
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 16
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 45.5064
New value of Value function: 45.5064
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 17
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 50
New value of Q matrix: 49.1959
New value of Value function: 49.1959
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 18
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 46.4716
New value of Value function: 46.4716
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 19
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 51
New value of Q matrix: 47.8414
New value of Value function: 47.8414
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 20
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 44.5661
New value of Value function: 44.5661
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 21
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 49.9023
New value of Value function: 49.9023
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 22
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 56
New value of Q matrix: 55.21
New value of Value function: 55.21
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 16.1384
New value of Value function: 25.4279
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 227
New value of Q matrix: 27.2183
New value of Value function: 27.2183
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 25
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 50.9676
New value of Value function: 50.9676
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 26
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 38.2914
New value of Value function: 55.21
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 27
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 57
New value of Q matrix: 56.7184
New value of Value function: 56.7184
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 28
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 32
New value of Q matrix: 63.2886
New value of Value function: 63.2886
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 58
New value of Q matrix: 57.7606
New value of Value function: 57.7606
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 30
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 61.8776
New value of Value function: 61.8776
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 31
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 59
New value of Q matrix: 58.4764
New value of Value function: 58.4764
New value of Policy matrix: 2

=======================================
Episode: 36
Iteration: 32
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 68.6806
New value of Value function: 68.6806
New value of Policy matrix: 0

=======================================
Episode: 36
Iteration: 33
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1726
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 15
New value of Q matrix: 98.3688
New value of Value function: 99
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 17.7677
New value of Value function: 27.2183
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 27.2003
New value of Value function: 27.2003
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 229
New value of Q matrix: 26.7057
New value of Value function: 26.7057
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 17.875
New value of Value function: 17.875
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 5
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 19.3663
New value of Value function: 19.3663
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 6
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 22.201
New value of Value function: 22.201
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 22.3462
New value of Value function: 22.3462
New value of Policy matrix: 3

=======================================
Episode: 37
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 27.3339
New value of Value function: 27.3339
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 9
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 22.1442
New value of Value function: 22.2157
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 27.1637
New value of Value function: 27.1637
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 11
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 16.1919
New value of Value function: 22.2157
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 12
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 12.7187
New value of Value function: 20.4855
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 13
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 23.6977
New value of Value function: 23.6977
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 14
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 18.4607
New value of Value function: 21.6238
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 15
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 21.9986
New value of Value function: 23.6977
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 16
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 27.7438
New value of Value function: 27.7438
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 17
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 24.601
New value of Value function: 24.601
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 18
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 27.2874
New value of Value function: 27.2874
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 19
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 28.2989
New value of Value function: 28.2989
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 20
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 33.0286
New value of Value function: 33.0286
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 21
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 49.7353
New value of Value function: 49.7353
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 22
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 57.4005
New value of Value function: 57.4005
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 23
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 67.8866
New value of Value function: 67.8866
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 55.6895
New value of Value function: 94.6079
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 25
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 56.544
New value of Value function: 67.8866
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 16.3348
New value of Value function: 67.8866
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 27
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 17.7444
New value of Value function: 39.3334
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 28
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 29.7214
New value of Value function: 29.7214
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 29
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 43.9279
New value of Value function: 43.9279
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 30
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 61.4794
New value of Value function: 61.4794
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 31
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 70.059
New value of Value function: 70.059
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 32
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 57.7951
New value of Value function: 57.7951
New value of Policy matrix: 3

=======================================
Episode: 37
Iteration: 33
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 65.3511
New value of Value function: 65.3511
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 34
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 58.6459
New value of Value function: 58.6459
New value of Policy matrix: 3

=======================================
Episode: 37
Iteration: 35
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 78.9501
New value of Value function: 78.9501
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 36
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 54
New value of Q matrix: 94.0071
New value of Value function: 94.0071
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 37
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 39
New value of Q matrix: 89.4014
New value of Value function: 89.4014
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 38
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 55
New value of Q matrix: 93.5352
New value of Value function: 93.5352
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 39
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 40
New value of Q matrix: 89.5909
New value of Value function: 89.5909
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 56
New value of Q matrix: 93.1556
New value of Value function: 93.1556
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 41
New value of Q matrix: 89.6898
New value of Value function: 89.6898
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 42
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 94.3728
New value of Value function: 94.3728
New value of Policy matrix: 2

=======================================
Episode: 37
Iteration: 43
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 80.3167
New value of Value function: 98.3281
New value of Policy matrix: 4

=======================================
Episode: 37
Iteration: 44
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 91.3339
New value of Value function: 91.3339
New value of Policy matrix: 0

=======================================
Episode: 37
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 18
New value of Q matrix: 98.7222
New value of Value function: 98.7222
New value of Policy matrix: 4

=======================================
Episode: 38
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 26.6881
New value of Value function: 26.6881
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 231
New value of Q matrix: 26.2939
New value of Value function: 26.2939
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 18.8609
New value of Value function: 18.8609
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 20.3497
New value of Value function: 20.3497
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 21.979
New value of Value function: 22.201
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 6
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 23.1929
New value of Value function: 23.1929
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 26.9454
New value of Value function: 26.9454
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 28.9411
New value of Value function: 28.9411
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 9
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 28.9248
New value of Value function: 28.9248
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 10
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 39.7356
New value of Value function: 39.7356
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 11
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 48.9479
New value of Value function: 48.9479
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 12
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 48.2723
New value of Value function: 48.2723
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 13
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 65.4968
New value of Value function: 65.4968
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 72.944
New value of Value function: 72.944
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 15
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 57.0842
New value of Value function: 58.6459
New value of Policy matrix: 3

=======================================
Episode: 38
Iteration: 16
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 74.128
New value of Value function: 74.128
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 17
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 35.7317
New value of Value function: 94.3728
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 18
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 70.2146
New value of Value function: 70.2146
New value of Policy matrix: 3

=======================================
Episode: 38
Iteration: 19
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 81.9543
New value of Value function: 81.9543
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 58
New value of Q matrix: 94.1164
New value of Value function: 94.1164
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 21
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 43
New value of Q matrix: 91.3097
New value of Value function: 91.3097
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 22
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 78.7733
New value of Value function: 94.1164
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 23
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 59
New value of Q matrix: 93.8925
New value of Value function: 93.8925
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 24
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 44
New value of Q matrix: 91.256
New value of Value function: 91.256
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 25
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 60
New value of Q matrix: 93.6925
New value of Value function: 93.6925
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 26
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 45
New value of Q matrix: 91.1814
New value of Value function: 91.1814
New value of Policy matrix: 0

=======================================
Episode: 38
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 35.4308
New value of Value function: 93.6925
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 28
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 55.4692
New value of Value function: 75.9811
New value of Policy matrix: 1

=======================================
Episode: 38
Iteration: 29
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 78.9969
New value of Value function: 78.9969
New value of Policy matrix: 1

=======================================
Episode: 38
Iteration: 30
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 61.2445
New value of Value function: 93.6925
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 31
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 75.5125
New value of Value function: 75.5125
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 32
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 81.3487
New value of Value function: 81.3487
New value of Policy matrix: 1

=======================================
Episode: 38
Iteration: 33
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 94.8503
New value of Value function: 94.8503
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 34
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 58.6378
New value of Value function: 98.7222
New value of Policy matrix: 4

=======================================
Episode: 38
Iteration: 35
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 10.6817
New value of Value function: 81.3487
New value of Policy matrix: 1

=======================================
Episode: 38
Iteration: 36
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 18.0811
New value of Value function: 37.5694
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 37
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 48.1882
New value of Value function: 48.1882
New value of Policy matrix: 1

=======================================
Episode: 38
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 77.0235
New value of Value function: 77.0235
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 39
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 26
New value of Q matrix: 83.4183
New value of Value function: 83.4183
New value of Policy matrix: 1

=======================================
Episode: 38
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 95.8517
New value of Value function: 95.8517
New value of Policy matrix: 2

=======================================
Episode: 38
Iteration: 41
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 19
New value of Q matrix: 99.0154
New value of Value function: 99.0154
New value of Policy matrix: 4

=======================================
Episode: 39
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 26.2766
New value of Value function: 26.2766
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 233
New value of Q matrix: 25.9189
New value of Value function: 25.9189
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 11.1975
New value of Value function: 17.9972
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 21.8793
New value of Value function: 21.8793
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 5
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 20.7316
New value of Value function: 20.7316
New value of Policy matrix: 1

=======================================
Episode: 39
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 234
New value of Q matrix: 25.5986
New value of Value function: 25.5986
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 7
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 18.1602
New value of Value function: 18.1602
New value of Policy matrix: 4

=======================================
Episode: 39
Iteration: 8
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 18.1206
New value of Value function: 18.1206
New value of Policy matrix: 4

=======================================
Episode: 39
Iteration: 9
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 13.5019
New value of Value function: 18.1206
New value of Policy matrix: 4

=======================================
Episode: 39
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 29.3491
New value of Value function: 29.3491
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 11
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 24.6208
New value of Value function: 24.6208
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 12
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 11.3661
New value of Value function: 17.4096
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 13
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 18.509
New value of Value function: 18.509
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 19.1614
New value of Value function: 19.1614
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 15
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 20.6206
New value of Value function: 20.6206
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 16
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 25.3169
New value of Value function: 25.3169
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 17
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 21.544
New value of Value function: 21.544
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 18
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 26.5956
New value of Value function: 26.5956
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 19
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 25.461
New value of Value function: 25.461
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 20
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 24.4193
New value of Value function: 24.4193
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 21
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 13.7921
New value of Value function: 25.461
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 22
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 29.9305
New value of Value function: 29.9305
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 23
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 42.0781
New value of Value function: 42.0781
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 24
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 39.8032
New value of Value function: 39.8032
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 25
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 44.4644
New value of Value function: 44.4644
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 26
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 42.0095
New value of Value function: 42.0095
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 27
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 33.9203
New value of Value function: 33.9203
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 28
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 43.8861
New value of Value function: 43.8861
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 29
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 17.4803
New value of Value function: 50.9676
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 30
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 44.2175
New value of Value function: 44.2175
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 54
New value of Q matrix: 49.7637
New value of Value function: 49.7637
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 32
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 46.7994
New value of Value function: 46.7994
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 55
New value of Q matrix: 49.0312
New value of Value function: 49.0312
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 34
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 47.9826
New value of Value function: 47.9826
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 56
New value of Q matrix: 50.6161
New value of Value function: 50.6161
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 60
New value of Q matrix: 53.8116
New value of Value function: 53.8116
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 16.6544
New value of Value function: 25.5986
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 38
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 38.266
New value of Value function: 38.266
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 39
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 45.3399
New value of Value function: 45.3399
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 51.3654
New value of Value function: 51.3654
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 41
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 61
New value of Q matrix: 55.8835
New value of Value function: 55.8835
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 42
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 35
New value of Q matrix: 66.085
New value of Value function: 66.085
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 43
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 62
New value of Q matrix: 57.3492
New value of Value function: 57.3492
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 44
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 64.2001
New value of Value function: 64.2001
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 45
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 41.5091
New value of Value function: 57.3492
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 46
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 63
New value of Q matrix: 63.1019
New value of Value function: 63.1019
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 47
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 71.8175
New value of Value function: 98.3688
New value of Policy matrix: 4

=======================================
Episode: 39
Iteration: 48
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 47.2679
New value of Value function: 64.2001
New value of Policy matrix: 0

=======================================
Episode: 39
Iteration: 49
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 57.5818
New value of Value function: 63.1019
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 50
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 93.7915
New value of Value function: 93.7915
New value of Policy matrix: 2

=======================================
Episode: 39
Iteration: 51
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1766
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 16
New value of Q matrix: 98.0266
New value of Value function: 98.0266
New value of Policy matrix: 4

=======================================
Episode: 40
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 25.5819
New value of Value function: 25.5819
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 236
New value of Q matrix: 25.2718
New value of Value function: 25.2718
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 21.4068
New value of Value function: 21.4068
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 25.7925
New value of Value function: 25.7925
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 5
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 15.9695
New value of Value function: 18.1206
New value of Policy matrix: 4

=======================================
Episode: 40
Iteration: 6
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 17.9826
New value of Value function: 17.9826
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 237
New value of Q matrix: 23.8894
New value of Value function: 23.8894
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 8
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 7.58926
New value of Value function: 7.58926
New value of Policy matrix: 1

=======================================
Episode: 40
Iteration: 9
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 20.6505
New value of Value function: 20.6505
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 18.8687
New value of Value function: 23.8894
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 238
New value of Q matrix: 23.8605
New value of Value function: 23.8605
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 12
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 20.6303
New value of Value function: 20.6303
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 239
New value of Q matrix: 23.8908
New value of Value function: 23.8908
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 14
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 22.5289
New value of Value function: 22.5289
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 15
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 25.983
New value of Value function: 25.983
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 16
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 11.4948
New value of Value function: 22.5289
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 240
New value of Q matrix: 23.982
New value of Value function: 23.982
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 18
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 25.8963
New value of Value function: 25.8963
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 19
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 31.5164
New value of Value function: 31.5164
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 20
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 35.1239
New value of Value function: 35.1239
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 21
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 40.3117
New value of Value function: 40.3117
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 22
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 39.837
New value of Value function: 44.4644
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 23
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 40.6937
New value of Value function: 40.6937
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 24
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 45.8644
New value of Value function: 45.8644
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 25
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 33
New value of Q matrix: 45.2416
New value of Value function: 45.2416
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 26
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 48.2369
New value of Value function: 48.2369
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 58
New value of Q matrix: 50.2393
New value of Value function: 50.2393
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 28
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 41.895
New value of Value function: 45.2416
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 29
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 46.3555
New value of Value function: 46.3555
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 30
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 59
New value of Q matrix: 49.6227
New value of Value function: 49.6227
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 31
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 48.9305
New value of Value function: 48.9305
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 32
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 51.6687
New value of Value function: 51.6687
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 33
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 44.528
New value of Value function: 63.1019
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 34
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 30.4218
New value of Value function: 30.4218
New value of Policy matrix: 1

=======================================
Episode: 40
Iteration: 35
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 54.2826
New value of Value function: 54.2826
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 64
New value of Q matrix: 57.8529
New value of Value function: 57.8529
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 37
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 11.7861
New value of Value function: 20.313
New value of Policy matrix: 1

=======================================
Episode: 40
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 241
New value of Q matrix: 25.9254
New value of Value function: 25.9254
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 39
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 52.7705
New value of Value function: 52.7705
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 40
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 65
New value of Q matrix: 58.8086
New value of Value function: 58.8086
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 41
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 37
New value of Q matrix: 62.8883
New value of Value function: 62.8883
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 42
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 46.1316
New value of Value function: 58.8086
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 43
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 25.2375
New value of Value function: 62.8883
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 44
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 51.2428
New value of Value function: 51.2428
New value of Policy matrix: 3

=======================================
Episode: 40
Iteration: 45
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 53.8437
New value of Value function: 53.8437
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 46
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 59.0557
New value of Value function: 59.0557
New value of Policy matrix: 0

=======================================
Episode: 40
Iteration: 47
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 96.5888
New value of Value function: 96.5888
New value of Policy matrix: 2

=======================================
Episode: 40
Iteration: 48
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 17
New value of Q matrix: 98.5052
New value of Value function: 98.5052
New value of Policy matrix: 4

=======================================
Episode: 41
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 25.9087
New value of Value function: 25.9087
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 243
New value of Q matrix: 25.637
New value of Value function: 25.637
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 19.8192
New value of Value function: 19.8192
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 12.1215
New value of Value function: 20.3497
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 20.5452
New value of Value function: 20.5452
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 21.3112
New value of Value function: 21.3112
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 23.1491
New value of Value function: 23.1491
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 8
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 23.9337
New value of Value function: 23.9337
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 9
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 13.5873
New value of Value function: 24.6208
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 10
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 23.4412
New value of Value function: 23.4412
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 26.6461
New value of Value function: 26.6461
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 12
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 11.4048
New value of Value function: 23.4412
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 13
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 25.5041
New value of Value function: 25.5041
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 14
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 24.5738
New value of Value function: 24.5738
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 15
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 15.3064
New value of Value function: 15.3064
New value of Policy matrix: 3

=======================================
Episode: 41
Iteration: 16
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 1.56586
New value of Value function: 25.5041
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 17
----------
State: 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 13.1108
New value of Value function: 13.1108
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 244
New value of Q matrix: 25.1579
New value of Value function: 25.1579
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 19
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 17.3242
New value of Value function: 17.3242
New value of Policy matrix: 3

=======================================
Episode: 41
Iteration: 20
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 26.3198
New value of Value function: 26.3198
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 21
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 13.1906
New value of Value function: 24.5738
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 22
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 16.9031
New value of Value function: 24.5738
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 23
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 26.9957
New value of Value function: 26.9957
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 24
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 17.9084
New value of Value function: 28.9248
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 25
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 28.7101
New value of Value function: 28.7101
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 26
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 25.5364
New value of Value function: 28.9248
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 27
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 31.9513
New value of Value function: 31.9513
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 28
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 11.356
New value of Value function: 39.7356
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 29
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 38.1968
New value of Value function: 38.1968
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 30
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 33.0336
New value of Value function: 33.0336
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 31
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 42.6024
New value of Value function: 42.6024
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 32
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 25.6198
New value of Value function: 48.9479
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 33
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 11.8366
New value of Value function: 42.6024
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 34
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 20.7278
New value of Value function: 20.7278
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 35
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 23.4914
New value of Value function: 23.4914
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 36
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 32.9569
New value of Value function: 32.9569
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 37
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 55.6889
New value of Value function: 55.6889
New value of Policy matrix: 1

=======================================
Episode: 41
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 78.5978
New value of Value function: 78.5978
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 39
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 85.2417
New value of Value function: 85.2417
New value of Policy matrix: 1

=======================================
Episode: 41
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 63
New value of Q matrix: 95.4004
New value of Value function: 95.4004
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 46
New value of Q matrix: 91.3679
New value of Value function: 91.3679
New value of Policy matrix: 0

=======================================
Episode: 41
Iteration: 42
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 66.509
New value of Value function: 95.4004
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 43
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 66.4648
New value of Value function: 81.9543
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 44
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 81.3768
New value of Value function: 81.3768
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 45
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 96.3535
New value of Value function: 96.3535
New value of Policy matrix: 2

=======================================
Episode: 41
Iteration: 46
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 20
New value of Q matrix: 99.2355
New value of Value function: 99.2355
New value of Policy matrix: 4

=======================================
Episode: 42
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 14.031
New value of Value function: 25.1579
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 25.1418
New value of Value function: 25.1418
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 25.1258
New value of Value function: 25.1258
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 247
New value of Q matrix: 25.0121
New value of Value function: 25.0121
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 21.3027
New value of Value function: 21.3027
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 22.206
New value of Value function: 22.206
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 24.3487
New value of Value function: 24.3487
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 8
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 26.2096
New value of Value function: 26.2096
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 9
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 17.0332
New value of Value function: 28.7101
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 23.1382
New value of Value function: 23.1382
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 11
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 19.4833
New value of Value function: 28.7101
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 12
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 25.0909
New value of Value function: 25.0909
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 13
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 30.9584
New value of Value function: 30.9584
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 14
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 39.1942
New value of Value function: 39.1942
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 15
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 49.3819
New value of Value function: 49.3819
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 18.89
New value of Value function: 48.2723
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 17
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 30.6064
New value of Value function: 48.2723
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 18
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 78.4737
New value of Value function: 78.4737
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 19
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 74.0856
New value of Value function: 74.0856
New value of Policy matrix: 3

=======================================
Episode: 42
Iteration: 20
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 77.4842
New value of Value function: 77.4842
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 21
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 74.4457
New value of Value function: 74.4457
New value of Policy matrix: 3

=======================================
Episode: 42
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 69.8215
New value of Value function: 77.4842
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 23
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 83.8585
New value of Value function: 83.8585
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 65
New value of Q matrix: 95.8698
New value of Value function: 95.8698
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 25
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 47
New value of Q matrix: 91.593
New value of Value function: 91.593
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 26
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 50.7954
New value of Value function: 95.8698
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 27
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: 86.6911
New value of Value function: 86.6911
New value of Policy matrix: 1

=======================================
Episode: 42
Iteration: 28
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 66
New value of Q matrix: 96.7774
New value of Value function: 96.7774
New value of Policy matrix: 2

=======================================
Episode: 42
Iteration: 29
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 83.6084
New value of Value function: 99.2355
New value of Policy matrix: 4

=======================================
Episode: 42
Iteration: 30
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 92.9859
New value of Value function: 92.9859
New value of Policy matrix: 0

=======================================
Episode: 42
Iteration: 31
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 21
New value of Q matrix: 99.4023
New value of Value function: 99.4023
New value of Policy matrix: 4

=======================================
Episode: 43
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 15.362
New value of Value function: 25.0121
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 24.9962
New value of Value function: 24.9962
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 24.9804
New value of Value function: 24.9804
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 250
New value of Q matrix: 24.9306
New value of Value function: 24.9306
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 5
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 23.286
New value of Value function: 23.286
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 24.4105
New value of Value function: 24.4105
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 7
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 18.082
New value of Value function: 18.082
New value of Policy matrix: 4

=======================================
Episode: 43
Iteration: 8
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 18.0443
New value of Value function: 18.0443
New value of Policy matrix: 4

=======================================
Episode: 43
Iteration: 9
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 18.2897
New value of Value function: 18.2897
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 10
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 22.6215
New value of Value function: 22.6215
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 11
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.6534
New value of Value function: 25.8963
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 17.9432
New value of Value function: 24.9306
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 13
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 13.7301
New value of Value function: 22.6215
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 14
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 21.1744
New value of Value function: 21.1744
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 15
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 26.4102
New value of Value function: 26.4102
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 16
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 25.3428
New value of Value function: 25.3428
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 17
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 28.858
New value of Value function: 28.858
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 18
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 30.4482
New value of Value function: 30.4482
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 45.2867
New value of Value function: 45.2867
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 20
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 6.28649
New value of Value function: 40.6937
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 21
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 29.9507
New value of Value function: 29.9507
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 22
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 41.2855
New value of Value function: 41.2855
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 23
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 47.1213
New value of Value function: 47.1213
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 24
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 47.8683
New value of Value function: 47.8683
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 25
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 63
New value of Q matrix: 52.7786
New value of Value function: 52.7786
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 26
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 48.932
New value of Value function: 48.932
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 64
New value of Q matrix: 51.9866
New value of Value function: 51.9866
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 28
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 49.6775
New value of Value function: 49.6775
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 29
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 65
New value of Q matrix: 51.956
New value of Value function: 51.956
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 30
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 54.0479
New value of Value function: 54.0479
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 53.1265
New value of Value function: 53.1265
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 32
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 47.1759
New value of Value function: 59.0557
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 54.1452
New value of Value function: 54.1452
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 44.417
New value of Value function: 59.0557
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 35
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 50.1977
New value of Value function: 58.8086
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 36
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 30.4218
New value of Policy matrix: 1

=======================================
Episode: 43
Iteration: 37
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 38
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 39
----------
State: 2205
	Distance: 5
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 40
----------
State: 2609
	Distance: 6
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 20.6454
New value of Value function: 20.6454
New value of Policy matrix: 1

=======================================
Episode: 43
Iteration: 41
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 29.6331
New value of Value function: 29.6331
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 42
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 17.1941
New value of Value function: 44.0567
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 43
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 29.3368
New value of Value function: 29.6331
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 44
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 35.3567
New value of Value function: 35.3567
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 45
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 76.7152
New value of Value function: 76.7152
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 46
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 83.3904
New value of Value function: 83.3904
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 47
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 38.7712
New value of Value function: 62.8883
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 48
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 52.2051
New value of Value function: 52.2051
New value of Policy matrix: 3

=======================================
Episode: 43
Iteration: 49
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 33.9711
New value of Value function: 54.1452
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 50
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 50.6389
New value of Value function: 50.6389
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 51
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 68
New value of Q matrix: 53.4161
New value of Value function: 53.4161
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 52
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 39
New value of Q matrix: 51.3183
New value of Value function: 51.3183
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 53
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 54.3556
New value of Value function: 54.3556
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 54
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 46.7502
New value of Value function: 58.8086
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 55
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 66
New value of Q matrix: 59.4795
New value of Value function: 59.4795
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 56
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 29.5411
New value of Value function: 62.8883
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 57
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 38
New value of Q matrix: 61.9144
New value of Value function: 61.9144
New value of Policy matrix: 0

=======================================
Episode: 43
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 67
New value of Q matrix: 64.7378
New value of Value function: 64.7378
New value of Policy matrix: 2

=======================================
Episode: 43
Iteration: 59
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1726
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 18
New value of Q matrix: 97.679
New value of Value function: 97.679
New value of Policy matrix: 4

=======================================
Episode: 44
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 24.9149
New value of Value function: 24.9149
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 19.5769
New value of Value function: 24.9149
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 252
New value of Q matrix: 24.8988
New value of Value function: 24.8988
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 21.7767
New value of Value function: 21.7767
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 16.5053
New value of Value function: 24.8988
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 24.8832
New value of Value function: 24.8832
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 254
New value of Q matrix: 24.9566
New value of Value function: 24.9566
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 8
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 24.1763
New value of Value function: 24.1763
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 16.5173
New value of Value function: 24.4105
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 10
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 24.8449
New value of Value function: 24.8449
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 23.0496
New value of Value function: 23.0496
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 12
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 22.8425
New value of Value function: 22.8425
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 13
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 24.7773
New value of Value function: 24.7773
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 14
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 25.7127
New value of Value function: 25.7127
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 15
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 14.9217
New value of Value function: 28.858
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 16
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 14.4674
New value of Value function: 24.7773
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 17
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 22.3161
New value of Value function: 22.3161
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 18
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 16.5937
New value of Value function: 24.7773
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 19
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 22.0929
New value of Value function: 22.3161
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 20
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 19.345
New value of Value function: 22.3161
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 21
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 19.9463
New value of Value function: 24.7773
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 22
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 26.3522
New value of Value function: 26.3522
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 23
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 14.0186
New value of Value function: 25.7127
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 24
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 25.96
New value of Value function: 25.96
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 25
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 12.4462
New value of Value function: 28.858
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 26
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 5.13784
New value of Value function: 14.1245
New value of Policy matrix: 1

=======================================
Episode: 44
Iteration: 27
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 14.9715
New value of Value function: 14.9715
New value of Policy matrix: 1

=======================================
Episode: 44
Iteration: 28
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 24.6626
New value of Value function: 24.6626
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 29
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 16.3296
New value of Value function: 28.858
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 30
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 26.4807
New value of Value function: 26.4807
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 31
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 19.1507
New value of Value function: 28.858
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 32
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 27.8984
New value of Value function: 27.8984
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 33
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 13.6967
New value of Value function: 28.858
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 34
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 19.69
New value of Value function: 19.69
New value of Policy matrix: 1

=======================================
Episode: 44
Iteration: 35
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 30.3825
New value of Value function: 30.3825
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 36
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 34.6062
New value of Value function: 34.6062
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 37
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 46.0908
New value of Value function: 46.0908
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 38
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 14.2684
New value of Value function: 41.2855
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 39
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 43.5356
New value of Value function: 43.5356
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 40
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 40
New value of Q matrix: 52.0288
New value of Value function: 52.0288
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 70
New value of Q matrix: 53.7763
New value of Value function: 53.7763
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 42
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 41
New value of Q matrix: 52.5301
New value of Value function: 52.5301
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 43
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 71
New value of Q matrix: 53.507
New value of Value function: 53.507
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 44
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 54.2949
New value of Value function: 54.2949
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 45
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 17.395
New value of Value function: 53.507
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 255
New value of Q matrix: 26.8988
New value of Value function: 26.8988
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 47
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 55.1078
New value of Value function: 55.1078
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 48
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 48.4405
New value of Value function: 64.7378
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 49
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 56.5103
New value of Value function: 56.5103
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 68
New value of Q matrix: 64.5629
New value of Value function: 64.5629
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 39
New value of Q matrix: 61.9148
New value of Value function: 61.9148
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 69
New value of Q matrix: 64.4103
New value of Value function: 64.4103
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 40
New value of Q matrix: 61.8913
New value of Value function: 61.8913
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 54
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 70
New value of Q matrix: 64.2743
New value of Value function: 64.2743
New value of Policy matrix: 2

=======================================
Episode: 44
Iteration: 55
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 36.6327
New value of Value function: 61.8913
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 56
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 67.7964
New value of Value function: 67.7964
New value of Policy matrix: 0

=======================================
Episode: 44
Iteration: 57
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 19
New value of Q matrix: 98.2115
New value of Value function: 98.2115
New value of Policy matrix: 4

=======================================
Episode: 45
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 26.882
New value of Value function: 26.882
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 257
New value of Q matrix: 26.7079
New value of Value function: 26.7079
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 22.0703
New value of Value function: 22.0703
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 22.9858
New value of Value function: 22.9858
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 23.4825
New value of Value function: 24.3487
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 6
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 23.842
New value of Value function: 24.3487
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 25.1747
New value of Value function: 25.1747
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 8
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 28.7324
New value of Value function: 28.7324
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 9
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 34.0735
New value of Value function: 34.0735
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 43.0922
New value of Value function: 43.0922
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 11
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 49.7049
New value of Value function: 49.7049
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 12
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 52.4246
New value of Value function: 52.4246
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 13
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 68.3393
New value of Value function: 68.3393
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 84.5171
New value of Value function: 84.5171
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 15
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 67
New value of Q matrix: 92.5839
New value of Value function: 92.5839
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 16
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 66.826
New value of Value function: 66.826
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 17
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 78.0588
New value of Value function: 78.0588
New value of Policy matrix: 3

=======================================
Episode: 45
Iteration: 18
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 63.3588
New value of Value function: 69.8215
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 19
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 14.024
New value of Value function: 14.024
New value of Policy matrix: 1

=======================================
Episode: 45
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 20.0554
New value of Value function: 26.7079
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 21
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 43.8554
New value of Value function: 43.8554
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 68.7671
New value of Value function: 68.7671
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 23
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 68.8767
New value of Value function: 68.8767
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 72.0177
New value of Value function: 72.0177
New value of Policy matrix: 0

=======================================
Episode: 45
Iteration: 25
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 48
New value of Q matrix: 84.8639
New value of Value function: 84.8639
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 26
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 101.408
New value of Value function: 101.408
New value of Policy matrix: 2

=======================================
Episode: 45
Iteration: 27
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 22
New value of Q matrix: 99.5298
New value of Value function: 99.5298
New value of Policy matrix: 4

=======================================
Episode: 46
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 26.6912
New value of Value function: 26.6912
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 259
New value of Q matrix: 26.7475
New value of Value function: 26.7475
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 25.0575
New value of Value function: 25.0575
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 23.5213
New value of Value function: 23.5213
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 5
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 26.5303
New value of Value function: 26.5303
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 6
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 27.5143
New value of Value function: 27.5143
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 7
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 26.5476
New value of Value function: 26.5476
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 8
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 29.8874
New value of Value function: 29.8874
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 9
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 29.4106
New value of Value function: 29.4106
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 10
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 36.9594
New value of Value function: 36.9594
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 11
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 45.701
New value of Value function: 45.701
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 12
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 41.7853
New value of Value function: 41.7853
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 13
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 45.4489
New value of Value function: 45.4489
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 14
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 23.3103
New value of Value function: 41.7853
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 15
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 46.4287
New value of Value function: 46.4287
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 16
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 29.8028
New value of Value function: 52.5301
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 17
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 25.9689
New value of Value function: 45.4489
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 18
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 48.1
New value of Value function: 48.1
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 19
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 46.4163
New value of Value function: 52.5301
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 20
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 42
New value of Q matrix: 53.3657
New value of Value function: 53.3657
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 21
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 74
New value of Q matrix: 55.8502
New value of Value function: 55.8502
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 22
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 53.9644
New value of Value function: 53.9644
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 23
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 75
New value of Q matrix: 55.377
New value of Value function: 55.377
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 24
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 54.9477
New value of Value function: 54.9477
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 25
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 76
New value of Q matrix: 56.668
New value of Value function: 56.668
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 26
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 71
New value of Q matrix: 59.4329
New value of Value function: 59.4329
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 260
New value of Q matrix: 28.754
New value of Value function: 28.754
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 77
New value of Q matrix: 57.2572
New value of Value function: 57.2572
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 59.3804
New value of Value function: 59.4329
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 30
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 77.9961
New value of Value function: 77.9961
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 31
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 50.1536
New value of Value function: 67.7964
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 32
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 72
New value of Q matrix: 60.5744
New value of Value function: 60.5744
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 33
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 42
New value of Q matrix: 66.2799
New value of Value function: 66.2799
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 73
New value of Q matrix: 61.3987
New value of Value function: 61.3987
New value of Policy matrix: 2

=======================================
Episode: 46
Iteration: 35
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 31.0897
New value of Value function: 66.2799
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 261
New value of Q matrix: 31.2214
New value of Value function: 31.2214
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 37
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 71.4572
New value of Value function: 71.4572
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 38
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 69.4649
New value of Value function: 98.2115
New value of Policy matrix: 4

=======================================
Episode: 46
Iteration: 39
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 75.7948
New value of Value function: 75.7948
New value of Policy matrix: 0

=======================================
Episode: 46
Iteration: 40
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 20
New value of Q matrix: 98.6114
New value of Value function: 98.6114
New value of Policy matrix: 4

=======================================
Episode: 47
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 31.2021
New value of Value function: 31.2021
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 263
New value of Q matrix: 30.8104
New value of Value function: 30.8104
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 22.8226
New value of Value function: 22.8226
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 23.758
New value of Value function: 23.758
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 26.2832
New value of Value function: 26.2832
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 31.3144
New value of Value function: 31.3144
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 37.2761
New value of Value function: 37.2761
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 41.8539
New value of Value function: 41.8539
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 9
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 45.8212
New value of Value function: 45.8212
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 10
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 50.8666
New value of Value function: 50.8666
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 11
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 51.3189
New value of Value function: 51.3189
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 12
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 55.7375
New value of Value function: 55.7375
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 13
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 69.9199
New value of Value function: 69.9199
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 14
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 74.7628
New value of Value function: 74.7628
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 15
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 81.4632
New value of Value function: 81.4632
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 16
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 62.8792
New value of Value function: 62.8792
New value of Policy matrix: 3

=======================================
Episode: 47
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 65.2796
New value of Value function: 74.7628
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 18
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 76.2804
New value of Value function: 76.2804
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 19
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 83.3293
New value of Value function: 83.3293
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 68
New value of Q matrix: 92.7624
New value of Value function: 92.7624
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 21
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 49
New value of Q matrix: 92.5357
New value of Value function: 92.5357
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 22
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 69
New value of Q matrix: 92.8645
New value of Value function: 92.8645
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 23
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 70.7926
New value of Value function: 92.5357
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 70
New value of Q matrix: 92.9537
New value of Value function: 92.9537
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 25
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 50
New value of Q matrix: 92.1806
New value of Value function: 92.1806
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 26
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 71
New value of Q matrix: 92.9899
New value of Value function: 92.9899
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 27
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 51
New value of Q matrix: 91.8836
New value of Value function: 91.8836
New value of Policy matrix: 0

=======================================
Episode: 47
Iteration: 28
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 83.7952
New value of Value function: 92.9899
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 29
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 72
New value of Q matrix: 94.2326
New value of Value function: 94.2326
New value of Policy matrix: 2

=======================================
Episode: 47
Iteration: 30
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 23
New value of Q matrix: 99.6278
New value of Value function: 99.6278
New value of Policy matrix: 4

=======================================
Episode: 48
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 30.7915
New value of Value function: 30.7915
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 265
New value of Q matrix: 30.4722
New value of Value function: 30.4722
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 23.5622
New value of Value function: 23.5622
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 24.5782
New value of Value function: 24.5782
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 33
New value of Q matrix: 27.6267
New value of Value function: 27.6267
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 33.9617
New value of Value function: 33.9617
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 39.3774
New value of Value function: 39.3774
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 46.4749
New value of Value function: 46.4749
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 9
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 55.3257
New value of Value function: 55.3257
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 10
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 22
New value of Q matrix: 51.4156
New value of Value function: 51.4156
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 11
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 59.2656
New value of Value function: 59.2656
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 12
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 71.5447
New value of Value function: 71.5447
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 13
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 77.833
New value of Value function: 77.833
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 14
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 32.3817
New value of Value function: 83.3293
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 15
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 62.6105
New value of Value function: 62.6105
New value of Policy matrix: 1

=======================================
Episode: 48
Iteration: 16
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 85.1442
New value of Value function: 85.1442
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 17
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 73
New value of Q matrix: 94.0842
New value of Value function: 94.0842
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 18
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 52
New value of Q matrix: 91.781
New value of Value function: 91.781
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 19
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 68.3576
New value of Value function: 94.0842
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 20
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 64.4381
New value of Value function: 77.833
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 21
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 48.1761
New value of Value function: 62.8792
New value of Policy matrix: 3

=======================================
Episode: 48
Iteration: 22
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 66.3472
New value of Value function: 66.3472
New value of Policy matrix: 3

=======================================
Episode: 48
Iteration: 23
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 79.404
New value of Value function: 79.404
New value of Policy matrix: 0

=======================================
Episode: 48
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 85.8325
New value of Value function: 85.8325
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 25
----------
State: 1777
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 97.0437
New value of Value function: 97.0437
New value of Policy matrix: 2

=======================================
Episode: 48
Iteration: 26
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 24
New value of Q matrix: 99.0914
New value of Value function: 99.0914
New value of Policy matrix: 4

=======================================
Episode: 49
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 18.1744
New value of Value function: 30.4722
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 30.4535
New value of Value function: 30.4535
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 19.6265
New value of Value function: 30.4535
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 20.8933
New value of Value function: 30.4535
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 30.4349
New value of Value function: 30.4349
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 21.5097
New value of Value function: 30.4349
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 30.4163
New value of Value function: 30.4163
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 269
New value of Q matrix: 29.6932
New value of Value function: 29.6932
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 9
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 20.564
New value of Value function: 20.564
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 10
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 19.1224
New value of Value function: 21.7767
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 270
New value of Q matrix: 29.5784
New value of Value function: 29.5784
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 12
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 25.3194
New value of Value function: 25.3194
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 13
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 15.0603
New value of Value function: 23.5213
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 14
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 25.521
New value of Value function: 25.521
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 15
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 16.5992
New value of Value function: 23.5213
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 16
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 11.8305
New value of Value function: 18.0806
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 17
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 23.4534
New value of Value function: 23.4534
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 18
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 19.7706
New value of Value function: 23.4534
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 19
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 23.3883
New value of Value function: 23.3883
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 20
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 27.4597
New value of Value function: 27.4597
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 21
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 32.8163
New value of Value function: 32.8163
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 22
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 29.219
New value of Value function: 29.219
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 23
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 28.9402
New value of Value function: 28.9402
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 24
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 30.0625
New value of Value function: 30.0625
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 25
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 28.6456
New value of Value function: 28.6456
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 26
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 32.6401
New value of Value function: 32.6401
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 27
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 38.903
New value of Value function: 38.903
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 28
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 46.0858
New value of Value function: 46.0858
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 29
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 42.5847
New value of Value function: 42.5847
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 30
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 47.2188
New value of Value function: 47.2188
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 31
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 45.4098
New value of Value function: 45.4098
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 44
New value of Q matrix: 54.676
New value of Value function: 54.676
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 37.4263
New value of Value function: 57.2572
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 34
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 47.7537
New value of Value function: 47.7537
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 35
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 45.5497
New value of Value function: 54.676
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 36
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 70.2499
New value of Value function: 70.2499
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 37
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 51.0502
New value of Value function: 61.3987
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 38
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 39.3936
New value of Value function: 39.3936
New value of Policy matrix: 1

=======================================
Episode: 49
Iteration: 39
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 57.6569
New value of Value function: 57.6569
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 40
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 74
New value of Q matrix: 63.2166
New value of Value function: 63.2166
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 41
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 45
New value of Q matrix: 73.5273
New value of Value function: 73.5273
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 42
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 75
New value of Q matrix: 64.5532
New value of Value function: 64.5532
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 43
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 39.3864
New value of Value function: 73.5273
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 44
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 54.214
New value of Value function: 54.214
New value of Policy matrix: 3

=======================================
Episode: 49
Iteration: 45
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 43.5406
New value of Value function: 57.2572
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 78
New value of Q matrix: 58.3499
New value of Value function: 58.3499
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 76
New value of Q matrix: 65.7277
New value of Value function: 65.7277
New value of Policy matrix: 2

=======================================
Episode: 49
Iteration: 48
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 77.5227
New value of Value function: 77.5227
New value of Policy matrix: 0

=======================================
Episode: 49
Iteration: 49
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1726
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 21
New value of Q matrix: 97.8234
New value of Value function: 97.8234
New value of Policy matrix: 4

=======================================
Episode: 50
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 29.5605
New value of Value function: 29.5605
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 272
New value of Q matrix: 29.3644
New value of Value function: 29.3644
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 24.3016
New value of Value function: 24.3016
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 4
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 25.4801
New value of Value function: 25.4801
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 5
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 28.9749
New value of Value function: 28.9749
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 35.4485
New value of Value function: 35.4485
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 7
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 41.9786
New value of Value function: 41.9786
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 8
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 50.5735
New value of Value function: 50.5735
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 9
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 58.1706
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 10
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 52.0773
New value of Value function: 52.0773
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 11
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 23.2565
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 12
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 28.2034
New value of Value function: 28.2034
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 13
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 49.4164
New value of Value function: 49.4164
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 14
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 70.067
New value of Value function: 85.8325
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 15
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 53
New value of Q matrix: 88.5195
New value of Value function: 88.5195
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 16
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 73.8098
New value of Value function: 101.408
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 17
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 95.366
New value of Value function: 95.366
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 18
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 53
New value of Q matrix: 91.6934
New value of Value function: 91.6934
New value of Policy matrix: 0

=======================================
Episode: 50
Iteration: 19
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 74
New value of Q matrix: 95.1323
New value of Value function: 95.1323
New value of Policy matrix: 2

=======================================
Episode: 50
Iteration: 20
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 25
New value of Q matrix: 99.2731
New value of Value function: 99.2731
New value of Policy matrix: 4

=======================================
Episode: 51
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 29.3466
New value of Value function: 29.3466
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 19.4501
New value of Value function: 29.3466
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 274
New value of Q matrix: 29.2084
New value of Value function: 29.2084
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 25.0567
New value of Value function: 25.0567
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 5
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 26.4467
New value of Value function: 26.4467
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 6
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 30.5163
New value of Value function: 30.5163
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 37.9973
New value of Value function: 37.9973
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 8
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 44.8349
New value of Value function: 44.8349
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 9
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 39.6996
New value of Value function: 50.5735
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 10
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 48.2963
New value of Value function: 48.2963
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 11
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 50.3025
New value of Value function: 50.3025
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 12
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 28.8408
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 13
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 51.3144
New value of Value function: 51.3144
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 14
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 35.2097
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 15
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 53.4749
New value of Value function: 53.4749
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 16
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 38.821
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 53.4509
New value of Value function: 53.4509
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 18
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 40.9029
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 55.7534
New value of Value function: 55.7534
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 20
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 44.2302
New value of Value function: 58.1706
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 21
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 54.9854
New value of Value function: 54.9854
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 22
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 57.4478
New value of Value function: 57.4478
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 23
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 56.3133
New value of Value function: 56.3133
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 24
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 73.4138
New value of Value function: 73.4138
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 25
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 81.2718
New value of Value function: 81.2718
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 89.6982
New value of Value function: 89.6982
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 75
New value of Q matrix: 94.8603
New value of Value function: 94.8603
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 28
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 24.0117
New value of Value function: 91.6934
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 275
New value of Q matrix: 32.288
New value of Value function: 32.288
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 30
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 95.7764
New value of Value function: 95.7764
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 31
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 54
New value of Q matrix: 91.7231
New value of Value function: 91.7231
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 76
New value of Q matrix: 94.6246
New value of Value function: 94.6246
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 33
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 55
New value of Q matrix: 91.7171
New value of Value function: 91.7171
New value of Policy matrix: 0

=======================================
Episode: 51
Iteration: 34
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 77
New value of Q matrix: 95.611
New value of Value function: 95.611
New value of Policy matrix: 2

=======================================
Episode: 51
Iteration: 35
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 26
New value of Q matrix: 98.8273
New value of Value function: 98.8273
New value of Policy matrix: 4

=======================================
Episode: 52
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 32.2686
New value of Value function: 32.2686
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 277
New value of Q matrix: 32.0281
New value of Value function: 32.0281
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 26.473
New value of Value function: 26.473
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 27.6676
New value of Value function: 27.6676
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 5
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 29.5499
New value of Value function: 29.5499
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 6
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 30.254
New value of Value function: 30.254
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 7
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 29.0502
New value of Value function: 29.0502
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 8
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 20.8851
New value of Value function: 32.6401
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 9
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 29.7449
New value of Value function: 29.7449
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 10
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 22.2752
New value of Value function: 32.6401
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 11
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 27.2945
New value of Value function: 32.6401
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 12
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 32.2298
New value of Value function: 32.2298
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 13
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 29.2522
New value of Value function: 29.2522
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 14
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 34.6356
New value of Value function: 34.6356
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 15
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 17.8579
New value of Value function: 38.903
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 16
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 36.4869
New value of Value function: 36.4869
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 17
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 40.5226
New value of Value function: 40.5226
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 49.181
New value of Value function: 49.181
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 19
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 49.5924
New value of Value function: 49.5924
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 20
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 45
New value of Q matrix: 50.8049
New value of Value function: 50.8049
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 278
New value of Q matrix: 30.2871
New value of Value function: 30.2871
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 22
----------
State: 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 62.7664
New value of Value function: 62.7664
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 23
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 79
New value of Q matrix: 57.9821
New value of Value function: 57.9821
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 24
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 59.4022
New value of Value function: 59.4022
New value of Policy matrix: 1

=======================================
Episode: 52
Iteration: 25
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 80
New value of Q matrix: 57.8508
New value of Value function: 57.8508
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 26
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 71.5474
New value of Value function: 71.5474
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 27
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 69.2752
New value of Value function: 69.2752
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 28
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 77
New value of Q matrix: 64.4677
New value of Value function: 64.4677
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 29
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 22.8345
New value of Value function: 54.214
New value of Policy matrix: 3

=======================================
Episode: 52
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 279
New value of Q matrix: 32.0822
New value of Value function: 32.0822
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 58.8477
New value of Value function: 58.8477
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 32
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 36.5193
New value of Value function: 64.4677
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 33
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 49.9469
New value of Value function: 59.4022
New value of Policy matrix: 1

=======================================
Episode: 52
Iteration: 34
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 45.9757
New value of Value function: 45.9757
New value of Policy matrix: 1

=======================================
Episode: 52
Iteration: 35
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 60.0082
New value of Value function: 60.0082
New value of Policy matrix: 1

=======================================
Episode: 52
Iteration: 36
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 82
New value of Q matrix: 59.7285
New value of Value function: 59.7285
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 37
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 78
New value of Q matrix: 66.0846
New value of Value function: 66.0846
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 38
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 34.2595
New value of Value function: 77.5227
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 280
New value of Q matrix: 33.878
New value of Value function: 33.878
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 60.6829
New value of Value function: 60.6829
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 41
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 79
New value of Q matrix: 67.5093
New value of Value function: 67.5093
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 42
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 47
New value of Q matrix: 75.6719
New value of Value function: 75.6719
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 43
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 80
New value of Q matrix: 68.5609
New value of Value function: 68.5609
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 44
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 48
New value of Q matrix: 74.2579
New value of Value function: 74.2579
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 45
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 81
New value of Q matrix: 72.2591
New value of Value function: 72.2591
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 46
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 69.9901
New value of Value function: 97.8234
New value of Policy matrix: 4

=======================================
Episode: 52
Iteration: 47
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 35.4298
New value of Value function: 74.2579
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 281
New value of Q matrix: 36.4215
New value of Value function: 36.4215
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 49
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 77.9132
New value of Value function: 77.9132
New value of Policy matrix: 0

=======================================
Episode: 52
Iteration: 50
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 51.7465
New value of Value function: 97.8234
New value of Policy matrix: 4

=======================================
Episode: 52
Iteration: 51
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 85.7209
New value of Value function: 85.7209
New value of Policy matrix: 2

=======================================
Episode: 52
Iteration: 52
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 22
New value of Q matrix: 97.6478
New value of Value function: 97.6478
New value of Policy matrix: 4

=======================================
Episode: 53
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 23.5879
New value of Value function: 36.4215
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 25.3513
New value of Value function: 36.4215
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 26.8505
New value of Value function: 36.4215
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 282
New value of Q matrix: 35.9085
New value of Value function: 35.9085
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 25.8363
New value of Value function: 25.8363
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 27.4991
New value of Value function: 27.4991
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 36
New value of Q matrix: 29.6343
New value of Value function: 29.6343
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 8
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 29.8874
New value of Value function: 29.8874
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 9
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 34.5077
New value of Value function: 34.5077
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 30.5414
New value of Value function: 30.5414
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 11
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 37.7545
New value of Value function: 37.7545
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 12
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 47.9477
New value of Value function: 47.9477
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 13
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 54.3088
New value of Value function: 54.3088
New value of Policy matrix: 0

=======================================
Episode: 53
Iteration: 14
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 57.2377
New value of Value function: 57.2377
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 15
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 17.7863
New value of Value function: 57.4478
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 16
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 32.1395
New value of Value function: 32.1395
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 17
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 61.4156
New value of Value function: 61.4156
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 18
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 29.9744
New value of Value function: 73.4138
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 19
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 54.2889
New value of Value function: 54.2889
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 20
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 69.1581
New value of Value function: 69.1581
New value of Policy matrix: 1

=======================================
Episode: 53
Iteration: 21
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 55
New value of Q matrix: 91.008
New value of Value function: 91.008
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 22
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 53.88
New value of Value function: 95.366
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 23
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 92.1311
New value of Value function: 92.1311
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 24
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 98.5259
New value of Value function: 98.5259
New value of Policy matrix: 2

=======================================
Episode: 53
Iteration: 25
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 27
New value of Q matrix: 98.0908
New value of Value function: 98.0908
New value of Policy matrix: 4

=======================================
Episode: 54
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 35.8872
New value of Value function: 35.8872
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 284
New value of Q matrix: 35.4908
New value of Value function: 35.4908
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 27.8256
New value of Value function: 27.8256
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 12.8106
New value of Value function: 30.5414
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 25.4413
New value of Value function: 25.4413
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 6
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 40.3769
New value of Value function: 40.3769
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 7
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 38.4724
New value of Value function: 38.4724
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 8
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 35.3586
New value of Value function: 35.3586
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 9
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 32.4331
New value of Value function: 32.4331
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 10
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 42.3788
New value of Value function: 42.3788
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 11
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 51.3792
New value of Value function: 51.3792
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 12
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 48.6598
New value of Value function: 48.6598
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 13
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 47.8635
New value of Value function: 47.8635
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 14
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: 48.0409
New value of Value function: 48.0409
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 15
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 49.4483
New value of Value function: 49.4483
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 16
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 46
New value of Q matrix: 50.5026
New value of Value function: 50.5026
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 17
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 47.7545
New value of Value function: 48.2369
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 18
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 53.8369
New value of Value function: 53.8369
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 19
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 22.9666
New value of Value function: 60.6829
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 285
New value of Q matrix: 37.1248
New value of Value function: 37.1248
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 21
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 47.238
New value of Value function: 60.6829
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 22
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 26.7804
New value of Value function: 60.6829
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 286
New value of Q matrix: 38.6594
New value of Value function: 38.6594
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 24
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 84
New value of Q matrix: 62.1944
New value of Value function: 62.1944
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 25
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 82
New value of Q matrix: 73.0184
New value of Value function: 73.0184
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 26
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 52.0065
New value of Value function: 77.9132
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 85
New value of Q matrix: 63.6147
New value of Value function: 63.6147
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 28
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 83
New value of Q matrix: 73.6896
New value of Value function: 73.6896
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 29
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 50
New value of Q matrix: 76.9288
New value of Value function: 76.9288
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 30
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 51.6406
New value of Value function: 73.6896
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 64.9451
New value of Value function: 64.9451
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 32
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 84
New value of Q matrix: 74.1773
New value of Value function: 74.1773
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 33
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 51
New value of Q matrix: 76.1596
New value of Value function: 76.1596
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 85
New value of Q matrix: 74.5267
New value of Value function: 74.5267
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 35
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 52
New value of Q matrix: 75.5525
New value of Value function: 75.5525
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 86
New value of Q matrix: 77.4538
New value of Value function: 77.4538
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 37
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 71.6792
New value of Value function: 97.6478
New value of Policy matrix: 4

=======================================
Episode: 54
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 87
New value of Q matrix: 80.0502
New value of Value function: 80.0502
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 39
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 66.5163
New value of Value function: 97.6478
New value of Policy matrix: 4

=======================================
Episode: 54
Iteration: 40
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 78.8655
New value of Value function: 78.8655
New value of Policy matrix: 0

=======================================
Episode: 54
Iteration: 41
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 69.1347
New value of Value function: 97.6478
New value of Policy matrix: 4

=======================================
Episode: 54
Iteration: 42
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 90.371
New value of Value function: 90.371
New value of Policy matrix: 2

=======================================
Episode: 54
Iteration: 43
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1286
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 23
New value of Q matrix: 97.5127
New value of Value function: 97.5127
New value of Policy matrix: 4

=======================================
Episode: 55
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 28.4345
New value of Value function: 38.6594
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 287
New value of Q matrix: 37.7562
New value of Value function: 37.7562
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 26.2038
New value of Value function: 26.2038
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 22.8637
New value of Value function: 37.7562
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 288
New value of Q matrix: 36.9785
New value of Value function: 36.9785
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 6
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 26.6071
New value of Value function: 26.6071
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 28.5042
New value of Value function: 36.9785
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 8
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 29.0026
New value of Value function: 29.0026
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 289
New value of Q matrix: 36.6002
New value of Value function: 36.6002
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 10
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 16.9613
New value of Value function: 27.8256
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 11
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 31.5474
New value of Value function: 31.5474
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 12
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 27.8965
New value of Value function: 27.8965
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 13
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 29.6006
New value of Value function: 29.6006
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 14
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 37.1127
New value of Value function: 37.1127
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 15
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 31.9165
New value of Value function: 31.9165
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 16
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 32.561
New value of Value function: 32.561
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 17
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 37.6779
New value of Value function: 37.6779
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 18
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 44.2623
New value of Value function: 44.2623
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 16.6176
New value of Value function: 51.3792
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 20
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 23.0898
New value of Value function: 51.3792
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 28.0476
New value of Value function: 51.3792
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 22
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 43.4686
New value of Value function: 43.4686
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 23
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 38.6253
New value of Value function: 38.6253
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 24
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 31.3114
New value of Value function: 48.0409
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 25
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 52.5461
New value of Value function: 52.5461
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 26
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 47.0692
New value of Value function: 47.0692
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 27
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 47
New value of Q matrix: 52.8062
New value of Value function: 52.8062
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 50.9603
New value of Value function: 64.9451
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 29
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 87
New value of Q matrix: 64.1371
New value of Value function: 64.1371
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 30
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 63.1764
New value of Value function: 63.1764
New value of Policy matrix: 1

=======================================
Episode: 55
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 22.7316
New value of Value function: 64.1371
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 21.5969
New value of Value function: 36.6002
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 36.5787
New value of Value function: 36.5787
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 291
New value of Q matrix: 38.3325
New value of Value function: 38.3325
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 88
New value of Q matrix: 66.0679
New value of Value function: 66.0679
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 88
New value of Q matrix: 75.2424
New value of Value function: 75.2424
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 24.654
New value of Value function: 38.3325
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 38.3101
New value of Value function: 38.3101
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 23.5628
New value of Value function: 38.3101
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 293
New value of Q matrix: 40.8085
New value of Value function: 40.8085
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 41
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 54
New value of Q matrix: 77.9979
New value of Value function: 77.9979
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 42
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 54.5181
New value of Value function: 75.2424
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 43
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 89
New value of Q matrix: 67.2786
New value of Value function: 67.2786
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 44
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 61.1545
New value of Value function: 75.2424
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 45
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 40.011
New value of Value function: 90.371
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 46
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 86.8441
New value of Value function: 86.8441
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 47
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 57.6876
New value of Value function: 77.9979
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 48
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 89
New value of Q matrix: 75.6638
New value of Value function: 75.6638
New value of Policy matrix: 2

=======================================
Episode: 55
Iteration: 49
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 80.9023
New value of Value function: 80.9023
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 50
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 73.1667
New value of Value function: 97.5127
New value of Policy matrix: 4

=======================================
Episode: 55
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 44.1342
New value of Value function: 80.9023
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 52
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 56
New value of Q matrix: 83.3925
New value of Value function: 83.3925
New value of Policy matrix: 0

=======================================
Episode: 55
Iteration: 53
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 24
New value of Q matrix: 98.0204
New value of Value function: 98.0204
New value of Policy matrix: 4
