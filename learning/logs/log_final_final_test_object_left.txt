=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 0.457496
New value of Value function: 0.457496
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 7
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 12
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 13
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 14
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 15
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 17
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 18
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 19
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 20
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 21
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 22
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 23
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 24
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 25
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 26
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 27
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 28
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 29
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 30
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 31
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 32
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 33
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 34
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 35
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 36
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 37
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.47056
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 44
New value of Q matrix: 0.840793
New value of Value function: 0.840793
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 39
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 40
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.16762
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.114337
New value of Value function: 0.840793
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.839539
New value of Value function: 0.839539
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 46
New value of Q matrix: 1.15808
New value of Value function: 1.15808
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 44
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 45
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 46
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 47
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 48
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.8535
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 2.1459
New value of Value function: 2.1459
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 50
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.839492
New value of Value function: 0.839492
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.313231
New value of Value function: 2.1459
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.369817
New value of Value function: 2.1459
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 2.38913
New value of Value function: 2.38913
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 54
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.62041
New value of Value function: 0.839492
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.420646
New value of Value function: 2.38913
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 2.38572
New value of Value function: 2.38572
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 50
New value of Q matrix: 2.59013
New value of Value function: 2.59013
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 58
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.23002
New value of Value function: 3.23002
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 59
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.71473
New value of Value function: 3.71473
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 60
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.2365
New value of Value function: 2.2365
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 61
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 3.96443
New value of Value function: 3.96443
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 62
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.08065
New value of Value function: 2.08065
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 63
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 4.0071
New value of Value function: 4.0071
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 64
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.38622
New value of Value function: 3.38622
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 65
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 66
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 67
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 68
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 69
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 70
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 71
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 72
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 73
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 74
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 75
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 76
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 77
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 78
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 79
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 80
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 81
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 82
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 83
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 84
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.95
New value of Value function: 7.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 85
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.14315
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 86
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 87
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 88
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 89
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 90
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 91
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 92
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 93
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 94
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 95
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 96
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 97
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 98
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 99
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 100
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 101
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 102
----------
State: 2489
	Distance: 6
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 103
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 104
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 105
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 106
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 107
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 108
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 109
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 110
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 111
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 112
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 113
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 114
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 115
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 116
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 117
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 118
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 119
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 120
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 121
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 122
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.435773
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 51
New value of Q matrix: 2.64752
New value of Value function: 2.64752
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 124
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 125
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.279676
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 52
New value of Q matrix: 2.6964
New value of Value function: 2.6964
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 127
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -0.141299
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 128
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 129
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 130
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.361378
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 53
New value of Q matrix: 2.7381
New value of Value function: 2.7381
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 132
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 133
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 134
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 135
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 136
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 137
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 138
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 139
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 140
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 141
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 142
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 143
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 144
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 145
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 146
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 147
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 148
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 149
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 150
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 151
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 152
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 153
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 154
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 155
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 156
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 0.424614
New value of Value function: 0.424614
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 157
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.579632
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 158
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 0.712307
New value of Value function: 0.712307
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 159
----------
State: 1649
	Distance: 4
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.294816
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 160
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.264385
New value of Value function: 0.264385
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 54
New value of Q matrix: 2.80936
New value of Value function: 2.80936
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 162
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 0.564699
New value of Value function: 0.564699
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 163
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.440948
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 164
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 0.729227
New value of Value function: 0.729227
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 165
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.278065
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 166
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 0.394073
New value of Value function: 0.394073
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 55
New value of Q matrix: 2.83507
New value of Value function: 2.83507
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 168
----------
State: 2085
	Distance: 5
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 169
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.73205
New value of Value function: 3.73205
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 170
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 171
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 172
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 173
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.69473
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 174
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 175
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 176
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 177
----------
State: 2209
	Distance: 5
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 178
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 179
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 180
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 181
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 182
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 183
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 184
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 185
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 186
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 187
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.8805
New value of Value function: 1.8805
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 188
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 189
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.92015
New value of Value function: 4.92015
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 190
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.87375
New value of Value function: 1.87375
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 191
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.88758
New value of Value function: 4.88758
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 192
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.85351
New value of Value function: 1.85351
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 193
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 4.86406
New value of Value function: 4.86406
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 194
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.83446
New value of Value function: 1.83446
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 195
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.13205
New value of Value function: 6.13205
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 196
----------
State: 2169
	Distance: 5
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.18388
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 197
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 198
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.193283
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.742384
New value of Value function: 2.83507
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 2.83128
New value of Value function: 2.83128
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 2.85363
New value of Value function: 2.85363
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 2
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 3
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 4
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.174909
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.679624
New value of Value function: 2.85363
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.484499
New value of Value function: 2.85363
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 58
New value of Q matrix: 2.87285
New value of Value function: 2.87285
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 9
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.155882
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.883347
New value of Value function: 2.87285
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 59
New value of Q matrix: 3.27606
New value of Value function: 3.27606
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 12
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.05072
New value of Value function: 1.05072
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 60
New value of Q matrix: 3.37471
New value of Value function: 3.37471
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 1.05072
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 15
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 5.04021
New value of Value function: 5.04021
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 16
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.17614
New value of Value function: 2.17614
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 17
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.845624
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 2.58807
New value of Value function: 2.58807
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 19
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 20
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 21
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.12132
New value of Value function: 2.12132
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 22
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 23
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 1.53553
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 24
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 25
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 26
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 27
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 28
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 29
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 30
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 31
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.92507
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 32
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1.53553
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 33
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 34
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 35
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 36
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 37
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 38
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.340966
New value of Value function: 0.340966
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 61
New value of Q matrix: 3.52137
New value of Value function: 3.52137
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 40
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.38104
New value of Value function: 2.38104
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 41
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.40543
New value of Value function: 1.40543
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 42
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.64764
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.10011
New value of Value function: 3.38622
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 44
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.83206
New value of Value function: 2.83206
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 45
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.04504
New value of Value function: 4.04504
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 46
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 47
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 48
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 49
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 50
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.18644
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 51
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.40598
New value of Value function: 4.40598
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 52
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 53
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 54
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 55
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 56
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 57
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.869843
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 58
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.616
New value of Value function: 4.616
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 59
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 60
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 61
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 62
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 63
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 64
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.608628
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 65
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 1.7487
New value of Value function: 1.7487
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 66
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 67
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 68
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 69
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 70
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 71
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 72
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 73
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 74
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 75
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 76
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 77
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 78
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 79
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.486161
New value of Value function: 0.486161
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 62
New value of Q matrix: 3.51629
New value of Value function: 3.51629
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 81
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 0.8495
New value of Value function: 0.8495
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 82
----------
State: 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.481122
New value of Value function: 0.481122
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 63
New value of Q matrix: 3.45124
New value of Value function: 3.45124
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 84
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 85
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 86
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 0.535534
New value of Value function: 0.535534
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 87
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.46982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 88
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.02015
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 89
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.599638
New value of Value function: 0.599638
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 64
New value of Q matrix: 3.46904
New value of Value function: 3.46904
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 91
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 1.03797
New value of Value function: 1.03797
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 92
----------
State: 2857
	Distance: 7
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.448049
New value of Value function: 0.448049
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 65
New value of Q matrix: 3.41086
New value of Value function: 3.41086
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 94
----------
State: 2897
	Distance: 7
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -1.84471
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 95
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 96
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 97
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 98
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 99
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 100
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 101
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 102
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 103
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 104
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 105
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 106
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 107
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.629929
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 108
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.368321
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 109
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.05939
New value of Value function: 4.05939
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 110
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.75242
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 111
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 112
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 113
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 114
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 115
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 116
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 117
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 118
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 119
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 120
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.376754
New value of Value function: 0.376754
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 66
New value of Q matrix: 3.4062
New value of Value function: 3.4062
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 122
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.372138
New value of Value function: 0.376754
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 67
New value of Q matrix: 3.35658
New value of Value function: 3.35658
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 124
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.323009
New value of Value function: 0.323009
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 68
New value of Q matrix: 3.35211
New value of Value function: 3.35211
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 126
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.319779
New value of Value function: 0.323009
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 127
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -2.73382
New value of Value function: 0.319779
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 128
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.31658
New value of Value function: 4.31658
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 129
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.317518
New value of Value function: 0.317518
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 130
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.315685
New value of Value function: 0.315685
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 131
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.314106
New value of Value function: 0.314106
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 132
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 133
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 134
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.50186
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 135
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 136
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.02
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 137
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 138
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 139
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 140
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 141
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -0.997592
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 142
----------
State: 1653
	Distance: 4
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.19283
New value of Value function: 6.19283
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 143
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 144
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 145
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 146
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 147
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 148
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.97
New value of Value function: 1.97
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 149
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 3.44274
New value of Value function: 3.44274
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 150
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.70711
New value of Value function: 1.70711
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 151
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 152
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 153
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.309964
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 154
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 1.87621
New value of Value function: 1.87621
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 155
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 156
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 157
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -2.0497
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 158
----------
State: 1253
	Distance: 3
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 3.40543
New value of Value function: 3.40543
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 159
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 160
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 161
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 162
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 163
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 164
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 165
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 166
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.59169
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 167
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.02029
New value of Value function: 4.02029
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 168
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 1.9381
New value of Value function: 1.9381
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 169
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 170
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 171
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 172
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.03053
New value of Value function: 2.03053
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 173
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 174
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 175
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 176
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 177
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 178
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 179
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 180
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 181
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 182
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 183
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 184
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 185
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 186
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 187
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 188
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 189
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 190
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 191
----------
State: 1493
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 192
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 193
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 194
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 195
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 196
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 197
----------
State: 2657
	Distance: 6
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 198
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 199
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 2.97
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 200
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.864538
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 69
New value of Q matrix: 3.30972
New value of Value function: 3.30972
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 2
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.276626
New value of Value function: 0.276626
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.868331
New value of Value function: 3.30972
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 36
New value of Q matrix: 2.06776
New value of Value function: 3.30972
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 5
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.11641
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 6
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.55436
New value of Value function: 1.55436
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 70
New value of Q matrix: 3.45663
New value of Value function: 3.45663
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.0921
New value of Value function: 1.0921
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 71
New value of Q matrix: 3.53075
New value of Value function: 3.53075
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 10
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.866585
New value of Value function: 0.866585
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 72
New value of Q matrix: 3.56931
New value of Value function: 3.56931
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 12
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 1.28684
New value of Value function: 1.28684
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 13
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.05525
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 14
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.533613
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 73
New value of Q matrix: 3.65178
New value of Value function: 3.65178
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 16
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 1.06298
New value of Value function: 1.06298
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 74
New value of Q matrix: 3.69835
New value of Value function: 3.69835
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.36396
New value of Value function: 2.36396
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 19
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.661363
New value of Value function: 0.661363
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 1.11
New value of Value function: 3.69835
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 75
New value of Q matrix: 3.8899
New value of Value function: 3.8899
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 22
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.17404
New value of Value function: 2.17404
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 23
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.197715
New value of Value function: 4.0071
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 24
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.10501
New value of Value function: 4.10501
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 25
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.98254
New value of Value function: 3.98254
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 26
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.38739
New value of Value function: 2.38739
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 27
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.2025
New value of Value function: 4.2025
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 28
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 2.38739
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 29
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 30
----------
State: 4261
	Distance: 10
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 31
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 32
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 33
----------
State: 4257
	Distance: 10
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 34
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.50018
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 35
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.69583
New value of Value function: 4.69583
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 36
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.95718
New value of Value function: 4.95718
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 37
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.09708
New value of Value function: 3.09708
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 38
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.23082
New value of Value function: 4.616
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 39
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 5.05333
New value of Value function: 5.05333
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 40
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.3123
New value of Value function: 6.3123
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 41
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.71275
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 42
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.59265
New value of Value function: 5.59265
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 43
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.89731
New value of Value function: 5.89731
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 44
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 45
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 46
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 47
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 48
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 49
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 50
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 51
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 52
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 53
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 54
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 55
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 56
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 57
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 58
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 59
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 60
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 61
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 62
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 63
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 64
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 65
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 66
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 67
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 68
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 69
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 70
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 71
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.536728
New value of Value function: 0.536728
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 72
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.7155
New value of Value function: 5.7155
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 73
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 7.04534
New value of Value function: 7.04534
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 74
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.10895
New value of Value function: 4.75242
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 75
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.87621
New value of Value function: 4.87621
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 76
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.15981
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 77
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 78
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 79
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 80
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 81
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 82
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.52139
New value of Value function: 5.52139
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 83
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.40007
New value of Value function: 3.40007
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 84
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.70711
New value of Value function: 2.70711
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 85
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 86
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 87
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 88
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.01023
New value of Value function: 4.01023
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 89
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.81128
New value of Value function: 0.81128
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 90
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 2.32497
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 91
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 0.556501
New value of Value function: 0.556501
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 92
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.11546
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 93
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 94
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 1.10011
New value of Value function: 1.10011
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 95
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 96
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 97
----------
State: 2257
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 3.9403
New value of Value function: 3.9403
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 98
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.76496
New value of Value function: 2.76496
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 99
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.03091
New value of Value function: 4.03091
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 100
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.487063
New value of Value function: 0.487063
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 101
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.544553
New value of Value function: 1.10011
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 102
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.11239
New value of Value function: 0.544553
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 103
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 104
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 105
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 106
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 107
----------
State: 1853
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -1.38104
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 108
----------
State: 1893
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.53911
New value of Value function: 2.53911
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 109
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.542118
New value of Value function: 0.542118
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 110
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.539905
New value of Value function: 0.539905
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 111
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.537864
New value of Value function: 0.537864
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 112
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.535962
New value of Value function: 0.535962
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 113
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.534176
New value of Value function: 0.534176
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 114
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.532486
New value of Value function: 0.532486
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 115
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.530881
New value of Value function: 0.530881
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 116
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.529348
New value of Value function: 0.529348
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 117
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.26269
New value of Value function: 0.529348
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 118
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 2.76496
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 119
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.93557
New value of Value function: 6.93557
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 120
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.47259
New value of Value function: 3.47259
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 121
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.75655
New value of Value function: 4.75655
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 122
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.502165
New value of Value function: 0.502165
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 123
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.52788
New value of Value function: 0.52788
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 124
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.52647
New value of Value function: 0.52647
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 125
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.52511
New value of Value function: 0.52511
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 126
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.523797
New value of Value function: 0.523797
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 127
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.522527
New value of Value function: 0.522527
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 128
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.521295
New value of Value function: 0.521295
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 129
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.222329
New value of Value function: 0.521295
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 130
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.507425
New value of Value function: 0.507425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 131
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.520099
New value of Value function: 0.520099
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 132
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.518936
New value of Value function: 0.518936
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 133
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.76733
New value of Value function: 0.518936
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 134
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.09079
New value of Value function: 4.09079
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 135
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.09008
New value of Value function: 5.09008
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 136
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.039182
New value of Value function: 0.507425
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 137
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.86622
New value of Value function: 5.09008
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 138
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.15627
New value of Value function: 8.15627
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 139
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.51492
New value of Value function: 4.51492
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 140
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.25839
New value of Value function: 5.25839
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 141
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.50966
New value of Value function: 0.50966
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 142
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.517804
New value of Value function: 0.517804
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 143
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.5167
New value of Value function: 0.5167
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 144
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.515623
New value of Value function: 0.515623
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 145
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.51457
New value of Value function: 0.51457
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 146
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.504564
New value of Value function: 0.51457
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 147
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.509582
New value of Value function: 0.509582
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 148
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.337519
New value of Value function: 0.51457
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 149
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.509532
New value of Value function: 0.509532
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 150
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.513541
New value of Value function: 0.513541
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 151
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.512534
New value of Value function: 0.512534
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 152
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.511548
New value of Value function: 0.511548
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 153
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.510581
New value of Value function: 0.510581
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 154
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.509633
New value of Value function: 0.509633
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 155
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.504474
New value of Value function: 0.509633
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 156
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.504437
New value of Value function: 0.509532
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 157
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.508026
New value of Value function: 0.508026
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 158
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.508702
New value of Value function: 0.508702
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 159
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.507789
New value of Value function: 0.507789
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 160
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.503591
New value of Value function: 0.507789
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 161
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 162
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1373
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 163
----------
State: 1373
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 164
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.09203
New value of Value function: 1.09203
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 165
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.553175
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 166
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 4.50463
New value of Value function: 4.50463
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 167
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.00638
New value of Value function: 2.32497
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 168
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 4.78644
New value of Value function: 4.78644
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 169
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 2.41722
New value of Value function: 2.41722
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 170
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.53475
New value of Value function: 2.53475
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 171
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.98586
New value of Value function: 1.98586
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 172
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.97439
New value of Value function: 1.97439
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 173
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.96452
New value of Value function: 1.96452
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 174
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.95573
New value of Value function: 1.95573
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 175
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.94775
New value of Value function: 1.94775
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 176
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.94039
New value of Value function: 1.94039
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 177
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.93353
New value of Value function: 1.93353
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 178
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.92708
New value of Value function: 1.92708
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 179
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.60695
New value of Value function: 1.92708
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 180
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.11451
New value of Value function: 4.11451
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 181
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -2.23554
New value of Value function: 1.92708
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 182
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.29507
New value of Value function: 3.29507
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 183
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.92099
New value of Value function: 1.92099
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 184
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.9152
New value of Value function: 1.9152
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 185
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.90967
New value of Value function: 1.90967
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 186
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.90437
New value of Value function: 1.90437
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 187
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.89928
New value of Value function: 1.89928
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 188
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.89438
New value of Value function: 1.89438
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 189
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.88964
New value of Value function: 1.88964
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 190
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.88506
New value of Value function: 1.88506
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 191
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.88062
New value of Value function: 1.88062
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 192
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.8763
New value of Value function: 1.8763
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 193
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.87211
New value of Value function: 1.87211
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 194
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.86802
New value of Value function: 1.86802
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 195
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.86404
New value of Value function: 1.86404
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 196
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.86015
New value of Value function: 1.86015
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 197
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.793514
New value of Value function: 1.86015
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 198
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.06831
New value of Value function: 4.06831
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 199
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.85635
New value of Value function: 1.85635
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 200
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 1.85264
New value of Value function: 1.85264
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.88544
New value of Value function: 3.88544
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 37
New value of Q matrix: 2.22102
New value of Value function: 3.88544
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.846584
New value of Value function: 0.846584
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 77
New value of Q matrix: 4.24766
New value of Value function: 4.24766
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 5
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.20519
New value of Value function: 4.10501
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 78
New value of Q matrix: 4.56655
New value of Value function: 4.56655
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 0.855157
New value of Value function: 1.20519
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 8
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.440544
New value of Value function: 0.846584
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 79
New value of Q matrix: 4.52453
New value of Value function: 4.52453
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 10
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -1.8828
New value of Value function: 0.855157
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 11
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.29397
New value of Value function: 1.29397
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 4.44874
New value of Value function: 4.44874
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 13
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 1.07932
New value of Value function: 1.07932
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 4.40649
New value of Value function: 4.40649
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 15
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 1.18633
New value of Value function: 1.18633
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 82
New value of Q matrix: 4.38087
New value of Value function: 4.38087
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 17
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 8.0028
New value of Value function: 8.0028
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 18
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 6.53554
New value of Value function: 6.53554
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 19
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 6.30196
New value of Value function: 6.30196
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 20
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 7.13778
New value of Value function: 7.13778
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 21
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 5.38616
New value of Value function: 5.38616
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 22
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.0817
New value of Value function: 11.0817
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 23
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.8705
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 24
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.67189
New value of Value function: 8.67189
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 25
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.0817
New value of Value function: 11.0817
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 26
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.56158
New value of Value function: 6.56158
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 27
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.98657
New value of Value function: 8.98657
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 28
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.09212
New value of Value function: 4.09212
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 29
----------
State: 2573
	Distance: 6
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 30
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 31
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 32
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 33
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 34
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 35
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 36
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 37
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.98
New value of Value function: 6.98
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 38
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.25967
New value of Value function: 1.83446
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 39
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 2.91938
New value of Value function: 2.91938
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.535534
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 41
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.948805
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 42
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.27408
New value of Value function: 5.27408
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 43
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 44
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.33706
New value of Value function: 1.33706
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 83
New value of Q matrix: 4.37459
New value of Value function: 4.37459
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 1.50571
New value of Value function: 1.50571
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.94595
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 48
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 2.25285
New value of Value function: 2.25285
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 49
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 51
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 53
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 54
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 55
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 56
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 57
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -0.899893
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 58
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 59
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 60
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 61
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 62
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 63
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -1.26683
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 64
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.58699
New value of Value function: 2.58699
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 65
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 66
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 67
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 68
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 69
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.59993
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 70
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.12132
New value of Value function: 4.12132
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 71
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 72
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.852855
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 73
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 2.7556
New value of Value function: 2.7556
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 74
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 75
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 76
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 77
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 78
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 79
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 80
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 81
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 82
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 83
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 84
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 85
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 86
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 87
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 88
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 89
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -4.40826
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 90
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 91
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 92
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.98
New value of Value function: 6.98
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 93
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 94
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 95
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 96
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 97
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 98
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 99
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 100
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 101
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.32017
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 102
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.08011
New value of Value function: 2.7556
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 103
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.47161
New value of Value function: 4.47161
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 104
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 3.59634
New value of Value function: 3.59634
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 105
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.39766
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 106
----------
State: 2165
	Distance: 5
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.14315
New value of Value function: 4.14315
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 107
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.34164
New value of Value function: 3.34164
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 108
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 1.57012
New value of Value function: 4.37459
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 1.4536
New value of Value function: 4.37459
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 4.36982
New value of Value function: 4.36982
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 85
New value of Q matrix: 4.22124
New value of Value function: 4.22124
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 5
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 6.92277
New value of Value function: 6.92277
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 6
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 9.46199
New value of Value function: 9.46199
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 7
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 7.20262
New value of Value function: 7.20262
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 8
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.47891
New value of Value function: 5.38616
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 4.18071
New value of Value function: 5.38616
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 7.24363
New value of Value function: 7.24363
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 11
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 7.57744
New value of Value function: 7.57744
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 12
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 8.84452
New value of Value function: 8.84452
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 13
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 11.0817
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 8.9709
New value of Value function: 8.9709
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 15
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.3209
New value of Value function: 11.3209
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 16
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.73528
New value of Value function: 6.73528
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 17
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 20
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 22
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 23
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 24
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 25
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 26
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.17903
New value of Value function: 1.17903
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 86
New value of Q matrix: 4.08955
New value of Value function: 4.08955
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 28
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 29
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 30
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 31
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 32
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 33
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 34
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 35
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 36
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 37
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 38
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 39
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 40
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 41
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 42
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 43
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 44
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 45
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.42335
New value of Value function: 3.42335
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 46
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.500179
New value of Value function: 8.98657
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 47
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.3836
New value of Value function: 6.3836
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 48
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.4826
New value of Value function: 2.4826
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 49
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.7896
New value of Value function: 6.7896
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 50
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.17197
New value of Value function: 2.17197
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 51
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.91711
New value of Value function: 6.91711
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 52
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.448357
New value of Value function: 2.17197
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 53
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.04949
New value of Value function: 2.04949
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 54
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.9544
New value of Value function: 6.9544
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 55
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.99129
New value of Value function: 1.99129
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 56
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.95977
New value of Value function: 6.95977
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 57
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 1.95758
New value of Value function: 1.95758
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 58
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 2.16724
New value of Value function: 6.95977
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 59
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.04866
New value of Value function: 1.17903
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 87
New value of Q matrix: 4.18052
New value of Value function: 4.18052
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 61
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 1.93627
New value of Value function: 1.93627
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 62
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.94685
New value of Value function: 6.94685
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 63
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 1.91851
New value of Value function: 1.91851
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 64
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.88119
New value of Value function: 6.94685
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 65
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.88119
New value of Value function: 8.9709
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 66
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.20767
New value of Value function: 9.20767
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 67
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 11.2182
New value of Value function: 11.2182
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 68
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 9.13582
New value of Value function: 9.13582
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 69
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 11.4193
New value of Value function: 11.4193
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 70
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.60979
New value of Value function: 7.60979
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 71
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 6.93313
New value of Value function: 6.93313
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 72
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 1.90272
New value of Value function: 1.90272
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 73
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 6.91942
New value of Value function: 6.91942
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 74
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 1.88816
New value of Value function: 1.88816
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 75
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.04969
New value of Value function: 6.91942
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 76
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 8.85022
New value of Value function: 8.85022
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 77
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.46932
New value of Value function: 6.91942
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 78
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.9745
New value of Value function: 8.9709
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 79
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 80
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 81
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 82
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 83
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 84
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 85
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 86
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 87
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 88
----------
State: 3693
	Distance: 9
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 89
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 90
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 91
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 7.88119
New value of Value function: 7.88119
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 92
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.8502
New value of Value function: 11.8502
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 93
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 5.64934
New value of Value function: 5.64934
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 94
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.15052
New value of Value function: 1.15052
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 88
New value of Q matrix: 4.65087
New value of Value function: 4.65087
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 96
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.79643
New value of Value function: 5.64934
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 97
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.14728
New value of Value function: 5.64934
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 98
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.59285
New value of Value function: 4.59285
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 99
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 5.96433
New value of Value function: 5.96433
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 100
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 1.62531
New value of Value function: 1.62531
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 101
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 6.12551
New value of Value function: 6.12551
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 102
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 1.48045
New value of Value function: 1.48045
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 103
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 6.20801
New value of Value function: 6.20801
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 104
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 1.39682
New value of Value function: 1.39682
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 105
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 18
New value of Q matrix: 6.05219
New value of Value function: 6.05219
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 106
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.87485
New value of Value function: 4.87485
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 107
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 6.12805
New value of Value function: 6.12805
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 108
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 1.31677
New value of Value function: 1.31677
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 109
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.25897
New value of Value function: 6.12805
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 110
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 6.1673
New value of Value function: 6.1673
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 111
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 1.267
New value of Value function: 1.267
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 112
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 6.18629
New value of Value function: 6.18629
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 113
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 1.23429
New value of Value function: 1.23429
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 114
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 5.60052
New value of Value function: 6.18629
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 115
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.337
New value of Value function: 11.337
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 116
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 6.1939
New value of Value function: 6.1939
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 117
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 1.21141
New value of Value function: 1.21141
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 118
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 6.19502
New value of Value function: 6.19502
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 119
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 1.19432
New value of Value function: 1.19432
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 120
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 6.19244
New value of Value function: 6.19244
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 121
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.587428
New value of Value function: 1.19432
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 122
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.82611
New value of Value function: 4.87485
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 123
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 5.02246
New value of Value function: 5.02246
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 124
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 25
New value of Q matrix: 6.1484
New value of Value function: 6.1484
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 125
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 5.05469
New value of Value function: 5.05469
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 126
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 6.12011
New value of Value function: 6.12011
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 127
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 5.05657
New value of Value function: 5.05657
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 128
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 6.09815
New value of Value function: 6.09815
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 129
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 5.04865
New value of Value function: 5.04865
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 130
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.37059
New value of Value function: 6.09815
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 131
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 5.04431
New value of Value function: 5.04431
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 132
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 28
New value of Q matrix: 6.07844
New value of Value function: 6.07844
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 133
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 5.03489
New value of Value function: 5.03489
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 134
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 29
New value of Q matrix: 6.061
New value of Value function: 6.061
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 135
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.4416
New value of Value function: 5.03489
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 89
New value of Q matrix: 5.11192
New value of Value function: 5.11192
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 137
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 6.08316
New value of Value function: 6.08316
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 138
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 1.15765
New value of Value function: 1.15765
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 139
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.87919
New value of Value function: 6.08316
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 140
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.1553
New value of Value function: 11.1553
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 141
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 6.09446
New value of Value function: 6.09446
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 142
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 1.13177
New value of Value function: 1.13177
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 143
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 6.09906
New value of Value function: 6.09906
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 144
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 24
New value of Q matrix: 1.11264
New value of Value function: 1.11264
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 145
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 6.09948
New value of Value function: 6.09948
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 146
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 25
New value of Q matrix: 1.09781
New value of Value function: 1.09781
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 147
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 6.09731
New value of Value function: 6.09731
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 148
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.29092
New value of Value function: 4.29092
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 149
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.56826
New value of Value function: 8.98657
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 150
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.40546
New value of Value function: 7.40546
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 151
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 7.53521
New value of Value function: 7.53521
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 152
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.50228
New value of Value function: 5.50228
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 153
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 4.70322
New value of Value function: 4.70322
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 154
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.18288
New value of Value function: 3.18288
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 155
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.81133
New value of Value function: 4.81133
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 156
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.84882
New value of Value function: 3.18288
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 90
New value of Q matrix: 5.22146
New value of Value function: 5.22146
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 158
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 4.22466
New value of Value function: 4.22466
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 159
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.86301
New value of Value function: 2.86301
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 91
New value of Q matrix: 5.42702
New value of Value function: 5.42702
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 161
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 4.7337
New value of Value function: 4.7337
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 162
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 2.53682
New value of Value function: 2.53682
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 163
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.355796
New value of Value function: 0.355796
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 164
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 0.80117
New value of Value function: 2.53682
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 165
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 166
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 167
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 168
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 169
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 0.511455
New value of Value function: 0.511455
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 170
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.52785
New value of Value function: 2.52785
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 171
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 1.56375
New value of Value function: 2.52785
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 172
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.505176
New value of Value function: 0.505176
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 173
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 36.3519
New value of Value function: 36.3519
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 174
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 99
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 175
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 5.42136
New value of Value function: 5.42136
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 93
New value of Q matrix: 6.14163
New value of Value function: 6.14163
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 9.87145
New value of Value function: 9.87145
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 7.92445
New value of Value function: 7.92445
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 7.18721
New value of Value function: 7.18721
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 6
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 3.51278
New value of Value function: 3.51278
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 7
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.64641
New value of Value function: 7.18721
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 8
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.29669
New value of Value function: 7.18721
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 9
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 10.3583
New value of Value function: 10.3583
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 10
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.18779
New value of Value function: 7.92445
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 11
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.5761
New value of Value function: 10.5761
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 12
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 8.26823
New value of Value function: 8.26823
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 13
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 6.9368
New value of Value function: 6.9368
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 14
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 8.43442
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 8.72389
New value of Value function: 8.72389
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 16
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 12.3756
New value of Value function: 12.3756
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 17
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.27472
New value of Value function: 8.27472
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 18
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 7.17278
New value of Value function: 7.17278
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 19
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 6.43331
New value of Value function: 6.43331
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 20
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 7.88722
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 6.15382
New value of Value function: 6.15382
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 22
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.24242
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 23
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.7518
New value of Value function: 8.7518
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 24
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 7.82603
New value of Value function: 7.82603
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 25
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 6.01278
New value of Value function: 6.01278
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 26
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.80287
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 27
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.57192
New value of Value function: 6.01278
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 28
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 5.93551
New value of Value function: 5.93551
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 29
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.0216
New value of Value function: 7.88722
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 30
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.0321
New value of Value function: 9.0321
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 31
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.16849
New value of Value function: 6.16849
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 32
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 4.21387
New value of Value function: 4.21387
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 94
New value of Q matrix: 6.24788
New value of Value function: 6.24788
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 34
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 3.2861
New value of Value function: 3.2861
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 35
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.06074
New value of Value function: 6.06074
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 36
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.00014
New value of Value function: 4.7337
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 37
----------
State: 1645
	Distance: 4
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 7.57665
New value of Value function: 7.57665
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 38
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 4.13958
New value of Value function: 4.13958
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 39
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 5.38683
New value of Value function: 5.38683
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 4.36204
New value of Value function: 4.36204
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 41
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.51219
New value of Value function: 6.51219
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 13.9657
New value of Value function: 13.9657
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 43
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 25.8637
New value of Value function: 25.8637
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 95
New value of Q matrix: 7.33317
New value of Value function: 7.33317
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 45
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.59799
New value of Value function: 13.9657
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 96
New value of Q matrix: 8.30203
New value of Value function: 8.30203
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 47
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 17.8782
New value of Value function: 17.8782
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 48
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 18.7748
New value of Value function: 18.7748
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 49
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 9.72689
New value of Value function: 9.72689
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 16.7121
New value of Value function: 16.7121
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 12.1359
New value of Value function: 12.1359
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.03765
New value of Value function: 16.7121
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 53
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.9834
New value of Value function: 11.9834
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 54
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 15.964
New value of Value function: 15.964
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 55
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 12.8821
New value of Value function: 12.8821
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 56
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.12641
New value of Value function: 15.964
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 57
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 13.2586
New value of Value function: 13.2586
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 39.4926
New value of Value function: 39.4926
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 59
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 8.2936
New value of Value function: 8.2936
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 98
New value of Q matrix: 8.81652
New value of Value function: 8.81652
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.46871
New value of Value function: 10.5761
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 10.8921
New value of Value function: 10.8921
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.78336
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.68621
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 11.0652
New value of Value function: 11.0652
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.54371
New value of Value function: 8.43442
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 9.02299
New value of Value function: 9.02299
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 10
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 8.30171
New value of Value function: 8.30171
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.32036
New value of Value function: 9.02299
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 12
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.47726
New value of Value function: 11.0652
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 13
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 11.3719
New value of Value function: 11.3719
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 14
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 9.33172
New value of Value function: 9.33172
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 9.89619
New value of Value function: 9.89619
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 16
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 12.8627
New value of Value function: 12.8627
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 17
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.4967
New value of Value function: 8.7518
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 18
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 9.78929
New value of Value function: 9.78929
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 19
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 13.1461
New value of Value function: 13.1461
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 20
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.24979
New value of Value function: 9.24979
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 21
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 8.32747
New value of Value function: 8.32747
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 22
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.05899
New value of Value function: 5.93551
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 99
New value of Q matrix: 8.82252
New value of Value function: 8.82252
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 24
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 26
New value of Q matrix: 1.51875
New value of Value function: 5.93551
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 25
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 11.9418
New value of Value function: 11.9418
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 26
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.99523
New value of Value function: 8.99523
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 27
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.79333
New value of Value function: 9.79333
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 28
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.71087
New value of Value function: 5.71087
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 29
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 14.8635
New value of Value function: 14.8635
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 30
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.29265
New value of Value function: 11.9834
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 31
----------
State: 2569
	Distance: 6
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 9.43224
New value of Value function: 9.43224
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 24.1214
New value of Value function: 24.1214
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 33
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 7.31711
New value of Value function: 39.4926
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 34
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 31.1841
New value of Value function: 31.1841
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 35
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 14.8922
New value of Value function: 39.4926
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 36
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 27.3559
New value of Value function: 27.3559
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 24.1316
New value of Value function: 24.1316
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 33.2012
New value of Value function: 33.2012
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 39
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 19.9147
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 40
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 30.3298
New value of Value function: 30.3298
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 41
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -2.3094
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 42
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.73429
New value of Value function: 5.73429
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 1.81035
New value of Value function: 8.82252
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 100
New value of Q matrix: 8.80796
New value of Value function: 8.80796
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 45
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.69374
New value of Value function: 5.69374
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 46
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.63681
New value of Value function: 5.69374
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 47
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.66087
New value of Value function: 5.66087
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 48
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.63257
New value of Value function: 5.63681
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 49
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.59695
New value of Value function: 5.63257
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 50
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.60738
New value of Value function: 5.60738
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 51
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.71988
New value of Value function: 5.71988
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 101
New value of Q matrix: 10.1918
New value of Value function: 10.1918
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 8.78508
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 54
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 26.3554
New value of Value function: 26.3554
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 55
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 48.1974
New value of Value function: 48.1974
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 56
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 10.1817
New value of Value function: 10.1817
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 103
New value of Q matrix: 10.1494
New value of Value function: 10.1494
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 3
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 9.28127
New value of Value function: 9.28127
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 4
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 11.6607
New value of Value function: 11.6607
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 5
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 9.9481
New value of Value function: 9.9481
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 6
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 11.2643
New value of Value function: 11.2643
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 7
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.4832
New value of Value function: 13.4832
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 8
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.71044
New value of Value function: 8.71044
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 9
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 10.8465
New value of Value function: 11.1553
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 10
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.18646
New value of Value function: 8.71044
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 11
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 10.6095
New value of Value function: 10.6095
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 12
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.62334
New value of Value function: 8.71044
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 13
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 8.43828
New value of Value function: 8.62334
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.9888
New value of Value function: 13.9888
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 15
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 8.74092
New value of Value function: 11.9418
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 16
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 6.55772
New value of Value function: 6.55772
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 17
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 9.33329
New value of Value function: 9.33329
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 7.2564
New value of Value function: 7.2564
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 19
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.632
New value of Value function: 10.632
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 20
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 25.6248
New value of Value function: 25.6248
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 21
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 27.5886
New value of Value function: 27.5886
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 22
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 26.1025
New value of Value function: 26.1025
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 23
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 27.6648
New value of Value function: 27.6648
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 24
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 31.9038
New value of Value function: 31.9038
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 25
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 38.4984
New value of Value function: 38.4984
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 104
New value of Q matrix: 12.5455
New value of Value function: 12.5455
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 27
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 31.5848
New value of Value function: 31.9038
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 34.0166
New value of Value function: 34.0166
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 34.6482
New value of Value function: 34.6482
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 30
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 17.6808
New value of Value function: 19.9147
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 31
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 34.7512
New value of Value function: 34.7512
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 32
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 31.7563
New value of Value function: 31.7563
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 33
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 23.282
New value of Value function: 23.282
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 16.4458
New value of Value function: 31.7563
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 34.683
New value of Value function: 34.683
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 30.2927
New value of Value function: 30.2927
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 37
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 24.8513
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 38
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 46.0072
New value of Value function: 46.0072
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 39
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 5
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.10453
New value of Value function: 12.5455
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 12.5332
New value of Value function: 12.5332
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.40726
New value of Value function: 12.5332
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 12.5211
New value of Value function: 12.5211
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 5.51508
New value of Value function: 12.5211
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.27731
New value of Value function: 12.5211
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 107
New value of Q matrix: 12.0792
New value of Value function: 12.0792
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 8
----------
State: 3253
	Distance: 8
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.79899
New value of Value function: 7.79899
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 12.5381
New value of Value function: 12.5381
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 10
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 11.1362
New value of Value function: 13.9888
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 11
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 13.5002
New value of Value function: 13.5002
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 12
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.56236
New value of Value function: 8.56236
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 13
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 9.34943
New value of Value function: 9.34943
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 14
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 15.256
New value of Value function: 15.256
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 15
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 4.08649
New value of Value function: 11.9418
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 16
----------
State: 2853
	Distance: 7
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.41275
New value of Value function: 9.41275
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 109
New value of Q matrix: 12.7569
New value of Value function: 12.7569
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 18
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.62839
New value of Value function: 8.74092
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 19
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 10.3231
New value of Value function: 10.3231
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 20
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 14.6018
New value of Value function: 14.6018
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 21
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 9.29223
New value of Value function: 9.29223
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 22
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 7.2512
New value of Value function: 7.2512
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 23
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.3974
New value of Value function: 11.3974
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 24
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 17.4647
New value of Value function: 17.4647
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 25
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 12.6902
New value of Value function: 12.6902
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 26
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 17.3999
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 27
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.98896
New value of Value function: 27.6648
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 28
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 21.5392
New value of Value function: 21.5392
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 29
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 22.4584
New value of Value function: 22.4584
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 110
New value of Q matrix: 11.8266
New value of Value function: 11.8266
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 31
----------
State: 1689
	Distance: 4
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 20.2339
New value of Value function: 20.2339
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 26.3074
New value of Value function: 26.3074
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 32.4148
New value of Value function: 32.4148
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 34
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 28.3876
New value of Value function: 28.3876
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 26.5832
New value of Value function: 31.5848
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 36
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 21.9602
New value of Value function: 21.9602
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 31.3614
New value of Value function: 31.3614
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 38
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 31.1804
New value of Value function: 31.1804
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 39
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 31.0245
New value of Value function: 31.0245
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 30.8857
New value of Value function: 30.8857
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 30.7596
New value of Value function: 30.7596
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 30.6434
New value of Value function: 30.6434
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 43
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 30.535
New value of Value function: 30.535
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 44
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.54847
New value of Value function: 30.535
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 111
New value of Q matrix: 13.8581
New value of Value function: 13.8581
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 31.0665
New value of Value function: 31.0665
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 47
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 38.6492
New value of Value function: 38.6492
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 112
New value of Q matrix: 15.7383
New value of Value function: 15.7383
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 49
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 33.1058
New value of Value function: 33.1058
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 36.1902
New value of Value function: 36.1902
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 21.8016
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 52
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 34.2281
New value of Value function: 34.2281
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 53
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 34.2727
New value of Value function: 34.2727
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 54
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 24.4792
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 55
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 31.6519
New value of Value function: 34.2281
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 56
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 27
New value of Q matrix: 34.748
New value of Value function: 34.748
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 57
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 6.65422
New value of Value function: 34.2727
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 11.9034
New value of Value function: 34.2727
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 59
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 32.7685
New value of Value function: 32.7685
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 60
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.1467
New value of Value function: 24.8513
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 61
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 49.2478
New value of Value function: 49.2478
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 62
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 15.7235
New value of Value function: 15.7235
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 114
New value of Q matrix: 14.751
New value of Value function: 14.751
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.2639
New value of Value function: 4.2639
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 4
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1.33756
New value of Value function: 1.33756
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 5
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.72614
New value of Value function: 0.340966
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 6
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.28593
New value of Value function: 8.28593
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 115
New value of Q matrix: 13.7787
New value of Value function: 13.7787
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 8
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.65391
New value of Value function: 4.65391
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 9
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.33254
New value of Value function: 5.33254
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 116
New value of Q matrix: 12.9778
New value of Value function: 12.9778
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 11
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 4.71179
New value of Value function: 4.71179
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 12
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 8.59364
New value of Value function: 8.59364
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 13
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.71469
New value of Value function: 5.71469
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 14
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 6.25085
New value of Value function: 6.25085
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 15
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 16
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 17
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.52239
New value of Value function: 1.52239
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 18
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.21371
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 19
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.2153
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 20
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 21
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 22
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.86517
New value of Value function: 8.86517
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 23
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.16377
New value of Value function: 7.16377
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.09213
New value of Value function: 3.40007
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 25
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 7.76492
New value of Value function: 7.76492
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.51296
New value of Value function: 3.40007
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 27
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.03376
New value of Value function: 8.03376
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 28
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.295012
New value of Value function: 2.51296
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 29
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 30
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 31
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 32
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.0795
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 33
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.49283
New value of Value function: 2.95
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 34
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.33198
New value of Value function: 4.33198
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 35
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.96536
New value of Value function: 7.21371
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 36
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 11.4997
New value of Value function: 11.4997
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 37
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.33079
New value of Value function: 8.33079
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 38
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 39
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 40
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 41
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.644427
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 42
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.16673
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 43
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 44
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 45
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 46
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 47
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 48
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 49
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 50
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 51
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.856846
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 52
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 53
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 54
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 55
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.438423
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 56
----------
State: 3097
	Distance: 7
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 57
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 58
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 59
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 60
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 61
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 62
----------
State: 3057
	Distance: 7
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.8905
New value of Value function: 0.8905
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 63
----------
State: 3457
	Distance: 8
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 8.28167
New value of Value function: 8.28167
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 64
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.9428
New value of Value function: 8.9428
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 65
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.66193
New value of Value function: 9.66193
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 66
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.07471
New value of Value function: 8.15627
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 67
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.81302
New value of Value function: 8.81302
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 68
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.79697
New value of Value function: 4.79697
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 69
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.68303
New value of Value function: 6.68303
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 70
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 3.17614
New value of Value function: 3.17614
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 71
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 4.25413
New value of Value function: 4.25413
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 72
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 2.40282
New value of Value function: 2.40282
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 73
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 4.29568
New value of Value function: 4.29568
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 74
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 2.34609
New value of Value function: 2.34609
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 75
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.0984
New value of Value function: 5.0984
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 76
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 1.35646
New value of Value function: 1.35646
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 77
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.68866
New value of Value function: 2.34609
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 78
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 4.8645
New value of Value function: 4.8645
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 79
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 3.05207
New value of Value function: 3.05207
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 80
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 1.35385
New value of Value function: 1.35385
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 81
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: -0.324566
New value of Value function: 1.35385
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 82
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 3.65141
New value of Value function: 3.65141
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 83
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 1.35129
New value of Value function: 1.35129
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 84
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 1.34879
New value of Value function: 1.34879
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 85
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 1.34632
New value of Value function: 1.34632
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 86
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1734
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 1
New value of Q matrix: 95
New value of Value function: 95
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 12.9658
New value of Value function: 12.9658
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 13.1111
New value of Value function: 13.1111
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.89503
New value of Value function: 11.6607
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 4
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 5.44497
New value of Value function: 5.44497
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 12.9658
New value of Value function: 12.9658
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 118
New value of Q matrix: 12.1663
New value of Value function: 12.1663
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 3
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.73861
New value of Value function: 8.73861
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.04464
New value of Value function: 9.28127
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.71865
New value of Value function: 12.1663
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 119
New value of Q matrix: 12.3843
New value of Value function: 12.3843
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 11.6123
New value of Value function: 11.6123
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 5.7389
New value of Value function: 8.59364
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 9
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 9.66797
New value of Value function: 9.66797
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 10
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.00105
New value of Value function: 11.2643
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 11
----------
State: 4217
	Distance: 10
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5.7155
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 12
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 13
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 14
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 15
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 16
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 17
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 18
----------
State: 4213
	Distance: 10
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 19
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 20
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 21
----------
State: 4253
	Distance: 10
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 22
----------
State: 3853
	Distance: 9
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 23
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 24
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 25
----------
State: 3533
	Distance: 8
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 26
----------
State: 2733
	Distance: 6
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 27
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 28
----------
State: 2369
	Distance: 5
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 29
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 30
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 31
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 32
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 33
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 34
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 35
----------
State: 2729
	Distance: 6
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 36
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 37
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 38
----------
State: 3133
	Distance: 7
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 39
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 40
----------
State: 3493
	Distance: 8
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 41
----------
State: 3093
	Distance: 7
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 42
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 43
----------
State: 3053
	Distance: 7
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 44
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 45
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 46
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 47
----------
State: 3813
	Distance: 9
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 48
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 49
----------
State: 3013
	Distance: 7
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 50
----------
State: 3413
	Distance: 8
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 51
----------
State: 3373
	Distance: 8
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 52
----------
State: 2973
	Distance: 7
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 9.28343
New value of Value function: 9.28343
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 53
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 6.99078
New value of Value function: 11.3974
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 54
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 11.1826
New value of Value function: 11.1826
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 55
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.28343
New value of Value function: 17.4647
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 56
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 14.842
New value of Value function: 14.842
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 57
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 19.6792
New value of Value function: 19.6792
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 58
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 25.8166
New value of Value function: 25.8166
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 59
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 30.4565
New value of Value function: 30.4565
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 60
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 34.8789
New value of Value function: 34.8789
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 61
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 36.2301
New value of Value function: 36.2301
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 62
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 15.4178
New value of Value function: 49.2478
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 63
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 44.6105
New value of Value function: 44.6105
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 64
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 38.1075
New value of Value function: 38.1075
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 65
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 42.0459
New value of Value function: 42.0459
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 66
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 39.1321
New value of Value function: 39.1321
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 67
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 40.5745
New value of Value function: 40.5745
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 68
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 50.9753
New value of Value function: 50.9753
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 69
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.49988
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 70
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 28.1951
New value of Value function: 28.1951
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 71
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 60.4989
New value of Value function: 60.4989
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 72
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.84963
New value of Value function: 12.3843
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.1945
New value of Value function: 12.3843
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 12.373
New value of Value function: 12.373
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 121
New value of Q matrix: 12.3074
New value of Value function: 12.3074
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 5
----------
State: 4057
	Distance: 10
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.48874
New value of Value function: 8.73861
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 122
New value of Q matrix: 12.5055
New value of Value function: 12.5055
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 7
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 11.9015
New value of Value function: 11.9015
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 10.4672
New value of Value function: 10.4672
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 10.2198
New value of Value function: 10.2198
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 10
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 4.87526
New value of Value function: 4.87526
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 11
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 11.3462
New value of Value function: 11.3462
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 12
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 10.918
New value of Value function: 10.918
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 13
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 14.0187
New value of Value function: 14.0187
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 14
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 8.87851
New value of Value function: 10.3231
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 15
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 14.3654
New value of Value function: 14.3654
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 16
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 10.6152
New value of Value function: 10.6152
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 17
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 10.364
New value of Value function: 10.364
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 18
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 2.02177
New value of Value function: 11.1826
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 19
----------
State: 2453
	Distance: 6
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 6.44338
New value of Value function: 6.44338
New value of Policy matrix: 3

=======================================
Simulation: 13
Iteration: 20
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 11.2552
New value of Value function: 11.2552
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 21
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 10.4108
New value of Value function: 10.4108
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 22
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.4144
New value of Value function: 11.4144
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 23
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 9.01632
New value of Value function: 11.2552
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 24
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 11.9355
New value of Value function: 11.9355
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 25
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.06924
New value of Value function: 11.2552
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 26
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 11.8804
New value of Value function: 11.8804
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 27
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 11.0439
New value of Value function: 11.0439
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 28
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 17.7487
New value of Value function: 17.7487
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 29
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 22.4649
New value of Value function: 22.4649
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 30
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 21.493
New value of Value function: 21.493
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 31
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 12.5712
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 32
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 20.4887
New value of Value function: 20.4887
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 33
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 22.736
New value of Value function: 22.736
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 34
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 25.8996
New value of Value function: 25.8996
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 35
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 30.152
New value of Value function: 30.4565
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 36
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 31.9749
New value of Value function: 31.9749
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 37
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 32.5621
New value of Value function: 34.8789
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 38
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 32.0678
New value of Value function: 32.5621
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 39
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 28.0983
New value of Value function: 28.0983
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 40
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 32.4639
New value of Value function: 32.4639
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 41
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 32.3702
New value of Value function: 32.3702
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 42
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.96447
New value of Value function: 32.3702
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 39
New value of Q matrix: 7.81937
New value of Value function: 12.5055
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 44
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 28.9952
New value of Value function: 28.9952
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 45
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 32.4774
New value of Value function: 32.4774
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 46
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 32.2804
New value of Value function: 32.2804
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 47
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 32.1941
New value of Value function: 32.1941
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 48
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 32.111
New value of Value function: 32.111
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 49
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 30
New value of Q matrix: 37.6959
New value of Value function: 37.6959
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 50
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 57.2585
New value of Value function: 57.2585
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 51
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 44.346
New value of Value function: 44.346
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 52
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 55.2817
New value of Value function: 55.2817
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 53
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 10.3568
New value of Value function: 44.346
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 123
New value of Q matrix: 15.607
New value of Value function: 15.607
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 55
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 46.5104
New value of Value function: 46.5104
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 56
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 28.3893
New value of Value function: 55.2817
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 57
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 48.065
New value of Value function: 48.065
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 58
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 54.3046
New value of Value function: 54.3046
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 59
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 25.5549
New value of Value function: 48.065
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 60
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 61.1462
New value of Value function: 61.1462
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 61
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 15.593
New value of Value function: 15.593
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 40
New value of Q matrix: 8.01478
New value of Value function: 15.593
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 3
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.05525
New value of Value function: 6.11641
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 4
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 7.33165
New value of Value function: 7.33165
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 6.73349
New value of Value function: 6.73349
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 6
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.6826
New value of Value function: 10.6826
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 125
New value of Q matrix: 15.0629
New value of Value function: 15.0629
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.01873
New value of Value function: 8.01873
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 9
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 4.84347
New value of Value function: 4.84347
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 10
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.372
New value of Value function: 10.6826
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 41
New value of Q matrix: 8.36516
New value of Value function: 15.0629
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 12
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 9.63509
New value of Value function: 9.63509
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 13
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 5.53874
New value of Value function: 8.01873
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 14
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 10.6652
New value of Value function: 10.6652
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 15
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.7439
New value of Value function: 8.7439
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 16
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 5.04265
New value of Value function: 5.04265
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 17
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 11.9122
New value of Value function: 11.9122
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 126
New value of Q matrix: 14.4038
New value of Value function: 14.4038
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 19
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 3.67022
New value of Value function: 3.67022
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 20
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.93002
New value of Value function: 5.93002
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 21
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.65754
New value of Value function: 5.71469
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 22
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.69136
New value of Value function: 5.69136
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 23
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.76902
New value of Value function: 7.76902
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 24
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.49103
New value of Value function: 7.49103
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 25
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.24999
New value of Value function: 5.24999
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 26
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 11.4997
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 27
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 28
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 29
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 30
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 31
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 32
----------
State: 3857
	Distance: 9
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 12.3847
New value of Value function: 12.3847
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 33
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.8586
New value of Value function: 12.8586
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 34
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 10.9307
New value of Value function: 10.9307
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 35
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.6934
New value of Value function: 11.6934
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 36
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.2316
New value of Value function: 9.2316
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 37
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.48457
New value of Value function: 5.48457
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.36605
New value of Value function: 7.36605
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 39
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 3.3356
New value of Value function: 3.3356
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 40
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 4.90984
New value of Value function: 4.90984
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 2.98829
New value of Value function: 2.98829
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 42
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.5327
New value of Value function: 4.90984
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 43
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.16771
New value of Value function: 3.16771
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 44
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 31.0196
New value of Value function: 31.0196
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 98.5355
New value of Value function: 98.5355
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 14.391
New value of Value function: 14.391
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 6.26437
New value of Value function: 14.391
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 128
New value of Q matrix: 14.1493
New value of Value function: 14.1493
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.21572
New value of Value function: 9.21572
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 5
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 8.02523
New value of Value function: 8.02523
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 129
New value of Q matrix: 13.9709
New value of Value function: 13.9709
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 7
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.59172
New value of Value function: 9.59172
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 8
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 1.66035
New value of Value function: 1.66035
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 9
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 5.64375
New value of Value function: 5.64375
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 10
----------
State: 3297
	Distance: 8
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 1.63275
New value of Value function: 1.63275
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 11
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.75871
New value of Value function: 7.75871
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 130
New value of Q matrix: 13.3274
New value of Value function: 13.3274
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 13
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 5.24115
New value of Value function: 5.24115
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 14
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.06232
New value of Value function: 6.06232
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 15
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 11.5693
New value of Value function: 11.5693
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 16
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.62578
New value of Value function: 7.49103
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 17
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.41612
New value of Value function: 12.8586
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 18
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.51397
New value of Value function: 8.51397
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.9205
New value of Value function: 7.9205
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 20
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 5.65576
New value of Value function: 5.65576
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 21
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 11.2255
New value of Value function: 11.2255
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 22
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 8.03376
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 23
----------
State: 2497
	Distance: 6
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 10.9534
New value of Value function: 10.9534
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 24
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.59132
New value of Value function: 7.59132
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 25
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 5.5154
New value of Value function: 5.5154
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 26
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.5522
New value of Value function: 7.5522
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.49201
New value of Value function: 2.49201
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 28
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.52211
New value of Value function: 7.52211
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 29
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.46945
New value of Value function: 2.46945
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 30
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 7.49633
New value of Value function: 7.49633
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 31
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.44476
New value of Value function: 2.46945
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 32
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.49869
New value of Value function: 4.49869
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 7.23407
New value of Value function: 7.23407
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 34
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 8.38291
New value of Value function: 8.38291
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 131
New value of Q matrix: 12.8391
New value of Value function: 12.8391
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 36
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 14.4274
New value of Value function: 14.4274
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 24.0545
New value of Value function: 24.0545
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 8.94148
New value of Value function: 8.94148
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 20.6456
New value of Value function: 20.6456
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 40
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 11.8051
New value of Value function: 11.8051
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 41
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.33437
New value of Value function: 20.6456
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 42
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 8.2582
New value of Value function: 8.2582
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 43
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 20.4392
New value of Value function: 20.6456
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 44
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 41.1218
New value of Value function: 41.1218
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 45
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 99.381
New value of Value function: 99.381
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 12.8279
New value of Value function: 12.8279
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 133
New value of Q matrix: 12.7991
New value of Value function: 12.7991
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 10.7095
New value of Value function: 10.7095
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 4
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.76131
New value of Value function: 8.76131
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 134
New value of Q matrix: 12.8685
New value of Value function: 12.8685
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 6
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 10.5448
New value of Value function: 10.5448
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 7
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 4.75663
New value of Value function: 4.75663
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 8
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 7.61213
New value of Value function: 7.61213
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 9
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.77007
New value of Value function: 9.77007
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 9.5397
New value of Value function: 9.5397
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 11
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 12.8956
New value of Value function: 12.8956
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 12
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.8234
New value of Value function: 11.8234
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 13
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.42136
New value of Value function: 7.49633
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.1153
New value of Value function: 8.1153
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 15
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 1.14517
New value of Value function: 2.46945
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 16
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.1617
New value of Value function: 12.1617
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 17
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 8.51954
New value of Value function: 8.51954
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 18
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 11.4453
New value of Value function: 11.4453
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 19
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 19.5721
New value of Value function: 19.5721
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 20
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 6.94665
New value of Value function: 41.1218
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 21
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.43993
New value of Value function: 8.2582
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.9234
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 23
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 17.8881
New value of Value function: 17.8881
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 24
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 36.3328
New value of Value function: 36.3328
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 25
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 23.5652
New value of Value function: 23.5652
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 26
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 33.7393
New value of Value function: 33.7393
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 27
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 25.6596
New value of Value function: 25.6596
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 28
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.1569
New value of Value function: 33.7393
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 29
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 21.9626
New value of Value function: 21.9626
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 30
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 29.6052
New value of Value function: 33.7393
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 31
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 49.7176
New value of Value function: 49.7176
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 32
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 30.505
New value of Value function: 99.381
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 33
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 61.7185
New value of Value function: 61.7185
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 34
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 99.6905
New value of Value function: 99.6905
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 12.8575
New value of Value function: 12.8575
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 136
New value of Q matrix: 12.9074
New value of Value function: 12.9074
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 11.4882
New value of Value function: 11.4882
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 4
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 7.86906
New value of Value function: 7.86906
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 5
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 10.2304
New value of Value function: 10.2304
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 6.51276
New value of Value function: 12.9074
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 137
New value of Q matrix: 12.7172
New value of Value function: 12.7172
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 8
----------
State: 3257
	Distance: 8
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.81599
New value of Value function: 8.81599
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 138
New value of Q matrix: 12.2908
New value of Value function: 12.2908
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 10
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 5.95859
New value of Value function: 5.95859
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 11
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 10.7367
New value of Value function: 10.7367
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 12
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 11.3281
New value of Value function: 11.3281
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 13
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 10.6402
New value of Value function: 10.6402
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 14
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.72851
New value of Value function: 7.9205
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 15
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.3363
New value of Value function: 11.3363
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 16
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 12.718
New value of Value function: 12.718
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 17
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.59083
New value of Value function: 11.8234
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 18
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.8653
New value of Value function: 13.8653
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 19
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 12.3649
New value of Value function: 12.3649
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 20
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.85467
New value of Value function: 8.1153
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 21
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 7.91313
New value of Value function: 7.91313
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.63248
New value of Value function: 2.63248
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 23
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 7.82451
New value of Value function: 7.85467
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.69112
New value of Value function: 2.69112
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 25
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.80932
New value of Value function: 7.82451
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 26
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 7.78005
New value of Value function: 7.80932
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 2.70628
New value of Value function: 2.70628
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 28
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.77027
New value of Value function: 7.78005
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 29
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 7.7531
New value of Value function: 7.77027
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 30
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 2.70143
New value of Value function: 2.70143
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 31
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 7.24124
New value of Value function: 7.77027
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 32
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 12.4987
New value of Value function: 12.4987
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 33
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.73552
New value of Value function: 7.7531
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 34
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 7.73279
New value of Value function: 7.73552
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 35
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 2.68701
New value of Value function: 2.68701
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 36
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 14.0401
New value of Value function: 14.0401
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 37
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 14.0444
New value of Value function: 14.0444
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 38
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.74653
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 39
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 4.65164
New value of Value function: 4.65164
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 40
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 15.358
New value of Value function: 15.358
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 41
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 14.4946
New value of Value function: 14.4946
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 42
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.13929
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 43
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.5148
New value of Value function: 11.5148
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 44
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.05177
New value of Value function: 9.9234
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 45
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.01885
New value of Value function: 7.01885
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 46
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 25.5632
New value of Value function: 25.5632
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 47
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 54.2303
New value of Value function: 54.2303
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 48
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 32.3801
New value of Value function: 32.3801
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 49
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 49.9292
New value of Value function: 49.9292
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 50
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 9.25386
New value of Value function: 32.3801
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 51
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 36.1426
New value of Value function: 36.1426
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 52
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 41.051
New value of Value function: 49.9292
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 53
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 16.5361
New value of Value function: 49.9292
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 54
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.5224
New value of Value function: 21.9626
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 55
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.506492
New value of Value function: 21.9626
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 56
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.506891
New value of Value function: 0.506891
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 57
----------
State: 1813
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 8.42804
New value of Value function: 8.42804
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 58
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 44.979
New value of Value function: 44.979
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 59
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1774
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 5
New value of Q matrix: 98.4873
New value of Value function: 98.4873
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 12.2804
New value of Value function: 12.2804
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.37141
New value of Value function: 12.2804
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 12.27
New value of Value function: 12.27
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 7.27953
New value of Value function: 12.27
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 12.3423
New value of Value function: 12.3423
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 6
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.86094
New value of Value function: 10.2304
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 142
New value of Q matrix: 12.0533
New value of Value function: 12.0533
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 8
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 5.82496
New value of Value function: 5.82496
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 9
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 9.29867
New value of Value function: 9.29867
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 10
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 10.0245
New value of Value function: 10.0245
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 11
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 10.8146
New value of Value function: 10.8146
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 12
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 9.62709
New value of Value function: 9.62709
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 13
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 11.1727
New value of Value function: 11.1727
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 14
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 9.62709
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 15
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.93281
New value of Value function: 8.93281
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 7.90697
New value of Value function: 12.0533
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 143
New value of Q matrix: 12.2473
New value of Value function: 12.2473
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 18
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 10.806
New value of Value function: 10.806
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 144
New value of Q matrix: 12.3682
New value of Value function: 12.3682
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 20
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 11.3571
New value of Value function: 11.3571
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 21
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 9.18599
New value of Value function: 11.9122
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 145
New value of Q matrix: 12.2372
New value of Value function: 12.2372
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 23
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 8.33991
New value of Value function: 8.33991
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 146
New value of Q matrix: 12.156
New value of Value function: 12.156
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 25
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.24353
New value of Value function: 8.33991
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 26
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 11.8647
New value of Value function: 11.8647
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 27
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 8.14659
New value of Value function: 8.14659
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 28
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 12.0651
New value of Value function: 12.0651
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 29
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 8.07922
New value of Value function: 8.07922
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 30
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 10.127
New value of Value function: 12.0651
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 31
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 12.1575
New value of Value function: 12.1575
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 32
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 6.80381
New value of Value function: 8.07922
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 33
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.0359
New value of Value function: 12.1575
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 34
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 14.061
New value of Value function: 14.061
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 35
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 11.1227
New value of Value function: 11.1227
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 36
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 10.2702
New value of Value function: 10.2702
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 147
New value of Q matrix: 12.549
New value of Value function: 12.549
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 38
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 13.4292
New value of Value function: 13.4292
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 39
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 10.1675
New value of Value function: 10.2702
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 40
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 9.95017
New value of Value function: 10.1675
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 148
New value of Q matrix: 12.8569
New value of Value function: 12.8569
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 42
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.2194
New value of Value function: 13.2194
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 43
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.0956
New value of Value function: 10.0956
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 44
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.87174
New value of Value function: 10.0956
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 8.55125
New value of Value function: 12.8569
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 12.8464
New value of Value function: 12.8464
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 9.10314
New value of Value function: 12.8464
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 13.111
New value of Value function: 13.111
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 49
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 13.107
New value of Value function: 13.107
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 50
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 9.21193
New value of Value function: 10.0956
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 51
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 9.15584
New value of Value function: 9.15584
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 52
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 10.0373
New value of Value function: 10.0373
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 53
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 9.91205
New value of Value function: 10.0373
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 54
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 9.11309
New value of Value function: 9.11309
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 55
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 6.85943
New value of Value function: 6.85943
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 56
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 12.5192
New value of Value function: 12.5192
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 57
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 13.5646
New value of Value function: 13.5646
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 58
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 14.6195
New value of Value function: 14.6195
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 59
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.4112
New value of Value function: 15.4112
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 60
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 10.7847
New value of Value function: 15.358
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 61
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.99171
New value of Value function: 10.7847
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 62
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 13.6768
New value of Value function: 13.6768
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 63
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 9.57387
New value of Value function: 10.7847
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 64
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 13.6768
New value of Value function: 13.6768
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 65
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 10.7439
New value of Value function: 10.7439
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 66
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 10.7059
New value of Value function: 10.7059
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 67
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 10.6703
New value of Value function: 10.6703
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 68
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 10.6365
New value of Value function: 10.6365
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 69
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 10.6044
New value of Value function: 10.6044
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 70
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 10.5738
New value of Value function: 10.5738
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 71
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 10.5445
New value of Value function: 10.5445
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 72
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 10.5163
New value of Value function: 10.5163
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 73
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 10.1317
New value of Value function: 10.5163
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 74
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.5235
New value of Value function: 13.5235
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 75
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 10.4892
New value of Value function: 10.4892
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 76
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 10.463
New value of Value function: 10.463
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 77
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 10.4376
New value of Value function: 10.4376
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 78
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 10.413
New value of Value function: 10.413
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 79
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 10.3891
New value of Value function: 10.3891
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 80
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 10.3659
New value of Value function: 10.3659
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 81
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 10.3432
New value of Value function: 10.3432
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 82
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 10.3212
New value of Value function: 10.3212
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 83
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 12.1707
New value of Value function: 12.1707
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 84
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 11.0499
New value of Value function: 11.0499
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 85
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 5.37446
New value of Value function: 5.37446
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 86
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 10.6815
New value of Value function: 12.1707
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 87
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 12.5144
New value of Value function: 12.5144
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 88
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.57058
New value of Value function: 11.0499
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 89
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 14.7314
New value of Value function: 14.7314
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 90
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 9.82935
New value of Value function: 9.82935
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 91
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 5.95609
New value of Value function: 5.95609
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 92
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.39651
New value of Value function: 12.5144
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 93
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 7.90622
New value of Value function: 7.90622
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 94
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.82716
New value of Value function: 5.95609
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 95
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.47798
New value of Value function: 8.47798
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 96
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 6.35359
New value of Value function: 6.35359
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 97
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 12.1946
New value of Value function: 12.1946
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 98
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 9.60918
New value of Value function: 9.60918
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 99
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 6.39622
New value of Value function: 6.39622
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 100
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 9.50451
New value of Value function: 9.50451
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 101
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.37299
New value of Value function: 6.39622
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 102
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.16718
New value of Value function: 7.16718
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 151
New value of Q matrix: 12.8656
New value of Value function: 12.8656
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 104
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.65082
New value of Value function: 8.65082
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 152
New value of Q matrix: 12.76
New value of Value function: 12.76
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 106
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 9.14163
New value of Value function: 9.14163
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 153
New value of Q matrix: 12.7026
New value of Value function: 12.7026
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 108
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 9.33572
New value of Value function: 9.33572
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 154
New value of Q matrix: 12.6656
New value of Value function: 12.6656
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 110
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 9.41867
New value of Value function: 9.41867
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 155
New value of Q matrix: 12.6382
New value of Value function: 12.6382
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 112
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 9.45386
New value of Value function: 9.45386
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 5.4312
New value of Value function: 12.6382
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 156
New value of Q matrix: 11.8665
New value of Value function: 11.8665
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 115
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 116
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 117
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 118
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 119
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 120
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 7.3932
New value of Value function: 7.3932
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 121
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 8.31927
New value of Value function: 8.47798
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 122
----------
State: 1657
	Distance: 4
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 7.3932
New value of Value function: 7.3932
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 123
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.90512
New value of Value function: 8.90512
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 124
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 6.57088
New value of Value function: 6.57088
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 125
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 11.8979
New value of Value function: 11.8979
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 126
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.8414
New value of Value function: 9.50451
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 127
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 6.57648
New value of Value function: 9.50451
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 128
----------
State: 3017
	Distance: 7
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 13.7981
New value of Value function: 13.7981
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 129
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.6788
New value of Value function: 11.6788
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 130
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 13.1151
New value of Value function: 13.1151
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 131
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.66457
New value of Value function: 25.5632
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 132
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.8595
New value of Value function: 16.8595
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 133
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 32.2102
New value of Value function: 32.2102
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 134
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 16.5551
New value of Value function: 44.979
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 135
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 36.8389
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 136
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 45.6587
New value of Value function: 45.6587
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 137
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 47.3961
New value of Value function: 47.3961
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 138
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 38.2719
New value of Value function: 38.2719
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 139
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 18.3953
New value of Value function: 47.3961
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 140
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 18.9446
New value of Value function: 38.2719
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 141
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 27.4169
New value of Value function: 38.2719
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 142
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 52.9398
New value of Value function: 52.9398
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 143
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 99.1048
New value of Value function: 99.1048
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 11.857
New value of Value function: 11.857
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 158
New value of Q matrix: 12.1847
New value of Value function: 12.1847
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 12.7006
New value of Value function: 13.107
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 13.031
New value of Value function: 13.031
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 5
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.98713
New value of Value function: 9.98713
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 9.94246
New value of Value function: 9.94246
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 7
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 9.90065
New value of Value function: 9.94246
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 8
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 12.9542
New value of Value function: 12.9542
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 9
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 9.90187
New value of Value function: 9.91205
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 10
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 10.3045
New value of Value function: 10.3045
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 11
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 9.29422
New value of Value function: 9.29422
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 12
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 9.56934
New value of Value function: 9.56934
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 13
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 13.5254
New value of Value function: 13.5254
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 14
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.67789
New value of Value function: 13.5254
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 15
----------
State: 3817
	Distance: 9
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 14.34
New value of Value function: 14.34
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 16
----------
State: 3417
	Distance: 8
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.8151
New value of Value function: 13.8151
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 17
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 17.8438
New value of Value function: 17.8438
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 18
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 25.0632
New value of Value function: 25.0632
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 19
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 2.62585
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 20
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 10.3813
New value of Value function: 10.3813
New value of Policy matrix: 3

=======================================
Simulation: 19
Iteration: 21
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 21.3362
New value of Value function: 21.3362
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 22
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 17
New value of Q matrix: 12.2589
New value of Value function: 12.2589
New value of Policy matrix: 3

=======================================
Simulation: 19
Iteration: 23
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 19.4669
New value of Value function: 19.4669
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 24
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 16.3832
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 25
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 7.81062
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 26
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.52642
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 27
----------
State: 2097
	Distance: 5
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 13.5178
New value of Value function: 13.5178
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 28
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.72729
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 29
----------
State: 1697
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 9.31562
New value of Value function: 9.31562
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 159
New value of Q matrix: 12.589
New value of Value function: 12.589
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 31
----------
State: 1693
	Distance: 4
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 14.3969
New value of Value function: 14.3969
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 32
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 33.4705
New value of Value function: 33.4705
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.63141
New value of Value function: 36.8389
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 34
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 20.5007
New value of Value function: 20.5007
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 35
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 40.2893
New value of Value function: 40.2893
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 36
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 45.4619
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 48.8279
New value of Value function: 48.8279
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 51.4256
New value of Value function: 51.4256
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 49.6446
New value of Value function: 49.6446
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 40
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 37.0085
New value of Value function: 51.4256
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 41
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 62.5362
New value of Value function: 62.5362
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 42
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 7
New value of Q matrix: 98.3093
New value of Value function: 98.3093
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 8.99749
New value of Value function: 12.589
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 160
New value of Q matrix: 12.6657
New value of Value function: 12.6657
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 3
----------
State: 4061
	Distance: 10
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 13.1798
New value of Value function: 13.1798
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 12.7723
New value of Value function: 12.9542
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 5
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 13.0477
New value of Value function: 13.0477
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 6
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 10.6034
New value of Value function: 10.6034
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 7
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.10578
New value of Value function: 9.29422
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 8
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.20128
New value of Value function: 9.20128
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 9
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 10.0946
New value of Value function: 10.0946
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 10
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 13.6934
New value of Value function: 13.6934
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 11
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 15.1751
New value of Value function: 15.1751
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 12
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 18.2177
New value of Value function: 18.2177
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 13
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 16.5925
New value of Value function: 16.5925
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 12.4384
New value of Value function: 12.4384
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 15
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 19.4952
New value of Value function: 19.4952
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 16
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 19.3954
New value of Value function: 19.3954
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 17
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 11.0934
New value of Value function: 16.3832
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 18
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 15.3594
New value of Value function: 15.3594
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 19
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.1018
New value of Value function: 19.3954
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 20
----------
State: 2617
	Distance: 6
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 16.4931
New value of Value function: 16.4931
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 21
----------
State: 2217
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 26.3457
New value of Value function: 26.3457
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 39.8864
New value of Value function: 40.2893
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 23
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 42.7188
New value of Value function: 42.7188
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 24
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 32.5455
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 25
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 26.9233
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 44.4865
New value of Value function: 44.4865
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 27
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 32.3428
New value of Value function: 45.4619
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 28
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 45.7878
New value of Value function: 45.7878
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 29
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 45.8973
New value of Value function: 45.8973
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 30
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 52.4424
New value of Value function: 52.4424
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 31
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 29.5339
New value of Value function: 62.5362
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 25.6556
New value of Value function: 52.4424
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 33
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 46.8547
New value of Value function: 46.8547
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 34
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 46.9025
New value of Value function: 46.9025
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 35
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 62.0426
New value of Value function: 62.0426
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 36
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 98.907
New value of Value function: 98.907
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 12.6557
New value of Value function: 12.6557
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 162
New value of Q matrix: 12.912
New value of Value function: 12.912
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 3
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.81161
New value of Value function: 13.0477
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 4
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 13.2067
New value of Value function: 13.2067
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 5
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.043
New value of Value function: 11.043
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 6
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 9.8041
New value of Value function: 9.8041
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 7
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 11.2429
New value of Value function: 11.2429
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 8
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 10.4516
New value of Value function: 10.4516
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 9
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 11.8168
New value of Value function: 11.8168
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 10
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 5.44383
New value of Value function: 15.1751
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 11
----------
State: 3737
	Distance: 9
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 17.7666
New value of Value function: 17.7666
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 12
----------
State: 3337
	Distance: 8
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 16.5763
New value of Value function: 16.5763
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 13
----------
State: 2937
	Distance: 7
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 17.1063
New value of Value function: 17.1063
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 14
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 15.6569
New value of Value function: 15.6569
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 15
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 19.1435
New value of Value function: 19.1435
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 16
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 11.6651
New value of Value function: 15.6569
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 17
----------
State: 2537
	Distance: 6
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 17.3287
New value of Value function: 17.3287
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 18
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 28.268
New value of Value function: 28.268
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 19
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 44.4579
New value of Value function: 44.4579
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 20
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 38.804
New value of Value function: 38.804
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 21
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 42.8045
New value of Value function: 44.4579
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 22
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 14.8194
New value of Value function: 44.4579
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 23
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 33.8124
New value of Value function: 33.8124
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 24
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 48.8144
New value of Value function: 48.8144
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 25
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 62.3956
New value of Value function: 62.3956
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 26
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 61.933
New value of Value function: 61.933
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 27
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 62.5661
New value of Value function: 62.5661
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 28
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 61.5082
New value of Value function: 61.5082
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 29
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 69.9333
New value of Value function: 69.9333
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 30
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 57.8931
New value of Value function: 98.907
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 31
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 69.7257
New value of Value function: 69.7257
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 32
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1294
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 9
New value of Q matrix: 98.2714
New value of Value function: 98.2714
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 12.9018
New value of Value function: 12.9018
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 164
New value of Q matrix: 13.0487
New value of Value function: 13.0487
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 3
----------
State: 4097
	Distance: 10
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 12.4002
New value of Value function: 12.4002
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 4
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 11.7884
New value of Value function: 11.7884
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 5
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 26
New value of Q matrix: 14.3854
New value of Value function: 14.3854
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 6
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 15.0452
New value of Value function: 15.0452
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 7
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 11.797
New value of Value function: 11.797
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 8
----------
State: 3293
	Distance: 8
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 15.4181
New value of Value function: 15.4181
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 9
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 12.4985
New value of Value function: 12.4985
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 10
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 12.9788
New value of Value function: 12.9788
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 11
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 18.9245
New value of Value function: 18.9245
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 12
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 13.9487
New value of Value function: 13.9487
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 13
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 21.2187
New value of Value function: 21.2187
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 14
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 25.2561
New value of Value function: 25.2561
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 15
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: -0.0906495
New value of Value function: 28.9952
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 16
----------
State: 2049
	Distance: 5
	Angle: 1
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 18.3526
New value of Value function: 18.3526
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 17
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 31.0477
New value of Value function: 31.0477
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 18
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 34.0899
New value of Value function: 34.0899
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 19
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 8.83821
New value of Value function: 37.6959
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 165
New value of Q matrix: 15.1717
New value of Value function: 15.1717
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 21
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: 36.6278
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 22
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 35.0469
New value of Value function: 35.0469
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 23
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 33.1486
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 24
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.72113
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 17.0414
New value of Value function: 17.0414
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 26
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 10.7961
New value of Value function: 36.6278
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 167
New value of Q matrix: 18.7608
New value of Value function: 18.7608
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 40.187
New value of Value function: 40.187
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 55.6958
New value of Value function: 55.6958
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 30
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 59.2588
New value of Value function: 59.2588
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 31
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 20.4877
New value of Value function: 55.6958
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 32
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 40.6577
New value of Value function: 40.6577
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 33
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 20.0741
New value of Value function: 55.6958
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 34
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 56.5242
New value of Value function: 56.5242
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 35
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 7
New value of Q matrix: 16.5245
New value of Value function: 59.2588
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 36
----------
State: 1245
	Distance: 3
	Angle: 1
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 12.6873
New value of Value function: 12.6873
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 168
New value of Q matrix: 22.0711
New value of Value function: 22.0711
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 38
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 69.0643
New value of Value function: 69.0643
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 39
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 9
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 10.7769
New value of Value function: 22.0711
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 22.0541
New value of Value function: 22.0541
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 170
New value of Q matrix: 21.3695
New value of Value function: 21.3695
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 4
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 13.7748
New value of Value function: 13.7748
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 171
New value of Q matrix: 20.5764
New value of Value function: 20.5764
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 6
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 8.57184
New value of Value function: 8.57184
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 7
----------
State: 3661
	Distance: 9
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 15.2428
New value of Value function: 15.2428
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 172
New value of Q matrix: 19.8833
New value of Value function: 19.8833
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 9
----------
State: 3701
	Distance: 9
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 11.0179
New value of Value function: 11.0179
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 173
New value of Q matrix: 19.5937
New value of Value function: 19.5937
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 11
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 13.5146
New value of Value function: 13.5146
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 12
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 10.2392
New value of Value function: 11.2429
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 13
----------
State: 4101
	Distance: 10
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 13.7094
New value of Value function: 13.7094
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 14
----------
State: 4141
	Distance: 10
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 11.5617
New value of Value function: 11.5617
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 15
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.10753
New value of Value function: 10.4516
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 16
----------
State: 4221
	Distance: 10
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 10.0115
New value of Value function: 10.0115
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 17
----------
State: 4181
	Distance: 10
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 12.7076
New value of Value function: 12.7076
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 18
----------
State: 3777
	Distance: 9
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 17.2759
New value of Value function: 17.2759
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 19
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 20.5587
New value of Value function: 20.5587
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 20
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 18.952
New value of Value function: 19.1435
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 21
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 9.83329
New value of Value function: 19.1435
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 22
----------
State: 3377
	Distance: 8
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 21.8413
New value of Value function: 21.8413
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 23
----------
State: 2977
	Distance: 7
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 25.5871
New value of Value function: 25.5871
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 24
----------
State: 2577
	Distance: 6
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 30.0445
New value of Value function: 30.0445
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 25
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 29.2125
New value of Value function: 29.2125
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 26
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 15.6121
New value of Value function: 48.8144
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 27
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 36.6773
New value of Value function: 36.6773
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 28
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 47.2371
New value of Value function: 47.2371
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 29
----------
State: 1737
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 41.6681
New value of Value function: 41.6681
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 30
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 52.4493
New value of Value function: 52.4493
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 31
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 55.1425
New value of Value function: 69.9333
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 32
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 31.3105
New value of Value function: 69.9333
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 33
----------
State: 2137
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 42.4265
New value of Value function: 42.4265
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 34
----------
State: 2177
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 52.2419
New value of Value function: 52.2419
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 35
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 39.4895
New value of Value function: 46.9025
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 36
----------
State: 1773
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 51.8336
New value of Value function: 51.8336
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 37
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 70.13
New value of Value function: 70.13
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 38
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 69.2568
New value of Value function: 69.2568
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 39
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 70.2068
New value of Value function: 70.2068
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 40
----------
State: 1293
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 68.9064
New value of Value function: 68.9064
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 41
----------
State: 1733
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 75.7915
New value of Value function: 75.7915
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 42
----------
State: 1333
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1334
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 10
New value of Q matrix: 98.818
New value of Value function: 98.818
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 19.5789
New value of Value function: 19.5789
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 11.8974
New value of Value function: 19.5789
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 175
New value of Q matrix: 19.2285
New value of Value function: 19.2285
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 4
----------
State: 3657
	Distance: 9
	Angle: 1
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 10.4399
New value of Value function: 11.9122
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 5
----------
State: 3697
	Distance: 9
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 6.98445
New value of Value function: 6.98445
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 6
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 12.7378
New value of Value function: 12.7378
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 7
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 13.6589
New value of Value function: 13.6589
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 8
----------
State: 4137
	Distance: 10
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 13.3184
New value of Value function: 13.3184
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 9
----------
State: 4177
	Distance: 10
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 14.0652
New value of Value function: 14.0652
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 10
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.09282
New value of Value function: 10.918
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 11
----------
State: 3773
	Distance: 9
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 11.6651
New value of Value function: 11.6651
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 12
----------
State: 3733
	Distance: 9
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 15.4818
New value of Value function: 15.4818
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 13
----------
State: 3333
	Distance: 8
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 12.5116
New value of Value function: 12.5116
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 14
----------
State: 2893
	Distance: 7
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 13.4499
New value of Value function: 13.4499
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 15
----------
State: 2493
	Distance: 6
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 15.2132
New value of Value function: 15.2132
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 16
----------
State: 2933
	Distance: 7
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 23.4869
New value of Value function: 23.4869
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 17
----------
State: 2533
	Distance: 6
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 27.5117
New value of Value function: 27.5117
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 18
----------
State: 2089
	Distance: 5
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 26.0444
New value of Value function: 26.0444
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 19
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 8.61295
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 20
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 12.4648
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 21
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 14.4085
New value of Value function: 17.3999
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 22
----------
State: 2529
	Distance: 6
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 28.7701
New value of Value function: 28.7701
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 23
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 37.2931
New value of Value function: 40.6577
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 24
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 39.0009
New value of Value function: 40.6577
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 25
----------
State: 2129
	Distance: 5
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 40.9037
New value of Value function: 40.9037
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 26
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 37.6855
New value of Value function: 37.6855
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 27
----------
State: 2125
	Distance: 5
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 33.1117
New value of Value function: 33.1117
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 28
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 34
New value of Q matrix: 41.3339
New value of Value function: 41.3339
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 29
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 37
New value of Q matrix: 49.868
New value of Value function: 49.868
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 7.1876
New value of Value function: 19.2285
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 19.214
New value of Value function: 19.214
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 177
New value of Q matrix: 21.0711
New value of Value function: 21.0711
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 33
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 12.5215
New value of Value function: 41.3339
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 178
New value of Q matrix: 22.7837
New value of Value function: 22.7837
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 35
----------
State: 1685
	Distance: 4
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 35
New value of Q matrix: 43.1992
New value of Value function: 43.1992
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 36
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 13.1374
New value of Value function: 49.868
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 37
----------
State: 1765
	Distance: 4
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 70.3737
New value of Value function: 70.3737
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 38
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 19.5559
New value of Value function: 69.0643
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 179
New value of Q matrix: 26.4155
New value of Value function: 26.4155
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 40
----------
State: 1285
	Distance: 3
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 64.2132
New value of Value function: 64.2132
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 41
----------
State: 1725
	Distance: 4
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 58.6494
New value of Value function: 58.6494
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 42
----------
State: 1325
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1326
	Distance: 3
	Angle: 3
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 10
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

