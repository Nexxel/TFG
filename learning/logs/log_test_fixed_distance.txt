=======================================
Episode: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 1.13389
New value of Value function: 1.13389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 45
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7961
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 46
----------
State: 7961
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 47
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8025
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.24264
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 48
----------
State: 8025
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 49
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.87745
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 0.866025
New value of Value function: 1.13389
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 51
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.87745
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 7
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 1.45788
New value of Value function: 1.45788
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 53
----------
State: 8089
	Distance: 7
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 54
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8025
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 55
----------
State: 8025
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8089
	Distance: 7
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -2.03536
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 56
----------
State: 8089
	Distance: 7
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.40007
New value of Value function: 6.40007
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 57
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 5.53553
New value of Value function: 5.53553
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 58
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 59
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 60
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 61
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 62
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 63
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 64
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 65
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 66
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 67
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 68
----------
State: 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.480179
New value of Value function: 0.480179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 69
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 3
New value of Q matrix: 6.38104
New value of Value function: 6.38104
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 70
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 71
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.94975
New value of Value function: 2.94975
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 72
----------
State: 5977
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 73
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 74
----------
State: 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 75
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 76
----------
State: 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 77
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 78
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 79
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 80
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.5567
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 1.87003
New value of Value function: 1.87003
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 82
----------
State: 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.14867
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 2.16179
New value of Value function: 2.16179
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 84
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 85
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6037
	Distance: 5
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -7
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 86
----------
State: 6037
	Distance: 5
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 87
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 88
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 89
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 90
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 91
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 92
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 93
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 94
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 95
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 96
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 97
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6037
	Distance: 5
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -2.09975
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 98
----------
State: 6037
	Distance: 5
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 99
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.07975
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 100
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.52462
New value of Value function: 2.94975
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 101
----------
State: 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.61978
New value of Value function: 3.61978
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 102
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.70504
New value of Value function: 4.70504
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 103
----------
State: 5977
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.50018
New value of Value function: 4.50018
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 104
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 105
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4949
	Distance: 4
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 106
----------
State: 4949
	Distance: 4
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.85983
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 2.37134
New value of Value function: 2.37134
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 108
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 109
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 110
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 111
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 112
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 113
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 114
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 115
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 116
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 117
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 118
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 119
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 120
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 121
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 122
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -2.04216
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 123
----------
State: 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 124
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.599929
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 125
----------
State: 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 126
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 127
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -1.03108
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 128
----------
State: 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.652372
New value of Value function: 2
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 1.79366
New value of Value function: 2.37134
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 130
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 131
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 132
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 133
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 134
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 135
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 136
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 137
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.265107
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 138
----------
State: 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6037
	Distance: 5
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.95959
New value of Value function: 1.95959
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 139
----------
State: 6037
	Distance: 5
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 140
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 1.5359
New value of Value function: 1.5359
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 141
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 142
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 143
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 144
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 145
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 146
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 147
----------
State: 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1.29289
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 148
----------
State: 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 149
----------
State: 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 150
----------
State: 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 151
----------
State: 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -5.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 152
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.20021
New value of Value function: 6.20021
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 153
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 154
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 155
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.46035
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 156
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.26795
New value of Value function: 3.26795
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 157
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.335327
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 158
----------
State: 5013
	Distance: 4
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.94979
New value of Value function: 4.94979
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 159
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 1.0187
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 160
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 1.85055
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 161
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 162
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 163
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 164
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.24785
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 165
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.04255
New value of Value function: 4.04255
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 166
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 167
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 168
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 169
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 170
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 171
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 172
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4949
	Distance: 4
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.719076
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 173
----------
State: 4949
	Distance: 4
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -0.861788
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 174
----------
State: 5009
	Distance: 4
	Angle: 14
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.20468
New value of Value function: 7.20468
New value of Policy matrix: 3

=======================================
Episode: 1
Iteration: 175
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 4
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 176
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 177
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 178
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 179
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 180
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6869
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.527405
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 181
----------
State: 6869
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 7897
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 182
----------
State: 7897
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 1
New value of Q matrix: 9
New value of Value function: 9
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 183
----------
State: 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 184
----------
State: 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 185
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 186
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 187
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 188
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 189
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8729
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 1
Iteration: 190
----------
State: 8729
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8729
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 191
----------
State: 8729
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 192
----------
State: 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 193
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 194
----------
State: 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 195
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 196
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 197
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 198
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 1
Iteration: 199
----------
State: 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 1
Iteration: 200
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 1
----------
State: 9117
	Distance: 8
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 2
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 3
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10077
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 4
----------
State: 10077
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.99
New value of Value function: 5.99
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 5
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9117
	Distance: 8
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -0.07
New value of Value function: 1
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 6
----------
State: 9117
	Distance: 8
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 7.70004
New value of Value function: 7.70004
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 7
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10077
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.950573
New value of Value function: 0.950573
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 8
----------
State: 10077
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.9554
New value of Value function: 5.9554
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 9
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10077
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.918976
New value of Value function: 0.918976
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 10
----------
State: 10077
	Distance: 9
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.92906
New value of Value function: 5.92906
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 11
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 12
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 13
----------
State: 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -5.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 14
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 7
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -1.43472
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 15
----------
State: 8093
	Distance: 7
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.99
New value of Value function: 2.99
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 16
----------
State: 9053
	Distance: 8
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 4.53553
New value of Value function: 4.53553
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 17
----------
State: 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 18
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 19
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 20
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 21
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 22
----------
State: 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 23
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9821
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 24
----------
State: 9821
	Distance: 9
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 6.8505
New value of Value function: 6.8505
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 25
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.87964
New value of Value function: 9.87964
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 26
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.92026
New value of Value function: 9.92026
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 27
----------
State: 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -2.05
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 28
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.07107
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 29
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 11.95
New value of Value function: 11.95
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 30
----------
State: 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 31
----------
State: 9757
	Distance: 9
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 4.89669
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 32
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 9.92026
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 33
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 34
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 35
----------
State: 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 36
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 37
----------
State: 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 38
----------
State: 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 39
----------
State: 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 40
----------
State: 11677
	Distance: 11
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 41
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 42
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 43
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 44
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 45
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 46
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 47
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 48
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 49
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.76075
New value of Value function: 3.76075
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 50
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: 4.88015
New value of Value function: 4.88015
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 51
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.61432
New value of Value function: 5.61432
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 52
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 7.95181
New value of Value function: 7.95181
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 53
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.907892
New value of Value function: 0.907892
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 54
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: -8
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 55
----------
State: 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 1
New value of Q matrix: 8
New value of Value function: 8
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 56
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 57
----------
State: 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 58
----------
State: 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 3.39469
New value of Value function: 3.39469
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 59
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.92
New value of Value function: 5.61432
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 60
----------
State: 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 4.96
New value of Value function: 8
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 61
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 6.06475
New value of Value function: 6.06475
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 62
----------
State: 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 8.39469
New value of Value function: 8.39469
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 63
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.1963
New value of Value function: 5.61432
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 64
----------
State: 11933
	Distance: 11
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.48908
New value of Value function: 8.48908
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 65
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.07266
New value of Value function: 8.07266
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 66
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.87229
New value of Value function: 7.95181
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 67
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 6.08774
New value of Value function: 7.87229
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 68
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.51667
New value of Value function: 4.51667
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 69
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 4
New value of Q matrix: 1.35073
New value of Value function: 1.35073
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 70
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.81663
New value of Value function: 7.81663
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 71
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.7715
New value of Value function: 7.7715
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 72
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.73264
New value of Value function: 7.73264
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 73
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.69806
New value of Value function: 7.69806
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 74
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 7.66663
New value of Value function: 7.66663
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 75
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 7.63765
New value of Value function: 7.63765
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 76
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 7.61065
New value of Value function: 7.61065
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 77
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.58528
New value of Value function: 7.58528
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 78
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 7.5613
New value of Value function: 7.5613
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 79
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.7502
New value of Value function: 9.7502
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 80
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.96013
New value of Value function: 3.96013
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 81
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 2.99194
New value of Value function: 2.99194
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 82
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 4
New value of Q matrix: 9.4966
New value of Value function: 9.4966
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 83
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 0.962017
New value of Value function: 3.96013
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 84
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.834785
New value of Value function: 2.99194
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 85
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.97078
New value of Value function: 2.97078
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 86
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 3.79688
New value of Value function: 3.79688
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 87
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.4608
New value of Value function: 10.4608
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 88
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 9.72205
New value of Value function: 9.72205
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 89
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 9.69509
New value of Value function: 9.69509
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 90
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 9.66918
New value of Value function: 9.66918
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 91
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 9.47588
New value of Value function: 9.47588
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 92
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1.94556
New value of Value function: 3.96013
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 93
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.5285
New value of Value function: 1.35073
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 94
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.50161
New value of Value function: 4.50161
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 95
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.48738
New value of Value function: 4.48738
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 96
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.47385
New value of Value function: 4.47385
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 97
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.46093
New value of Value function: 4.46093
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 98
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.44856
New value of Value function: 4.44856
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 99
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.43667
New value of Value function: 4.43667
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 100
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.42521
New value of Value function: 4.42521
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 101
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.41415
New value of Value function: 4.41415
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 102
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 2.53553
New value of Value function: 4.41415
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 103
----------
State: 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 2.33722
New value of Value function: 2.33722
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 104
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.464925
New value of Value function: 0.464925
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 105
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.40345
New value of Value function: 4.40345
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 106
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.39307
New value of Value function: 4.39307
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 107
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.38299
New value of Value function: 4.38299
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 108
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.37319
New value of Value function: 4.37319
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 109
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.36364
New value of Value function: 4.36364
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 110
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.35434
New value of Value function: 4.35434
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 111
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4.71695
New value of Value function: 4.71695
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 112
----------
State: 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 1.15816
New value of Value function: 1.15816
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 113
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.93176
New value of Value function: 4.93176
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 114
----------
State: 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 0.998976
New value of Value function: 0.998976
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 115
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 4.95735
New value of Value function: 4.95735
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 116
----------
State: 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 0.953378
New value of Value function: 0.953378
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 117
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.46974
New value of Value function: 4.95735
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 118
----------
State: 11741
	Distance: 11
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 4.95184
New value of Value function: 4.95184
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 119
----------
State: 10653
	Distance: 10
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10589
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0.953378
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 120
----------
State: 10589
	Distance: 10
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11613
	Distance: 11
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 121
----------
State: 11613
	Distance: 11
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10525
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 122
----------
State: 10525
	Distance: 10
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8413
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 123
----------
State: 8413
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7325
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 124
----------
State: 7325
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8413
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 125
----------
State: 8413
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7325
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 126
----------
State: 7325
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7325
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 127
----------
State: 7325
	Distance: 7
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9437
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 128
----------
State: 9437
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9437
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 129
----------
State: 9437
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9437
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 130
----------
State: 9437
	Distance: 9
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9501
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 131
----------
State: 9501
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9501
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 132
----------
State: 9501
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8477
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 133
----------
State: 8477
	Distance: 8
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9501
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 134
----------
State: 9501
	Distance: 9
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8413
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 2.17157
New value of Value function: 2.17157
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 135
----------
State: 8413
	Distance: 8
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8349
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.88675
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 136
----------
State: 8349
	Distance: 8
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.652372
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.36559
New value of Value function: 2.36559
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 3.4392
New value of Value function: 3.4392
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 139
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.35044
New value of Value function: 2.35044
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 140
----------
State: 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 6.25923
New value of Value function: 6.25923
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 141
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 10.8365
New value of Value function: 10.8365
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 142
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 9.45219
New value of Value function: 9.45219
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 143
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 9.42926
New value of Value function: 9.42926
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 144
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 9.40704
New value of Value function: 9.40704
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 145
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 9.38546
New value of Value function: 9.38546
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 146
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 6.75891
New value of Value function: 9.38546
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 147
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.7779
New value of Value function: 3.7779
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 148
----------
State: 10845
	Distance: 10
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.32693
New value of Value function: 4.32693
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 149
----------
State: 10781
	Distance: 10
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.2916
New value of Value function: 4.2916
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 150
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 9.36447
New value of Value function: 9.36447
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 151
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 9.34403
New value of Value function: 9.34403
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 152
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 9.32411
New value of Value function: 9.32411
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 153
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 9.30467
New value of Value function: 9.30467
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 154
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 9.28568
New value of Value function: 9.28568
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 155
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 9.26711
New value of Value function: 9.26711
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 156
----------
State: 11805
	Distance: 11
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 4
New value of Q matrix: 6.04387
New value of Value function: 9.26711
New value of Policy matrix: 4

=======================================
Episode: 2
Iteration: 157
----------
State: 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 158
----------
State: 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 159
----------
State: 9693
	Distance: 9
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.62101
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 160
----------
State: 10717
	Distance: 10
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -7
New value of Visit matrix: 6
New value of Q matrix: 1.79714
New value of Value function: 1.79714
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 161
----------
State: 11869
	Distance: 11
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.92855
New value of Value function: 10.8365
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 162
----------
State: 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.0041
New value of Value function: 6.25923
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 163
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 8.4503
New value of Value function: 8.4503
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 164
----------
State: 10909
	Distance: 10
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.08717
New value of Value function: 6.25923
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 165
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11037
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.07107
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 166
----------
State: 11037
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 13.3658
New value of Value function: 13.3658
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 167
----------
State: 10973
	Distance: 10
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11997
	Distance: 11
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 8.4503
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 168
----------
State: 11997
	Distance: 11
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 169
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 170
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 171
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 172
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 173
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 11037
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 3.87749
New value of Value function: 3.87749
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 174
----------
State: 11037
	Distance: 10
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9949
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 2
New value of Q matrix: 10.9858
New value of Value function: 10.9858
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 175
----------
State: 9949
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 176
----------
State: 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9949
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 177
----------
State: 9949
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 178
----------
State: 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 179
----------
State: 8989
	Distance: 8
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9949
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.02083
New value of Value function: 2.02083
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 180
----------
State: 9949
	Distance: 9
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.38104
New value of Value function: 4.38104
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 181
----------
State: 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 182
----------
State: 8861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 183
----------
State: 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 2
New value of Q matrix: -5.82115
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 184
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.71673
New value of Value function: 3.87749
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 185
----------
State: 10013
	Distance: 9
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 3.87749
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 186
----------
State: 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 187
----------
State: 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 2
Iteration: 188
----------
State: 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 2.49256
New value of Value function: 2.49256
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 189
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8025
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 4.19052
New value of Value function: 4.19052
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 190
----------
State: 8025
	Distance: 7
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.65799
New value of Value function: 9.65799
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 191
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 3.14431
New value of Value function: 3.14431
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 192
----------
State: 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.48182
New value of Value function: 4.48182
New value of Policy matrix: 3

=======================================
Episode: 2
Iteration: 193
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 2.82799
New value of Value function: 2.82799
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 194
----------
State: 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.79971
New value of Value function: 4.79971
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 195
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.844145
New value of Value function: 2.82799
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 196
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5977
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.53353
New value of Value function: 5.53353
New value of Policy matrix: 2

=======================================
Episode: 2
Iteration: 197
----------
State: 5977
	Distance: 5
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.404808
New value of Value function: 4.50018
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 4.17577
New value of Value function: 4.17577
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 199
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 2
Iteration: 200
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: -0.859538
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 1
----------
State: 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 2
----------
State: 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 3
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 4
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 5
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 6
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6741
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 7
----------
State: 6741
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 8
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 9
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 10
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 11
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 12
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 13
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 14
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 15
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 16
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 17
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 18
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 19
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 20
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 21
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 22
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 23
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 24
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 25
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 26
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 27
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 28
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 29
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 30
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 31
----------
State: 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 32
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 33
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 34
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6741
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 35
----------
State: 6741
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 36
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 37
----------
State: 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 38
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 39
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 40
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 41
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 42
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 43
----------
State: 7705
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6681
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 1.21268
New value of Value function: 1.21268
New value of Policy matrix: 4

=======================================
Episode: 3
Iteration: 44
----------
State: 6681
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 45
----------
State: 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 46
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 47
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 48
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6741
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 49
----------
State: 6741
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 50
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 51
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 52
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 53
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 54
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 55
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 56
----------
State: 5717
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5781
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 57
----------
State: 5781
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 58
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5777
	Distance: 5
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 59
----------
State: 5777
	Distance: 5
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 60
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 61
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 62
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 63
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 64
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 65
----------
State: 4817
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5841
	Distance: 5
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.82843
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 66
----------
State: 5841
	Distance: 5
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5777
	Distance: 5
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.99
New value of Value function: 4.99
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 67
----------
State: 5777
	Distance: 5
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4753
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.82843
New value of Value function: 3.82843
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 68
----------
State: 4753
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 69
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 70
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 71
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 72
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 73
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 74
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 75
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 76
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 77
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 78
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 79
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 80
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 81
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 82
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2885
	Distance: 2
	Angle: 13
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 83
----------
State: 2885
	Distance: 2
	Angle: 13
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 3

=======================================
Episode: 3
Iteration: 84
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 85
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 86
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.662767
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 87
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 88
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 89
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 90
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 91
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 92
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 93
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 94
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 95
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 96
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 97
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.356383
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 98
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.77097
New value of Value function: 6.77097
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 99
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 100
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 101
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 102
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 103
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 104
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 105
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 106
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 107
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 108
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 109
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 110
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 111
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 112
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 113
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4813
	Distance: 4
	Angle: 11
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 114
----------
State: 4813
	Distance: 4
	Angle: 11
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.70326
New value of Value function: 6.70326
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 115
----------
State: 3849
	Distance: 3
	Angle: 12
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.66464
New value of Value function: 7.66464
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 116
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3725
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 117
----------
State: 3725
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 118
----------
State: 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 119
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 120
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 121
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 122
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 123
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 124
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 125
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 126
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 127
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 128
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 129
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 130
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 131
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 3
Iteration: 132
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 2
	Angle: 11
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 133
----------
State: 2757
	Distance: 2
	Angle: 11
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 3
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 3
Iteration: 134
----------
State: 3717
	Distance: 3
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2693
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 3
Iteration: 135
----------
State: 2693
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3590
	Distance: 3
	Angle: 8
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 98
New value of Visit matrix: 1
New value of Q matrix: 98
New value of Value function: 98
New value of Policy matrix: 4

=======================================
Episode: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.16257
New value of Value function: 4.16257
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.15002
New value of Value function: 4.15002
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.59275
New value of Value function: 4.15002
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.45258
New value of Value function: 4.15002
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.13804
New value of Value function: 4.13804
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.12656
New value of Value function: 4.12656
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.0853
New value of Value function: 4.12656
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.11553
New value of Value function: 4.11553
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.10491
New value of Value function: 4.10491
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.09464
New value of Value function: 4.09464
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.08471
New value of Value function: 4.0853
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.904365
New value of Value function: 4.0853
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.05641
New value of Value function: 4.08471
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.07509
New value of Value function: 4.07509
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.06574
New value of Value function: 4.06574
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.05665
New value of Value function: 4.05665
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.04779
New value of Value function: 4.05641
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.03299
New value of Value function: 4.04779
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.03916
New value of Value function: 4.03916
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.03074
New value of Value function: 4.03299
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.01282
New value of Value function: 4.03074
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.02251
New value of Value function: 4.02251
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.01447
New value of Value function: 4.01447
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.57428
New value of Value function: 4.01447
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.67807
New value of Value function: 4.01447
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 2.08598
New value of Value function: 4.01447
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.0066
New value of Value function: 4.01282
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.99488
New value of Value function: 4.0066
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.74102
New value of Value function: 4.0066
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.99888
New value of Value function: 3.99888
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.78747
New value of Value function: 3.99888
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.98019
New value of Value function: 3.99888
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.99133
New value of Value function: 3.99133
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.96931
New value of Value function: 3.99133
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.98392
New value of Value function: 3.98392
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.28308
New value of Value function: 3.98392
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 2.47342
New value of Value function: 3.98392
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.97664
New value of Value function: 3.97664
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.9695
New value of Value function: 3.9695
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.96248
New value of Value function: 3.96931
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.95528
New value of Value function: 3.96248
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.95559
New value of Value function: 3.95559
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.9488
New value of Value function: 3.95528
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.9421
New value of Value function: 3.9488
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.94213
New value of Value function: 3.94213
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.8115
New value of Value function: 3.94213
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.93556
New value of Value function: 3.9421
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.92963
New value of Value function: 3.93556
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.92909
New value of Value function: 3.92963
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.91778
New value of Value function: 3.92909
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.92271
New value of Value function: 3.92271
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.90788
New value of Value function: 3.92271
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.91643
New value of Value function: 3.91643
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.91024
New value of Value function: 3.91024
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.82367
New value of Value function: 3.91024
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.78527
New value of Value function: 3.91024
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.90413
New value of Value function: 3.90788
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.89704
New value of Value function: 3.90413
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.89811
New value of Value function: 3.89811
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.89216
New value of Value function: 3.89704
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.88663
New value of Value function: 3.89216
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.8863
New value of Value function: 3.88663
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.10562
New value of Value function: 3.88663
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.87659
New value of Value function: 3.8863
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.8805
New value of Value function: 3.8805
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.87478
New value of Value function: 3.87659
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.8669
New value of Value function: 3.87478
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.86913
New value of Value function: 3.86913
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.82503
New value of Value function: 3.86913
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.86354
New value of Value function: 3.8669
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.85752
New value of Value function: 3.86354
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.85802
New value of Value function: 3.85802
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.31168
New value of Value function: 3.85802
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.82393
New value of Value function: 3.85802
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.85257
New value of Value function: 3.85752
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.84843
New value of Value function: 3.85257
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.84717
New value of Value function: 3.84843
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.8396
New value of Value function: 3.84717
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.84184
New value of Value function: 3.84184
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.83656
New value of Value function: 3.8396
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.83101
New value of Value function: 3.83656
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.83134
New value of Value function: 3.83134
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.82617
New value of Value function: 3.83101
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.82265
New value of Value function: 3.82617
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.82106
New value of Value function: 3.82393
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.81657
New value of Value function: 3.82265
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.8145
New value of Value function: 3.82106
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 2.7407
New value of Value function: 3.82106
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.816
New value of Value function: 3.81657
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.80936
New value of Value function: 3.816
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.44097
New value of Value function: 3.816
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.81099
New value of Value function: 3.8145
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.80323
New value of Value function: 3.8145
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.80655
New value of Value function: 3.81099
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.80603
New value of Value function: 3.80655
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.79878
New value of Value function: 3.80603
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.80112
New value of Value function: 3.80323
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.79629
New value of Value function: 3.80112
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.79625
New value of Value function: 3.79878
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.79118
New value of Value function: 3.79629
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 2.94423
New value of Value function: 3.79629
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.78947
New value of Value function: 3.79625
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.10388
New value of Value function: 3.79625
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.79143
New value of Value function: 3.79143
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.78665
New value of Value function: 3.79118
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.78375
New value of Value function: 3.78947
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.78277
New value of Value function: 3.78665
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.78192
New value of Value function: 3.78375
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.77647
New value of Value function: 3.78277
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.77619
New value of Value function: 3.78192
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.77723
New value of Value function: 3.77723
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.76989
New value of Value function: 3.77723
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.76947
New value of Value function: 3.77723
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.77258
New value of Value function: 3.77258
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.51952
New value of Value function: 3.77258
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.76797
New value of Value function: 3.76989
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.76351
New value of Value function: 3.76947
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.76247
New value of Value function: 3.76797
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.7634
New value of Value function: 3.76351
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.75724
New value of Value function: 3.7634
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.75577
New value of Value function: 3.7634
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.75887
New value of Value function: 3.75887
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.75438
New value of Value function: 3.75724
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.75106
New value of Value function: 3.75577
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.74902
New value of Value function: 3.75438
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.74992
New value of Value function: 3.75106
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.74498
New value of Value function: 3.74992
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.7455
New value of Value function: 3.74902
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.7424
New value of Value function: 3.7455
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.74112
New value of Value function: 3.74498
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.73898
New value of Value function: 3.7424
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.73588
New value of Value function: 3.74112
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.73036
New value of Value function: 3.74112
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.72586
New value of Value function: 3.74112
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.73677
New value of Value function: 3.73898
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.73307
New value of Value function: 3.73677
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.73245
New value of Value function: 3.73307
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.21778
New value of Value function: 3.73307
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.72724
New value of Value function: 3.73245
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.72074
New value of Value function: 3.73245
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.72817
New value of Value function: 3.72817
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.72392
New value of Value function: 3.72724
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.72149
New value of Value function: 3.72392
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.71971
New value of Value function: 3.72149
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.71581
New value of Value function: 3.72074
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.3058
New value of Value function: 3.72074
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.71462
New value of Value function: 3.71971
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.71079
New value of Value function: 3.71971
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.71552
New value of Value function: 3.71552
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.71137
New value of Value function: 3.71462
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.7076
New value of Value function: 3.71462
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.70859
New value of Value function: 3.71079
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.703
New value of Value function: 3.71079
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.37411
New value of Value function: 3.71079
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.70526
New value of Value function: 3.7076
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.70351
New value of Value function: 3.70526
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.42781
New value of Value function: 3.70526
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.6998
New value of Value function: 3.70351
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.69494
New value of Value function: 3.70351
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.69723
New value of Value function: 3.70351
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.69944
New value of Value function: 3.69944
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.69541
New value of Value function: 3.69723
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.69145
New value of Value function: 3.69541
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.68967
New value of Value function: 3.69541
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.6914
New value of Value function: 3.69145
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.46853
New value of Value function: 3.69145
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.68576
New value of Value function: 3.6914
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.55436
New value of Value function: 3.6914
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.68099
New value of Value function: 3.6914
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.68742
New value of Value function: 3.68967
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.6837
New value of Value function: 3.68967
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.6844
New value of Value function: 3.6844
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.57766
New value of Value function: 3.6844
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.67919
New value of Value function: 3.6837
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.50006
New value of Value function: 3.6837
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.67978
New value of Value function: 3.68099
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.59379
New value of Value function: 3.68099
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.67544
New value of Value function: 3.67978
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.67587
New value of Value function: 3.67919
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.67404
New value of Value function: 3.67587
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.52426
New value of Value function: 3.67587
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.672
New value of Value function: 3.67544
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.66996
New value of Value function: 3.67404
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.66894
New value of Value function: 3.672
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.66815
New value of Value function: 3.66996
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.66455
New value of Value function: 3.66894
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.6639
New value of Value function: 3.66815
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.54265
New value of Value function: 3.66815
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.66433
New value of Value function: 3.66455
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.6592
New value of Value function: 3.66433
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.66053
New value of Value function: 3.6639
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.55695
New value of Value function: 3.6639
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.65892
New value of Value function: 3.66053
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.6009
New value of Value function: 3.66053
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.65675
New value of Value function: 3.6592
New value of Policy matrix: 0

=======================================
Episode: 4
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.65392
New value of Value function: 3.65892
New value of Policy matrix: 3

=======================================
Episode: 4
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.65398
New value of Value function: 3.65675
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.56749
New value of Value function: 3.65675
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.6491
New value of Value function: 3.65675
New value of Policy matrix: 1

=======================================
Episode: 4
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.653
New value of Value function: 3.65398
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 1
----------
State: 6425
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 2
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 3
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5273
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 4
----------
State: 5273
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.617443
New value of Value function: 0.617443
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 56
New value of Q matrix: 3.56659
New value of Value function: 3.653
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 6
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 7
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 8
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 9
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 10
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 11
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5273
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.432232
New value of Value function: 0.432232
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 12
----------
State: 5273
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.616755
New value of Value function: 0.616755
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.60447
New value of Value function: 3.653
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.64927
New value of Value function: 3.64927
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.64557
New value of Value function: 3.6491
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.64394
New value of Value function: 3.64557
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.64188
New value of Value function: 3.64394
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.63884
New value of Value function: 3.64188
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.63822
New value of Value function: 3.63884
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.63465
New value of Value function: 3.63884
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.63379
New value of Value function: 3.63465
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.63103
New value of Value function: 3.63379
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.6288
New value of Value function: 3.63103
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.62416
New value of Value function: 3.63103
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.57197
New value of Value function: 3.63103
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.62019
New value of Value function: 3.63103
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.62743
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.61631
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.56985
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 57
New value of Q matrix: 3.59136
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 31
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.161735
New value of Value function: 0.432232
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 32
----------
State: 6361
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5273
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.535206
New value of Value function: 0.535206
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 33
----------
State: 5273
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.601977
New value of Value function: 0.601977
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.57508
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.60149
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.57765
New value of Value function: 3.62743
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.62386
New value of Value function: 3.62386
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.59087
New value of Value function: 3.62386
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.62031
New value of Value function: 3.62031
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.57867
New value of Value function: 3.62031
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.61677
New value of Value function: 3.61677
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.61326
New value of Value function: 3.61326
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.60977
New value of Value function: 3.60977
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.60629
New value of Value function: 3.60629
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.60284
New value of Value function: 3.60284
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.56945
New value of Value function: 3.60284
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.57682
New value of Value function: 3.60284
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.5994
New value of Value function: 3.60149
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.59363
New value of Value function: 3.5994
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.57475
New value of Value function: 3.5994
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.59599
New value of Value function: 3.59599
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.59259
New value of Value function: 3.59363
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.58597
New value of Value function: 3.59259
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.58641
New value of Value function: 3.59259
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.58921
New value of Value function: 3.58921
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.58585
New value of Value function: 3.58641
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.58178
New value of Value function: 3.58597
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.57849
New value of Value function: 3.58585
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.58251
New value of Value function: 3.58251
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.57918
New value of Value function: 3.58178
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.5772
New value of Value function: 3.57918
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.56605
New value of Value function: 3.57918
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.57587
New value of Value function: 3.57849
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.57282
New value of Value function: 3.57849
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.57119
New value of Value function: 3.5772
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.56967
New value of Value function: 3.5772
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.57266
New value of Value function: 3.57282
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.56437
New value of Value function: 3.57282
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.56954
New value of Value function: 3.57266
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.56815
New value of Value function: 3.56967
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.56429
New value of Value function: 3.56954
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.56628
New value of Value function: 3.56815
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.56369
New value of Value function: 3.56628
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.56304
New value of Value function: 3.56605
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.56145
New value of Value function: 3.56437
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.55738
New value of Value function: 3.56429
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.55898
New value of Value function: 3.56369
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.55927
New value of Value function: 3.56304
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.55982
New value of Value function: 3.56145
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.55689
New value of Value function: 3.55982
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.55661
New value of Value function: 3.55927
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.55489
New value of Value function: 3.55898
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.55373
New value of Value function: 3.55738
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.55053
New value of Value function: 3.55689
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.55344
New value of Value function: 3.55689
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.55079
New value of Value function: 3.55689
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.55237
New value of Value function: 3.55373
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.54854
New value of Value function: 3.55344
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.55026
New value of Value function: 3.55237
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.5479
New value of Value function: 3.55079
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.54387
New value of Value function: 3.55079
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.54649
New value of Value function: 3.55026
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.5471
New value of Value function: 3.54854
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.53815
New value of Value function: 3.54854
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.54342
New value of Value function: 3.5479
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.54238
New value of Value function: 3.5479
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.54346
New value of Value function: 3.5471
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.54395
New value of Value function: 3.54395
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.54082
New value of Value function: 3.54346
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.53907
New value of Value function: 3.54342
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.53836
New value of Value function: 3.54238
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.53815
New value of Value function: 3.54082
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.53492
New value of Value function: 3.54082
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.5377
New value of Value function: 3.53836
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.53336
New value of Value function: 3.53815
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.53395
New value of Value function: 3.53815
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.53169
New value of Value function: 3.5377
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.5346
New value of Value function: 3.53492
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.52863
New value of Value function: 3.53492
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.53061
New value of Value function: 3.5346
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.53151
New value of Value function: 3.53395
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.52979
New value of Value function: 3.53169
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.52535
New value of Value function: 3.53151
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.52843
New value of Value function: 3.53061
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.52632
New value of Value function: 3.52979
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.52566
New value of Value function: 3.52863
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.52373
New value of Value function: 3.52843
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.52233
New value of Value function: 3.52843
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.51966
New value of Value function: 3.52843
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.52537
New value of Value function: 3.52566
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.52156
New value of Value function: 3.52537
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.52233
New value of Value function: 3.52373
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.51889
New value of Value function: 3.52233
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.51399
New value of Value function: 3.52233
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.51812
New value of Value function: 3.52233
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.5193
New value of Value function: 3.52156
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.51749
New value of Value function: 3.5193
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.51628
New value of Value function: 3.51889
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.5141
New value of Value function: 3.51812
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.5099
New value of Value function: 3.51812
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.51395
New value of Value function: 3.51749
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.51346
New value of Value function: 3.51628
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.51008
New value of Value function: 3.51628
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.51328
New value of Value function: 3.51399
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.50796
New value of Value function: 3.51346
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.50945
New value of Value function: 3.51328
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.51028
New value of Value function: 3.51028
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.50731
New value of Value function: 3.51008
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.50523
New value of Value function: 3.51008
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.50597
New value of Value function: 3.50945
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.50548
New value of Value function: 3.50796
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.50203
New value of Value function: 3.50731
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.50434
New value of Value function: 3.50597
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.50189
New value of Value function: 3.50548
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.50153
New value of Value function: 3.50523
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.50147
New value of Value function: 3.50523
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.50059
New value of Value function: 3.50203
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.4962
New value of Value function: 3.50189
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.49785
New value of Value function: 3.50153
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.49762
New value of Value function: 3.50147
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.49853
New value of Value function: 3.50059
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.49415
New value of Value function: 3.50059
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.496
New value of Value function: 3.49853
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.49177
New value of Value function: 3.49853
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.4956
New value of Value function: 3.49762
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.49373
New value of Value function: 3.4962
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.49045
New value of Value function: 3.4956
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.49269
New value of Value function: 3.49415
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.49017
New value of Value function: 3.49373
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.48987
New value of Value function: 3.49269
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.48979
New value of Value function: 3.49177
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.48726
New value of Value function: 3.49045
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.48479
New value of Value function: 3.49017
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.48621
New value of Value function: 3.48987
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.48313
New value of Value function: 3.48987
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.48604
New value of Value function: 3.48979
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.48269
New value of Value function: 3.48979
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.4869
New value of Value function: 3.4869
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.48402
New value of Value function: 3.48604
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.48224
New value of Value function: 3.48479
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.48122
New value of Value function: 3.48479
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.47874
New value of Value function: 3.48479
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.47921
New value of Value function: 3.48313
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.4787
New value of Value function: 3.48269
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.4788
New value of Value function: 3.48122
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.47402
New value of Value function: 3.48122
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.47837
New value of Value function: 3.4788
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.47493
New value of Value function: 3.47874
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.47499
New value of Value function: 3.4787
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.47166
New value of Value function: 3.4787
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.47432
New value of Value function: 3.47837
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.47553
New value of Value function: 3.47553
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.4727
New value of Value function: 3.47493
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.47109
New value of Value function: 3.47432
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.46998
New value of Value function: 3.47402
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.4686
New value of Value function: 3.4727
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.46989
New value of Value function: 3.47166
New value of Policy matrix: 0

=======================================
Episode: 5
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.46795
New value of Value function: 3.47109
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.46728
New value of Value function: 3.46998
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.46379
New value of Value function: 3.46998
New value of Policy matrix: 4

=======================================
Episode: 5
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.46568
New value of Value function: 3.46989
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.46448
New value of Value function: 3.46989
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.46139
New value of Value function: 3.46989
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.46708
New value of Value function: 3.4686
New value of Policy matrix: 2

=======================================
Episode: 5
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.46324
New value of Value function: 3.46708
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.45835
New value of Value function: 3.46708
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.46158
New value of Value function: 3.46708
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.46429
New value of Value function: 3.46429
New value of Policy matrix: 1

=======================================
Episode: 5
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.4615
New value of Value function: 3.46379
New value of Policy matrix: 3

=======================================
Episode: 5
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.46003
New value of Value function: 3.46324
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 1
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 2
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 3
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 4
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 5
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10785
	Distance: 10
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 6
----------
State: 10785
	Distance: 10
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 7
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 8
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 9
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 10
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 11
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 12
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 13
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 14
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 15
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 16
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 17
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 18
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 19
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 20
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 21
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 22
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 23
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 24
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 25
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.025
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 26
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 27
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 28
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 29
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 30
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 31
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 32
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 33
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 34
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 35
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 36
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 37
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 38
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 39
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9953
	Distance: 9
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 40
----------
State: 9953
	Distance: 9
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8929
	Distance: 8
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 41
----------
State: 8929
	Distance: 8
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8929
	Distance: 8
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 42
----------
State: 8929
	Distance: 8
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9953
	Distance: 9
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 43
----------
State: 9953
	Distance: 9
	Angle: 11
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 7969
	Distance: 7
	Angle: 12
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 44
----------
State: 7969
	Distance: 7
	Angle: 12
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8033
	Distance: 7
	Angle: 13
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 45
----------
State: 8033
	Distance: 7
	Angle: 13
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 7
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -4.0399
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 46
----------
State: 8093
	Distance: 7
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8033
	Distance: 7
	Angle: 13
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 5.8255
New value of Value function: 5.8255
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 47
----------
State: 8033
	Distance: 7
	Angle: 13
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9057
	Distance: 8
	Angle: 13
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 48
----------
State: 9057
	Distance: 8
	Angle: 13
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8097
	Distance: 7
	Angle: 14
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 49
----------
State: 8097
	Distance: 7
	Angle: 14
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.428611
New value of Value function: 0.428611
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.45796
New value of Value function: 3.46158
New value of Policy matrix: 4

=======================================
Episode: 6
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.45735
New value of Value function: 3.4615
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 8093
	Distance: 7
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 156
New value of Q matrix: 3.8863
New value of Value function: 3.8863
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 53
----------
State: 8093
	Distance: 7
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 3
New value of Q matrix: 7.92828
New value of Value function: 7.92828
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 54
----------
State: 8029
	Distance: 7
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.74628
New value of Value function: 3.74628
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 55
----------
State: 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6045
	Distance: 5
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 56
----------
State: 6045
	Distance: 5
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 57
----------
State: 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 58
----------
State: 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 59
----------
State: 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 60
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -0.06
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 61
----------
State: 7005
	Distance: 6
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 62
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5981
	Distance: 5
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 63
----------
State: 5981
	Distance: 5
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6045
	Distance: 5
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -5.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 64
----------
State: 6045
	Distance: 5
	Angle: 14
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5981
	Distance: 5
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 5.53553
New value of Value function: 5.53553
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 65
----------
State: 5981
	Distance: 5
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 66
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5981
	Distance: 5
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.0246447
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 67
----------
State: 5981
	Distance: 5
	Angle: 13
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5917
	Distance: 5
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 4.53553
New value of Value function: 4.53553
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 68
----------
State: 5917
	Distance: 5
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 69
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7901
	Distance: 7
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 70
----------
State: 7901
	Distance: 7
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 71
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 72
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 73
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 74
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7965
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.53553
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 75
----------
State: 7965
	Distance: 7
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 76
----------
State: 6941
	Distance: 6
	Angle: 12
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7901
	Distance: 7
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 77
----------
State: 7901
	Distance: 7
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.04
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 78
----------
State: 8925
	Distance: 8
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 2
New value of Q matrix: 7.53553
New value of Value function: 7.53553
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 79
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 80
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 81
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 82
----------
State: 8861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 83
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 84
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10913
	Distance: 10
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 85
----------
State: 10913
	Distance: 10
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 86
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10913
	Distance: 10
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 87
----------
State: 10913
	Distance: 10
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 88
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10913
	Distance: 10
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 89
----------
State: 10913
	Distance: 10
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 90
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 91
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 92
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 93
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 94
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 95
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 96
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.025
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 97
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 98
----------
State: 8865
	Distance: 8
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 99
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.86562
New value of Value function: 2.86562
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 100
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 101
----------
State: 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9761
	Distance: 9
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 102
----------
State: 9761
	Distance: 9
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10785
	Distance: 10
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.0795
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 103
----------
State: 10785
	Distance: 10
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.99139
New value of Value function: 4.99139
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 104
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.92281
New value of Value function: 4.92281
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 105
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9761
	Distance: 9
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.53553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 106
----------
State: 9761
	Distance: 9
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 107
----------
State: 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 108
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 109
----------
State: 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 110
----------
State: 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 111
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 112
----------
State: 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 113
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 114
----------
State: 9697
	Distance: 9
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 115
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.8905
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 116
----------
State: 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 117
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 11745
	Distance: 11
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 4.8905
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 118
----------
State: 11745
	Distance: 11
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 11745
	Distance: 11
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 119
----------
State: 11745
	Distance: 11
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.84159
New value of Value function: 9.84159
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 120
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.8905
New value of Value function: 4.8905
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 121
----------
State: 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 5.88741
New value of Value function: 5.88741
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 122
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.85473
New value of Value function: 4.85473
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 123
----------
State: 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.8468
New value of Value function: 5.8468
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 124
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 4.82153
New value of Value function: 4.82153
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 125
----------
State: 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 5.81393
New value of Value function: 5.81393
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 126
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 4.79213
New value of Value function: 4.79213
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 127
----------
State: 10657
	Distance: 10
	Angle: 6
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 11745
	Distance: 11
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 5.78505
New value of Value function: 5.78505
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 128
----------
State: 11745
	Distance: 11
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.74421
New value of Value function: 9.84159
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 129
----------
State: 10721
	Distance: 10
	Angle: 7
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10785
	Distance: 10
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.94148
New value of Value function: 4.79213
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 130
----------
State: 10785
	Distance: 10
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.81279
New value of Value function: 3.81279
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 131
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.9811
New value of Value function: 4.9811
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 132
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.98778
New value of Value function: 4.98778
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 133
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 134
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 135
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 136
----------
State: 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 137
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 138
----------
State: 8733
	Distance: 8
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0211325
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 139
----------
State: 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 140
----------
State: 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 141
----------
State: 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 142
----------
State: 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 143
----------
State: 8737
	Distance: 8
	Angle: 8
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.50018
New value of Value function: 1.50018
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 144
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.4213
New value of Value function: 1.4213
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 145
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.5866
New value of Value function: 5.5866
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 146
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.21065
New value of Value function: 3.21065
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 147
----------
State: 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 148
----------
State: 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 149
----------
State: 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 150
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 151
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 152
----------
State: 8861
	Distance: 8
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 153
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 154
----------
State: 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 155
----------
State: 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 156
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 157
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 158
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 159
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 1.32861
New value of Value function: 1.32861
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 160
----------
State: 7837
	Distance: 7
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.70004
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 161
----------
State: 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 162
----------
State: 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 163
----------
State: 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 164
----------
State: 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.60546
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 165
----------
State: 6877
	Distance: 6
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 3.44251
New value of Value function: 3.44251
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 166
----------
State: 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 167
----------
State: 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 168
----------
State: 5853
	Distance: 5
	Angle: 11
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5789
	Distance: 5
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 169
----------
State: 5789
	Distance: 5
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.01
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 170
----------
State: 6813
	Distance: 6
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5789
	Distance: 5
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 171
----------
State: 5789
	Distance: 5
	Angle: 10
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5725
	Distance: 5
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 172
----------
State: 5725
	Distance: 5
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5661
	Distance: 5
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 173
----------
State: 5661
	Distance: 5
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5725
	Distance: 5
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 174
----------
State: 5725
	Distance: 5
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5725
	Distance: 5
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.98
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 175
----------
State: 5725
	Distance: 5
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5661
	Distance: 5
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 176
----------
State: 5661
	Distance: 5
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5597
	Distance: 5
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 177
----------
State: 5597
	Distance: 5
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5533
	Distance: 5
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 178
----------
State: 5533
	Distance: 5
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5469
	Distance: 5
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 179
----------
State: 5469
	Distance: 5
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5405
	Distance: 5
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 180
----------
State: 5405
	Distance: 5
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5469
	Distance: 5
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 181
----------
State: 5469
	Distance: 5
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4377
	Distance: 4
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 182
----------
State: 4377
	Distance: 4
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4313
	Distance: 4
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 183
----------
State: 4313
	Distance: 4
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5405
	Distance: 5
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.97
New value of Value function: 1.97
New value of Policy matrix: 3

=======================================
Episode: 6
Iteration: 1
----------
State: 5649
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5713
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 2
----------
State: 5713
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4689
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 3
----------
State: 4689
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 4
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5649
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 5
----------
State: 5649
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 6
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 7
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 8
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 9
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 10
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 11
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 12
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 13
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 14
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4621
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 15
----------
State: 4621
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 5649
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 16
----------
State: 5649
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 17
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3597
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 18
----------
State: 3597
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4621
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 19
----------
State: 4621
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4557
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 20
----------
State: 4557
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 21
----------
State: 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 22
----------
State: 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 23
----------
State: 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 24
----------
State: 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4561
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 25
----------
State: 4561
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 0

=======================================
Episode: 6
Iteration: 26
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4689
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 27
----------
State: 4689
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.50018
New value of Value function: 5.50018
New value of Policy matrix: 1

=======================================
Episode: 6
Iteration: 28
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3661
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.8453
New value of Value function: 3.8453
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 29
----------
State: 3661
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2629
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 6
Iteration: 30
----------
State: 2629
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2694
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 1
New value of Q matrix: 97
New value of Value function: 97
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.45755
New value of Value function: 3.46324
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.45796
New value of Value function: 3.4615
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.45873
New value of Value function: 3.46003
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.4563
New value of Value function: 3.45873
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.45597
New value of Value function: 3.45835
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.45474
New value of Value function: 3.45796
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.45275
New value of Value function: 3.45755
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.45336
New value of Value function: 3.4563
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.45259
New value of Value function: 3.45597
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.45322
New value of Value function: 3.45474
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.45116
New value of Value function: 3.45336
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.4492
New value of Value function: 3.45322
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.45048
New value of Value function: 3.45275
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.4476
New value of Value function: 3.45259
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.44891
New value of Value function: 3.45116
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.4476
New value of Value function: 3.45048
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.44775
New value of Value function: 3.4492
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.44529
New value of Value function: 3.4492
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.44508
New value of Value function: 3.44775
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.44504
New value of Value function: 3.4476
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.44407
New value of Value function: 3.4476
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.44252
New value of Value function: 3.44529
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.44166
New value of Value function: 3.44508
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.44099
New value of Value function: 3.44504
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.44233
New value of Value function: 3.44407
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.44055
New value of Value function: 3.44252
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.43965
New value of Value function: 3.44252
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.43749
New value of Value function: 3.44166
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.43712
New value of Value function: 3.44166
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.43717
New value of Value function: 3.44166
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.43805
New value of Value function: 3.44099
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.43694
New value of Value function: 3.43805
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.43446
New value of Value function: 3.43749
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.43253
New value of Value function: 3.43717
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.4337
New value of Value function: 3.43712
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.43444
New value of Value function: 3.43694
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.43291
New value of Value function: 3.43446
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.4279
New value of Value function: 3.43446
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.4309
New value of Value function: 3.43444
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 3.72272
New value of Value function: 3.72272
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 41
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 5
New value of Q matrix: 7.89688
New value of Value function: 7.89688
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 42
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -7
New value of Visit matrix: 7
New value of Q matrix: 3.75119
New value of Value function: 3.75119
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 43
----------
State: 7065
	Distance: 6
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 6
New value of Q matrix: 9.04684
New value of Value function: 9.04684
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 44
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 3.39782
New value of Value function: 3.39782
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 45
----------
State: 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.19861
New value of Value function: 5.19861
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 46
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.77845
New value of Value function: 3.39782
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 47
----------
State: 6041
	Distance: 5
	Angle: 14
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.29401
New value of Value function: 5.29401
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 48
----------
State: 7001
	Distance: 6
	Angle: 13
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.91188
New value of Value function: 5.91188
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 49
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 5.59262
New value of Value function: 5.59262
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 50
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.00212
New value of Value function: 4.04255
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 51
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.00212
New value of Value function: 4.04255
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 52
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.43343
New value of Value function: 4.43343
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 53
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 54
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 55
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.569156
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 56
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.64757
New value of Value function: 4.64757
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 57
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.493017
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 58
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.77217
New value of Value function: 4.77217
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 59
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 60
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 61
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 62
----------
State: 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 63
----------
State: 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 64
----------
State: 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6869
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.88675
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 65
----------
State: 6869
	Distance: 6
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 7897
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.30032
New value of Value function: 1.30032
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 66
----------
State: 7897
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 9
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 67
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 68
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 69
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 70
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 71
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 72
----------
State: 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4885
	Distance: 4
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 73
----------
State: 4885
	Distance: 4
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4949
	Distance: 4
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 74
----------
State: 4949
	Distance: 4
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 75
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 76
----------
State: 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4881
	Distance: 4
	Angle: 12
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 77
----------
State: 4881
	Distance: 4
	Angle: 12
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3981
	Distance: 3
	Angle: 14
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 78
----------
State: 3981
	Distance: 3
	Angle: 14
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.685489
New value of Value function: 0.685489
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3917
	Distance: 3
	Angle: 13
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 167
New value of Q matrix: 3.66679
New value of Value function: 3.66679
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 80
----------
State: 3917
	Distance: 3
	Angle: 13
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 81
----------
State: 4945
	Distance: 4
	Angle: 13
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 82
----------
State: 5909
	Distance: 5
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.72909
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 83
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 84
----------
State: 5845
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 85
----------
State: 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 86
----------
State: 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 87
----------
State: 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 88
----------
State: 6805
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 89
----------
State: 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8793
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 90
----------
State: 8793
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 91
----------
State: 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 92
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.8905
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 93
----------
State: 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.8905
New value of Value function: 5.95
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 94
----------
State: 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.37836
New value of Value function: 7.37836
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 95
----------
State: 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 96
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.36093
New value of Value function: 6.36093
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 97
----------
State: 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 5.80044
New value of Value function: 5.80044
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 98
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 99
----------
State: 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6681
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 100
----------
State: 6681
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 101
----------
State: 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.93489
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 102
----------
State: 6677
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 103
----------
State: 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.80685
New value of Value function: 8.80685
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 104
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.80685
New value of Value function: 3.8453
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 105
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.42265
New value of Value function: 4.42265
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 106
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 107
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 108
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 109
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 110
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 111
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 112
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 113
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 114
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 115
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 116
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 117
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 118
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 119
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 120
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 121
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.01
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 122
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.274577
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 123
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.465782
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 124
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 125
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 126
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 127
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 128
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 129
----------
State: 3529
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3465
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 130
----------
State: 3465
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3781
	Distance: 3
	Angle: 11
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 131
----------
State: 3781
	Distance: 3
	Angle: 11
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.95
New value of Value function: 3.95
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 132
----------
State: 4749
	Distance: 4
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.70004
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 133
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 2
	Angle: 11
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 134
----------
State: 2757
	Distance: 2
	Angle: 11
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2821
	Distance: 2
	Angle: 12
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 135
----------
State: 2821
	Distance: 2
	Angle: 12
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2821
	Distance: 2
	Angle: 12
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 136
----------
State: 2821
	Distance: 2
	Angle: 12
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.96
New value of Value function: 3.96
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 137
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2821
	Distance: 2
	Angle: 12
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.47925
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 138
----------
State: 2821
	Distance: 2
	Angle: 12
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.96
New value of Value function: 3.96
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 139
----------
State: 3785
	Distance: 3
	Angle: 11
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 4.44274
New value of Value function: 4.44274
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 140
----------
State: 3721
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 3
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.28053
New value of Value function: 3.28053
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 141
----------
State: 3717
	Distance: 3
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 4745
	Distance: 4
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 142
----------
State: 4745
	Distance: 4
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 143
----------
State: 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.12132
New value of Value function: 4.12132
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 144
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.919893
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 145
----------
State: 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.62863
New value of Value function: 4.62863
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 146
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 147
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 148
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 149
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 150
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 151
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 152
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 153
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 154
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 155
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 156
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 157
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 158
----------
State: 3657
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.564761
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 159
----------
State: 4685
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4621
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.99
New value of Value function: 4.62863
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 160
----------
State: 4621
	Distance: 4
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4557
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 161
----------
State: 4557
	Distance: 4
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 162
----------
State: 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 163
----------
State: 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 164
----------
State: 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 165
----------
State: 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 166
----------
State: 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 167
----------
State: 3469
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3401
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 168
----------
State: 3401
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4429
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 169
----------
State: 4429
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 4493
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 170
----------
State: 4493
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 0.95
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 171
----------
State: 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 4497
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.29289
New value of Value function: 4.29289
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 172
----------
State: 4497
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.249964
New value of Value function: 0.249964
New value of Policy matrix: 3

=======================================
Episode: 7
Iteration: 173
----------
State: 5585
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 6613
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.29289
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 174
----------
State: 6613
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 175
----------
State: 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 176
----------
State: 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 177
----------
State: 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 178
----------
State: 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 179
----------
State: 6549
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 6553
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 180
----------
State: 6553
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6553
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 181
----------
State: 6553
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6553
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 182
----------
State: 6553
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7641
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 183
----------
State: 7641
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 8793
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -5.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 184
----------
State: 8793
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 7.16511
New value of Value function: 7.16511
New value of Policy matrix: 0

=======================================
Episode: 7
Iteration: 185
----------
State: 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.33576
New value of Value function: 7.33576
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 186
----------
State: 7833
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.03909
New value of Value function: 9.03909
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 187
----------
State: 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 7.84047
New value of Value function: 7.84047
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 188
----------
State: 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.8505
New value of Value function: 6.95
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 189
----------
State: 7769
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 7961
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 190
----------
State: 7961
	Distance: 7
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.72445
New value of Value function: 9.72445
New value of Policy matrix: 4

=======================================
Episode: 7
Iteration: 191
----------
State: 6937
	Distance: 6
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 4.69368
New value of Value function: 4.69368
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 192
----------
State: 5973
	Distance: 5
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 5.74659
New value of Value function: 5.74659
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 193
----------
State: 5913
	Distance: 5
	Angle: 12
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.45288
New value of Value function: 4.45288
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 194
----------
State: 6873
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 9.47928
New value of Value function: 9.47928
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 195
----------
State: 6809
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 8.7528
New value of Value function: 8.7528
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 196
----------
State: 6745
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 6681
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 1

=======================================
Episode: 7
Iteration: 197
----------
State: 6681
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.0338
New value of Value function: 10.0338
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 198
----------
State: 5653
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.21101
New value of Value function: 9.21101
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 199
----------
State: 4625
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.12359
New value of Value function: 5.12359
New value of Policy matrix: 2

=======================================
Episode: 7
Iteration: 200
----------
State: 3593
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 4553
	Distance: 4
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: -1.88675
New value of Value function: 0.465782
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 1
----------
State: 11937
	Distance: 11
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 1
New value of Q matrix: 8
New value of Value function: 8
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 2
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 3
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 4
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 11873
	Distance: 11
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 5
----------
State: 11873
	Distance: 11
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 6
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 7
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 8
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 9
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 10
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 11
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 12
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 13
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 14
----------
State: 9889
	Distance: 9
	Angle: 10
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 15
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 16
----------
State: 10849
	Distance: 10
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 17
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 18
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 19
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 20
----------
State: 9825
	Distance: 9
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.52089
New value of Value function: 3.52089
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 21
----------
State: 8801
	Distance: 8
	Angle: 9
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 22
----------
State: 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 8797
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 23
----------
State: 8797
	Distance: 8
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 24
----------
State: 7773
	Distance: 7
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6749
	Distance: 6
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 25
----------
State: 6749
	Distance: 6
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 26
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 27
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6749
	Distance: 6
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 28
----------
State: 6749
	Distance: 6
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 29
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 30
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 31
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 32
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 33
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 34
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 35
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 36
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 37
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7709
	Distance: 7
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -1.58114
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 38
----------
State: 7709
	Distance: 7
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6749
	Distance: 6
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 39
----------
State: 6749
	Distance: 6
	Angle: 9
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 40
----------
State: 6685
	Distance: 6
	Angle: 8
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6621
	Distance: 6
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 41
----------
State: 6621
	Distance: 6
	Angle: 7
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6557
	Distance: 6
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 42
----------
State: 6557
	Distance: 6
	Angle: 6
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 43
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 44
----------
State: 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 45
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 46
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 47
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 48
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 49
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 50
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 51
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 52
----------
State: 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 53
----------
State: 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 54
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 55
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5405
	Distance: 5
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 56
----------
State: 5405
	Distance: 5
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5341
	Distance: 5
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 57
----------
State: 5341
	Distance: 5
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 4253
	Distance: 4
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 58
----------
State: 4253
	Distance: 4
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.630123
New value of Value function: 0.630123
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 5277
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 99
New value of Q matrix: 3.39011
New value of Value function: 3.66679
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 60
----------
State: 5277
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.9205
New value of Value function: 2.9205
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 61
----------
State: 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 62
----------
State: 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.14315
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 63
----------
State: 6493
	Distance: 6
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -8
New value of Visit matrix: 2
New value of Q matrix: -5.07107
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 64
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 65
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 66
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 67
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 68
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 69
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 70
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 2.99367
New value of Value function: 2.99367
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 71
----------
State: 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 3.6034
New value of Value function: 3.6034
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 72
----------
State: 7517
	Distance: 7
	Angle: 5
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 5.85526
New value of Value function: 5.85526
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 73
----------
State: 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.783565
New value of Value function: 0.783565
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 74
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.98308
New value of Value function: 2.98308
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 75
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.97314
New value of Value function: 2.97314
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 76
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.96374
New value of Value function: 2.96374
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 77
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.9548
New value of Value function: 2.9548
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 78
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.94627
New value of Value function: 2.94627
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 79
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.9381
New value of Value function: 2.9381
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 80
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.93025
New value of Value function: 2.93025
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 81
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.92268
New value of Value function: 2.92268
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 82
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 2.92268
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 83
----------
State: 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.77573
New value of Value function: 4.77573
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 84
----------
State: 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.508931
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 85
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.91538
New value of Value function: 2.91538
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 86
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.72797
New value of Value function: 5.72797
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 87
----------
State: 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5277
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.89129
New value of Value function: 4.77573
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 88
----------
State: 5277
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5277
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.89129
New value of Value function: 2.9205
New value of Policy matrix: 3

=======================================
Episode: 8
Iteration: 89
----------
State: 5277
	Distance: 5
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6301
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.68014
New value of Value function: 2.89129
New value of Policy matrix: 4

=======================================
Episode: 8
Iteration: 90
----------
State: 6301
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7389
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 91
----------
State: 7389
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6301
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 92
----------
State: 6301
	Distance: 6
	Angle: 2
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7389
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 93
----------
State: 7389
	Distance: 7
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.87872
New value of Value function: 6.87872
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 94
----------
State: 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 4.70146
New value of Value function: 4.70146
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 95
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 5.67598
New value of Value function: 5.67598
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 96
----------
State: 6365
	Distance: 6
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.65398
New value of Value function: 4.65398
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 97
----------
State: 7453
	Distance: 7
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.2857
New value of Value function: 5.2857
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 98
----------
State: 6429
	Distance: 6
	Angle: 4
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 5341
	Distance: 5
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 99
----------
State: 5341
	Distance: 5
	Angle: 3
	Height: 7
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.445564
New value of Value function: 0.445564
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.4565
New value of Value function: 3.66679
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.48081
New value of Value function: 3.66679
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.66396
New value of Value function: 3.66396
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.66114
New value of Value function: 3.66114
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.65834
New value of Value function: 3.65834
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.65554
New value of Value function: 3.65554
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.49997
New value of Value function: 3.65554
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.65275
New value of Value function: 3.65275
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.64997
New value of Value function: 3.64997
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.64721
New value of Value function: 3.64721
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.44945
New value of Value function: 3.64721
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.64445
New value of Value function: 3.64445
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.6417
New value of Value function: 3.6417
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.63896
New value of Value function: 3.63896
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.45264
New value of Value function: 3.63896
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.41135
New value of Value function: 3.63896
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.43038
New value of Value function: 3.63896
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.63624
New value of Value function: 3.63624
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.63352
New value of Value function: 3.63352
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.63081
New value of Value function: 3.63081
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.62811
New value of Value function: 3.62811
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.62542
New value of Value function: 3.62542
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.62274
New value of Value function: 3.62274
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.62007
New value of Value function: 3.62007
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.61741
New value of Value function: 3.61741
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.61476
New value of Value function: 3.61476
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.61212
New value of Value function: 3.61212
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.4448
New value of Value function: 3.61212
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.60948
New value of Value function: 3.60948
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.60686
New value of Value function: 3.60686
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.5097
New value of Value function: 3.60686
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.60424
New value of Value function: 3.60424
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.60163
New value of Value function: 3.60163
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.59903
New value of Value function: 3.59903
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 3.59644
New value of Value function: 3.59644
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 3.59386
New value of Value function: 3.59386
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.46058
New value of Value function: 3.59386
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.59128
New value of Value function: 3.59128
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 3.58872
New value of Value function: 3.58872
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 3.58616
New value of Value function: 3.58616
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 3.58361
New value of Value function: 3.58361
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.58107
New value of Value function: 3.58107
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.46922
New value of Value function: 3.58107
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 3.57854
New value of Value function: 3.57854
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 3.57602
New value of Value function: 3.57602
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.5735
New value of Value function: 3.5735
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.57099
New value of Value function: 3.57099
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.56849
New value of Value function: 3.56849
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 3.566
New value of Value function: 3.566
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 3.56352
New value of Value function: 3.56352
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.47518
New value of Value function: 3.56352
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 3.56104
New value of Value function: 3.56104
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 3.55857
New value of Value function: 3.55857
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.55611
New value of Value function: 3.55611
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 3.55365
New value of Value function: 3.55365
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 3.55121
New value of Value function: 3.55121
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 3.54877
New value of Value function: 3.54877
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 3.54634
New value of Value function: 3.54634
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 3.54391
New value of Value function: 3.54391
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 3.5415
New value of Value function: 3.5415
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 3.53909
New value of Value function: 3.53909
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 3.53668
New value of Value function: 3.53668
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 3.53429
New value of Value function: 3.53429
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.45798
New value of Value function: 3.53429
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3989
	Distance: 3
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 219
New value of Q matrix: 3.49819
New value of Value function: 3.5097
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 165
----------
State: 3989
	Distance: 3
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.474603
New value of Value function: 0.474603
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.50492
New value of Value function: 3.50492
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.5002
New value of Value function: 3.5002
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.49552
New value of Value function: 3.49819
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 3.49583
New value of Value function: 3.49583
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 3.49348
New value of Value function: 3.49552
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.49089
New value of Value function: 3.49348
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 3.49113
New value of Value function: 3.49113
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 3.48879
New value of Value function: 3.49089
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.48631
New value of Value function: 3.48879
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 3.48646
New value of Value function: 3.48646
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 3.48414
New value of Value function: 3.48631
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.48177
New value of Value function: 3.48414
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 226
New value of Q matrix: 3.45193
New value of Value function: 3.48177
New value of Policy matrix: 2

=======================================
Episode: 8
Iteration: 179
----------
State: 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 180
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 181
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 182
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 183
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 184
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -0.07
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 185
----------
State: 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 186
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -0.07
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 187
----------
State: 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 3
New value of Q matrix: 7
New value of Value function: 7
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 188
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 189
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0205025
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 190
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 191
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.00866539
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 192
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 193
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 194
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 195
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 196
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 197
----------
State: 2901
	Distance: 2
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2837
	Distance: 2
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 198
----------
State: 2837
	Distance: 2
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 3
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 8
Iteration: 199
----------
State: 3861
	Distance: 3
	Angle: 12
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3925
	Distance: 3
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Episode: 8
Iteration: 200
----------
State: 3925
	Distance: 3
	Angle: 13
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2965
	Distance: 2
	Angle: 14
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 4.93
New value of Value function: 4.93
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.47727
New value of Value function: 3.47727
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.44457
New value of Value function: 3.47727
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.47282
New value of Value function: 3.47518
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.47167
New value of Value function: 3.47282
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.46841
New value of Value function: 3.47167
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.46818
New value of Value function: 3.46841
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.46404
New value of Value function: 3.46818
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.46471
New value of Value function: 3.46471
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.46126
New value of Value function: 3.46404
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.45971
New value of Value function: 3.46126
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.45784
New value of Value function: 3.45971
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.45542
New value of Value function: 3.45798
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.45402
New value of Value function: 3.45784
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.45051
New value of Value function: 3.45784
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.44743
New value of Value function: 3.45784
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.45443
New value of Value function: 3.45542
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.44444
New value of Value function: 3.45542
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.45117
New value of Value function: 3.45443
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.45104
New value of Value function: 3.45193
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 3.44964
New value of Value function: 3.45117
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.44695
New value of Value function: 3.45104
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.44767
New value of Value function: 3.44964
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 3.44736
New value of Value function: 3.44767
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.44432
New value of Value function: 3.44736
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 3.44508
New value of Value function: 3.44695
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.44277
New value of Value function: 3.44508
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 3.44281
New value of Value function: 3.44457
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.4412
New value of Value function: 3.44444
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.44059
New value of Value function: 3.44432
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.44099
New value of Value function: 3.44281
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 3.44054
New value of Value function: 3.44277
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.43863
New value of Value function: 3.4412
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.43784
New value of Value function: 3.44099
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.43768
New value of Value function: 3.44059
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.43676
New value of Value function: 3.44054
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 3.43828
New value of Value function: 3.43863
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.43317
New value of Value function: 3.43863
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.43452
New value of Value function: 3.43828
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 3.43603
New value of Value function: 3.43784
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.4345
New value of Value function: 3.43768
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.43439
New value of Value function: 3.43603
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 3.43378
New value of Value function: 3.43452
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.43044
New value of Value function: 3.4345
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.42955
New value of Value function: 3.4345
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.43118
New value of Value function: 3.43439
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.43112
New value of Value function: 3.43378
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 3.43155
New value of Value function: 3.43155
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.42791
New value of Value function: 3.43155
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 3.42931
New value of Value function: 3.43112
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.42786
New value of Value function: 3.43044
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.4264
New value of Value function: 3.42955
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.42581
New value of Value function: 3.42931
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 3.42708
New value of Value function: 3.42791
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.42463
New value of Value function: 3.42786
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.42462
New value of Value function: 3.42708
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 3.42486
New value of Value function: 3.4264
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 3.42275
New value of Value function: 3.4264
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.42239
New value of Value function: 3.42581
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.42209
New value of Value function: 3.42463
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.42136
New value of Value function: 3.42462
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.4214
New value of Value function: 3.42275
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 3.42054
New value of Value function: 3.42239
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.41843
New value of Value function: 3.42239
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.41519
New value of Value function: 3.42239
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.41841
New value of Value function: 3.4214
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.41812
New value of Value function: 3.4214
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.41819
New value of Value function: 3.42054
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 3.41833
New value of Value function: 3.41841
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.41446
New value of Value function: 3.41833
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 3.41614
New value of Value function: 3.41819
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.41501
New value of Value function: 3.41812
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.41489
New value of Value function: 3.41614
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 3.41394
New value of Value function: 3.41519
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 3.41184
New value of Value function: 3.41519
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.41155
New value of Value function: 3.41501
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.41184
New value of Value function: 3.41489
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.41168
New value of Value function: 3.41446
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.41054
New value of Value function: 3.41184
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 3.40966
New value of Value function: 3.41184
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.4068
New value of Value function: 3.41184
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.40868
New value of Value function: 3.41168
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.40848
New value of Value function: 3.41155
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.40793
New value of Value function: 3.40966
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.40541
New value of Value function: 3.40966
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 3.40748
New value of Value function: 3.40868
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.40554
New value of Value function: 3.40793
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.40434
New value of Value function: 3.40748
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 3.40531
New value of Value function: 3.4068
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.40295
New value of Value function: 3.40554
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.40242
New value of Value function: 3.40541
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.40225
New value of Value function: 3.40531
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 3.40315
New value of Value function: 3.40434
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.40077
New value of Value function: 3.40315
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 3.401
New value of Value function: 3.40295
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.39912
New value of Value function: 3.40242
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.39932
New value of Value function: 3.40225
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.3991
New value of Value function: 3.401
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 3.39884
New value of Value function: 3.40077
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.39613
New value of Value function: 3.40077
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.39636
New value of Value function: 3.40077
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.39722
New value of Value function: 3.39912
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.39353
New value of Value function: 3.39912
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.39532
New value of Value function: 3.39884
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 3.3967
New value of Value function: 3.39722
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.3937
New value of Value function: 3.3967
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 3.39456
New value of Value function: 3.39613
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.39301
New value of Value function: 3.39532
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.39154
New value of Value function: 3.39456
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 3.39243
New value of Value function: 3.3937
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.3902
New value of Value function: 3.39353
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.39047
New value of Value function: 3.39301
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.38992
New value of Value function: 3.39243
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 3.3903
New value of Value function: 3.39154
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.38698
New value of Value function: 3.39154
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.3878
New value of Value function: 3.39047
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.38742
New value of Value function: 3.3903
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.38673
New value of Value function: 3.3903
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.38435
New value of Value function: 3.3903
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 3.38817
New value of Value function: 3.38817
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 3.38606
New value of Value function: 3.38742
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.38439
New value of Value function: 3.38698
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 3.384
New value of Value function: 3.38698
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.3833
New value of Value function: 3.38698
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.38391
New value of Value function: 3.38439
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.38138
New value of Value function: 3.38435
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.38066
New value of Value function: 3.384
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.37993
New value of Value function: 3.384
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 3.38189
New value of Value function: 3.38391
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.38086
New value of Value function: 3.38189
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.37672
New value of Value function: 3.38189
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 3.37979
New value of Value function: 3.38138
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.37838
New value of Value function: 3.38086
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.37783
New value of Value function: 3.38066
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.37699
New value of Value function: 3.37979
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.37498
New value of Value function: 3.37979
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 3.3777
New value of Value function: 3.37838
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.37539
New value of Value function: 3.3777
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.37342
New value of Value function: 3.3777
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 3.37561
New value of Value function: 3.37699
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.37335
New value of Value function: 3.37561
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 3.37352
New value of Value function: 3.37539
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.37242
New value of Value function: 3.37498
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.37197
New value of Value function: 3.37352
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 3.37144
New value of Value function: 3.37342
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.37005
New value of Value function: 3.37335
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.36973
New value of Value function: 3.37242
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.36946
New value of Value function: 3.37197
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.36638
New value of Value function: 3.37197
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.36898
New value of Value function: 3.37144
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 3.36937
New value of Value function: 3.37005
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.36669
New value of Value function: 3.36946
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.36652
New value of Value function: 3.36937
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 3.3673
New value of Value function: 3.36898
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.366
New value of Value function: 3.3673
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 3.36523
New value of Value function: 3.36669
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.36336
New value of Value function: 3.36652
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.36359
New value of Value function: 3.36638
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.36281
New value of Value function: 3.366
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.36304
New value of Value function: 3.36523
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 3.36317
New value of Value function: 3.36359
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.36067
New value of Value function: 3.36336
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.36005
New value of Value function: 3.36317
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 3.36112
New value of Value function: 3.36304
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.36009
New value of Value function: 3.36281
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.35926
New value of Value function: 3.36112
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 3.35907
New value of Value function: 3.36067
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.35777
New value of Value function: 3.36009
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.35715
New value of Value function: 3.36005
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.35675
New value of Value function: 3.35926
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.35574
New value of Value function: 3.35907
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 3.35702
New value of Value function: 3.35777
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.35488
New value of Value function: 3.35715
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.35423
New value of Value function: 3.35702
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 3.35498
New value of Value function: 3.35675
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.35348
New value of Value function: 3.35574
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.35224
New value of Value function: 3.35498
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 3.35295
New value of Value function: 3.35488
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.352
New value of Value function: 3.35423
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.35132
New value of Value function: 3.35348
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.35022
New value of Value function: 3.35295
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 3.35092
New value of Value function: 3.35224
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.34877
New value of Value function: 3.352
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.34914
New value of Value function: 3.35132
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.34843
New value of Value function: 3.35092
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 3.3489
New value of Value function: 3.35022
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.34698
New value of Value function: 3.34914
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.34629
New value of Value function: 3.3489
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 3.34688
New value of Value function: 3.34877
New value of Policy matrix: 2

=======================================
Episode: 9
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.34531
New value of Value function: 3.34843
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.34555
New value of Value function: 3.34698
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.34376
New value of Value function: 3.34688
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.3435
New value of Value function: 3.34688
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.34204
New value of Value function: 3.34688
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 3.34486
New value of Value function: 3.34555
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.34268
New value of Value function: 3.34486
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 196
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 3.34285
New value of Value function: 3.34376
New value of Policy matrix: 4

=======================================
Episode: 9
Iteration: 197
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.34056
New value of Value function: 3.3435
New value of Policy matrix: 3

=======================================
Episode: 9
Iteration: 198
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.34067
New value of Value function: 3.34285
New value of Policy matrix: 1

=======================================
Episode: 9
Iteration: 199
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 3.34085
New value of Value function: 3.34268
New value of Policy matrix: 0

=======================================
Episode: 9
Iteration: 200
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.33982
New value of Value function: 3.34204
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.33863
New value of Value function: 3.34085
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 3.33885
New value of Value function: 3.34067
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.33786
New value of Value function: 3.34056
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.33737
New value of Value function: 3.33982
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.33698
New value of Value function: 3.33885
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 139
New value of Q matrix: 3.3084
New value of Value function: 3.33885
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 7
----------
State: 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 8417
	Distance: 8
	Angle: 3
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 8
----------
State: 8417
	Distance: 8
	Angle: 3
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 9
----------
State: 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 10
----------
State: 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.305459
New value of Value function: 0.305459
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 140
New value of Q matrix: 3.30789
New value of Value function: 3.33885
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 12
----------
State: 7329
	Distance: 7
	Angle: 2
	Height: 8
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.305459
New value of Value function: 0.305459
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 3.33685
New value of Value function: 3.33863
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.33524
New value of Value function: 3.33786
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 3.33492
New value of Value function: 3.33786
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.33506
New value of Value function: 3.33737
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.3342
New value of Value function: 3.33524
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.33187
New value of Value function: 3.33506
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.33227
New value of Value function: 3.33492
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 3.33294
New value of Value function: 3.3342
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.33105
New value of Value function: 3.33294
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.32955
New value of Value function: 3.33294
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 3.33095
New value of Value function: 3.33187
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.32852
New value of Value function: 3.33105
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.32792
New value of Value function: 3.33095
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 3.32898
New value of Value function: 3.32955
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.32678
New value of Value function: 3.32898
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 3.32701
New value of Value function: 3.32852
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.32486
New value of Value function: 3.32852
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.32519
New value of Value function: 3.32701
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.32206
New value of Value function: 3.32701
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 3.32504
New value of Value function: 3.32678
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.32403
New value of Value function: 3.32504
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 3.32308
New value of Value function: 3.32486
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 3.32122
New value of Value function: 3.32486
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.32176
New value of Value function: 3.32403
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.32129
New value of Value function: 3.32206
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.31877
New value of Value function: 3.32176
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.31867
New value of Value function: 3.32129
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.31856
New value of Value function: 3.32122
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.31574
New value of Value function: 3.32122
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 3.31927
New value of Value function: 3.31927
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 3.31732
New value of Value function: 3.31867
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.31278
New value of Value function: 3.31867
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.31561
New value of Value function: 3.31856
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.31584
New value of Value function: 3.31732
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 3.31537
New value of Value function: 3.31584
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.31257
New value of Value function: 3.31584
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.31313
New value of Value function: 3.31537
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.30573
New value of Value function: 3.31537
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 3.31343
New value of Value function: 3.31343
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 3.3115
New value of Value function: 3.31313
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.31044
New value of Value function: 3.31278
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.30954
New value of Value function: 3.31257
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.30954
New value of Value function: 3.3115
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.30784
New value of Value function: 3.3115
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 3.30957
New value of Value function: 3.30957
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.3053
New value of Value function: 3.30957
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 3.30764
New value of Value function: 3.30954
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.30633
New value of Value function: 3.30954
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.30652
New value of Value function: 3.30764
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 3.30572
New value of Value function: 3.30652
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.30351
New value of Value function: 3.30633
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 3.30383
New value of Value function: 3.30633
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.30313
New value of Value function: 3.30573
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.30295
New value of Value function: 3.3053
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.30016
New value of Value function: 3.3053
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.30264
New value of Value function: 3.30383
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 3.30192
New value of Value function: 3.30351
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.30052
New value of Value function: 3.30295
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 3.30007
New value of Value function: 3.30295
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.30019
New value of Value function: 3.30264
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.29998
New value of Value function: 3.30052
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.29738
New value of Value function: 3.30052
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 3.29819
New value of Value function: 3.30052
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.29754
New value of Value function: 3.30019
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 3.2964
New value of Value function: 3.30019
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.29744
New value of Value function: 3.30016
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.297
New value of Value function: 3.29754
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.29471
New value of Value function: 3.29754
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.29458
New value of Value function: 3.29738
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.29475
New value of Value function: 3.297
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.29386
New value of Value function: 3.2964
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 3.29451
New value of Value function: 3.29475
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.29213
New value of Value function: 3.29471
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.29199
New value of Value function: 3.29458
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.2908
New value of Value function: 3.29458
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.29164
New value of Value function: 3.29451
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 3.29261
New value of Value function: 3.29261
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.28956
New value of Value function: 3.29261
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.28786
New value of Value function: 3.29261
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 3.29073
New value of Value function: 3.29199
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.28927
New value of Value function: 3.29164
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 3.28889
New value of Value function: 3.29164
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.2887
New value of Value function: 3.28956
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.28696
New value of Value function: 3.28927
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.28657
New value of Value function: 3.28889
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 3.28701
New value of Value function: 3.2887
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.28484
New value of Value function: 3.2887
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.28579
New value of Value function: 3.28701
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 3.28514
New value of Value function: 3.28696
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.28437
New value of Value function: 3.28657
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.28387
New value of Value function: 3.28579
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.28288
New value of Value function: 3.28514
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 3.28327
New value of Value function: 3.28484
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.28177
New value of Value function: 3.28437
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.28179
New value of Value function: 3.28387
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.28119
New value of Value function: 3.28327
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 3.2814
New value of Value function: 3.28288
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.27999
New value of Value function: 3.28179
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.27922
New value of Value function: 3.28177
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.27871
New value of Value function: 3.2814
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 3.27953
New value of Value function: 3.28119
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.27852
New value of Value function: 3.27999
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.27711
New value of Value function: 3.27953
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.27594
New value of Value function: 3.27953
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 3.27767
New value of Value function: 3.27922
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 3.2759
New value of Value function: 3.27922
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.27666
New value of Value function: 3.27871
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.27566
New value of Value function: 3.27711
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.27425
New value of Value function: 3.27666
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.27411
New value of Value function: 3.27594
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.27171
New value of Value function: 3.27594
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.27155
New value of Value function: 3.27594
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.2695
New value of Value function: 3.27594
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.2733
New value of Value function: 3.2759
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 3.27405
New value of Value function: 3.27566
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.27263
New value of Value function: 3.27405
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 3.27221
New value of Value function: 3.2733
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.26886
New value of Value function: 3.2733
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.27066
New value of Value function: 3.27263
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.26962
New value of Value function: 3.27221
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 3.27036
New value of Value function: 3.27066
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.26803
New value of Value function: 3.27036
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.2656
New value of Value function: 3.27036
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.26337
New value of Value function: 3.27036
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 3.26852
New value of Value function: 3.26962
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.26662
New value of Value function: 3.2695
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.26698
New value of Value function: 3.26886
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.26604
New value of Value function: 3.26852
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.26344
New value of Value function: 3.26852
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.26458
New value of Value function: 3.26852
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 3.26669
New value of Value function: 3.26669
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 3.26485
New value of Value function: 3.26662
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.26223
New value of Value function: 3.26662
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.26364
New value of Value function: 3.26485
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 3.26303
New value of Value function: 3.26364
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.26068
New value of Value function: 3.26344
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.26064
New value of Value function: 3.26337
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.26077
New value of Value function: 3.26303
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 3.2612
New value of Value function: 3.26223
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 152
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 3.25944
New value of Value function: 3.26223
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 153
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.25974
New value of Value function: 3.26077
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 154
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.25819
New value of Value function: 3.26068
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 155
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.25772
New value of Value function: 3.26064
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 156
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.25785
New value of Value function: 3.25974
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 157
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.25725
New value of Value function: 3.25944
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 158
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 3.25762
New value of Value function: 3.25819
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 159
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.25561
New value of Value function: 3.25785
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 160
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.2548
New value of Value function: 3.25785
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 161
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.25508
New value of Value function: 3.25762
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 162
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.2548
New value of Value function: 3.25762
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 163
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 3.25581
New value of Value function: 3.25581
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 164
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 3.254
New value of Value function: 3.25561
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 165
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.25305
New value of Value function: 3.25508
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 166
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 3.25226
New value of Value function: 3.25508
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 167
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.25232
New value of Value function: 3.2548
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 168
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.25234
New value of Value function: 3.2548
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 169
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.25188
New value of Value function: 3.25305
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 170
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 3.2505
New value of Value function: 3.25305
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 171
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.25049
New value of Value function: 3.25234
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 172
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.24957
New value of Value function: 3.25234
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 173
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.24988
New value of Value function: 3.25188
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 174
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.24897
New value of Value function: 3.2505
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 175
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 3.2487
New value of Value function: 3.25049
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 176
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.24794
New value of Value function: 3.24988
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 177
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.24686
New value of Value function: 3.24988
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 178
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.24556
New value of Value function: 3.24988
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 179
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.24743
New value of Value function: 3.24897
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 180
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.24607
New value of Value function: 3.2487
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 181
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 3.24691
New value of Value function: 3.24743
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 182
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.24499
New value of Value function: 3.24691
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 183
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 3.24512
New value of Value function: 3.24686
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 184
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.24414
New value of Value function: 3.24607
New value of Policy matrix: 2

=======================================
Episode: 10
Iteration: 185
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.24319
New value of Value function: 3.24556
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 186
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.2426
New value of Value function: 3.24556
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 187
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.24303
New value of Value function: 3.24512
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 188
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 3.24333
New value of Value function: 3.24414
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 189
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.24041
New value of Value function: 3.24414
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 190
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.24142
New value of Value function: 3.24333
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 191
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 3.24155
New value of Value function: 3.24303
New value of Policy matrix: 0

=======================================
Episode: 10
Iteration: 192
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.24051
New value of Value function: 3.2426
New value of Policy matrix: 3

=======================================
Episode: 10
Iteration: 193
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.24017
New value of Value function: 3.24155
New value of Policy matrix: 1

=======================================
Episode: 10
Iteration: 194
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 3.23977
New value of Value function: 3.24142
New value of Policy matrix: 4

=======================================
Episode: 10
Iteration: 195
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.23872
New value of Value function: 3.24051
New value of Policy matrix: 0

