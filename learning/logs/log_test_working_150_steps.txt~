=======================================
Simulation: 1
Iteration: 1
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 2.475
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.025
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.866583
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.45025
New value of Value function: 2.475
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.3
New value of Value function: 3.3
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.662437
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.53995
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.458292
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.81675
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.7125
New value of Value function: 3.7125
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.399964
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.356219
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.322194
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 44
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 46
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 49
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.525
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3.975
New value of Value function: 3.975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 55
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 56
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.025
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 60
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.62842
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.31175
New value of Value function: 3.975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.96762
New value of Value function: 3.975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.96762
New value of Value function: 3.975
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.96175
New value of Value function: 3.96175
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.35853
New value of Value function: 3.96175
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.61913
New value of Value function: 3.96175
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.94488
New value of Value function: 3.96175
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.14033
New value of Value function: 3.96175
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.27063
New value of Value function: 3.96175
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.95185
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.3623
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.91233
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.43105
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.91233
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.48453
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.52731
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.56231
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.59148
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.61616
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.63731
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.65565
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.67169
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.68585
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.69843
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.70969
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.71982
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.72899
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.73732
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.74493
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.7519
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.75832
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.76424
New value of Value function: 3.95185
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.94394
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.76944
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.77426
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.77875
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.78294
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.90841
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.78687
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.79054
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.90711
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.90646
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.794
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.90841
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.79725
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.80031
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.61619
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.8032
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.80594
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.80854
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.811
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.90607
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.80023
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.90711
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.81333
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.81556
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.81768
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.81969
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.82162
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.82346
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.82523
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.82691
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.82853
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.90581
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.90562
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.83008
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.83157
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.90646
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.833
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.83437
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.8357
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.90607
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.83697
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.8382
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.83938
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.90581
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.84052
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.84163
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.84269
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.84372
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.90548
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.84472
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.84568
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.90537
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.84662
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.84752
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.90562
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.8484
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.84925
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.85007
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 1
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 2
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.301501
New value of Value function: 0.301501
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.85087
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.85165
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.85241
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.85314
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.85385
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.85455
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.85522
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.85588
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.85652
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.85714
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.93827
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.85775
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.04563
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.85834
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.90548
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.85892
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.90537
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.90528
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.85948
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.86003
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.90528
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.86057
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.86109
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.8616
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.8621
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.86259
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.13151
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.90521
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.86306
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.86353
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.86398
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.90521
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.86443
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.86486
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.86529
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.86571
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.86612
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.86652
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.86691
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.20179
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.86729
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.86767
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.90515
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.9051
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.86804
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.8684
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.86875
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.90515
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.8691
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.86944
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.86977
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.8701
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.87042
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.87074
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.90506
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.87105
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.87135
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.87165
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.26035
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.9051
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.87194
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.87223
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.87251
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.87279
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.90506
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.87307
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.87333
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.8736
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.87386
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.87411
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.87436
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.87461
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.87485
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.3099
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.90502
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.87509
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.87533
New value of Value function: 3.94394
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.93737
New value of Value function: 3.93737
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.87551
New value of Value function: 3.93737
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.93174
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.87564
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.90424
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.87577
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.8759
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.87603
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.90422
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.35151
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.87615
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.87628
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.8764
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.87652
New value of Value function: 3.93174
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.92683
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.8766
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.87668
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.87676
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.87684
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.90318
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.87692
New value of Value function: 3.92683
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.92247
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.87696
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.87701
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.90201
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.87705
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.87709
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.87714
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.87718
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.87722
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.87726
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.8773
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.90096
New value of Value function: 3.92247
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.91854
New value of Value function: 3.91854
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.87731
New value of Value function: 3.91854
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.87733
New value of Value function: 3.91854
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.91498
New value of Value function: 3.91498
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.89964
New value of Value function: 3.91498
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.87732
New value of Value function: 3.91498
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.87731
New value of Value function: 3.91498
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.8773
New value of Value function: 3.91498
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.91172
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.87727
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.87724
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.87721
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.89829
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.87718
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.87715
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.87712
New value of Value function: 3.91172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.90871
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.38605
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.87707
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.87703
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 162
New value of Q matrix: 3.87161
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 134
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 135
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 136
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 137
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.434811
New value of Value function: 0.434811
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.41627
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.8716
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 164
New value of Q matrix: 3.86629
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 141
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 142
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.107616
New value of Value function: 0.107616
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 143
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.10654
New value of Value function: 0.434811
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 144
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1.08609
New value of Value function: 1.08609
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 145
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 146
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 147
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 148
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 149
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 150
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.07523
New value of Value function: 1.07523
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.86631
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.86633
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.86635
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.86637
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.86639
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.86641
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.86642
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.86644
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.9022
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.86646
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.86648
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.8665
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.86651
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.86653
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.86655
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.86657
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.86658
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.8666
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.89692
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.86662
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.86663
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.86665
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.86667
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.86668
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.8667
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.86671
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.86673
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.86674
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.86676
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.86677
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.90039
New value of Value function: 3.90871
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.90592
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 3.86677
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.89863
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 3.86677
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.89704
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 3.86678
New value of Value function: 3.90592
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.90331
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.86677
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.86675
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.89548
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.86674
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 3.86673
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 3.86672
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 3.86671
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.89406
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.89276
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 3.86669
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.89158
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.86668
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 3.86667
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.44262
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 3.86666
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.89544
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.89408
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 3.86665
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.46605
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 3.86664
New value of Value function: 3.90331
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.90087
New value of Value function: 3.90087
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 3.86661
New value of Value function: 3.90087
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 3.86659
New value of Value function: 3.90087
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 3.86657
New value of Value function: 3.90087
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 3.86655
New value of Value function: 3.90087
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.89858
New value of Value function: 3.89858
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.89641
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 3.86651
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 3.86647
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 3.86642
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 3.86638
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 3.86634
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 3.8663
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 3.86626
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 3.86623
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 3.86619
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.48665
New value of Value function: 3.89641
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.89436
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 3.86614
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 3.86609
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 3.86605
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 3.866
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 3.86595
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 3.86591
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 3.86586
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 3.86582
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 3.86577
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.89013
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 3.86573
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 3.86569
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 3.86564
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 3.8656
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 3.86556
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 3.86552
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 3.86547
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 3.86543
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 3.86539
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 3.86535
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.50509
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 3.86531
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 3.86527
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.52177
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 3.86523
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 3.86519
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 3.86515
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 3.86511
New value of Value function: 3.89436
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.89242
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.88879
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 3.86507
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 3.86504
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 3.865
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 3.86496
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 3.86492
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 3.86488
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 258
New value of Q matrix: 3.86153
New value of Value function: 3.89408
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 120
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 121
----------
State: 4729
	Distance: 8
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 122
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 123
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 124
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 125
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 126
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 127
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 128
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 129
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 130
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 131
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 132
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 133
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.833333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 134
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 135
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.714286
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 136
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 137
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.63125
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 138
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 139
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 140
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 141
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 142
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 143
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 144
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.92525
New value of Value function: 9.92525
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 145
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 146
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 147
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.826
New value of Value function: 4.826
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 148
----------
State: 5449
	Distance: 9
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.85149
New value of Value function: 9.85149
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 149
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.38887
New value of Value function: 4.826
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 150
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.89246
New value of Value function: 3.89246
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 3.8615
New value of Value function: 3.89246
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.53685
New value of Value function: 3.89246
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 3.86147
New value of Value function: 3.89246
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.88748
New value of Value function: 3.89246
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.89091
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 3.86144
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 3.86141
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 3.86138
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 3.86135
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 3.86132
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 3.86129
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 3.86126
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 3.86123
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 3.8612
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 270
New value of Q matrix: 3.86199
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 17
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.07523
New value of Value function: 1.08609
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 18
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.06448
New value of Value function: 1.08609
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 19
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.53224
New value of Value function: 1.07523
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 20
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.709653
New value of Value function: 1.07523
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 21
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 1.07523
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 22
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 23
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 24
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 25
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 26
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1.2129
New value of Value function: 1.2129
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 27
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 1.07523
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 28
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 29
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 30
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 31
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 32
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 33
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 34
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.833333
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 35
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 36
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 37
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 38
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 39
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.721429
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 40
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 41
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 0.714286
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 42
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 43
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 44
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.65
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 45
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.24375
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 46
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 47
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 48
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 49
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 50
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 1.79453
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 51
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.21087
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 52
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 53
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 54
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 55
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 56
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 57
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 58
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 59
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 60
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 61
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 62
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.799177
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 63
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 64
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 65
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 66
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 67
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 68
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 69
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 70
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 71
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 72
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 73
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 74
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 75
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 76
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 77
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 78
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.19877
New value of Value function: 1.19877
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 79
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 80
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.599383
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 81
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 82
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 83
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 84
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 85
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 86
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 87
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.70631
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 88
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 89
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 90
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.46262
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 91
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 92
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 93
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 94
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 95
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 96
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.93762
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 97
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.26708
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 98
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.876
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 99
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.876
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 100
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.876
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 101
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.90067
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 102
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 103
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.95505
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 104
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.11675
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 105
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.66931
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 106
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.876
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 107
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.25067
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 108
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 109
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 110
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 111
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 112
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.525
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 113
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.475
New value of Value function: 2.5
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 114
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.49167
New value of Value function: 2.49167
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 115
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.11875
New value of Value function: 3.11875
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 116
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.21872
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 117
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.495
New value of Value function: 3.495
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 118
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.99246
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 119
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 3.74583
New value of Value function: 3.74583
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 120
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.29162
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 121
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.74048
New value of Value function: 3.74048
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 122
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 3.89792
New value of Value function: 3.89792
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 123
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 124
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 125
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 126
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 127
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.49435
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 128
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 129
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 130
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 131
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 132
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 133
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 134
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 135
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 136
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 137
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 138
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.525
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 139
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.475
New value of Value function: 2.5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 140
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.7375
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 141
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 142
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 143
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 144
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 145
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 146
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 0.833333
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 147
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.5875
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 148
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.233312
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 149
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -1.42369
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 150
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 4.11204
New value of Value function: 4.11204
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 1
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.70012
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 2
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.925031
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 3
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.85006
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 4
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.51787
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 3.86196
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 3.86193
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 3.8619
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 3.86187
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 3.86184
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.88947
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.88813
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 3.86181
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 3.86178
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 3.86175
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 3.86172
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.8869
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 3.86169
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 3.86166
New value of Value function: 3.89242
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.89056
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 3.86163
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.88568
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 3.86159
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 3.86156
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 3.86152
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.8862
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 3.86149
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 3.86145
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 3.86142
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.55054
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 3.86138
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 3.86135
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.56308
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 3.86132
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 3.86128
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 3.86125
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.57463
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 3.86122
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 3.86119
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 3.86115
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.58528
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 3.86112
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.59515
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 3.86109
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 3.86106
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.60431
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 3.86103
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 3.861
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 3.86097
New value of Value function: 3.89056
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.88879
New value of Value function: 3.88879
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 3.86093
New value of Value function: 3.88879
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 3.86089
New value of Value function: 3.88879
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 3.86086
New value of Value function: 3.88879
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 3.86082
New value of Value function: 3.88879
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.8871
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 3.86078
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.88489
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 3.86074
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 3.8607
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 3.86066
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.88367
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.88253
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 3.86062
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 3.86058
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 3.86054
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 3.8605
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 3.86046
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 3.86042
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 3.86038
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 3.86035
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.61272
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 3.86031
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.62057
New value of Value function: 3.8871
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.88548
New value of Value function: 3.88568
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.88439
New value of Value function: 3.88548
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 3.88393
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 3.86026
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 3.86022
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 3.86017
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 3.86012
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 3.88245
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 3.86008
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 3.86003
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 3.85999
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 3.85995
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 3.8599
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.62783
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 3.85986
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 3.85982
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 3.85977
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.88137
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 3.85973
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 3.85969
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 3.85964
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 3.8596
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 3.85956
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 3.85952
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 3.85948
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 3.85944
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 3.8594
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 3.88109
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 3.85935
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 3.85931
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.63463
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 3.85927
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.88029
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 3.85923
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 3.85919
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 3.85916
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 3.85912
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 3.85908
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.64102
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.64704
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.65271
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 3.85904
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 3.859
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 3.85896
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 3.85892
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 3.85889
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 3.85885
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 3.85881
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.65807
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 3.85877
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 3.85874
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.87926
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 3.8587
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 3.85866
New value of Value function: 3.88439
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.88313
New value of Value function: 3.88313
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 3.85862
New value of Value function: 3.88313
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 3.85858
New value of Value function: 3.88313
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.88192
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 3.85854
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 3.8585
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 3.85846
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 365
New value of Q matrix: 3.85935
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 135
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0741736
New value of Value function: 1.19877
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 136
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.90062
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 137
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 0.127641
New value of Value function: 0.127641
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 138
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.382922
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 139
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.97
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 140
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.23579
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 141
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.11008
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 142
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.32506
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 143
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.39175
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 144
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.94175
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 145
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.9205
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 146
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.07975
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 147
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.657
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 148
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.876
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 149
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.9256
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 150
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.35697
New value of Value function: 1.35697
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 3.85931
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 3.85927
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 3.85922
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 369
New value of Q matrix: 3.85689
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 5
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 6
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 7
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 8
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 9
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 10
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 11
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 12
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.12636
New value of Value function: 5.12636
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 13
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0.127641
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 14
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.820817
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 15
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.12636
New value of Value function: 5.12636
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 16
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 0.122387
New value of Value function: 0.122387
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 17
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.0751
New value of Value function: 5.12636
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 18
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 19
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 3.9451
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 20
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0166667
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 21
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 22
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 23
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 24
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 25
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 26
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 27
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 28
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 29
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 30
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1.26868
New value of Value function: 1.26868
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 31
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.0817288
New value of Value function: 0.0817288
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 32
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 1.90405
New value of Value function: 1.90405
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 33
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.11499
New value of Value function: 0.0817288
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 34
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 2.35789
New value of Value function: 2.35789
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 35
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.934617
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 36
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.07092
New value of Value function: 9.07092
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 37
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.70084
New value of Value function: 3.70084
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 38
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 39
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 40
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 41
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.83191
New value of Value function: 1.83191
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 42
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 3.52927
New value of Value function: 3.52927
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 43
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.906798
New value of Value function: 1.83191
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 44
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.8136
New value of Value function: 1.83191
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 45
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.54801
New value of Value function: 2.54801
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 46
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.29673
New value of Value function: 8.29673
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 47
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.26127
New value of Value function: 2.54801
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 48
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.74089
New value of Value function: 3.74089
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 49
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.111596
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 50
----------
State: 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.70012
New value of Value function: 8.70012
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 51
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.650748
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 52
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.9477
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 3.85686
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 3.85682
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 3.85678
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 3.85675
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 3.85671
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 3.85667
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 3.85664
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 3.8566
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 3.85657
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 3.87973
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 3.85653
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 3.85649
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 3.85646
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 3.85642
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 3.85639
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 3.85635
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 3.85632
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.87823
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 3.85629
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 3.85625
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 3.85622
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 3.85618
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 3.85615
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 3.85612
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 3.85608
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 3.85605
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 3.85602
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 3.85599
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 3.85595
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 3.85592
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 3.85589
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.87725
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 3.85586
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 3.85582
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 3.85579
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 3.85576
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 3.85573
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 3.8557
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.87633
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 3.85567
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.66307
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 3.85564
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 3.85561
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 3.85558
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 3.85554
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 3.85551
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 3.85548
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 3.85545
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 3.85542
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 3.85539
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 3.85536
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 3.85534
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 3.85531
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 3.85528
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 3.85525
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 3.87847
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 3.85522
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 3.85519
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 3.85516
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.87546
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 3.85513
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 3.8551
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 3.85508
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 3.85505
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 3.85502
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.87463
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 3.85499
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.87384
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 3.85496
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 3.85494
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 3.85491
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 3.85488
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 3.85486
New value of Value function: 3.88192
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.88074
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.87306
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 3.85483
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 3.8548
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 3.85477
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 3.85474
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 3.85471
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 3.87725
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 3.85468
New value of Value function: 3.88074
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.8796
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 3.85465
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.87229
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 3.87607
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 3.87497
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.87156
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 3.85462
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 3.85458
New value of Value function: 3.8796
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.87849
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 3.85455
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 3.85452
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 3.85448
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.66772
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 3.85445
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 3.85442
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 3.85439
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 3.85435
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 3.85432
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 3.85429
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 3.8739
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 3.85426
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 3.85422
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.87084
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 3.85419
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 3.85416
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 3.85413
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 3.8541
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 458
New value of Q matrix: 3.85406
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 3.8729
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.87014
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 459
New value of Q matrix: 3.85403
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 460
New value of Q matrix: 3.85451
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 17
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.976821
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 18
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.58551
New value of Value function: 0.58551
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 19
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.36838
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 20
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 21
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.19877
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 22
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.274691
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 23
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.03645
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 24
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 4.11675
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 25
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 26
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.17894
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 27
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.20053
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 28
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.30047
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 29
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 30
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 31
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 32
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 33
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 34
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 35
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 36
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 37
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 38
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 39
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 40
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 41
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 42
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 43
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 44
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 45
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 46
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 47
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 48
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 49
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 50
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 51
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 52
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 53
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 54
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.35
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 55
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.65
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 56
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.55
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 57
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 58
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 0.714286
New value of Value function: 0.714286
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 59
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.35
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 60
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.235714
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 61
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 62
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.7
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 63
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.55
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 64
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.41429
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 65
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 66
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 67
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 68
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 69
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 70
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 71
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 72
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 73
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -4.725
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 74
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 75
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 76
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 77
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 78
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 79
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 80
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 81
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.167336
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 82
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.49398
New value of Value function: 3.52927
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 83
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.52633
New value of Value function: 3.52633
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 84
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.98303
New value of Value function: 3.52633
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 85
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.52362
New value of Value function: 3.52362
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 86
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 3.688
New value of Value function: 3.688
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 87
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.20625
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 88
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.20625
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 89
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.33
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 90
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.119458
New value of Value function: 0.833333
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 91
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.832143
New value of Value function: 0.832143
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 92
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.831103
New value of Value function: 0.831103
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 93
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1.165
New value of Value function: 1.165
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 94
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 95
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 96
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 97
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.209927
New value of Value function: 0.209927
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 3.85448
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 3.87195
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 3.85445
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 3.85442
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.67213
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 3.85439
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 3.85435
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 466
New value of Q matrix: 3.85432
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 467
New value of Q matrix: 3.85429
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.67631
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 468
New value of Q matrix: 3.85426
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 469
New value of Q matrix: 3.85423
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.86948
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 3.8542
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 3.85417
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 3.85414
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 3.85411
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 3.85408
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 3.85405
New value of Value function: 3.87849
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.87742
New value of Value function: 3.87742
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 3.85401
New value of Value function: 3.87742
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.86883
New value of Value function: 3.87742
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 3.87102
New value of Value function: 3.87742
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 3.85398
New value of Value function: 3.87742
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 3.85395
New value of Value function: 3.87742
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.87637
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 3.85392
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 3.85388
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 3.85385
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 3.85381
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 3.85378
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 3.85375
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 3.87012
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 3.85371
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 3.85368
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 3.85365
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 3.85362
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 3.85358
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 3.85355
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.86926
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 3.85352
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 3.85348
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 3.85345
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 3.85342
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 3.85339
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 3.85336
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 3.85333
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 3.85329
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 3.85326
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 3.85323
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.86818
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.86845
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 3.8532
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 3.85317
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 503
New value of Q matrix: 3.85147
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 3
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 4
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.418802
New value of Value function: 0.418802
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 3.85144
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 505
New value of Q matrix: 3.85058
New value of Value function: 3.87637
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 7
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0.418802
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 8
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 9
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 10
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 11
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 0.103654
New value of Value function: 0.103654
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 12
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0.418802
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 13
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 14
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 15
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 16
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 17
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 18
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.279201
New value of Value function: 0.279201
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 3.87535
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 506
New value of Q matrix: 3.84945
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 21
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0921365
New value of Value function: 0.279201
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 22
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.836595
New value of Value function: 0.836595
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 507
New value of Q matrix: 3.84797
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 24
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0513085
New value of Value function: 0.103654
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 25
----------
State: 4105
	Distance: 7
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1.09761
New value of Value function: 1.09761
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 26
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0734319
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 27
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.2426
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 28
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.15166
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 29
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0605814
New value of Value function: 0.122387
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 30
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.122275
New value of Value function: 0.122275
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 31
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.524586
New value of Value function: 0.524586
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 32
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.23402
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 33
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 34
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.2801
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 35
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.36989
New value of Value function: 4.975
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 36
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.95842
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 37
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.42378
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 38
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.93352
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 39
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.46489
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 40
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.438
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 41
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.55749
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 42
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -1.22313
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 43
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.33431
New value of Value function: 2.35789
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 44
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.65112
New value of Value function: 8.65112
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 45
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.65112
New value of Value function: 3.688
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 46
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.68554
New value of Value function: 3.68554
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 47
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.68666
New value of Value function: 3.68666
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 48
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.73153
New value of Value function: 3.73153
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 49
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.98523
New value of Value function: 2.98523
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 50
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 51
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 52
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 53
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 54
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 55
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 1.45002
New value of Value function: 1.45002
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 56
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.0678228
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 57
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.44795
New value of Value function: 1.44795
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 58
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.95537
New value of Value function: 2.95537
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 59
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.97533
New value of Value function: 2.97533
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 60
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 61
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 62
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.418297
New value of Value function: 0.418297
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 3.84795
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.68022
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 3.84793
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 3.84791
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 3.84788
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 3.84786
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 3.84784
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.86766
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 3.84782
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 3.8478
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 3.84777
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.68395
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.6875
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 3.84775
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.8669
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 3.84773
New value of Value function: 3.87535
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 3.87435
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 3.84771
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.86751
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 3.84768
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 3.84766
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 3.84764
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 3.84761
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.69086
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 3.84759
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 3.84757
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 3.84755
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 3.84752
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 3.8475
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 3.84748
New value of Value function: 3.87435
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 3.87339
New value of Value function: 3.87339
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 3.84745
New value of Value function: 3.87339
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 3.84743
New value of Value function: 3.87339
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 3.84741
New value of Value function: 3.87339
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 3.84738
New value of Value function: 3.87339
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 3.87244
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.69404
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 3.84736
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 3.84733
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 3.84731
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 3.84728
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.86684
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 3.84726
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 3.84723
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.69707
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.86619
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 3.84721
New value of Value function: 3.87244
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.87152
New value of Value function: 3.87152
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.87062
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.86553
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 3.84718
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 3.84715
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 3.84712
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 3.84709
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 3.84706
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 546
New value of Q matrix: 3.84704
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 547
New value of Q matrix: 3.84701
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 548
New value of Q matrix: 3.84698
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 3.84695
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 550
New value of Q matrix: 3.84693
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 3.8469
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 552
New value of Q matrix: 3.84687
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 553
New value of Q matrix: 3.84685
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.69994
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 3.84682
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 3.84679
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 3.84676
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 3.84674
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 558
New value of Q matrix: 3.84671
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 3.84669
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 3.84666
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 561
New value of Q matrix: 3.84663
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 3.84661
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.70269
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 3.84658
New value of Value function: 3.87062
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.86974
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 3.84655
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 3.84653
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 566
New value of Q matrix: 3.8465
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 3.84647
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 3.84644
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 3.86604
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 3.86523
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 3.84642
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 3.84639
New value of Value function: 3.86974
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.86888
New value of Value function: 3.86888
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 3.84636
New value of Value function: 3.86888
New value of Policy matrix: 4

=======================================
Simulation: 8
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.86804
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 1
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 2
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 3
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 4
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -4.79375
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 5
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 0.349398
New value of Value function: 0.349398
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 6
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 7
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 8
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -3.835
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 9
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.6541
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 10
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.34908
New value of Value function: 0.34908
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 11
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.348789
New value of Value function: 0.348789
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 12
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 0.706575
New value of Value function: 0.706575
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 13
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.30049
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 14
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.70607
New value of Value function: 0.70607
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 15
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.988999
New value of Value function: 0.988999
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 16
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.98955
New value of Value function: 2.98955
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 17
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.98838
New value of Value function: 0.98838
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 18
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.987799
New value of Value function: 0.987799
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 19
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.977921
New value of Value function: 0.987799
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 20
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.98725
New value of Value function: 0.98725
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 21
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.06564
New value of Value function: 1.06564
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 22
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 1.80417
New value of Value function: 1.80417
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 23
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -3.73148
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 24
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 2.26071
New value of Value function: 2.26071
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 25
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -3.59297
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 26
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.987437
New value of Value function: 2.26071
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 27
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 2.6291
New value of Value function: 2.6291
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 28
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.39719
New value of Value function: 0.209927
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 29
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 2.91563
New value of Value function: 2.91563
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 30
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.103914
New value of Value function: 0.209927
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 31
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.138552
New value of Value function: 0.209927
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 32
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.311253
New value of Value function: 0.311253
New value of Policy matrix: 0

=======================================
Simulation: 9
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 3.84633
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 3.8463
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.70528
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 3.84627
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 3.86442
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 3.84624
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.86485
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 3.84621
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 3.84618
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 3.84616
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 3.84613
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 3.8461
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 3.84607
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 3.84604
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.70776
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 3.84601
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 3.84598
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 3.84595
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 3.84593
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 3.8459
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 3.84587
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 3.84584
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 3.84581
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 3.84579
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 3.84576
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 3.84573
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 3.8457
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.86419
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 3.84568
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 3.84565
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 3.84562
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 3.84559
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.86355
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 3.84557
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 3.84554
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.86294
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 3.84551
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 3.84549
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 603
New value of Q matrix: 3.84546
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 604
New value of Q matrix: 3.84543
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 605
New value of Q matrix: 3.84541
New value of Value function: 3.86804
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.86722
New value of Value function: 3.86722
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.86641
New value of Value function: 3.86641
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 606
New value of Q matrix: 3.84538
New value of Value function: 3.86641
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.86562
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 3.86358
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 607
New value of Q matrix: 3.84535
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 608
New value of Q matrix: 3.84532
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 609
New value of Q matrix: 3.84529
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 610
New value of Q matrix: 3.84526
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 611
New value of Q matrix: 3.84523
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.86231
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 3.8452
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.7101
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 613
New value of Q matrix: 3.84517
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 3.84514
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 615
New value of Q matrix: 3.84511
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.8617
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 616
New value of Q matrix: 3.84508
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 617
New value of Q matrix: 3.84505
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 618
New value of Q matrix: 3.84502
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 619
New value of Q matrix: 3.84499
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 620
New value of Q matrix: 3.84496
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 621
New value of Q matrix: 3.84493
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 3.86279
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 622
New value of Q matrix: 3.8449
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 3.86202
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.71234
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 3.86129
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 623
New value of Q matrix: 3.84487
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 624
New value of Q matrix: 3.84485
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 625
New value of Q matrix: 3.84482
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 3.84479
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 627
New value of Q matrix: 3.84476
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 628
New value of Q matrix: 3.84473
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 629
New value of Q matrix: 3.8447
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 630
New value of Q matrix: 3.84467
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 3.84465
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 632
New value of Q matrix: 3.84462
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 633
New value of Q matrix: 3.84459
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.86111
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 634
New value of Q matrix: 3.84456
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 635
New value of Q matrix: 3.84454
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 3.84451
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 3.86059
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 637
New value of Q matrix: 3.84448
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 638
New value of Q matrix: 3.84445
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 3.84443
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 3.8444
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 641
New value of Q matrix: 3.84437
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 642
New value of Q matrix: 3.84434
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 643
New value of Q matrix: 3.84432
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 644
New value of Q matrix: 3.84429
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.85992
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 645
New value of Q matrix: 3.84426
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 646
New value of Q matrix: 3.84424
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 647
New value of Q matrix: 3.84421
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 648
New value of Q matrix: 3.84418
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 649
New value of Q matrix: 3.84416
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 650
New value of Q matrix: 3.84413
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 651
New value of Q matrix: 3.8441
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.86055
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.85999
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 652
New value of Q matrix: 3.84408
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 653
New value of Q matrix: 3.84405
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.85928
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 654
New value of Q matrix: 3.84403
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 655
New value of Q matrix: 3.844
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 656
New value of Q matrix: 3.84397
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 657
New value of Q matrix: 3.84395
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 658
New value of Q matrix: 3.84392
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.71451
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 659
New value of Q matrix: 3.8439
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 660
New value of Q matrix: 3.84387
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 3.84384
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 662
New value of Q matrix: 3.84418
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 149
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.557425
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 150
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.36838
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.24066
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 2
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.30842
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 3
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.22123
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 10
Iteration: 4
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.3447
New value of Value function: 2.3447
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 5
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.06208
New value of Value function: 1.06208
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 6
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.04656
New value of Value function: 2.04656
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 7
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -3.51558
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 8
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.0261
New value of Value function: 2.04656
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 9
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.21454
New value of Value function: 2.21454
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 3.12407
New value of Value function: 3.12407
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 11
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -3.33687
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 3.29461
New value of Value function: 3.29461
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 13
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -3.17702
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 14
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 3.43672
New value of Value function: 3.43672
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 15
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: -3.03344
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 16
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 3.55697
New value of Value function: 3.55697
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 17
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 18
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 19
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.15407
New value of Value function: 0.15407
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 20
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.310631
New value of Value function: 0.310631
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 21
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.310113
New value of Value function: 0.310113
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 22
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.383949
New value of Value function: 0.383949
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 3.84415
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 664
New value of Q matrix: 3.84413
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 3.8441
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 666
New value of Q matrix: 3.84407
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 667
New value of Q matrix: 3.84405
New value of Value function: 3.86562
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 3.86485
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 668
New value of Q matrix: 3.84402
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 669
New value of Q matrix: 3.844
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 670
New value of Q matrix: 3.84397
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 671
New value of Q matrix: 3.84394
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.85945
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 672
New value of Q matrix: 3.84392
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 673
New value of Q matrix: 3.84389
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 674
New value of Q matrix: 3.84386
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.85864
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 675
New value of Q matrix: 3.84384
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 676
New value of Q matrix: 3.84381
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 677
New value of Q matrix: 3.84378
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 678
New value of Q matrix: 3.84376
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 679
New value of Q matrix: 3.84373
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 680
New value of Q matrix: 3.84371
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 681
New value of Q matrix: 3.84368
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.85803
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 682
New value of Q matrix: 3.84366
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 683
New value of Q matrix: 3.84363
New value of Value function: 3.86485
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 3.86409
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.85742
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 684
New value of Q matrix: 3.8436
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.85684
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 685
New value of Q matrix: 3.84358
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 686
New value of Q matrix: 3.84355
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.85628
New value of Value function: 3.86409
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 3.86335
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 687
New value of Q matrix: 3.84352
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 688
New value of Q matrix: 3.8435
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 689
New value of Q matrix: 3.84347
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 690
New value of Q matrix: 3.84344
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 691
New value of Q matrix: 3.84341
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 692
New value of Q matrix: 3.84339
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 693
New value of Q matrix: 3.84336
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 694
New value of Q matrix: 3.84333
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 695
New value of Q matrix: 3.84331
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 696
New value of Q matrix: 3.84328
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 697
New value of Q matrix: 3.84325
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 698
New value of Q matrix: 3.84323
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 699
New value of Q matrix: 3.8432
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 700
New value of Q matrix: 3.84317
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 701
New value of Q matrix: 3.84315
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 702
New value of Q matrix: 3.84312
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 703
New value of Q matrix: 3.8431
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.8589
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 704
New value of Q matrix: 3.84307
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 705
New value of Q matrix: 3.84304
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 706
New value of Q matrix: 3.84302
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.85836
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 707
New value of Q matrix: 3.84299
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 708
New value of Q matrix: 3.84297
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 709
New value of Q matrix: 3.84294
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 710
New value of Q matrix: 3.84291
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 711
New value of Q matrix: 3.84289
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 712
New value of Q matrix: 3.84286
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 713
New value of Q matrix: 3.84284
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 714
New value of Q matrix: 3.84281
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 715
New value of Q matrix: 3.84279
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.85785
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.85734
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 716
New value of Q matrix: 3.84276
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 717
New value of Q matrix: 3.84274
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 718
New value of Q matrix: 3.84271
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 719
New value of Q matrix: 3.84269
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.71655
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.71851
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 720
New value of Q matrix: 3.84266
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.85573
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 721
New value of Q matrix: 3.84264
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 722
New value of Q matrix: 3.84261
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 723
New value of Q matrix: 3.84259
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.85519
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 724
New value of Q matrix: 3.84256
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.85468
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 725
New value of Q matrix: 3.84254
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 726
New value of Q matrix: 3.84251
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 727
New value of Q matrix: 3.84249
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 728
New value of Q matrix: 3.84246
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 729
New value of Q matrix: 3.84244
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 730
New value of Q matrix: 3.84242
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.72041
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 731
New value of Q matrix: 3.84239
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 732
New value of Q matrix: 3.84237
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 733
New value of Q matrix: 3.84234
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 734
New value of Q matrix: 3.84232
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 735
New value of Q matrix: 3.8423
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 736
New value of Q matrix: 3.84227
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 737
New value of Q matrix: 3.84225
New value of Value function: 3.86335
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 3.86262
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 738
New value of Q matrix: 3.84222
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 739
New value of Q matrix: 3.8422
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 740
New value of Q matrix: 3.84217
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 741
New value of Q matrix: 3.84215
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 742
New value of Q matrix: 3.84212
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.72223
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 743
New value of Q matrix: 3.8421
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.85416
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 744
New value of Q matrix: 3.84208
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 745
New value of Q matrix: 3.84205
New value of Value function: 3.86262
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 3.8619
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 746
New value of Q matrix: 3.84203
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 747
New value of Q matrix: 3.842
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.85366
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.72397
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 748
New value of Q matrix: 3.84198
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.85317
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 749
New value of Q matrix: 3.84195
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.85269
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 750
New value of Q matrix: 3.84193
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.85684
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 751
New value of Q matrix: 3.8419
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.85634
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.72565
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 752
New value of Q matrix: 3.84188
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 753
New value of Q matrix: 3.84185
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 754
New value of Q matrix: 3.84183
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 755
New value of Q matrix: 3.8418
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 756
New value of Q matrix: 3.84178
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 757
New value of Q matrix: 3.84175
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 758
New value of Q matrix: 3.84173
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 759
New value of Q matrix: 3.84202
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 150
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.881806
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 1
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.98869
New value of Value function: 3.68666
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 2
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 3
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 4
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 5
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 6
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -1.0484
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 7
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.461122
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 8
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.68449
New value of Value function: 3.68449
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 9
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.57081
New value of Value function: 3.68449
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 10
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.40343
New value of Value function: 3.68449
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 11
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.68245
New value of Value function: 3.68245
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 12
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 3.93713
New value of Value function: 3.93713
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 13
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.5672
New value of Value function: 3.5672
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 14
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.15898
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 15
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.48005
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 16
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.522
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 17
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 1.43466
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 760
New value of Q matrix: 3.842
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 761
New value of Q matrix: 3.84197
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 762
New value of Q matrix: 3.84195
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 763
New value of Q matrix: 3.84192
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 764
New value of Q matrix: 3.8419
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 765
New value of Q matrix: 3.84188
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 766
New value of Q matrix: 3.84185
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 767
New value of Q matrix: 3.84183
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 768
New value of Q matrix: 3.8418
New value of Value function: 3.8619
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 3.8612
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 769
New value of Q matrix: 3.84178
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.85585
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 770
New value of Q matrix: 3.84175
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 771
New value of Q matrix: 3.84173
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.85222
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 772
New value of Q matrix: 3.8417
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.85538
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 773
New value of Q matrix: 3.84168
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 774
New value of Q matrix: 3.84165
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 775
New value of Q matrix: 3.84163
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 776
New value of Q matrix: 3.84161
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 777
New value of Q matrix: 3.84158
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 778
New value of Q matrix: 3.84156
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.72727
New value of Value function: 3.8612
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 3.86051
New value of Value function: 3.86051
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 779
New value of Q matrix: 3.84153
New value of Value function: 3.86051
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.85491
New value of Value function: 3.86051
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 780
New value of Q matrix: 3.84151
New value of Value function: 3.86051
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 781
New value of Q matrix: 3.84148
New value of Value function: 3.86051
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 3.85983
New value of Value function: 3.85983
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 782
New value of Q matrix: 3.84145
New value of Value function: 3.85983
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 783
New value of Q matrix: 3.84143
New value of Value function: 3.85983
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 784
New value of Q matrix: 3.8414
New value of Value function: 3.85983
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.72881
New value of Value function: 3.85983
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 785
New value of Q matrix: 3.84138
New value of Value function: 3.85983
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 3.85917
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 786
New value of Q matrix: 3.84135
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 787
New value of Q matrix: 3.84132
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.85174
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 788
New value of Q matrix: 3.8413
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 789
New value of Q matrix: 3.84127
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.85126
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 790
New value of Q matrix: 3.84125
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 791
New value of Q matrix: 3.84122
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 792
New value of Q matrix: 3.84119
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.85081
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 793
New value of Q matrix: 3.84117
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 794
New value of Q matrix: 3.84114
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.73029
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 795
New value of Q matrix: 3.84112
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 796
New value of Q matrix: 3.84109
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.85036
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 797
New value of Q matrix: 3.84106
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 798
New value of Q matrix: 3.84104
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 799
New value of Q matrix: 3.84101
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 800
New value of Q matrix: 3.84099
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 801
New value of Q matrix: 3.84096
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 802
New value of Q matrix: 3.84094
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 803
New value of Q matrix: 3.84091
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 804
New value of Q matrix: 3.84089
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 805
New value of Q matrix: 3.84086
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 806
New value of Q matrix: 3.84084
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 807
New value of Q matrix: 3.84081
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 808
New value of Q matrix: 3.84079
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 809
New value of Q matrix: 3.84076
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 810
New value of Q matrix: 3.84074
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 811
New value of Q matrix: 3.84071
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 812
New value of Q matrix: 3.84069
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 813
New value of Q matrix: 3.84066
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 814
New value of Q matrix: 3.84064
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 815
New value of Q matrix: 3.84061
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.85443
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.84993
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 816
New value of Q matrix: 3.84059
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 817
New value of Q matrix: 3.84056
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 818
New value of Q matrix: 3.84054
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 819
New value of Q matrix: 3.84051
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 820
New value of Q matrix: 3.84049
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.84951
New value of Value function: 3.85917
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 3.85851
New value of Value function: 3.85851
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.84909
New value of Value function: 3.85851
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 821
New value of Q matrix: 3.84046
New value of Value function: 3.85851
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 822
New value of Q matrix: 3.84044
New value of Value function: 3.85851
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 823
New value of Q matrix: 3.84041
New value of Value function: 3.85851
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.84869
New value of Value function: 3.85851
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 3.85787
New value of Value function: 3.85787
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 824
New value of Q matrix: 3.84039
New value of Value function: 3.85787
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 825
New value of Q matrix: 3.84036
New value of Value function: 3.85787
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 3.85724
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 826
New value of Q matrix: 3.84034
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 827
New value of Q matrix: 3.84031
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 828
New value of Q matrix: 3.84029
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 829
New value of Q matrix: 3.84026
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.73169
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 830
New value of Q matrix: 3.84023
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 831
New value of Q matrix: 3.84021
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.73305
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 832
New value of Q matrix: 3.84018
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 833
New value of Q matrix: 3.84016
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 834
New value of Q matrix: 3.84013
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 835
New value of Q matrix: 3.8401
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 836
New value of Q matrix: 3.84008
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 837
New value of Q matrix: 3.84005
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 838
New value of Q matrix: 3.84003
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 839
New value of Q matrix: 3.84
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 840
New value of Q matrix: 3.83998
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 841
New value of Q matrix: 3.83995
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 842
New value of Q matrix: 3.83993
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 843
New value of Q matrix: 3.8399
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 844
New value of Q matrix: 3.83988
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 845
New value of Q matrix: 3.83985
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.84828
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.84788
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 846
New value of Q matrix: 3.83983
New value of Value function: 3.85724
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 3.85662
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 847
New value of Q matrix: 3.8398
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 848
New value of Q matrix: 3.83977
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 849
New value of Q matrix: 3.83975
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 850
New value of Q matrix: 3.83972
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 851
New value of Q matrix: 3.8397
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 852
New value of Q matrix: 3.83967
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 853
New value of Q matrix: 3.83965
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 854
New value of Q matrix: 3.83962
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 855
New value of Q matrix: 3.8396
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 856
New value of Q matrix: 3.83957
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 857
New value of Q matrix: 3.83983
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 144
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -1.55593
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 145
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0734319
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 146
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1.48157
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 147
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.204803
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 148
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 2.48178
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 149
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.617741
New value of Value function: 1.21087
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 150
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -1.03485
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 858
New value of Q matrix: 3.83981
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 859
New value of Q matrix: 3.83978
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.73436
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 860
New value of Q matrix: 3.83976
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.84748
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.73563
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 861
New value of Q matrix: 3.83973
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 862
New value of Q matrix: 3.83876
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 9
----------
State: 3525
	Distance: 6
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 10
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 11
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 12
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 13
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 14
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 15
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 16
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 17
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 18
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 19
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 20
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 21
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 22
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 23
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 24
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 25
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.2625
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 26
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 27
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -1.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 28
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 29
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 30
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 31
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.858333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 32
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 33
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 34
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 35
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.475
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 36
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 37
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 38
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 39
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 40
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 41
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 42
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 43
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 44
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 45
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 46
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 47
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 48
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 49
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 50
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 51
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 52
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 53
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 54
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 55
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 56
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 57
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 58
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 59
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 60
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 61
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 62
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 63
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 64
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 65
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 66
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 67
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 68
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.65
New value of Value function: 1.65
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 69
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.1945
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 70
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.3267
New value of Value function: 1.65
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 71
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0960882
New value of Value function: 1.65
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 72
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.475
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 73
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.25844
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 74
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.612562
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 75
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.9801
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 76
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 77
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 78
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 79
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 80
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 81
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 82
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 83
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 84
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 85
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 86
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 87
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 88
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 89
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 90
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 91
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 92
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 93
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 94
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 95
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 96
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 97
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 98
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 99
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 100
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 101
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 102
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 103
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 104
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 105
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 106
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.408375
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 107
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0673819
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 108
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.101073
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 109
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0808582
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 110
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.161716
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 111
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0808582
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 112
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.0673819
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 113
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 114
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 115
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 116
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 117
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 118
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 119
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 120
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 121
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 122
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 123
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 124
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 125
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 126
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.101073
New value of Value function: 0.101073
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 127
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0720505
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 128
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0200124
New value of Value function: 0.101073
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 129
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.050031
New value of Value function: 0.101073
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 130
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.016677
New value of Value function: 0.101073
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 131
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0200124
New value of Value function: 0.0200124
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 132
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.0171249
New value of Value function: 0.101073
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 133
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00990615
New value of Value function: 0.0200124
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 134
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.00990615
New value of Value function: 0.0200124
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 135
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0132082
New value of Value function: 0.0200124
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 136
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00396246
New value of Value function: 0.0200124
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 137
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.0066041
New value of Value function: 0.0200124
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 138
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.49245
New value of Value function: 2.49245
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 139
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.99545
New value of Value function: 4.99545
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 140
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.99167
New value of Value function: 4.99167
New value of Policy matrix: 0

=======================================
Simulation: 12
Iteration: 141
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.95881
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 142
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.33066
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 863
New value of Q matrix: 3.83873
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 864
New value of Q matrix: 3.83871
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 865
New value of Q matrix: 3.83869
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.84709
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 866
New value of Q matrix: 3.83866
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 867
New value of Q matrix: 3.83864
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 868
New value of Q matrix: 3.83861
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 869
New value of Q matrix: 3.83859
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 1
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.70002
New value of Value function: 1.70002
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 2
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.31698
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 3
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 1.09941
New value of Value function: 1.70002
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 4
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.31698
New value of Value function: 3.7125
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 5
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 1.94118
New value of Value function: 1.94118
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 6
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.06281
New value of Value function: 3.7125
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 7
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.70507
New value of Value function: 3.70507
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 8
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.175522
New value of Value function: 3.70507
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 9
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.6989
New value of Value function: 3.6989
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 10
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 3.88477
New value of Value function: 3.88477
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 11
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -0.405383
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 12
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.84592
New value of Value function: 3.88477
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 13
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 4.02417
New value of Value function: 4.02417
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 14
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.35076
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 15
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.300747
New value of Value function: 0.300747
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 16
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.0372175
New value of Value function: 0.300747
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 17
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.35113
New value of Value function: 0.300747
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 18
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.300146
New value of Value function: 0.300146
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 19
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.299645
New value of Value function: 0.299645
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 20
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 0.373703
New value of Value function: 0.373703
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 870
New value of Q matrix: 3.83857
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 871
New value of Q matrix: 3.83854
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 872
New value of Q matrix: 3.83852
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 873
New value of Q matrix: 3.8385
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 874
New value of Q matrix: 3.83847
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 875
New value of Q matrix: 3.83845
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 876
New value of Q matrix: 3.83843
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 877
New value of Q matrix: 3.8384
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.85393
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 878
New value of Q matrix: 3.83838
New value of Value function: 3.85662
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 3.856
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 879
New value of Q matrix: 3.83836
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 880
New value of Q matrix: 3.83833
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.73685
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.73803
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 881
New value of Q matrix: 3.83831
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 882
New value of Q matrix: 3.83829
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.85344
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 883
New value of Q matrix: 3.83826
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 884
New value of Q matrix: 3.83824
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 885
New value of Q matrix: 3.83821
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 886
New value of Q matrix: 3.83819
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 887
New value of Q matrix: 3.83817
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 888
New value of Q matrix: 3.83814
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 889
New value of Q matrix: 3.83812
New value of Value function: 3.856
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 3.8554
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 890
New value of Q matrix: 3.8381
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 891
New value of Q matrix: 3.83807
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 892
New value of Q matrix: 3.83805
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 893
New value of Q matrix: 3.83803
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.8467
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 894
New value of Q matrix: 3.838
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.85295
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 895
New value of Q matrix: 3.83798
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.73918
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 896
New value of Q matrix: 3.83796
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 897
New value of Q matrix: 3.83793
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 898
New value of Q matrix: 3.83791
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 899
New value of Q matrix: 3.83788
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 900
New value of Q matrix: 3.83786
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.85248
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 901
New value of Q matrix: 3.83784
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 902
New value of Q matrix: 3.83781
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.84632
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 903
New value of Q matrix: 3.83779
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 904
New value of Q matrix: 3.83777
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 905
New value of Q matrix: 3.83775
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.84594
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.84558
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 906
New value of Q matrix: 3.83772
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.85201
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 907
New value of Q matrix: 3.8377
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 908
New value of Q matrix: 3.83768
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 909
New value of Q matrix: 3.83765
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.85156
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 910
New value of Q matrix: 3.83763
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 911
New value of Q matrix: 3.83761
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 912
New value of Q matrix: 3.83758
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 913
New value of Q matrix: 3.83756
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.74029
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 914
New value of Q matrix: 3.83754
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 915
New value of Q matrix: 3.83752
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 916
New value of Q matrix: 3.83749
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 917
New value of Q matrix: 3.83747
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 918
New value of Q matrix: 3.83745
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 919
New value of Q matrix: 3.83743
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 920
New value of Q matrix: 3.8374
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 921
New value of Q matrix: 3.83738
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.84523
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 922
New value of Q matrix: 3.83736
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 923
New value of Q matrix: 3.83734
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.84488
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 924
New value of Q matrix: 3.83732
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 925
New value of Q matrix: 3.83729
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.85112
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 926
New value of Q matrix: 3.83727
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 927
New value of Q matrix: 3.83725
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 928
New value of Q matrix: 3.83723
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 929
New value of Q matrix: 3.83721
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 930
New value of Q matrix: 3.83718
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 931
New value of Q matrix: 3.83716
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 932
New value of Q matrix: 3.83714
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 933
New value of Q matrix: 3.83712
New value of Value function: 3.8554
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 3.85481
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 934
New value of Q matrix: 3.8371
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.85069
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.84454
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 935
New value of Q matrix: 3.83707
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.8442
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 936
New value of Q matrix: 3.83705
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 937
New value of Q matrix: 3.83703
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 938
New value of Q matrix: 3.83701
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 939
New value of Q matrix: 3.83698
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.85026
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 940
New value of Q matrix: 3.83696
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 941
New value of Q matrix: 3.83694
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 942
New value of Q matrix: 3.83692
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.74136
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 943
New value of Q matrix: 3.8369
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 944
New value of Q matrix: 3.83687
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 945
New value of Q matrix: 3.83685
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.84387
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 946
New value of Q matrix: 3.83683
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 947
New value of Q matrix: 3.83681
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.7424
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 948
New value of Q matrix: 3.83679
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 949
New value of Q matrix: 3.83677
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 950
New value of Q matrix: 3.83674
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.84985
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 951
New value of Q matrix: 3.83672
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 952
New value of Q matrix: 3.8367
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 953
New value of Q matrix: 3.83668
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 954
New value of Q matrix: 3.83666
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 955
New value of Q matrix: 3.83664
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.74341
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 956
New value of Q matrix: 3.83662
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 957
New value of Q matrix: 3.83659
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 958
New value of Q matrix: 3.83657
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.74439
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 959
New value of Q matrix: 3.83655
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 960
New value of Q matrix: 3.83653
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 961
New value of Q matrix: 3.83651
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 962
New value of Q matrix: 3.83649
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 963
New value of Q matrix: 3.83647
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.84355
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 964
New value of Q matrix: 3.83645
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 965
New value of Q matrix: 3.83643
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 966
New value of Q matrix: 3.83556
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 149
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 150
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 1
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.3194
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 2
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 4.08865
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 3
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 4
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.942
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 5
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.78628
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 6
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.438
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 7
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.409886
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 8
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0208781
New value of Value function: 0.0208781
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 9
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 4.16685
New value of Value function: 4.16685
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.56482
New value of Value function: 3.56482
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 11
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.57328
New value of Value function: 3.57328
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 12
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.38581
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 13
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.32127
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 14
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.416903
New value of Value function: 0.416903
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 15
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.516742
New value of Value function: 0.516742
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 967
New value of Q matrix: 3.83554
New value of Value function: 3.85481
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 3.85422
New value of Value function: 3.85422
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.84944
New value of Value function: 3.85422
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 968
New value of Q matrix: 3.83552
New value of Value function: 3.85422
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 969
New value of Q matrix: 3.8355
New value of Value function: 3.85422
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 3.85365
New value of Value function: 3.85365
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 970
New value of Q matrix: 3.83548
New value of Value function: 3.85365
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 3.85308
New value of Value function: 3.85308
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 971
New value of Q matrix: 3.83546
New value of Value function: 3.85308
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.84902
New value of Value function: 3.85308
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 3.85252
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 972
New value of Q matrix: 3.83543
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 973
New value of Q matrix: 3.83541
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 974
New value of Q matrix: 3.83539
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 975
New value of Q matrix: 3.83537
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.84861
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.84821
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.84781
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 976
New value of Q matrix: 3.83535
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.84743
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 977
New value of Q matrix: 3.83533
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 978
New value of Q matrix: 3.8353
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 979
New value of Q matrix: 3.83528
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 980
New value of Q matrix: 3.83526
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 981
New value of Q matrix: 3.83524
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 982
New value of Q matrix: 3.83522
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 983
New value of Q matrix: 3.83519
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 984
New value of Q matrix: 3.83517
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 985
New value of Q matrix: 3.83515
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 986
New value of Q matrix: 3.83513
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.74532
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 987
New value of Q matrix: 3.83511
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 988
New value of Q matrix: 3.83509
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 989
New value of Q matrix: 3.83507
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 990
New value of Q matrix: 3.83505
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 991
New value of Q matrix: 3.83502
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 992
New value of Q matrix: 3.835
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 993
New value of Q matrix: 3.83498
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 994
New value of Q matrix: 3.83496
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.74622
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 995
New value of Q matrix: 3.83494
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 996
New value of Q matrix: 3.83492
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 997
New value of Q matrix: 3.8349
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 998
New value of Q matrix: 3.83488
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 999
New value of Q matrix: 3.83486
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.84705
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.7471
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1000
New value of Q matrix: 3.83483
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1001
New value of Q matrix: 3.83481
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1002
New value of Q matrix: 3.83479
New value of Value function: 3.85252
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 3.85197
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1003
New value of Q matrix: 3.83477
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1004
New value of Q matrix: 3.83475
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1005
New value of Q matrix: 3.83473
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1006
New value of Q matrix: 3.83471
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1007
New value of Q matrix: 3.83469
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.74795
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1008
New value of Q matrix: 3.83467
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1009
New value of Q matrix: 3.83465
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.84668
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1010
New value of Q matrix: 3.83462
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1011
New value of Q matrix: 3.8346
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1012
New value of Q matrix: 3.83458
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.84631
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1013
New value of Q matrix: 3.83456
New value of Value function: 3.85197
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 3.85143
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1014
New value of Q matrix: 3.83454
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.8432
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1015
New value of Q matrix: 3.83452
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1016
New value of Q matrix: 3.8345
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.84285
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.84252
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1017
New value of Q matrix: 3.83448
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1018
New value of Q matrix: 3.83446
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1019
New value of Q matrix: 3.83443
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.84219
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1020
New value of Q matrix: 3.83441
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1021
New value of Q matrix: 3.83439
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1022
New value of Q matrix: 3.83437
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1023
New value of Q matrix: 3.83435
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1024
New value of Q matrix: 3.83433
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1025
New value of Q matrix: 3.83431
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1026
New value of Q matrix: 3.83429
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1027
New value of Q matrix: 3.83427
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1028
New value of Q matrix: 3.83425
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1029
New value of Q matrix: 3.83422
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1030
New value of Q matrix: 3.8342
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1031
New value of Q matrix: 3.83418
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.74878
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1032
New value of Q matrix: 3.83416
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.74958
New value of Value function: 3.85143
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 3.8509
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1033
New value of Q matrix: 3.83414
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1034
New value of Q matrix: 3.83412
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1035
New value of Q matrix: 3.8341
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1036
New value of Q matrix: 3.83408
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1037
New value of Q matrix: 3.83406
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1038
New value of Q matrix: 3.83404
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1039
New value of Q matrix: 3.83402
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1040
New value of Q matrix: 3.834
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1041
New value of Q matrix: 3.83397
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1042
New value of Q matrix: 3.83395
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1043
New value of Q matrix: 3.83393
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1044
New value of Q matrix: 3.83391
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1045
New value of Q matrix: 3.83389
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1046
New value of Q matrix: 3.83387
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.75035
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1047
New value of Q matrix: 3.83385
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.84595
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1048
New value of Q matrix: 3.83383
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1049
New value of Q matrix: 3.83381
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1050
New value of Q matrix: 3.83379
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1051
New value of Q matrix: 3.83377
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1052
New value of Q matrix: 3.83375
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1053
New value of Q matrix: 3.83373
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1054
New value of Q matrix: 3.83371
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1055
New value of Q matrix: 3.83331
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 133
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.414614
New value of Value function: 0.418802
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 134
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0734319
New value of Value function: 0.418802
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 135
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.715763
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 136
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.20914
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 137
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -0.576107
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 138
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.213501
New value of Value function: 0.524586
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 139
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.863098
New value of Value function: 0.863098
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 140
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.35503
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 141
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.3858
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 142
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.14922
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 143
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.70889
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 144
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.44007
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 145
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0208591
New value of Value function: 0.0208591
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 146
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.362886
New value of Value function: 0.362886
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 147
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.16487
New value of Value function: 4.16487
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 148
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 4.36362
New value of Value function: 4.36362
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 149
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.57118
New value of Value function: 3.57118
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 150
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.97346
New value of Value function: 3.57118
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 1
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 2
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 3
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 4
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 5
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 6
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 7
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 8
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 9
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 10
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 11
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 12
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 13
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 14
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 15
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 16
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 17
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 18
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 19
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 20
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 2.5
New value of Value function: 2.5
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 21
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 22
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.406193
New value of Value function: 0.406193
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1056
New value of Q matrix: 3.83329
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.84558
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1057
New value of Q matrix: 3.83327
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1058
New value of Q matrix: 3.83325
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1059
New value of Q matrix: 3.83323
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.84523
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1060
New value of Q matrix: 3.83321
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1061
New value of Q matrix: 3.83319
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1062
New value of Q matrix: 3.83317
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1063
New value of Q matrix: 3.83315
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1064
New value of Q matrix: 3.83313
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.84489
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1065
New value of Q matrix: 3.83311
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1066
New value of Q matrix: 3.8331
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1067
New value of Q matrix: 3.83308
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1068
New value of Q matrix: 3.83306
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1069
New value of Q matrix: 3.83304
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1070
New value of Q matrix: 3.83302
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1071
New value of Q matrix: 3.833
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.84186
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1072
New value of Q matrix: 3.83298
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1073
New value of Q matrix: 3.83296
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1074
New value of Q matrix: 3.83294
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1075
New value of Q matrix: 3.83292
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1076
New value of Q matrix: 3.8329
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1077
New value of Q matrix: 3.83288
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1078
New value of Q matrix: 3.83286
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1079
New value of Q matrix: 3.83285
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1080
New value of Q matrix: 3.83283
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.84154
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1081
New value of Q matrix: 3.83281
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1082
New value of Q matrix: 3.83279
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1083
New value of Q matrix: 3.83277
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1084
New value of Q matrix: 3.83275
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1085
New value of Q matrix: 3.83273
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1086
New value of Q matrix: 3.83271
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1087
New value of Q matrix: 3.8327
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1088
New value of Q matrix: 3.83268
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.84455
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1089
New value of Q matrix: 3.83266
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1090
New value of Q matrix: 3.83264
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1091
New value of Q matrix: 3.83262
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.75111
New value of Value function: 3.8509
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 3.85037
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1092
New value of Q matrix: 3.8326
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1093
New value of Q matrix: 3.83258
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1094
New value of Q matrix: 3.83256
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1095
New value of Q matrix: 3.83254
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1096
New value of Q matrix: 3.83253
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.84122
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.75184
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1097
New value of Q matrix: 3.83251
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1098
New value of Q matrix: 3.83249
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1099
New value of Q matrix: 3.83247
New value of Value function: 3.85037
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 3.84985
New value of Value function: 3.84985
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1100
New value of Q matrix: 3.83245
New value of Value function: 3.84985
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.8409
New value of Value function: 3.84985
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1101
New value of Q matrix: 3.83243
New value of Value function: 3.84985
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 3.84933
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1102
New value of Q matrix: 3.83241
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.8442
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1103
New value of Q matrix: 3.83239
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.75254
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1104
New value of Q matrix: 3.83237
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1105
New value of Q matrix: 3.83235
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1106
New value of Q matrix: 3.83233
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1107
New value of Q matrix: 3.83231
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1108
New value of Q matrix: 3.83229
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1109
New value of Q matrix: 3.83228
New value of Value function: 3.84933
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 3.84883
New value of Value function: 3.84883
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1110
New value of Q matrix: 3.83226
New value of Value function: 3.84883
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 3.84833
New value of Value function: 3.84833
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1111
New value of Q matrix: 3.83224
New value of Value function: 3.84833
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 3.84783
New value of Value function: 3.84783
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.84735
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1112
New value of Q matrix: 3.83221
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1113
New value of Q matrix: 3.83219
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1114
New value of Q matrix: 3.83217
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1115
New value of Q matrix: 3.83215
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1116
New value of Q matrix: 3.83213
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.75321
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1117
New value of Q matrix: 3.83211
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1118
New value of Q matrix: 3.83209
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1119
New value of Q matrix: 3.83207
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1120
New value of Q matrix: 3.83205
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1121
New value of Q matrix: 3.83203
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1122
New value of Q matrix: 3.83201
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1123
New value of Q matrix: 3.83199
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1124
New value of Q matrix: 3.83197
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.84384
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1125
New value of Q matrix: 3.83194
New value of Value function: 3.84735
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.84687
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1126
New value of Q matrix: 3.83192
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1127
New value of Q matrix: 3.8319
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1128
New value of Q matrix: 3.83188
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.75385
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1129
New value of Q matrix: 3.83186
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1130
New value of Q matrix: 3.83184
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1131
New value of Q matrix: 3.83182
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1132
New value of Q matrix: 3.8318
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1133
New value of Q matrix: 3.83178
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.84056
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1134
New value of Q matrix: 3.83176
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1135
New value of Q matrix: 3.83174
New value of Value function: 3.84687
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.84639
New value of Value function: 3.84639
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1136
New value of Q matrix: 3.83172
New value of Value function: 3.84639
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1137
New value of Q matrix: 3.8317
New value of Value function: 3.84639
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1138
New value of Q matrix: 3.83167
New value of Value function: 3.84639
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.84592
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1139
New value of Q matrix: 3.83165
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1140
New value of Q matrix: 3.83092
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 134
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 135
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 136
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 137
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -3.33333
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 138
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 139
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 140
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.269155
New value of Value function: 0.269155
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.84022
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1141
New value of Q matrix: 3.8309
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1142
New value of Q matrix: 3.83088
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1143
New value of Q matrix: 3.83039
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 145
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.268482
New value of Value function: 0.268482
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 146
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 0.376278
New value of Value function: 0.376278
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1144
New value of Q matrix: 3.83037
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1145
New value of Q matrix: 3.82997
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 149
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.372515
New value of Value function: 0.376278
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 150
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.66126
New value of Value function: 2.66126
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1146
New value of Q matrix: 3.82995
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1147
New value of Q matrix: 3.82993
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.83988
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1148
New value of Q matrix: 3.82991
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1149
New value of Q matrix: 3.82989
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1150
New value of Q matrix: 3.82987
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1151
New value of Q matrix: 3.82985
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1152
New value of Q matrix: 3.82983
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1153
New value of Q matrix: 3.82981
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1154
New value of Q matrix: 3.82979
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1155
New value of Q matrix: 3.82977
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1156
New value of Q matrix: 3.82975
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1157
New value of Q matrix: 3.82974
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1158
New value of Q matrix: 3.82972
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1159
New value of Q matrix: 3.8297
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.83955
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.84347
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1160
New value of Q matrix: 3.82968
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1161
New value of Q matrix: 3.82966
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1162
New value of Q matrix: 3.82964
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.75447
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1163
New value of Q matrix: 3.82962
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.84311
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1164
New value of Q matrix: 3.8296
New value of Value function: 3.84592
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.84546
New value of Value function: 3.84546
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1165
New value of Q matrix: 3.82958
New value of Value function: 3.84546
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.845
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1166
New value of Q matrix: 3.82956
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1167
New value of Q matrix: 3.82954
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1168
New value of Q matrix: 3.82952
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1169
New value of Q matrix: 3.8295
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1170
New value of Q matrix: 3.82948
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1171
New value of Q matrix: 3.82946
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1172
New value of Q matrix: 3.82944
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.84275
New value of Value function: 3.845
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.84455
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1173
New value of Q matrix: 3.82942
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1174
New value of Q matrix: 3.8294
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1175
New value of Q matrix: 3.82939
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1176
New value of Q matrix: 3.82937
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1177
New value of Q matrix: 3.82935
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1178
New value of Q matrix: 3.82933
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1179
New value of Q matrix: 3.82931
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1180
New value of Q matrix: 3.82929
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1181
New value of Q matrix: 3.82927
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.83921
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1182
New value of Q matrix: 3.82925
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1183
New value of Q matrix: 3.82923
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.83888
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1184
New value of Q matrix: 3.82921
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1185
New value of Q matrix: 3.82919
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1186
New value of Q matrix: 3.82917
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1187
New value of Q matrix: 3.82915
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1188
New value of Q matrix: 3.82913
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1189
New value of Q matrix: 3.82911
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.83855
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1190
New value of Q matrix: 3.82909
New value of Value function: 3.84455
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.8441
New value of Value function: 3.8441
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.75505
New value of Value function: 3.8441
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1191
New value of Q matrix: 3.82907
New value of Value function: 3.8441
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.83823
New value of Value function: 3.8441
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1192
New value of Q matrix: 3.82905
New value of Value function: 3.8441
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.84366
New value of Value function: 3.84366
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1193
New value of Q matrix: 3.82903
New value of Value function: 3.84366
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1194
New value of Q matrix: 3.82901
New value of Value function: 3.84366
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1195
New value of Q matrix: 3.82899
New value of Value function: 3.84366
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1196
New value of Q matrix: 3.82897
New value of Value function: 3.84366
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1197
New value of Q matrix: 3.82895
New value of Value function: 3.84366
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.84322
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.83791
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1198
New value of Q matrix: 3.82893
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1199
New value of Q matrix: 3.82891
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1200
New value of Q matrix: 3.82889
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1201
New value of Q matrix: 3.82887
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1202
New value of Q matrix: 3.82885
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.83759
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1203
New value of Q matrix: 3.82883
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1204
New value of Q matrix: 3.82881
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1205
New value of Q matrix: 3.82879
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1206
New value of Q matrix: 3.82877
New value of Value function: 3.84322
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.84279
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1207
New value of Q matrix: 3.82875
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1208
New value of Q matrix: 3.82873
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1209
New value of Q matrix: 3.82871
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.83727
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1210
New value of Q matrix: 3.82869
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1211
New value of Q matrix: 3.82867
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1212
New value of Q matrix: 3.82865
New value of Value function: 3.84279
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.84236
New value of Value function: 3.84275
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1213
New value of Q matrix: 3.82863
New value of Value function: 3.84275
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1214
New value of Q matrix: 3.82861
New value of Value function: 3.84275
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.7556
New value of Value function: 3.84275
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.83696
New value of Value function: 3.84275
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.75614
New value of Value function: 3.84275
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.84237
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1215
New value of Q matrix: 3.82859
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1216
New value of Q matrix: 3.82857
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1217
New value of Q matrix: 3.82855
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1218
New value of Q matrix: 3.82853
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1219
New value of Q matrix: 3.82851
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1220
New value of Q matrix: 3.82849
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.84194
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1221
New value of Q matrix: 3.82847
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1222
New value of Q matrix: 3.82845
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1223
New value of Q matrix: 3.82843
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1224
New value of Q matrix: 3.82841
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1225
New value of Q matrix: 3.82839
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1226
New value of Q matrix: 3.82837
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1227
New value of Q matrix: 3.82835
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1228
New value of Q matrix: 3.82833
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1229
New value of Q matrix: 3.82831
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1230
New value of Q matrix: 3.82829
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.83665
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.83635
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1231
New value of Q matrix: 3.82827
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1232
New value of Q matrix: 3.82825
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.83605
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1233
New value of Q matrix: 3.82823
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1234
New value of Q matrix: 3.82821
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1235
New value of Q matrix: 3.82819
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1236
New value of Q matrix: 3.82817
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.75667
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.75718
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1237
New value of Q matrix: 3.82815
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.83576
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1238
New value of Q matrix: 3.82813
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.84153
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.84113
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.84073
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1239
New value of Q matrix: 3.82811
New value of Value function: 3.84237
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.842
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1240
New value of Q matrix: 3.82809
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1241
New value of Q matrix: 3.82807
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1242
New value of Q matrix: 3.82747
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 135
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.617114
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 136
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.0734319
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 137
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.41554
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 138
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.322799
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 139
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.291793
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 140
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.41333
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 141
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.20348
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 142
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.24831
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 143
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.66151
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 144
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.46966
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 145
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.362607
New value of Value function: 0.362607
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 146
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.645277
New value of Value function: 0.645277
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 147
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.05051
New value of Value function: 4.36362
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 148
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.890257
New value of Value function: 0.890257
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 149
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.36173
New value of Value function: 4.36173
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 150
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 4.53563
New value of Value function: 4.53563
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 1
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 2
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 3
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 4
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 5
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 6
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 7
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 8
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 9
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 10
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 11
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 12
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 13
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 14
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 15
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 16
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 17
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 18
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 19
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 20
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 21
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 22
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 23
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 24
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 25
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 26
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 27
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 28
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 29
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 30
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 31
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 32
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 33
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 34
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 35
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 36
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 0.84151
New value of Value function: 0.84151
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 37
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 38
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -1.83338
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 39
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.22767
New value of Value function: 2.22767
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 40
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.01607
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 41
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.0197
New value of Value function: 4.0197
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 42
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 4.11773
New value of Value function: 4.11773
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 43
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.44385
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 44
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.0741895
New value of Value function: 0.373703
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 45
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.373236
New value of Value function: 0.373236
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 46
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.106501
New value of Value function: 0.373236
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 47
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.372821
New value of Value function: 0.372821
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 48
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 0.415897
New value of Value function: 0.415897
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1243
New value of Q matrix: 3.82745
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1244
New value of Q matrix: 3.82743
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1245
New value of Q matrix: 3.82741
New value of Value function: 3.842
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.84163
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.84034
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.75768
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1246
New value of Q matrix: 3.82739
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1247
New value of Q matrix: 3.82737
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1248
New value of Q matrix: 3.82735
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1249
New value of Q matrix: 3.82733
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1250
New value of Q matrix: 3.82731
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1251
New value of Q matrix: 3.82729
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.75816
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1252
New value of Q matrix: 3.82727
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1253
New value of Q matrix: 3.82725
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.83547
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1254
New value of Q matrix: 3.82724
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1255
New value of Q matrix: 3.82722
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1256
New value of Q matrix: 3.8272
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1257
New value of Q matrix: 3.82718
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1258
New value of Q matrix: 3.82716
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1259
New value of Q matrix: 3.82714
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1260
New value of Q matrix: 3.82712
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1261
New value of Q matrix: 3.8271
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1262
New value of Q matrix: 3.82708
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1263
New value of Q matrix: 3.82706
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.83995
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1264
New value of Q matrix: 3.82705
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1265
New value of Q matrix: 3.82703
New value of Value function: 3.84163
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.84126
New value of Value function: 3.84126
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1266
New value of Q matrix: 3.82701
New value of Value function: 3.84126
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.8409
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1267
New value of Q matrix: 3.82699
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1268
New value of Q matrix: 3.82697
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1269
New value of Q matrix: 3.82695
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.75863
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1270
New value of Q matrix: 3.82693
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1271
New value of Q matrix: 3.82691
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1272
New value of Q matrix: 3.82689
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1273
New value of Q matrix: 3.82687
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1274
New value of Q matrix: 3.82685
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1275
New value of Q matrix: 3.82683
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1276
New value of Q matrix: 3.82682
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1277
New value of Q matrix: 3.8268
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1278
New value of Q matrix: 3.82678
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1279
New value of Q matrix: 3.82676
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1280
New value of Q matrix: 3.82674
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1281
New value of Q matrix: 3.82672
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1282
New value of Q matrix: 3.8267
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1283
New value of Q matrix: 3.82668
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1284
New value of Q matrix: 3.82666
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1285
New value of Q matrix: 3.82665
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1286
New value of Q matrix: 3.82663
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1287
New value of Q matrix: 3.82661
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1288
New value of Q matrix: 3.82659
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1289
New value of Q matrix: 3.82657
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1290
New value of Q matrix: 3.82655
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1291
New value of Q matrix: 3.82653
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.83517
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1292
New value of Q matrix: 3.82651
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1293
New value of Q matrix: 3.8265
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.75908
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1294
New value of Q matrix: 3.82648
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1295
New value of Q matrix: 3.82646
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1296
New value of Q matrix: 3.82644
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1297
New value of Q matrix: 3.82642
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.75953
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1298
New value of Q matrix: 3.8264
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.83956
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1299
New value of Q matrix: 3.82638
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1300
New value of Q matrix: 3.82637
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1301
New value of Q matrix: 3.82635
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1302
New value of Q matrix: 3.82633
New value of Value function: 3.8409
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.84054
New value of Value function: 3.84054
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1303
New value of Q matrix: 3.82631
New value of Value function: 3.84054
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1304
New value of Q matrix: 3.82629
New value of Value function: 3.84054
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.83918
New value of Value function: 3.84054
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.84019
New value of Value function: 3.84019
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.83984
New value of Value function: 3.83984
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1305
New value of Q matrix: 3.82627
New value of Value function: 3.83984
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.83949
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1306
New value of Q matrix: 3.82625
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1307
New value of Q matrix: 3.82624
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1308
New value of Q matrix: 3.82622
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1309
New value of Q matrix: 3.8262
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.83487
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1310
New value of Q matrix: 3.82618
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1311
New value of Q matrix: 3.82616
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1312
New value of Q matrix: 3.82614
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.75996
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1313
New value of Q matrix: 3.82612
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1314
New value of Q matrix: 3.8261
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1315
New value of Q matrix: 3.82608
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.76037
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1316
New value of Q matrix: 3.82606
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.76078
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1317
New value of Q matrix: 3.82604
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1318
New value of Q matrix: 3.82603
New value of Value function: 3.83949
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.83914
New value of Value function: 3.83918
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.83879
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1319
New value of Q matrix: 3.82601
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1320
New value of Q matrix: 3.82599
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 1
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.516667
New value of Value function: 0.516667
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 2
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 1.10663
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 3
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.65476
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 4
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 2.98808
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 5
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.33883
New value of Value function: 2.33883
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 6
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.30955
New value of Value function: 2.30955
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 7
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.21085
New value of Value function: 2.21085
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 8
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.40008
New value of Value function: 2.40008
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 9
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.864244
New value of Value function: 3.57118
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 3.65903
New value of Value function: 3.65903
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 11
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.380109
New value of Value function: 0.380109
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 12
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.383469
New value of Value function: 0.383469
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 13
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 0.429833
New value of Value function: 0.429833
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1321
New value of Q matrix: 3.82597
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.83457
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1322
New value of Q matrix: 3.82595
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1323
New value of Q matrix: 3.82593
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.83841
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1324
New value of Q matrix: 3.82591
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1325
New value of Q matrix: 3.82589
New value of Value function: 3.83914
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.8388
New value of Value function: 3.8388
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.83846
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1326
New value of Q matrix: 3.82587
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1327
New value of Q matrix: 3.82585
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1328
New value of Q matrix: 3.82583
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1329
New value of Q matrix: 3.82581
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1330
New value of Q matrix: 3.82579
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1331
New value of Q matrix: 3.82578
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1332
New value of Q matrix: 3.82576
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1333
New value of Q matrix: 3.82574
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1334
New value of Q matrix: 3.82572
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1335
New value of Q matrix: 3.8257
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.76117
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1336
New value of Q matrix: 3.82568
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1337
New value of Q matrix: 3.82566
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1338
New value of Q matrix: 3.82564
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1339
New value of Q matrix: 3.82562
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1340
New value of Q matrix: 3.8256
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1341
New value of Q matrix: 3.82558
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1342
New value of Q matrix: 3.82556
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1343
New value of Q matrix: 3.82555
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1344
New value of Q matrix: 3.82553
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1345
New value of Q matrix: 3.82551
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1346
New value of Q matrix: 3.82549
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.76155
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.76192
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1347
New value of Q matrix: 3.82547
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1348
New value of Q matrix: 3.82545
New value of Value function: 3.83846
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.83812
New value of Value function: 3.83841
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1349
New value of Q matrix: 3.82543
New value of Value function: 3.83841
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1350
New value of Q matrix: 3.82541
New value of Value function: 3.83841
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1351
New value of Q matrix: 3.82539
New value of Value function: 3.83841
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.83427
New value of Value function: 3.83841
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1352
New value of Q matrix: 3.82538
New value of Value function: 3.83841
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.83803
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1353
New value of Q matrix: 3.82536
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1354
New value of Q matrix: 3.82534
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1355
New value of Q matrix: 3.82532
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1356
New value of Q matrix: 3.8253
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1357
New value of Q matrix: 3.82528
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1358
New value of Q matrix: 3.82526
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.76229
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1359
New value of Q matrix: 3.82524
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1360
New value of Q matrix: 3.82523
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1361
New value of Q matrix: 3.82521
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1362
New value of Q matrix: 3.82519
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1363
New value of Q matrix: 3.82517
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1364
New value of Q matrix: 3.82515
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.83397
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.76264
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1365
New value of Q matrix: 3.82513
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.83368
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1366
New value of Q matrix: 3.82511
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1367
New value of Q matrix: 3.82509
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1368
New value of Q matrix: 3.82508
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1369
New value of Q matrix: 3.82506
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1370
New value of Q matrix: 3.82504
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1371
New value of Q matrix: 3.82502
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.83766
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1372
New value of Q matrix: 3.825
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1373
New value of Q matrix: 3.82498
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1374
New value of Q matrix: 3.82497
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1375
New value of Q matrix: 3.82495
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.76299
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1376
New value of Q matrix: 3.82493
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1377
New value of Q matrix: 3.82491
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1378
New value of Q matrix: 3.82489
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1379
New value of Q matrix: 3.82487
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1380
New value of Q matrix: 3.82486
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1381
New value of Q matrix: 3.82484
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1382
New value of Q matrix: 3.82482
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1383
New value of Q matrix: 3.8248
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1384
New value of Q matrix: 3.82478
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1385
New value of Q matrix: 3.82477
New value of Value function: 3.83812
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.83779
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1386
New value of Q matrix: 3.82475
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1387
New value of Q matrix: 3.82473
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1388
New value of Q matrix: 3.82471
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1389
New value of Q matrix: 3.82469
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.76333
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1390
New value of Q matrix: 3.82467
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.83339
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.76367
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1391
New value of Q matrix: 3.82466
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1392
New value of Q matrix: 3.82464
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1393
New value of Q matrix: 3.82462
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1394
New value of Q matrix: 3.8246
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1395
New value of Q matrix: 3.82458
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1396
New value of Q matrix: 3.82457
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.83729
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1397
New value of Q matrix: 3.82455
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1398
New value of Q matrix: 3.82453
New value of Value function: 3.83779
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.83746
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1399
New value of Q matrix: 3.82451
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1400
New value of Q matrix: 3.82449
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1401
New value of Q matrix: 3.82447
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1402
New value of Q matrix: 3.82446
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1403
New value of Q matrix: 3.82444
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1404
New value of Q matrix: 3.82442
New value of Value function: 3.83746
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.83713
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1405
New value of Q matrix: 3.8244
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1406
New value of Q matrix: 3.82438
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1407
New value of Q matrix: 3.82437
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1408
New value of Q matrix: 3.82435
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.8331
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1409
New value of Q matrix: 3.82433
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1410
New value of Q matrix: 3.82431
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1411
New value of Q matrix: 3.82429
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1412
New value of Q matrix: 3.82428
New value of Value function: 3.83729
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.83692
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1413
New value of Q matrix: 3.82426
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1414
New value of Q matrix: 3.82424
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1415
New value of Q matrix: 3.82441
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 134
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.989344
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 135
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -1.18159
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 136
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.90083
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 137
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.06986
New value of Value function: 1.06986
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 138
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.683054
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 18
Iteration: 139
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.353052
New value of Value function: 1.06986
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 140
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.31361
New value of Value function: 1.06986
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 141
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.06629
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 142
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.721304
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 143
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -1.47474
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 144
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 145
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 146
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 147
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 148
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 149
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 150
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1416
New value of Q matrix: 3.82439
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1417
New value of Q matrix: 3.82437
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1418
New value of Q matrix: 3.82436
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1419
New value of Q matrix: 3.82434
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1420
New value of Q matrix: 3.82432
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1421
New value of Q matrix: 3.8243
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1422
New value of Q matrix: 3.82428
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.83282
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1423
New value of Q matrix: 3.82427
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.83253
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1424
New value of Q matrix: 3.82425
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1425
New value of Q matrix: 3.82423
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1426
New value of Q matrix: 3.82421
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.83655
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1427
New value of Q matrix: 3.82419
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1428
New value of Q matrix: 3.82418
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1429
New value of Q matrix: 3.82416
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1430
New value of Q matrix: 3.82414
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1431
New value of Q matrix: 3.82412
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1432
New value of Q matrix: 3.82411
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1433
New value of Q matrix: 3.82409
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1434
New value of Q matrix: 3.82407
New value of Value function: 3.83713
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.8368
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.76399
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1435
New value of Q matrix: 3.82405
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1436
New value of Q matrix: 3.82403
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.83225
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1437
New value of Q matrix: 3.82402
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1438
New value of Q matrix: 3.824
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1439
New value of Q matrix: 3.82398
New value of Value function: 3.8368
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.83648
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.83198
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.83616
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1440
New value of Q matrix: 3.82396
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1441
New value of Q matrix: 3.82395
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1442
New value of Q matrix: 3.82393
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1443
New value of Q matrix: 3.82391
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1444
New value of Q matrix: 3.82389
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1445
New value of Q matrix: 3.82387
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1446
New value of Q matrix: 3.82386
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1447
New value of Q matrix: 3.82384
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1448
New value of Q matrix: 3.82382
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1449
New value of Q matrix: 3.8238
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1450
New value of Q matrix: 3.82379
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.7643
New value of Value function: 3.83655
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.83619
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1451
New value of Q matrix: 3.82377
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.83585
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1452
New value of Q matrix: 3.82375
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1453
New value of Q matrix: 3.82373
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1454
New value of Q matrix: 3.82371
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1455
New value of Q matrix: 3.8237
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1456
New value of Q matrix: 3.82368
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1457
New value of Q matrix: 3.82366
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1458
New value of Q matrix: 3.82364
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1459
New value of Q matrix: 3.82363
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1460
New value of Q matrix: 3.82361
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1461
New value of Q matrix: 3.82359
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1462
New value of Q matrix: 3.82357
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1463
New value of Q matrix: 3.82355
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1464
New value of Q matrix: 3.82354
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1465
New value of Q matrix: 3.82352
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1466
New value of Q matrix: 3.8235
New value of Value function: 3.83619
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.83583
New value of Value function: 3.83585
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1467
New value of Q matrix: 3.82348
New value of Value function: 3.83585
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.83553
New value of Value function: 3.83583
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.83548
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.83513
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1468
New value of Q matrix: 3.82347
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1469
New value of Q matrix: 3.82345
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1470
New value of Q matrix: 3.82343
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1471
New value of Q matrix: 3.82341
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1472
New value of Q matrix: 3.82339
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.83478
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1473
New value of Q matrix: 3.82338
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1474
New value of Q matrix: 3.82336
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1475
New value of Q matrix: 3.82334
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1476
New value of Q matrix: 3.82332
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1477
New value of Q matrix: 3.82331
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1478
New value of Q matrix: 3.82329
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1479
New value of Q matrix: 3.82327
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1480
New value of Q matrix: 3.82325
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1481
New value of Q matrix: 3.82324
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.76459
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1482
New value of Q matrix: 3.82322
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.8317
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.83444
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.83142
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1483
New value of Q matrix: 3.8232
New value of Value function: 3.83553
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.83522
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1484
New value of Q matrix: 3.82318
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1485
New value of Q matrix: 3.82316
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1486
New value of Q matrix: 3.82315
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1487
New value of Q matrix: 3.82313
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1488
New value of Q matrix: 3.82311
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1489
New value of Q matrix: 3.82309
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.83115
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1490
New value of Q matrix: 3.82308
New value of Value function: 3.83522
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.83491
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1491
New value of Q matrix: 3.82306
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1492
New value of Q matrix: 3.82304
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.8341
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1493
New value of Q matrix: 3.82302
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1494
New value of Q matrix: 3.82301
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1495
New value of Q matrix: 3.82299
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1496
New value of Q matrix: 3.82297
New value of Value function: 3.83491
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.8346
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1497
New value of Q matrix: 3.82295
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1498
New value of Q matrix: 3.82293
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.83377
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1499
New value of Q matrix: 3.82292
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.83087
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1500
New value of Q matrix: 3.8229
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1501
New value of Q matrix: 3.82288
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1502
New value of Q matrix: 3.82286
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.76488
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1503
New value of Q matrix: 3.82259
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 118
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0734319
New value of Value function: 0.418802
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 119
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.0734319
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 120
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.25428
New value of Value function: 0.0741736
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 121
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.126365
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 122
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -0.121204
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 123
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.43892
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 124
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.4613
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 125
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.28959
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 126
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.92803
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 127
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.32409
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 128
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.11394
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 129
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.97441
New value of Value function: 4.92525
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 130
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.438
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 131
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.90062
New value of Value function: 4.90067
New value of Policy matrix: 3

=======================================
Simulation: 19
Iteration: 132
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.08483
New value of Value function: 4.90067
New value of Policy matrix: 3

=======================================
Simulation: 19
Iteration: 133
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.04754
New value of Value function: 4.90067
New value of Policy matrix: 3

=======================================
Simulation: 19
Iteration: 134
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.11526
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 135
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.53382
New value of Value function: 4.53382
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 136
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 4.69107
New value of Value function: 4.69107
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 137
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.6571
New value of Value function: 3.6571
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 138
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.65925
New value of Value function: 3.65925
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 139
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 1.68914
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 140
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 141
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.398128
New value of Value function: 0.398128
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1504
New value of Q matrix: 3.82257
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1505
New value of Q matrix: 3.82256
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1506
New value of Q matrix: 3.82254
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.8306
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1507
New value of Q matrix: 3.82252
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.76515
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1508
New value of Q matrix: 3.8225
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1509
New value of Q matrix: 3.82249
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1510
New value of Q matrix: 3.82247
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.83344
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1511
New value of Q matrix: 3.82245
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1512
New value of Q matrix: 3.82244
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1513
New value of Q matrix: 3.82242
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1514
New value of Q matrix: 3.8224
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1515
New value of Q matrix: 3.82238
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.83033
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1516
New value of Q matrix: 3.82237
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1517
New value of Q matrix: 3.82235
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1518
New value of Q matrix: 3.82233
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1519
New value of Q matrix: 3.82231
New value of Value function: 3.8346
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.8343
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1520
New value of Q matrix: 3.8223
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.76542
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1521
New value of Q matrix: 3.82228
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1522
New value of Q matrix: 3.82226
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.83007
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1523
New value of Q matrix: 3.82225
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.82981
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.83311
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1524
New value of Q matrix: 3.82223
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1525
New value of Q matrix: 3.82221
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1526
New value of Q matrix: 3.82219
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1527
New value of Q matrix: 3.82218
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.83279
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1528
New value of Q matrix: 3.82216
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1529
New value of Q matrix: 3.82214
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.82955
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1530
New value of Q matrix: 3.82213
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.83248
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.83217
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1531
New value of Q matrix: 3.82211
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.8293
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1532
New value of Q matrix: 3.82209
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1533
New value of Q matrix: 3.82207
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1534
New value of Q matrix: 3.82206
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1535
New value of Q matrix: 3.82204
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.83187
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.83157
New value of Value function: 3.8343
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.834
New value of Value function: 3.834
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1536
New value of Q matrix: 3.82202
New value of Value function: 3.834
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1537
New value of Q matrix: 3.82201
New value of Value function: 3.834
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1538
New value of Q matrix: 3.82199
New value of Value function: 3.834
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1539
New value of Q matrix: 3.82197
New value of Value function: 3.834
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.76569
New value of Value function: 3.834
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.8337
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1540
New value of Q matrix: 3.82195
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.82905
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.83127
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1541
New value of Q matrix: 3.82194
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.76594
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.8288
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.76619
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.76644
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1542
New value of Q matrix: 3.82192
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1543
New value of Q matrix: 3.8219
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.76668
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1544
New value of Q matrix: 3.82189
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1545
New value of Q matrix: 3.82187
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1546
New value of Q matrix: 3.82185
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1547
New value of Q matrix: 3.82183
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1548
New value of Q matrix: 3.82182
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.83097
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1549
New value of Q matrix: 3.8218
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1550
New value of Q matrix: 3.82178
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1551
New value of Q matrix: 3.82177
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1552
New value of Q matrix: 3.82175
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.82855
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1553
New value of Q matrix: 3.82173
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1554
New value of Q matrix: 3.82171
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.83068
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1555
New value of Q matrix: 3.8217
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1556
New value of Q matrix: 3.82168
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1557
New value of Q matrix: 3.82166
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1558
New value of Q matrix: 3.82165
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1559
New value of Q matrix: 3.82163
New value of Value function: 3.8337
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.8334
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1560
New value of Q matrix: 3.82161
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1561
New value of Q matrix: 3.8216
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1562
New value of Q matrix: 3.82158
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.76692
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1563
New value of Q matrix: 3.82156
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.82831
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1564
New value of Q matrix: 3.82154
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1565
New value of Q matrix: 3.82153
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.8304
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1566
New value of Q matrix: 3.82151
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1567
New value of Q matrix: 3.82149
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.82807
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.76715
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1568
New value of Q matrix: 3.82148
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1569
New value of Q matrix: 3.82146
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1570
New value of Q matrix: 3.82144
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1571
New value of Q matrix: 3.82143
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1572
New value of Q matrix: 3.82141
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1573
New value of Q matrix: 3.82139
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1574
New value of Q matrix: 3.82138
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1575
New value of Q matrix: 3.82136
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1576
New value of Q matrix: 3.82134
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1577
New value of Q matrix: 3.82133
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.76738
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1578
New value of Q matrix: 3.82131
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1579
New value of Q matrix: 3.82129
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1580
New value of Q matrix: 3.82128
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1581
New value of Q matrix: 3.82126
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1582
New value of Q matrix: 3.82124
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1583
New value of Q matrix: 3.82123
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.76761
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1584
New value of Q matrix: 3.82121
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1585
New value of Q matrix: 3.82119
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1586
New value of Q matrix: 3.82118
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1587
New value of Q matrix: 3.82116
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1588
New value of Q matrix: 3.82114
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.76783
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1589
New value of Q matrix: 3.82113
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.76805
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1590
New value of Q matrix: 3.82111
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.82783
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1591
New value of Q matrix: 3.8211
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1592
New value of Q matrix: 3.82108
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1593
New value of Q matrix: 3.82106
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1594
New value of Q matrix: 3.82105
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1595
New value of Q matrix: 3.82103
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1596
New value of Q matrix: 3.82101
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1597
New value of Q matrix: 3.821
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1598
New value of Q matrix: 3.82098
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1599
New value of Q matrix: 3.82097
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.8276
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.76826
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.76847
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1600
New value of Q matrix: 3.82095
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1601
New value of Q matrix: 3.82093
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.82736
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1602
New value of Q matrix: 3.82092
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1603
New value of Q matrix: 3.8204
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 136
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 137
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 138
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 139
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 140
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 141
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 142
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 143
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.742857
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 144
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.9975
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 145
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 20
Iteration: 146
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 147
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.662438
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 148
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.78685
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 149
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.73075
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 150
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.407792
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1604
New value of Q matrix: 3.82039
New value of Value function: 3.8334
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.83311
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.83011
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1605
New value of Q matrix: 3.82037
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1606
New value of Q matrix: 3.82036
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.76868
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1607
New value of Q matrix: 3.82034
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.82983
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1608
New value of Q matrix: 3.82033
New value of Value function: 3.83311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.83281
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1609
New value of Q matrix: 3.82031
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1610
New value of Q matrix: 3.82029
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1611
New value of Q matrix: 3.82028
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1612
New value of Q matrix: 3.82026
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1613
New value of Q matrix: 3.82025
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.82713
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1614
New value of Q matrix: 3.82023
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1615
New value of Q matrix: 3.82021
New value of Value function: 3.83281
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.83252
New value of Value function: 3.83252
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.83223
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1616
New value of Q matrix: 3.8202
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1617
New value of Q matrix: 3.82018
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1618
New value of Q matrix: 3.82016
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1619
New value of Q matrix: 3.82015
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1620
New value of Q matrix: 3.82013
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1621
New value of Q matrix: 3.82012
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1622
New value of Q matrix: 3.8201
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.8269
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.82955
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1623
New value of Q matrix: 3.82008
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1624
New value of Q matrix: 3.82007
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1625
New value of Q matrix: 3.82005
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1626
New value of Q matrix: 3.82004
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1627
New value of Q matrix: 3.82002
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1628
New value of Q matrix: 3.82
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1629
New value of Q matrix: 3.81999
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1630
New value of Q matrix: 3.81997
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1631
New value of Q matrix: 3.81996
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1632
New value of Q matrix: 3.81994
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1633
New value of Q matrix: 3.81992
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1634
New value of Q matrix: 3.81991
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.82667
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1635
New value of Q matrix: 3.81989
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1636
New value of Q matrix: 3.81988
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1637
New value of Q matrix: 3.81986
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1638
New value of Q matrix: 3.81984
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1639
New value of Q matrix: 3.81983
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1640
New value of Q matrix: 3.81981
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1641
New value of Q matrix: 3.8198
New value of Value function: 3.83223
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.83195
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1642
New value of Q matrix: 3.81978
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1643
New value of Q matrix: 3.81976
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1644
New value of Q matrix: 3.81975
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1645
New value of Q matrix: 3.81973
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.76887
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1646
New value of Q matrix: 3.81972
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1647
New value of Q matrix: 3.8197
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.82644
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1648
New value of Q matrix: 3.81969
New value of Value function: 3.83195
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.83166
New value of Value function: 3.83166
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1649
New value of Q matrix: 3.81967
New value of Value function: 3.83166
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.83138
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.82926
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1650
New value of Q matrix: 3.81965
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1651
New value of Q matrix: 3.81964
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1652
New value of Q matrix: 3.81962
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1653
New value of Q matrix: 3.8196
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1654
New value of Q matrix: 3.81959
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1655
New value of Q matrix: 3.81957
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1656
New value of Q matrix: 3.81956
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1657
New value of Q matrix: 3.81954
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1658
New value of Q matrix: 3.81952
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.76906
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1659
New value of Q matrix: 3.81951
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1660
New value of Q matrix: 3.81949
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1661
New value of Q matrix: 3.81948
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1662
New value of Q matrix: 3.81946
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1663
New value of Q matrix: 3.81945
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1664
New value of Q matrix: 3.81943
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.82622
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1665
New value of Q matrix: 3.81941
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1666
New value of Q matrix: 3.8194
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1667
New value of Q matrix: 3.81938
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.76924
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.82898
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1668
New value of Q matrix: 3.81937
New value of Value function: 3.83138
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.8311
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1669
New value of Q matrix: 3.81935
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1670
New value of Q matrix: 3.81933
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1671
New value of Q matrix: 3.81932
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1672
New value of Q matrix: 3.8193
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1673
New value of Q matrix: 3.81929
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1674
New value of Q matrix: 3.81927
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1675
New value of Q matrix: 3.81926
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1676
New value of Q matrix: 3.81924
New value of Value function: 3.8311
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.83083
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1677
New value of Q matrix: 3.81922
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1678
New value of Q matrix: 3.81921
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1679
New value of Q matrix: 3.81919
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1680
New value of Q matrix: 3.81918
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.82599
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1681
New value of Q matrix: 3.81916
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.82576
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.82554
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.76942
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1682
New value of Q matrix: 3.81914
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1683
New value of Q matrix: 3.81913
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1684
New value of Q matrix: 3.81911
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1685
New value of Q matrix: 3.8191
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1686
New value of Q matrix: 3.81908
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1687
New value of Q matrix: 3.81907
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1688
New value of Q matrix: 3.81905
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1689
New value of Q matrix: 3.81903
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1690
New value of Q matrix: 3.81902
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1691
New value of Q matrix: 3.819
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1692
New value of Q matrix: 3.81899
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1693
New value of Q matrix: 3.81897
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.82532
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1694
New value of Q matrix: 3.81896
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1695
New value of Q matrix: 3.81894
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1696
New value of Q matrix: 3.81892
New value of Value function: 3.83083
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.83055
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1697
New value of Q matrix: 3.81891
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1698
New value of Q matrix: 3.81843
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 125
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 126
----------
State: 4149
	Distance: 7
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.98333
New value of Value function: 4.98333
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 127
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 128
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 129
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 130
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0995
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 131
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.04071
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 132
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.96691
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 133
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.663099
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 134
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 0.0338657
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 135
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.45025
New value of Value function: 7.45025
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 136
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 0.268054
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 137
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.45025
New value of Value function: 7.45025
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 138
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.280439
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 139
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 0.360013
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 140
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.37575
New value of Value function: 7.45025
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 141
----------
State: 4917
	Distance: 8
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.40429
New value of Value function: 7.45025
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 142
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.235544
New value of Value function: 0.408375
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 143
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 144
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.73376
New value of Value function: 3.73376
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 145
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.336972
New value of Value function: 2.49245
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 146
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.144841
New value of Value function: 1.94118
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 147
----------
State: 4965
	Distance: 8
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.48918
New value of Value function: 2.48918
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 148
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.92177
New value of Value function: 6.92177
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 149
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 1.93232
New value of Value function: 1.93232
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 150
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.91738
New value of Value function: 6.91738
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1699
New value of Q matrix: 3.81841
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1700
New value of Q matrix: 3.8184
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.76959
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.76976
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1701
New value of Q matrix: 3.81838
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1702
New value of Q matrix: 3.81836
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.8251
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1703
New value of Q matrix: 3.81835
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1704
New value of Q matrix: 3.81833
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.82488
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1705
New value of Q matrix: 3.81832
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1706
New value of Q matrix: 3.8183
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1707
New value of Q matrix: 3.81829
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1708
New value of Q matrix: 3.81827
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1709
New value of Q matrix: 3.81826
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1710
New value of Q matrix: 3.81824
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1711
New value of Q matrix: 3.81823
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1712
New value of Q matrix: 3.81821
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1713
New value of Q matrix: 3.8182
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1714
New value of Q matrix: 3.81818
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1715
New value of Q matrix: 3.81817
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1716
New value of Q matrix: 3.81815
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.8287
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.82842
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1717
New value of Q matrix: 3.81814
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1718
New value of Q matrix: 3.81812
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1719
New value of Q matrix: 3.81811
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1720
New value of Q matrix: 3.81809
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.76992
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1721
New value of Q matrix: 3.81808
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.77009
New value of Value function: 3.83055
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.83028
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1722
New value of Q matrix: 3.81806
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1723
New value of Q matrix: 3.81805
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1724
New value of Q matrix: 3.81803
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1725
New value of Q matrix: 3.81802
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1726
New value of Q matrix: 3.818
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1727
New value of Q matrix: 3.81799
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1728
New value of Q matrix: 3.81797
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1729
New value of Q matrix: 3.81796
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1730
New value of Q matrix: 3.81794
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1731
New value of Q matrix: 3.81793
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1732
New value of Q matrix: 3.81791
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1733
New value of Q matrix: 3.8179
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.77025
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1734
New value of Q matrix: 3.81788
New value of Value function: 3.83028
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.83
New value of Value function: 3.83
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1735
New value of Q matrix: 3.81787
New value of Value function: 3.83
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1736
New value of Q matrix: 3.81785
New value of Value function: 3.83
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.82973
New value of Value function: 3.82973
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1737
New value of Q matrix: 3.81784
New value of Value function: 3.82973
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1738
New value of Q matrix: 3.81782
New value of Value function: 3.82973
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1739
New value of Q matrix: 3.8178
New value of Value function: 3.82973
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.82947
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1740
New value of Q matrix: 3.81779
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1741
New value of Q matrix: 3.81777
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1742
New value of Q matrix: 3.81776
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1743
New value of Q matrix: 3.81774
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.82814
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1744
New value of Q matrix: 3.81773
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1745
New value of Q matrix: 3.81771
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1746
New value of Q matrix: 3.8177
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1747
New value of Q matrix: 3.81768
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1748
New value of Q matrix: 3.81767
New value of Value function: 3.82947
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.8292
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1749
New value of Q matrix: 3.81765
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1750
New value of Q matrix: 3.81764
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1751
New value of Q matrix: 3.81762
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1752
New value of Q matrix: 3.81761
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1753
New value of Q matrix: 3.81759
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1754
New value of Q matrix: 3.81758
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.7704
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1755
New value of Q matrix: 3.81756
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.82466
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1756
New value of Q matrix: 3.81755
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1757
New value of Q matrix: 3.81753
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1758
New value of Q matrix: 3.81752
New value of Value function: 3.8292
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.82894
New value of Value function: 3.82894
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.82867
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1759
New value of Q matrix: 3.8175
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1760
New value of Q matrix: 3.81748
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1761
New value of Q matrix: 3.81747
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.77054
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1762
New value of Q matrix: 3.81745
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1763
New value of Q matrix: 3.81744
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.77068
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1764
New value of Q matrix: 3.81742
New value of Value function: 3.82867
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.82841
New value of Value function: 3.82841
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1765
New value of Q matrix: 3.81741
New value of Value function: 3.82841
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1766
New value of Q matrix: 3.81739
New value of Value function: 3.82841
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1767
New value of Q matrix: 3.81738
New value of Value function: 3.82841
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.82816
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1768
New value of Q matrix: 3.81736
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1769
New value of Q matrix: 3.81735
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1770
New value of Q matrix: 3.81733
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.82785
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1771
New value of Q matrix: 3.81731
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1772
New value of Q matrix: 3.8173
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.82757
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.82729
New value of Value function: 3.82816
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.8279
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1773
New value of Q matrix: 3.81728
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1774
New value of Q matrix: 3.81727
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1775
New value of Q matrix: 3.81725
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1776
New value of Q matrix: 3.81724
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1777
New value of Q matrix: 3.81722
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1778
New value of Q matrix: 3.81721
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1779
New value of Q matrix: 3.81719
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1780
New value of Q matrix: 3.81718
New value of Value function: 3.8279
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.82764
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1781
New value of Q matrix: 3.81716
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1782
New value of Q matrix: 3.81714
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1783
New value of Q matrix: 3.81713
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1784
New value of Q matrix: 3.81711
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1785
New value of Q matrix: 3.8171
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1786
New value of Q matrix: 3.81708
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1787
New value of Q matrix: 3.81707
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 3.76522
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 119
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.588833
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 120
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.04975
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 121
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 122
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.1027
New value of Value function: 1.1027
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 123
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.2221
New value of Value function: 2.2221
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 124
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.59299
New value of Value function: 2.59299
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 125
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.11399
New value of Value function: 4.11399
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 126
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.18297
New value of Value function: 4.18297
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 127
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 4.99231
New value of Value function: 4.99231
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 128
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.411738
New value of Value function: 0.411738
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 129
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.415519
New value of Value function: 0.415519
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 130
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.415173
New value of Value function: 0.415173
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 131
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 0.443957
New value of Value function: 0.443957
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1788
New value of Q matrix: 3.81705
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1789
New value of Q matrix: 3.81704
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1790
New value of Q matrix: 3.81702
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.82443
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1791
New value of Q matrix: 3.817
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1792
New value of Q matrix: 3.81699
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1793
New value of Q matrix: 3.81697
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1794
New value of Q matrix: 3.81696
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1795
New value of Q matrix: 3.81694
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1796
New value of Q matrix: 3.81693
New value of Value function: 3.82764
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.82739
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1797
New value of Q matrix: 3.81691
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1798
New value of Q matrix: 3.8169
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1799
New value of Q matrix: 3.81688
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1800
New value of Q matrix: 3.81687
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1801
New value of Q matrix: 3.81685
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.8242
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1802
New value of Q matrix: 3.81683
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1803
New value of Q matrix: 3.81682
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1804
New value of Q matrix: 3.8168
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1805
New value of Q matrix: 3.81679
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1806
New value of Q matrix: 3.81677
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1807
New value of Q matrix: 3.81676
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1808
New value of Q matrix: 3.81674
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1809
New value of Q matrix: 3.81673
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1810
New value of Q matrix: 3.81671
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1811
New value of Q matrix: 3.8167
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.82398
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1812
New value of Q matrix: 3.81668
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1813
New value of Q matrix: 3.81667
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1814
New value of Q matrix: 3.81665
New value of Value function: 3.82739
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.82714
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1815
New value of Q matrix: 3.81664
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1816
New value of Q matrix: 3.81662
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.82375
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1817
New value of Q matrix: 3.81661
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1818
New value of Q matrix: 3.81659
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1819
New value of Q matrix: 3.81658
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1820
New value of Q matrix: 3.81656
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1821
New value of Q matrix: 3.81655
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1822
New value of Q matrix: 3.81653
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1823
New value of Q matrix: 3.81651
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.82689
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1824
New value of Q matrix: 3.8165
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.82664
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1825
New value of Q matrix: 3.81648
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1826
New value of Q matrix: 3.81647
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.76539
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1827
New value of Q matrix: 3.81645
New value of Value function: 3.82729
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.82701
New value of Value function: 3.82701
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.8264
New value of Value function: 3.82701
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1828
New value of Q matrix: 3.81644
New value of Value function: 3.82701
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.76555
New value of Value function: 3.82701
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1829
New value of Q matrix: 3.81642
New value of Value function: 3.82701
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.82673
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1830
New value of Q matrix: 3.81641
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.82615
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1831
New value of Q matrix: 3.81639
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1832
New value of Q matrix: 3.81638
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1833
New value of Q matrix: 3.81636
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1834
New value of Q matrix: 3.81635
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1835
New value of Q matrix: 3.81633
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1836
New value of Q matrix: 3.81632
New value of Value function: 3.82673
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.82645
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1837
New value of Q matrix: 3.8163
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1838
New value of Q matrix: 3.81629
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1839
New value of Q matrix: 3.81627
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.82353
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.76571
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1840
New value of Q matrix: 3.81626
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1841
New value of Q matrix: 3.81624
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1842
New value of Q matrix: 3.81623
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1843
New value of Q matrix: 3.81621
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1844
New value of Q matrix: 3.8162
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1845
New value of Q matrix: 3.81618
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1846
New value of Q matrix: 3.81617
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1847
New value of Q matrix: 3.81615
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1848
New value of Q matrix: 3.81614
New value of Value function: 3.82645
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.82618
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1849
New value of Q matrix: 3.81612
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1850
New value of Q matrix: 3.8161
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1851
New value of Q matrix: 3.81609
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1852
New value of Q matrix: 3.81607
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1853
New value of Q matrix: 3.81606
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1854
New value of Q matrix: 3.81604
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1855
New value of Q matrix: 3.81603
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1856
New value of Q matrix: 3.81601
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.82331
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1857
New value of Q matrix: 3.816
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1858
New value of Q matrix: 3.81598
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1859
New value of Q matrix: 3.81597
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1860
New value of Q matrix: 3.81595
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.76586
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1861
New value of Q matrix: 3.81594
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1862
New value of Q matrix: 3.81592
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.82308
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1863
New value of Q matrix: 3.81591
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1864
New value of Q matrix: 3.81589
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.82591
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.76601
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1865
New value of Q matrix: 3.81588
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1866
New value of Q matrix: 3.81586
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1867
New value of Q matrix: 3.81585
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.82287
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1868
New value of Q matrix: 3.81583
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.76616
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.82265
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.82244
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1869
New value of Q matrix: 3.81582
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1870
New value of Q matrix: 3.8158
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1871
New value of Q matrix: 3.81579
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.82223
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1872
New value of Q matrix: 3.81577
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1873
New value of Q matrix: 3.81576
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1874
New value of Q matrix: 3.81574
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1875
New value of Q matrix: 3.81573
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1876
New value of Q matrix: 3.81571
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1877
New value of Q matrix: 3.8157
New value of Value function: 3.82618
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.8259
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1878
New value of Q matrix: 3.81568
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1879
New value of Q matrix: 3.81567
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.82202
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1880
New value of Q matrix: 3.81565
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1881
New value of Q matrix: 3.81564
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1882
New value of Q matrix: 3.81562
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.7663
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.76645
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1883
New value of Q matrix: 3.81561
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1884
New value of Q matrix: 3.81559
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1885
New value of Q matrix: 3.81558
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 3.82563
New value of Value function: 3.82591
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.82567
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.82536
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1886
New value of Q matrix: 3.81557
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1887
New value of Q matrix: 3.81555
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1888
New value of Q matrix: 3.81554
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1889
New value of Q matrix: 3.81552
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.82181
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1890
New value of Q matrix: 3.81551
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1891
New value of Q matrix: 3.81549
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1892
New value of Q matrix: 3.81548
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1893
New value of Q matrix: 3.81546
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1894
New value of Q matrix: 3.81545
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1895
New value of Q matrix: 3.81543
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1896
New value of Q matrix: 3.81542
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1897
New value of Q matrix: 3.8154
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1898
New value of Q matrix: 3.81539
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1899
New value of Q matrix: 3.81537
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1900
New value of Q matrix: 3.8155
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 131
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.509186
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 132
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.796146
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 133
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.848042
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 134
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -1.86278
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 135
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.339815
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 136
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.8
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 137
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.19719
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 138
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.72977
New value of Value function: 1.72977
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 139
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 3.56203
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 140
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.34944
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 141
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.3057
New value of Value function: 2.3057
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 142
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.28264
New value of Value function: 2.3057
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 143
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.3024
New value of Value function: 2.3024
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 144
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.31161
New value of Value function: 2.31161
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 145
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.39708
New value of Value function: 2.39708
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 146
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.53326
New value of Value function: 2.53326
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 147
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.5033
New value of Value function: 3.65925
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 148
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 3.74102
New value of Value function: 3.74102
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 149
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.402822
New value of Value function: 0.402822
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 150
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.425535
New value of Value function: 0.429833
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 1
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.44364
New value of Value function: 0.44364
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 2
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 0.466558
New value of Value function: 0.466558
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1901
New value of Q matrix: 3.81549
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1902
New value of Q matrix: 3.81547
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.8251
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1903
New value of Q matrix: 3.81546
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.8216
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1904
New value of Q matrix: 3.81544
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.76659
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1905
New value of Q matrix: 3.81543
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1906
New value of Q matrix: 3.81542
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1907
New value of Q matrix: 3.8154
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1908
New value of Q matrix: 3.81539
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1909
New value of Q matrix: 3.81537
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1910
New value of Q matrix: 3.81536
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1911
New value of Q matrix: 3.81534
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.82483
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1912
New value of Q matrix: 3.81533
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1913
New value of Q matrix: 3.81531
New value of Value function: 3.82567
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.82543
New value of Value function: 3.82543
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1914
New value of Q matrix: 3.8153
New value of Value function: 3.82543
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.82519
New value of Value function: 3.82519
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1915
New value of Q matrix: 3.81528
New value of Value function: 3.82519
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.82495
New value of Value function: 3.82495
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1916
New value of Q matrix: 3.81527
New value of Value function: 3.82495
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1917
New value of Q matrix: 3.81525
New value of Value function: 3.82495
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1918
New value of Q matrix: 3.81524
New value of Value function: 3.82495
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1919
New value of Q matrix: 3.81522
New value of Value function: 3.82495
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.82472
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1920
New value of Q matrix: 3.81521
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1921
New value of Q matrix: 3.81519
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1922
New value of Q matrix: 3.81518
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1923
New value of Q matrix: 3.81516
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.76672
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1924
New value of Q matrix: 3.81515
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1925
New value of Q matrix: 3.81513
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1926
New value of Q matrix: 3.81512
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1927
New value of Q matrix: 3.8151
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1928
New value of Q matrix: 3.81509
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1929
New value of Q matrix: 3.81508
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.76685
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1930
New value of Q matrix: 3.81506
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1931
New value of Q matrix: 3.81505
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1932
New value of Q matrix: 3.81503
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1933
New value of Q matrix: 3.81502
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1934
New value of Q matrix: 3.815
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1935
New value of Q matrix: 3.81499
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1936
New value of Q matrix: 3.81497
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1937
New value of Q matrix: 3.81496
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1938
New value of Q matrix: 3.81494
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1939
New value of Q matrix: 3.81493
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1940
New value of Q matrix: 3.81491
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1941
New value of Q matrix: 3.8149
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.82448
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1942
New value of Q matrix: 3.81488
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1943
New value of Q matrix: 3.81487
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1944
New value of Q matrix: 3.81486
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.76698
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1945
New value of Q matrix: 3.81484
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.82139
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1946
New value of Q matrix: 3.81483
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1947
New value of Q matrix: 3.81481
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1948
New value of Q matrix: 3.8148
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1949
New value of Q matrix: 3.81478
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1950
New value of Q matrix: 3.81477
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1951
New value of Q matrix: 3.81475
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1952
New value of Q matrix: 3.81474
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1953
New value of Q matrix: 3.81472
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1954
New value of Q matrix: 3.81471
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1955
New value of Q matrix: 3.8147
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1956
New value of Q matrix: 3.81468
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1957
New value of Q matrix: 3.81467
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.82425
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1958
New value of Q matrix: 3.81465
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1959
New value of Q matrix: 3.81464
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1960
New value of Q matrix: 3.81462
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1961
New value of Q matrix: 3.81461
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1962
New value of Q matrix: 3.8146
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.76711
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1963
New value of Q matrix: 3.81458
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1964
New value of Q matrix: 3.81457
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1965
New value of Q matrix: 3.81455
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1966
New value of Q matrix: 3.81454
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1967
New value of Q matrix: 3.81452
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1968
New value of Q matrix: 3.81451
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.76723
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.76736
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1969
New value of Q matrix: 3.8145
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1970
New value of Q matrix: 3.81448
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1971
New value of Q matrix: 3.81447
New value of Value function: 3.82483
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.82457
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.82119
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1972
New value of Q matrix: 3.81445
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1973
New value of Q matrix: 3.81444
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1974
New value of Q matrix: 3.81443
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1975
New value of Q matrix: 3.81441
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1976
New value of Q matrix: 3.8144
New value of Value function: 3.82457
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.82431
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1977
New value of Q matrix: 3.81438
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.76748
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1978
New value of Q matrix: 3.81437
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1979
New value of Q matrix: 3.81435
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1980
New value of Q matrix: 3.81434
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1981
New value of Q matrix: 3.81433
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1982
New value of Q matrix: 3.81431
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1983
New value of Q matrix: 3.8143
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1984
New value of Q matrix: 3.81428
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1985
New value of Q matrix: 3.81427
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1986
New value of Q matrix: 3.81425
New value of Value function: 3.82431
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.82405
New value of Value function: 3.82425
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1987
New value of Q matrix: 3.81384
New value of Value function: 3.82425
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 112
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 113
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.393004
New value of Value function: 0.393004
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1988
New value of Q matrix: 3.81343
New value of Value function: 3.82425
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 115
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 116
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 117
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 118
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 119
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 120
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 121
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 122
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 123
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0331667
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 124
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.024875
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 125
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0199
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 126
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0165833
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 127
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 128
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0142143
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 129
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.0124375
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 130
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -0.0221111
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 131
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 3.19281
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 132
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 133
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0199
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 134
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0995
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 135
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.11855
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 136
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 0.673736
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 137
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 138
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.54975
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 139
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 1.00653
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 140
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 141
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 142
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.637438
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 143
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 1.29177
New value of Value function: 2.475
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 144
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 145
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.50995
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 146
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 147
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.29785
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 148
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 1.06432
New value of Value function: 1.06432
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 149
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.84734
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 150
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.106622
New value of Value function: 1.06432
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 1
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0180909
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 2
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 3
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 4
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 5
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0995
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 6
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 3.28959
New value of Value function: 4.95
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 7
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -2.13551
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 8
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.27488
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 9
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 10
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1.49007
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 11
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.09902
New value of Value function: 1.09902
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 12
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.08803
New value of Value function: 1.09902
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 13
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.46603
New value of Value function: 1.46603
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 14
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.58867
New value of Value function: 2.58867
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 15
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.14114
New value of Value function: 4.14114
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 16
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.17975
New value of Value function: 4.17975
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 17
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.23423
New value of Value function: 4.23423
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 18
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 5.02197
New value of Value function: 5.02197
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 19
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.967414
New value of Value function: 0.411738
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 20
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.466266
New value of Value function: 0.466266
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 21
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.465992
New value of Value function: 0.465992
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 22
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 0.483771
New value of Value function: 0.483771
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.82402
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1989
New value of Q matrix: 3.81342
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1990
New value of Q matrix: 3.81341
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1991
New value of Q matrix: 3.81339
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1992
New value of Q matrix: 3.81338
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1993
New value of Q matrix: 3.81337
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1994
New value of Q matrix: 3.81335
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1995
New value of Q matrix: 3.81334
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1996
New value of Q matrix: 3.81332
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1997
New value of Q matrix: 3.81331
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1998
New value of Q matrix: 3.8133
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1999
New value of Q matrix: 3.81328
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2000
New value of Q matrix: 3.81327
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2001
New value of Q matrix: 3.81326
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.82379
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2002
New value of Q matrix: 3.81324
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2003
New value of Q matrix: 3.81323
New value of Value function: 3.82405
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.82379
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2004
New value of Q matrix: 3.81321
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.82356
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2005
New value of Q matrix: 3.8132
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.82098
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2006
New value of Q matrix: 3.81319
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.76759
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2007
New value of Q matrix: 3.81317
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2008
New value of Q matrix: 3.81316
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2009
New value of Q matrix: 3.81315
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2010
New value of Q matrix: 3.81313
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2011
New value of Q matrix: 3.81312
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2012
New value of Q matrix: 3.8131
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2013
New value of Q matrix: 3.81309
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.7677
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2014
New value of Q matrix: 3.81308
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2015
New value of Q matrix: 3.81306
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.82077
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2016
New value of Q matrix: 3.81305
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2017
New value of Q matrix: 3.81304
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2018
New value of Q matrix: 3.81302
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.76781
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2019
New value of Q matrix: 3.81301
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2020
New value of Q matrix: 3.813
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2021
New value of Q matrix: 3.81298
New value of Value function: 3.82379
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.82353
New value of Value function: 3.82356
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2022
New value of Q matrix: 3.81297
New value of Value function: 3.82356
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.82328
New value of Value function: 3.82356
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2023
New value of Q matrix: 3.81295
New value of Value function: 3.82356
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2024
New value of Q matrix: 3.81294
New value of Value function: 3.82356
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2025
New value of Q matrix: 3.81293
New value of Value function: 3.82356
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.82333
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2026
New value of Q matrix: 3.81291
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.76792
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2027
New value of Q matrix: 3.8129
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2028
New value of Q matrix: 3.81289
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2029
New value of Q matrix: 3.81287
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2030
New value of Q matrix: 3.81286
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2031
New value of Q matrix: 3.81284
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2032
New value of Q matrix: 3.81283
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.76803
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2033
New value of Q matrix: 3.81282
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2034
New value of Q matrix: 3.8128
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2035
New value of Q matrix: 3.81279
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2036
New value of Q matrix: 3.81278
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2037
New value of Q matrix: 3.81276
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2038
New value of Q matrix: 3.81275
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.76813
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.82303
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2039
New value of Q matrix: 3.81274
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2040
New value of Q matrix: 3.81272
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2041
New value of Q matrix: 3.81271
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2042
New value of Q matrix: 3.8127
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2043
New value of Q matrix: 3.81268
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2044
New value of Q matrix: 3.81267
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.82056
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2045
New value of Q matrix: 3.81265
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.82036
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.82015
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2046
New value of Q matrix: 3.81264
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2047
New value of Q matrix: 3.81263
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2048
New value of Q matrix: 3.81261
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2049
New value of Q matrix: 3.8126
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2050
New value of Q matrix: 3.81259
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.82278
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2051
New value of Q matrix: 3.81257
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2052
New value of Q matrix: 3.81256
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2053
New value of Q matrix: 3.81255
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2054
New value of Q matrix: 3.81253
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2055
New value of Q matrix: 3.81252
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2056
New value of Q matrix: 3.81251
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2057
New value of Q matrix: 3.81249
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2058
New value of Q matrix: 3.81248
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2059
New value of Q matrix: 3.81247
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2060
New value of Q matrix: 3.81245
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.81995
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2061
New value of Q matrix: 3.81244
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2062
New value of Q matrix: 3.81243
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2063
New value of Q matrix: 3.81241
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2064
New value of Q matrix: 3.8124
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2065
New value of Q matrix: 3.81239
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2066
New value of Q matrix: 3.81237
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2067
New value of Q matrix: 3.81236
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2068
New value of Q matrix: 3.81235
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2069
New value of Q matrix: 3.81234
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2070
New value of Q matrix: 3.81232
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2071
New value of Q matrix: 3.81231
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.76824
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2072
New value of Q matrix: 3.8123
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2073
New value of Q matrix: 3.81228
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2074
New value of Q matrix: 3.81227
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.76834
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2075
New value of Q matrix: 3.81226
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2076
New value of Q matrix: 3.81224
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2077
New value of Q matrix: 3.81223
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2078
New value of Q matrix: 3.81222
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2079
New value of Q matrix: 3.8122
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.82253
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2080
New value of Q matrix: 3.81181
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 139
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 140
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 141
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -3.33333
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 142
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 143
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 144
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 145
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 146
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 147
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -1.24173
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 148
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.856998
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 149
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.45137
New value of Value function: 1.46603
New value of Policy matrix: 0

=======================================
Simulation: 25
Iteration: 150
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.4631
New value of Value function: 1.4631
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 1
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -2.13994
New value of Value function: 1.06629
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 2
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 0.305268
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 3
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 4.56363
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 4
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.50215
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 5
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.3534
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 6
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.1425
New value of Value function: 4.90067
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 7
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 3.3498
New value of Value function: 4.90067
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 8
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 1.76739
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 9
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 1.4913
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 10
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.53073
New value of Value function: 2.53073
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 11
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.63735
New value of Value function: 2.63735
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 3.81759
New value of Value function: 3.81759
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 13
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.429404
New value of Value function: 0.429404
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 14
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.425322
New value of Value function: 0.429404
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 15
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.425251
New value of Value function: 0.429404
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 16
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.429013
New value of Value function: 0.429013
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 17
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 0.458687
New value of Value function: 0.458687
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2081
New value of Q matrix: 3.8118
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2082
New value of Q matrix: 3.81179
New value of Value function: 3.82333
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.82311
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2083
New value of Q matrix: 3.81178
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2084
New value of Q matrix: 3.81176
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2085
New value of Q matrix: 3.81175
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2086
New value of Q matrix: 3.81174
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2087
New value of Q matrix: 3.81172
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2088
New value of Q matrix: 3.81171
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2089
New value of Q matrix: 3.8117
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2090
New value of Q matrix: 3.81168
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2091
New value of Q matrix: 3.81167
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.82229
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2092
New value of Q matrix: 3.81166
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2093
New value of Q matrix: 3.81165
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2094
New value of Q matrix: 3.81163
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2095
New value of Q matrix: 3.81162
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2096
New value of Q matrix: 3.81161
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2097
New value of Q matrix: 3.8116
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2098
New value of Q matrix: 3.81158
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2099
New value of Q matrix: 3.81157
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.81976
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2100
New value of Q matrix: 3.81156
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2101
New value of Q matrix: 3.81154
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2102
New value of Q matrix: 3.81153
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2103
New value of Q matrix: 3.81152
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2104
New value of Q matrix: 3.81151
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.82204
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2105
New value of Q matrix: 3.81149
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2106
New value of Q matrix: 3.81148
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2107
New value of Q matrix: 3.81147
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2108
New value of Q matrix: 3.81146
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.82181
New value of Value function: 3.82311
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.82288
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2109
New value of Q matrix: 3.81144
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2110
New value of Q matrix: 3.81143
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2111
New value of Q matrix: 3.81142
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2112
New value of Q matrix: 3.81141
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2113
New value of Q matrix: 3.81139
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.76844
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2114
New value of Q matrix: 3.81138
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2115
New value of Q matrix: 3.81137
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2116
New value of Q matrix: 3.81135
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2117
New value of Q matrix: 3.81134
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2118
New value of Q matrix: 3.81133
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2119
New value of Q matrix: 3.81132
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2120
New value of Q matrix: 3.8113
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2121
New value of Q matrix: 3.81129
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2122
New value of Q matrix: 3.81128
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2123
New value of Q matrix: 3.81127
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2124
New value of Q matrix: 3.81125
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2125
New value of Q matrix: 3.81124
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2126
New value of Q matrix: 3.81123
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2127
New value of Q matrix: 3.81122
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2128
New value of Q matrix: 3.8112
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.81956
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2129
New value of Q matrix: 3.81119
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.76853
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2130
New value of Q matrix: 3.81118
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.81936
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2131
New value of Q matrix: 3.81117
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2132
New value of Q matrix: 3.81115
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.82157
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2133
New value of Q matrix: 3.81114
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.82134
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2134
New value of Q matrix: 3.81113
New value of Value function: 3.82288
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.82266
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2135
New value of Q matrix: 3.81112
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.8211
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2136
New value of Q matrix: 3.8111
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2137
New value of Q matrix: 3.81109
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2138
New value of Q matrix: 3.81108
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2139
New value of Q matrix: 3.81107
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2140
New value of Q matrix: 3.81105
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2141
New value of Q matrix: 3.81104
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2142
New value of Q matrix: 3.81103
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2143
New value of Q matrix: 3.81102
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2144
New value of Q matrix: 3.811
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2145
New value of Q matrix: 3.81099
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2146
New value of Q matrix: 3.81098
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2147
New value of Q matrix: 3.81097
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2148
New value of Q matrix: 3.81096
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2149
New value of Q matrix: 3.81094
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2150
New value of Q matrix: 3.81093
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2151
New value of Q matrix: 3.81092
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2152
New value of Q matrix: 3.81091
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2153
New value of Q matrix: 3.81089
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2154
New value of Q matrix: 3.81088
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2155
New value of Q matrix: 3.81087
New value of Value function: 3.82266
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.82244
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2156
New value of Q matrix: 3.81086
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2157
New value of Q matrix: 3.81084
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2158
New value of Q matrix: 3.81083
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2159
New value of Q matrix: 3.81082
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2160
New value of Q matrix: 3.81081
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2161
New value of Q matrix: 3.8108
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2162
New value of Q matrix: 3.81078
New value of Value function: 3.82244
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.82221
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2163
New value of Q matrix: 3.81077
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2164
New value of Q matrix: 3.81076
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2165
New value of Q matrix: 3.81075
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2166
New value of Q matrix: 3.81073
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2167
New value of Q matrix: 3.81072
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2168
New value of Q matrix: 3.81071
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2169
New value of Q matrix: 3.8107
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2170
New value of Q matrix: 3.81068
New value of Value function: 3.82221
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.82199
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2171
New value of Q matrix: 3.81067
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2172
New value of Q matrix: 3.81079
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 127
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: -0.808618
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 128
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.373867
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 129
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.700733
New value of Value function: 1.20914
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 130
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.63
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 131
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.63333
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 132
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.51858
New value of Value function: 1.66667
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 133
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.85925
New value of Value function: 1.85925
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 134
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.57455
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 135
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.95842
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 136
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.41021
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 137
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.85175
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 138
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.63515
New value of Value function: 2.63515
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 139
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.72317
New value of Value function: 2.72317
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 140
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.88265
New value of Value function: 3.81759
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 141
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 3.88634
New value of Value function: 3.88634
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 142
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.15253
New value of Value function: 0.402822
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 143
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 3.95166
New value of Value function: 3.95166
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 144
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.432464
New value of Value function: 0.458687
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 145
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.258762
New value of Value function: 0.458687
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 146
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.436791
New value of Value function: 0.458687
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 147
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.458334
New value of Value function: 0.458334
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 148
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.439618
New value of Value function: 0.458334
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 149
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.458007
New value of Value function: 0.458007
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 150
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 0.479725
New value of Value function: 0.479725
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2173
New value of Q matrix: 3.81091
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 2
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: -1.15178
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 3
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 0.319347
New value of Value function: 0.319347
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 4
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.371244
New value of Value function: 0.848042
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 5
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 0.779365
New value of Value function: 0.779365
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 6
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -2.34782
New value of Value function: 0.848042
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 7
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.82397
New value of Value function: 1.82397
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 8
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.10714
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 9
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.83235
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 10
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.38263
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 11
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.92858
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 12
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.40608
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 13
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.39241
New value of Value function: 7.39241
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 14
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 3.28891
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 15
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 3.53599
New value of Value function: 7.39241
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 16
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.88885
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.25981
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 18
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.95611
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 19
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.36102
New value of Value function: 2.72317
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 20
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.72123
New value of Value function: 2.72123
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 21
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.80062
New value of Value function: 2.80062
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 22
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 4.01259
New value of Value function: 4.01259
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 23
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.479425
New value of Value function: 0.479425
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 24
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.479143
New value of Value function: 0.479143
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 25
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 18
New value of Q matrix: 0.496067
New value of Value function: 0.496067
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2174
New value of Q matrix: 3.81089
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.82087
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2175
New value of Q matrix: 3.81088
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2176
New value of Q matrix: 3.81087
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2177
New value of Q matrix: 3.81086
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2178
New value of Q matrix: 3.81084
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2179
New value of Q matrix: 3.81083
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2180
New value of Q matrix: 3.81082
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2181
New value of Q matrix: 3.81081
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2182
New value of Q matrix: 3.81079
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2183
New value of Q matrix: 3.81078
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2184
New value of Q matrix: 3.81077
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2185
New value of Q matrix: 3.81076
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.82064
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2186
New value of Q matrix: 3.81074
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2187
New value of Q matrix: 3.81073
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2188
New value of Q matrix: 3.81072
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2189
New value of Q matrix: 3.81071
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2190
New value of Q matrix: 3.81069
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2191
New value of Q matrix: 3.81068
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2192
New value of Q matrix: 3.81067
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2193
New value of Q matrix: 3.81066
New value of Value function: 3.82199
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.82178
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2194
New value of Q matrix: 3.81065
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2195
New value of Q matrix: 3.81063
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2196
New value of Q matrix: 3.81062
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2197
New value of Q matrix: 3.81061
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2198
New value of Q matrix: 3.8106
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2199
New value of Q matrix: 3.81058
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2200
New value of Q matrix: 3.81057
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2201
New value of Q matrix: 3.81056
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.81916
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.76862
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.81896
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2202
New value of Q matrix: 3.81055
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2203
New value of Q matrix: 3.81053
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2204
New value of Q matrix: 3.81052
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2205
New value of Q matrix: 3.81051
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.76871
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2206
New value of Q matrix: 3.8105
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.81877
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2207
New value of Q matrix: 3.81049
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2208
New value of Q matrix: 3.81047
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2209
New value of Q matrix: 3.81046
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2210
New value of Q matrix: 3.81045
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2211
New value of Q matrix: 3.81044
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2212
New value of Q matrix: 3.81043
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2213
New value of Q matrix: 3.81041
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2214
New value of Q matrix: 3.8104
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2215
New value of Q matrix: 3.81039
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2216
New value of Q matrix: 3.81038
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.7688
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2217
New value of Q matrix: 3.81036
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.76889
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.76897
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.81857
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2218
New value of Q matrix: 3.81035
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2219
New value of Q matrix: 3.81034
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.82041
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2220
New value of Q matrix: 3.81033
New value of Value function: 3.82178
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.82156
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2221
New value of Q matrix: 3.81032
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2222
New value of Q matrix: 3.8103
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.82018
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2223
New value of Q matrix: 3.81029
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2224
New value of Q matrix: 3.81028
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.76905
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2225
New value of Q matrix: 3.81027
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2226
New value of Q matrix: 3.81026
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.81838
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2227
New value of Q matrix: 3.81024
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2228
New value of Q matrix: 3.81023
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.76914
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2229
New value of Q matrix: 3.81022
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2230
New value of Q matrix: 3.81021
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2231
New value of Q matrix: 3.8102
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2232
New value of Q matrix: 3.81018
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2233
New value of Q matrix: 3.81017
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2234
New value of Q matrix: 3.81016
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2235
New value of Q matrix: 3.81015
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2236
New value of Q matrix: 3.81014
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2237
New value of Q matrix: 3.81012
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2238
New value of Q matrix: 3.81011
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2239
New value of Q matrix: 3.8101
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2240
New value of Q matrix: 3.81009
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2241
New value of Q matrix: 3.81008
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2242
New value of Q matrix: 3.81006
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2243
New value of Q matrix: 3.81005
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2244
New value of Q matrix: 3.81004
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2245
New value of Q matrix: 3.81003
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2246
New value of Q matrix: 3.81002
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2247
New value of Q matrix: 3.81
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2248
New value of Q matrix: 3.80999
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2249
New value of Q matrix: 3.80998
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2250
New value of Q matrix: 3.80997
New value of Value function: 3.82156
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.82134
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2251
New value of Q matrix: 3.80996
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.76922
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2252
New value of Q matrix: 3.80994
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2253
New value of Q matrix: 3.80993
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2254
New value of Q matrix: 3.80992
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2255
New value of Q matrix: 3.80991
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2256
New value of Q matrix: 3.8099
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2257
New value of Q matrix: 3.80989
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.81819
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2258
New value of Q matrix: 3.80987
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2259
New value of Q matrix: 3.80986
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2260
New value of Q matrix: 3.80985
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2261
New value of Q matrix: 3.80984
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2262
New value of Q matrix: 3.80983
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2263
New value of Q matrix: 3.80981
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2264
New value of Q matrix: 3.8098
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2265
New value of Q matrix: 3.80979
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.818
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2266
New value of Q matrix: 3.80978
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2267
New value of Q matrix: 3.80968
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 142
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.579654
New value of Value function: 0.58551
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 143
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.681392
New value of Value function: 0.681392
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2268
New value of Q matrix: 3.80979
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 145
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.981299
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 146
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.851238
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 147
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: -2.09251
New value of Value function: 0.848042
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 148
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 2.18431
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 149
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -2.03984
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 27
Iteration: 150
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.325
New value of Value function: 3.325
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2269
New value of Q matrix: 3.80978
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.81781
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.81996
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2270
New value of Q matrix: 3.80977
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2271
New value of Q matrix: 3.80975
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 6
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.94048
New value of Value function: 1.94048
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 7
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.514734
New value of Value function: 0.681392
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 8
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.78313
New value of Value function: 0.78313
New value of Policy matrix: 4

=======================================
Simulation: 28
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2272
New value of Q matrix: 3.80973
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 10
----------
State: 2953
	Distance: 5
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.745166
New value of Value function: 0.78313
New value of Policy matrix: 4

=======================================
Simulation: 28
Iteration: 11
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: -1.00744
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 12
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.7744
New value of Value function: 1.82397
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 13
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 0.721328
New value of Value function: 1.82397
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 14
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.57935
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 15
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 3.29587
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 16
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.59308
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 17
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.54477
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 18
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.23122
New value of Value function: 8.23122
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 19
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 3.27491
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 20
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.71273
New value of Value function: 8.23122
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 21
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.48497
New value of Value function: 8.23122
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 22
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 1.81177
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 23
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.01891
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 24
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.79887
New value of Value function: 2.79887
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 25
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.77088
New value of Value function: 2.79887
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 26
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.86791
New value of Value function: 2.86791
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 27
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.00057
New value of Value function: 4.00057
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 28
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 1.85006
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 29
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.87196
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 30
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.0243
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 31
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 1.92883
New value of Value function: 3.7375
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2273
New value of Q matrix: 3.80972
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2274
New value of Q matrix: 3.80971
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.81763
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.76929
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2275
New value of Q matrix: 3.8097
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.81973
New value of Value function: 3.82134
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.82113
New value of Value function: 3.82113
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2276
New value of Q matrix: 3.80969
New value of Value function: 3.82113
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2277
New value of Q matrix: 3.80968
New value of Value function: 3.82113
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.81951
New value of Value function: 3.82113
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.81929
New value of Value function: 3.82113
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.82092
New value of Value function: 3.82092
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2278
New value of Q matrix: 3.80966
New value of Value function: 3.82092
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2279
New value of Q matrix: 3.80965
New value of Value function: 3.82092
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.8207
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2280
New value of Q matrix: 3.80964
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2281
New value of Q matrix: 3.80963
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2282
New value of Q matrix: 3.80962
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.81907
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2283
New value of Q matrix: 3.8096
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2284
New value of Q matrix: 3.80959
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.81886
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2285
New value of Q matrix: 3.80958
New value of Value function: 3.8207
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.82049
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2286
New value of Q matrix: 3.80957
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2287
New value of Q matrix: 3.80956
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2288
New value of Q matrix: 3.80955
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2289
New value of Q matrix: 3.80953
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2290
New value of Q matrix: 3.80952
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2291
New value of Q matrix: 3.80951
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2292
New value of Q matrix: 3.8095
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2293
New value of Q matrix: 3.80949
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2294
New value of Q matrix: 3.80947
New value of Value function: 3.82049
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.82028
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2295
New value of Q matrix: 3.80946
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2296
New value of Q matrix: 3.80945
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.81744
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.81725
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2297
New value of Q matrix: 3.80944
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.76937
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2298
New value of Q matrix: 3.80943
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2299
New value of Q matrix: 3.80941
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.81864
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2300
New value of Q matrix: 3.8094
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2301
New value of Q matrix: 3.80939
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2302
New value of Q matrix: 3.80938
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2303
New value of Q matrix: 3.80937
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.81843
New value of Value function: 3.82028
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.82007
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2304
New value of Q matrix: 3.80935
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2305
New value of Q matrix: 3.80934
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2306
New value of Q matrix: 3.80933
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2307
New value of Q matrix: 3.80932
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2308
New value of Q matrix: 3.80931
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2309
New value of Q matrix: 3.8093
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2310
New value of Q matrix: 3.80928
New value of Value function: 3.82007
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.81987
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.81821
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2311
New value of Q matrix: 3.80927
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2312
New value of Q matrix: 3.80926
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2313
New value of Q matrix: 3.80925
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2314
New value of Q matrix: 3.80924
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2315
New value of Q matrix: 3.80922
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2316
New value of Q matrix: 3.80921
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2317
New value of Q matrix: 3.8092
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.76944
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.81706
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2318
New value of Q matrix: 3.80919
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2319
New value of Q matrix: 3.80918
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2320
New value of Q matrix: 3.80916
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2321
New value of Q matrix: 3.80915
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2322
New value of Q matrix: 3.80914
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2323
New value of Q matrix: 3.80913
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.7695
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.81688
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2324
New value of Q matrix: 3.80912
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2325
New value of Q matrix: 3.80911
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2326
New value of Q matrix: 3.80909
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2327
New value of Q matrix: 3.80908
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2328
New value of Q matrix: 3.80907
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2329
New value of Q matrix: 3.80906
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2330
New value of Q matrix: 3.80905
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2331
New value of Q matrix: 3.80903
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.76957
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2332
New value of Q matrix: 3.80902
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2333
New value of Q matrix: 3.80901
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2334
New value of Q matrix: 3.809
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2335
New value of Q matrix: 3.80899
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2336
New value of Q matrix: 3.80898
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.76964
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2337
New value of Q matrix: 3.80896
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2338
New value of Q matrix: 3.80895
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.76971
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2339
New value of Q matrix: 3.80894
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2340
New value of Q matrix: 3.80893
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2341
New value of Q matrix: 3.80892
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2342
New value of Q matrix: 3.80891
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.818
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2343
New value of Q matrix: 3.80889
New value of Value function: 3.81987
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.81966
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2344
New value of Q matrix: 3.80888
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2345
New value of Q matrix: 3.80887
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.81779
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2346
New value of Q matrix: 3.80886
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2347
New value of Q matrix: 3.80885
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2348
New value of Q matrix: 3.80884
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.81669
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2349
New value of Q matrix: 3.80882
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2350
New value of Q matrix: 3.80881
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.76977
New value of Value function: 3.81966
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.81945
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2351
New value of Q matrix: 3.8088
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2352
New value of Q matrix: 3.80879
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2353
New value of Q matrix: 3.80878
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2354
New value of Q matrix: 3.80877
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2355
New value of Q matrix: 3.80875
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2356
New value of Q matrix: 3.80874
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2357
New value of Q matrix: 3.80873
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.81758
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 193
New value of Q matrix: 3.81246
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 2
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 3
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.781259
New value of Value function: 0.781259
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2358
New value of Q matrix: 3.80872
New value of Value function: 3.81945
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.81925
New value of Value function: 3.81925
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2359
New value of Q matrix: 3.80871
New value of Value function: 3.81925
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2360
New value of Q matrix: 3.8087
New value of Value function: 3.81925
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2361
New value of Q matrix: 3.80868
New value of Value function: 3.81925
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.81905
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2362
New value of Q matrix: 3.80867
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2363
New value of Q matrix: 3.80866
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2364
New value of Q matrix: 3.80865
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2365
New value of Q matrix: 3.80864
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.76983
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2366
New value of Q matrix: 3.80863
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2367
New value of Q matrix: 3.80861
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2368
New value of Q matrix: 3.8086
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2369
New value of Q matrix: 3.80859
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2370
New value of Q matrix: 3.80858
New value of Value function: 3.81905
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.81884
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2371
New value of Q matrix: 3.80857
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2372
New value of Q matrix: 3.80855
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.76989
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2373
New value of Q matrix: 3.80854
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2374
New value of Q matrix: 3.80853
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2375
New value of Q matrix: 3.80852
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.76995
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2376
New value of Q matrix: 3.80851
New value of Value function: 3.81884
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.81864
New value of Value function: 3.81864
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2377
New value of Q matrix: 3.8085
New value of Value function: 3.81864
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2378
New value of Q matrix: 3.80848
New value of Value function: 3.81864
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2379
New value of Q matrix: 3.80847
New value of Value function: 3.81864
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2380
New value of Q matrix: 3.80846
New value of Value function: 3.81864
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.81844
New value of Value function: 3.81844
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2381
New value of Q matrix: 3.80845
New value of Value function: 3.81844
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.81824
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2382
New value of Q matrix: 3.80844
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2383
New value of Q matrix: 3.80843
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2384
New value of Q matrix: 3.80841
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2385
New value of Q matrix: 3.8084
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2386
New value of Q matrix: 3.80839
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2387
New value of Q matrix: 3.80838
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2388
New value of Q matrix: 3.80837
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2389
New value of Q matrix: 3.80835
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2390
New value of Q matrix: 3.80834
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2391
New value of Q matrix: 3.80833
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2392
New value of Q matrix: 3.80832
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2393
New value of Q matrix: 3.80831
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 3.8123
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2394
New value of Q matrix: 3.80829
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2395
New value of Q matrix: 3.80828
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2396
New value of Q matrix: 3.80827
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2397
New value of Q matrix: 3.80826
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.81737
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.81716
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2398
New value of Q matrix: 3.80825
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2399
New value of Q matrix: 3.80824
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2400
New value of Q matrix: 3.80822
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2401
New value of Q matrix: 3.80821
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.81213
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.81695
New value of Value function: 3.81824
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 3.81805
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2402
New value of Q matrix: 3.8082
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2403
New value of Q matrix: 3.80819
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2404
New value of Q matrix: 3.80818
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2405
New value of Q matrix: 3.80817
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2406
New value of Q matrix: 3.80815
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2407
New value of Q matrix: 3.80814
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2408
New value of Q matrix: 3.80813
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2409
New value of Q matrix: 3.80812
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2410
New value of Q matrix: 3.80811
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2411
New value of Q matrix: 3.80809
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2412
New value of Q matrix: 3.80808
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2413
New value of Q matrix: 3.80807
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2414
New value of Q matrix: 3.80806
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2415
New value of Q matrix: 3.80805
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2416
New value of Q matrix: 3.80804
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2417
New value of Q matrix: 3.80802
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2418
New value of Q matrix: 3.80801
New value of Value function: 3.81805
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 3.81785
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2419
New value of Q matrix: 3.808
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2420
New value of Q matrix: 3.80799
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2421
New value of Q matrix: 3.80798
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2422
New value of Q matrix: 3.80797
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2423
New value of Q matrix: 3.80795
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 3.81196
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2424
New value of Q matrix: 3.80794
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2425
New value of Q matrix: 3.80793
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2426
New value of Q matrix: 3.80792
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2427
New value of Q matrix: 3.80791
New value of Value function: 3.81785
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.81765
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2428
New value of Q matrix: 3.8079
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2429
New value of Q matrix: 3.80788
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2430
New value of Q matrix: 3.80787
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2431
New value of Q matrix: 3.80786
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 3.8118
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.81674
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2432
New value of Q matrix: 3.80785
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2433
New value of Q matrix: 3.80784
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2434
New value of Q matrix: 3.80783
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2435
New value of Q matrix: 3.80781
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2436
New value of Q matrix: 3.8078
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2437
New value of Q matrix: 3.80779
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2438
New value of Q matrix: 3.80778
New value of Value function: 3.81765
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 3.81746
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2439
New value of Q matrix: 3.80777
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2440
New value of Q matrix: 3.80776
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2441
New value of Q matrix: 3.80774
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2442
New value of Q matrix: 3.80773
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.81653
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2443
New value of Q matrix: 3.80772
New value of Value function: 3.81746
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 3.81727
New value of Value function: 3.81727
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2444
New value of Q matrix: 3.80771
New value of Value function: 3.81727
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2445
New value of Q matrix: 3.8077
New value of Value function: 3.81727
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 3.81707
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2446
New value of Q matrix: 3.80769
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2447
New value of Q matrix: 3.80767
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2448
New value of Q matrix: 3.80766
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2449
New value of Q matrix: 3.80765
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2450
New value of Q matrix: 3.80764
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2451
New value of Q matrix: 3.80731
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 122
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 123
----------
State: 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 124
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 125
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 126
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 127
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.778902
New value of Value function: 0.778902
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.81633
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2452
New value of Q matrix: 3.8073
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 130
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.775007
New value of Value function: 0.775007
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 131
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -1.84655
New value of Value function: 0.775007
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 132
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: -2.37212
New value of Value function: 0.775007
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 133
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.693406
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 134
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -1.88326
New value of Value function: 0.848042
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 135
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 136
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 137
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 138
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -1.42857
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 139
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 140
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -1.25
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 141
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 142
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 143
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 144
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0911675
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 145
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 3.43173
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 146
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 147
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 148
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -1.66667
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 149
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 29
Iteration: 150
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.58842
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2453
New value of Q matrix: 3.80728
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 3.81163
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2454
New value of Q matrix: 3.80727
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2455
New value of Q matrix: 3.80726
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2456
New value of Q matrix: 3.80725
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.76999
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2457
New value of Q matrix: 3.80724
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2458
New value of Q matrix: 3.80723
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2459
New value of Q matrix: 3.80721
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2460
New value of Q matrix: 3.8072
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2461
New value of Q matrix: 3.80719
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2462
New value of Q matrix: 3.80718
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2463
New value of Q matrix: 3.80717
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2464
New value of Q matrix: 3.80716
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2465
New value of Q matrix: 3.80715
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2466
New value of Q matrix: 3.80713
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2467
New value of Q matrix: 3.80712
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.81612
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2468
New value of Q matrix: 3.80711
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.81147
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2469
New value of Q matrix: 3.8071
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2470
New value of Q matrix: 3.80709
New value of Value function: 3.81707
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.81688
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2471
New value of Q matrix: 3.80708
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 3.81131
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2472
New value of Q matrix: 3.80707
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2473
New value of Q matrix: 3.80705
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.77004
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.81592
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2474
New value of Q matrix: 3.80704
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2475
New value of Q matrix: 3.80703
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2476
New value of Q matrix: 3.80702
New value of Value function: 3.81688
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 3.81669
New value of Value function: 3.81669
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2477
New value of Q matrix: 3.80701
New value of Value function: 3.81669
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2478
New value of Q matrix: 3.807
New value of Value function: 3.81669
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2479
New value of Q matrix: 3.80698
New value of Value function: 3.81669
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2480
New value of Q matrix: 3.80697
New value of Value function: 3.81669
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2481
New value of Q matrix: 3.80696
New value of Value function: 3.81669
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 3.8165
New value of Value function: 3.8165
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.81631
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2482
New value of Q matrix: 3.80695
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2483
New value of Q matrix: 3.80694
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.77008
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2484
New value of Q matrix: 3.80693
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2485
New value of Q matrix: 3.80692
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2486
New value of Q matrix: 3.8069
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.81571
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2487
New value of Q matrix: 3.80689
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2488
New value of Q matrix: 3.80688
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2489
New value of Q matrix: 3.80687
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.77013
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2490
New value of Q matrix: 3.80686
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2491
New value of Q matrix: 3.80685
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2492
New value of Q matrix: 3.80683
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2493
New value of Q matrix: 3.80682
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2494
New value of Q matrix: 3.80681
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2495
New value of Q matrix: 3.8068
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2496
New value of Q matrix: 3.80679
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 3.81114
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2497
New value of Q matrix: 3.80678
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2498
New value of Q matrix: 3.80677
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.77017
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2499
New value of Q matrix: 3.80675
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2500
New value of Q matrix: 3.80674
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2501
New value of Q matrix: 3.80673
New value of Value function: 3.81631
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.81612
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2502
New value of Q matrix: 3.80672
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2503
New value of Q matrix: 3.80671
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2504
New value of Q matrix: 3.8067
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2505
New value of Q matrix: 3.80669
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.81098
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2506
New value of Q matrix: 3.80667
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2507
New value of Q matrix: 3.80666
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2508
New value of Q matrix: 3.80665
New value of Value function: 3.81612
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.81594
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2509
New value of Q matrix: 3.80664
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2510
New value of Q matrix: 3.80663
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2511
New value of Q matrix: 3.80662
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2512
New value of Q matrix: 3.80661
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2513
New value of Q matrix: 3.80659
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2514
New value of Q matrix: 3.80658
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2515
New value of Q matrix: 3.80657
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2516
New value of Q matrix: 3.80656
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2517
New value of Q matrix: 3.80655
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2518
New value of Q matrix: 3.80654
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.77021
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2519
New value of Q matrix: 3.80653
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2520
New value of Q matrix: 3.80651
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2521
New value of Q matrix: 3.8065
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.81081
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2522
New value of Q matrix: 3.80649
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2523
New value of Q matrix: 3.80648
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.81551
New value of Value function: 3.81594
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 3.81575
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2524
New value of Q matrix: 3.80647
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2525
New value of Q matrix: 3.80646
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2526
New value of Q matrix: 3.80645
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2527
New value of Q matrix: 3.80643
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.81065
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2528
New value of Q matrix: 3.80642
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2529
New value of Q matrix: 3.80641
New value of Value function: 3.81575
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 3.81556
New value of Value function: 3.81556
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2530
New value of Q matrix: 3.8064
New value of Value function: 3.81556
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2531
New value of Q matrix: 3.80639
New value of Value function: 3.81556
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2532
New value of Q matrix: 3.80638
New value of Value function: 3.81556
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 3.81538
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2533
New value of Q matrix: 3.80637
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2534
New value of Q matrix: 3.80635
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2535
New value of Q matrix: 3.80634
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2536
New value of Q matrix: 3.80633
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2537
New value of Q matrix: 3.80632
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 3.81049
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2538
New value of Q matrix: 3.80631
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2539
New value of Q matrix: 3.8063
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2540
New value of Q matrix: 3.80629
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2541
New value of Q matrix: 3.80627
New value of Value function: 3.81551
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.8153
New value of Value function: 3.81538
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2542
New value of Q matrix: 3.80626
New value of Value function: 3.81538
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2543
New value of Q matrix: 3.80625
New value of Value function: 3.81538
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2544
New value of Q matrix: 3.80624
New value of Value function: 3.81538
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2545
New value of Q matrix: 3.80623
New value of Value function: 3.81538
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 3.81033
New value of Value function: 3.81538
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 3.8152
New value of Value function: 3.8153
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2546
New value of Q matrix: 3.80622
New value of Value function: 3.8153
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2547
New value of Q matrix: 3.80621
New value of Value function: 3.8153
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.8151
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2548
New value of Q matrix: 3.80619
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2549
New value of Q matrix: 3.80618
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2550
New value of Q matrix: 3.80617
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 3.81017
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2551
New value of Q matrix: 3.80616
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2552
New value of Q matrix: 3.80601
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 133
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.689313
New value of Value function: 0.689313
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 134
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.858317
New value of Value function: 1.94048
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 135
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.785116
New value of Value function: 1.82397
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 136
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 0.737346
New value of Value function: 1.82397
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 137
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.60637
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 138
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.6854
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 139
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.61863
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 140
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.62938
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 141
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.70859
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 142
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 3.68775
New value of Value function: 8.23122
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 143
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 3.63466
New value of Value function: 8.23122
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 144
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.84345
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 145
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.41994
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 146
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 1.84929
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 147
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.64416
New value of Value function: 4.69107
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 148
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.64416
New value of Value function: 4.69107
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 149
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.68933
New value of Value function: 4.68933
New value of Policy matrix: 0

=======================================
Simulation: 30
Iteration: 150
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 4.84188
New value of Value function: 4.84188
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 1
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 2
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 3
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 4
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 5
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 6
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 7
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 8
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 9
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 10
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 11
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 12
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 13
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 1.66667
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 14
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.675
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 15
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.495
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 16
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.495
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 17
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.2475
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 18
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.99
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 19
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.33
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 20
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.66
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 21
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.825
New value of Value function: 1.66667
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 22
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.6625
New value of Value function: 1.6625
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 23
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.33
New value of Value function: 1.33
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 24
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 25
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 26
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -1.52782
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 27
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -1.30956
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 28
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -1.2584
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 29
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 2.93315
New value of Value function: 4.14114
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 30
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -1.11858
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 31
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: -1.09674
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 32
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 3.09049
New value of Value function: 4.14114
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 33
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.2314
New value of Value function: 4.2314
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 34
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.27767
New value of Value function: 4.27767
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 35
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.59245
New value of Value function: 5.02197
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 36
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.3185
New value of Value function: 4.3185
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 37
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 5.04768
New value of Value function: 5.04768
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 38
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.678145
New value of Value function: 0.411738
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 39
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.483516
New value of Value function: 0.483516
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 40
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.114639
New value of Value function: 0.483516
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 41
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 1.52324
New value of Value function: 1.52324
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 42
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.386723
New value of Value function: 0.781259
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 43
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.777045
New value of Value function: 0.781259
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 3.77024
New value of Value function: 3.8152
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.81501
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2553
New value of Q matrix: 3.80599
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2554
New value of Q matrix: 3.80598
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2555
New value of Q matrix: 3.80597
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2556
New value of Q matrix: 3.80596
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2557
New value of Q matrix: 3.80595
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2558
New value of Q matrix: 3.80594
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2559
New value of Q matrix: 3.80593
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2560
New value of Q matrix: 3.80592
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2561
New value of Q matrix: 3.8059
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2562
New value of Q matrix: 3.80589
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 3.77028
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2563
New value of Q matrix: 3.80588
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2564
New value of Q matrix: 3.80587
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.77031
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2565
New value of Q matrix: 3.80586
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2566
New value of Q matrix: 3.80585
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2567
New value of Q matrix: 3.80584
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2568
New value of Q matrix: 3.80583
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2569
New value of Q matrix: 3.80581
New value of Value function: 3.8151
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.81489
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.81469
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 3.77034
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2570
New value of Q matrix: 3.8058
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2571
New value of Q matrix: 3.80579
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2572
New value of Q matrix: 3.80578
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 3.81001
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2573
New value of Q matrix: 3.80577
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2574
New value of Q matrix: 3.80576
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2575
New value of Q matrix: 3.80575
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2576
New value of Q matrix: 3.80574
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2577
New value of Q matrix: 3.80572
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2578
New value of Q matrix: 3.80571
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 3.77038
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2579
New value of Q matrix: 3.8057
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2580
New value of Q matrix: 3.80569
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.80985
New value of Value function: 3.81501
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 3.81483
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.81449
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2581
New value of Q matrix: 3.80568
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2582
New value of Q matrix: 3.80567
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2583
New value of Q matrix: 3.80566
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.81429
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2584
New value of Q matrix: 3.80565
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2585
New value of Q matrix: 3.80563
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2586
New value of Q matrix: 3.80562
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2587
New value of Q matrix: 3.80561
New value of Value function: 3.81483
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 3.81465
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2588
New value of Q matrix: 3.8056
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2589
New value of Q matrix: 3.80559
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2590
New value of Q matrix: 3.80558
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2591
New value of Q matrix: 3.80557
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2592
New value of Q matrix: 3.80556
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2593
New value of Q matrix: 3.80554
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.8141
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 3.8139
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2594
New value of Q matrix: 3.80553
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2595
New value of Q matrix: 3.80552
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2596
New value of Q matrix: 3.80551
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2597
New value of Q matrix: 3.8055
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2598
New value of Q matrix: 3.80549
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2599
New value of Q matrix: 3.80548
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2600
New value of Q matrix: 3.80547
New value of Value function: 3.81465
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 3.81447
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2601
New value of Q matrix: 3.80546
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2602
New value of Q matrix: 3.80544
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2603
New value of Q matrix: 3.80543
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2604
New value of Q matrix: 3.80542
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 3.81371
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2605
New value of Q matrix: 3.80541
New value of Value function: 3.81447
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 3.81429
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 3.81352
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2606
New value of Q matrix: 3.8054
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 3.80969
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2607
New value of Q matrix: 3.80539
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2608
New value of Q matrix: 3.80538
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2609
New value of Q matrix: 3.80537
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2610
New value of Q matrix: 3.80535
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2611
New value of Q matrix: 3.80534
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2612
New value of Q matrix: 3.80533
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 3.80953
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2613
New value of Q matrix: 3.80532
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2614
New value of Q matrix: 3.80531
New value of Value function: 3.81429
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 3.81411
New value of Value function: 3.81411
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2615
New value of Q matrix: 3.8053
New value of Value function: 3.81411
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2616
New value of Q matrix: 3.80529
New value of Value function: 3.81411
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 3.80937
New value of Value function: 3.81411
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2617
New value of Q matrix: 3.80528
New value of Value function: 3.81411
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 3.81394
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2618
New value of Q matrix: 3.80526
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2619
New value of Q matrix: 3.80525
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2620
New value of Q matrix: 3.80524
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2621
New value of Q matrix: 3.80523
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2622
New value of Q matrix: 3.80522
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2623
New value of Q matrix: 3.80521
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2624
New value of Q matrix: 3.8052
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 3.77041
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2625
New value of Q matrix: 3.80519
New value of Value function: 3.81394
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 3.81376
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2626
New value of Q matrix: 3.80518
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2627
New value of Q matrix: 3.80516
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2628
New value of Q matrix: 3.80515
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2629
New value of Q matrix: 3.80514
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 3.81332
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2630
New value of Q matrix: 3.80513
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 3.81313
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 1
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 2
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 3
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 4
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -2.32705
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 5
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 6
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.0815242
New value of Value function: 0.0815242
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 7
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.497184
New value of Value function: 0.411738
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 8
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.405266
New value of Value function: 0.405266
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 9
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.236451
New value of Value function: 0.402822
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 10
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.210728
New value of Value function: 0.405266
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 11
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 2.21859
New value of Value function: 2.21859
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 12
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 13
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 14
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 15
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 16
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.8036
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 32
Iteration: 17
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.30389
New value of Value function: 2.21859
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 18
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.569161
New value of Value function: 2.21859
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 19
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 0.578992
New value of Value function: 2.21859
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2631
New value of Q matrix: 3.80512
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2632
New value of Q matrix: 3.80511
New value of Value function: 3.81376
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 3.81359
New value of Value function: 3.81359
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2633
New value of Q matrix: 3.8051
New value of Value function: 3.81359
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2634
New value of Q matrix: 3.80509
New value of Value function: 3.81359
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2635
New value of Q matrix: 3.80507
New value of Value function: 3.81359
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2636
New value of Q matrix: 3.80506
New value of Value function: 3.81359
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 3.81341
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2637
New value of Q matrix: 3.80505
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2638
New value of Q matrix: 3.80504
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2639
New value of Q matrix: 3.80503
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2640
New value of Q matrix: 3.80502
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2641
New value of Q matrix: 3.80501
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 3.80921
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2642
New value of Q matrix: 3.805
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2643
New value of Q matrix: 3.80498
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2644
New value of Q matrix: 3.80497
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2645
New value of Q matrix: 3.80496
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2646
New value of Q matrix: 3.80495
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2647
New value of Q matrix: 3.80494
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2648
New value of Q matrix: 3.80493
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.77043
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2649
New value of Q matrix: 3.80492
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2650
New value of Q matrix: 3.80491
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2651
New value of Q matrix: 3.80489
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2652
New value of Q matrix: 3.80488
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 3.80905
New value of Value function: 3.81341
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 3.81324
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2653
New value of Q matrix: 3.80487
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2654
New value of Q matrix: 3.80486
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2655
New value of Q matrix: 3.80485
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2656
New value of Q matrix: 3.80484
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 3.77045
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 3.77048
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 3.81294
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 3.81275
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2657
New value of Q matrix: 3.80483
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2658
New value of Q matrix: 3.80482
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2659
New value of Q matrix: 3.8048
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2660
New value of Q matrix: 3.80479
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2661
New value of Q matrix: 3.80478
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 3.81256
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2662
New value of Q matrix: 3.80477
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2663
New value of Q matrix: 3.80476
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 3.81238
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 3.80889
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2664
New value of Q matrix: 3.80475
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2665
New value of Q matrix: 3.80474
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2666
New value of Q matrix: 3.80473
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2667
New value of Q matrix: 3.80472
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2668
New value of Q matrix: 3.8047
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2669
New value of Q matrix: 3.80469
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2670
New value of Q matrix: 3.80468
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2671
New value of Q matrix: 3.80467
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2672
New value of Q matrix: 3.80466
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2673
New value of Q matrix: 3.80465
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2674
New value of Q matrix: 3.80464
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2675
New value of Q matrix: 3.80463
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2676
New value of Q matrix: 3.80462
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.7705
New value of Value function: 3.81324
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 3.81306
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2677
New value of Q matrix: 3.8046
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2678
New value of Q matrix: 3.80459
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2679
New value of Q matrix: 3.80458
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2680
New value of Q matrix: 3.80457
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2681
New value of Q matrix: 3.80456
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2682
New value of Q matrix: 3.80455
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.77052
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 3.80874
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2683
New value of Q matrix: 3.80454
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2684
New value of Q matrix: 3.80453
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2685
New value of Q matrix: 3.80452
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2686
New value of Q matrix: 3.80451
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2687
New value of Q matrix: 3.80449
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2688
New value of Q matrix: 3.80448
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2689
New value of Q matrix: 3.80447
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2690
New value of Q matrix: 3.80446
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2691
New value of Q matrix: 3.80445
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2692
New value of Q matrix: 3.80444
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2693
New value of Q matrix: 3.80443
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2694
New value of Q matrix: 3.80442
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2695
New value of Q matrix: 3.80441
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2696
New value of Q matrix: 3.8044
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2697
New value of Q matrix: 3.80438
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2698
New value of Q matrix: 3.80437
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 3.80858
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 3.80842
New value of Value function: 3.81306
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 3.81289
New value of Value function: 3.81289
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2699
New value of Q matrix: 3.80436
New value of Value function: 3.81289
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2700
New value of Q matrix: 3.80435
New value of Value function: 3.81289
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2701
New value of Q matrix: 3.80434
New value of Value function: 3.81289
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 3.81272
New value of Value function: 3.81272
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2702
New value of Q matrix: 3.80433
New value of Value function: 3.81272
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.77054
New value of Value function: 3.81272
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 3.80827
New value of Value function: 3.81272
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2703
New value of Q matrix: 3.80432
New value of Value function: 3.81272
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2704
New value of Q matrix: 3.80431
New value of Value function: 3.81272
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 3.81255
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 3.77056
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 3.80812
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 3.80796
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2705
New value of Q matrix: 3.8043
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2706
New value of Q matrix: 3.80429
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2707
New value of Q matrix: 3.80427
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 3.77058
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2708
New value of Q matrix: 3.80426
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2709
New value of Q matrix: 3.80425
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2710
New value of Q matrix: 3.80424
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2711
New value of Q matrix: 3.80423
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 3.80781
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 3.7706
New value of Value function: 3.81255
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 3.81238
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2712
New value of Q matrix: 3.80422
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2713
New value of Q matrix: 3.80421
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2714
New value of Q matrix: 3.8042
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2715
New value of Q matrix: 3.80419
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2716
New value of Q matrix: 3.80418
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 3.80766
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2717
New value of Q matrix: 3.80416
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2718
New value of Q matrix: 3.80415
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2719
New value of Q matrix: 3.80414
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2720
New value of Q matrix: 3.80413
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2721
New value of Q matrix: 3.80412
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2722
New value of Q matrix: 3.80411
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2723
New value of Q matrix: 3.8041
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 3.80751
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2724
New value of Q matrix: 3.80409
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2725
New value of Q matrix: 3.80408
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2726
New value of Q matrix: 3.80407
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2727
New value of Q matrix: 3.80405
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2728
New value of Q matrix: 3.80404
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2729
New value of Q matrix: 3.80403
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2730
New value of Q matrix: 3.80399
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 3
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.548517
New value of Value function: 0.689313
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 4
----------
State: 3529
	Distance: 6
	Angle: 1
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.525958
New value of Value function: 0.548517
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 5
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.416458
New value of Value function: 0.836595
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 6
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0.427234
New value of Value function: 0.836595
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 7
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.373743
New value of Value function: 0.863098
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 8
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 1.14791
New value of Value function: 1.14791
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 9
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.43762
New value of Value function: 7.43762
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 10
----------
State: 4825
	Distance: 8
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.46881
New value of Value function: 4.975
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 11
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.29175
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 12
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 28
New value of Q matrix: 4.46226
New value of Value function: 4.975
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 13
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.7065
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 14
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 15
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 16
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 17
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 18
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 1.8534
New value of Value function: 1.8534
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 19
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 1.92951
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 20
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 8.43244
New value of Value function: 8.43244
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 21
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.79564
New value of Value function: 8.79564
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 22
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 29
New value of Q matrix: 4.5025
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 23
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.59772
New value of Value function: 9.59772
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 24
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 30
New value of Q matrix: 4.50248
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 25
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.59772
New value of Value function: 9.59772
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 26
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 31
New value of Q matrix: 4.50245
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 27
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.59772
New value of Value function: 9.59772
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 28
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 2.3267
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 29
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.99616
New value of Value function: 8.99616
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 30
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.12442
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 31
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 32
New value of Q matrix: 4.50243
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 32
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.59772
New value of Value function: 9.59772
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 33
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.45525
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 34
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 3.25742
New value of Value function: 3.25742
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 35
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.975
New value of Value function: 4.975
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 36
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.92525
New value of Value function: 4.975
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 37
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.95842
New value of Value function: 4.95842
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 38
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.774253
New value of Value function: 4.95842
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2731
New value of Q matrix: 3.80398
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2732
New value of Q matrix: 3.80397
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2733
New value of Q matrix: 3.80396
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 3.77061
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.77063
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 3.77065
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 3.77067
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2734
New value of Q matrix: 3.80394
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2735
New value of Q matrix: 3.80393
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2736
New value of Q matrix: 3.80392
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2737
New value of Q matrix: 3.80391
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2738
New value of Q matrix: 3.8039
New value of Value function: 3.81238
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 3.81221
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2739
New value of Q matrix: 3.80389
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2740
New value of Q matrix: 3.80388
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 3.77068
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 3.80737
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 3.80722
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2741
New value of Q matrix: 3.80387
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2742
New value of Q matrix: 3.80386
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2743
New value of Q matrix: 3.80385
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2744
New value of Q matrix: 3.80384
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 3.80707
New value of Value function: 3.81238
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 3.81219
New value of Value function: 3.81221
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 3.80693
New value of Value function: 3.81221
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 3.812
New value of Value function: 3.81221
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2745
New value of Q matrix: 3.80383
New value of Value function: 3.81221
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2746
New value of Q matrix: 3.80382
New value of Value function: 3.81221
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 3.81204
New value of Value function: 3.81204
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2747
New value of Q matrix: 3.8038
New value of Value function: 3.81204
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 3.81187
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2748
New value of Q matrix: 3.80379
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 3.7707
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2749
New value of Q matrix: 3.80378
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2750
New value of Q matrix: 3.80377
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2751
New value of Q matrix: 3.80376
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2752
New value of Q matrix: 3.80375
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2753
New value of Q matrix: 3.80374
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2754
New value of Q matrix: 3.80373
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2755
New value of Q matrix: 3.80372
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2756
New value of Q matrix: 3.80371
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2757
New value of Q matrix: 3.8037
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2758
New value of Q matrix: 3.80368
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2759
New value of Q matrix: 3.80367
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2760
New value of Q matrix: 3.80366
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2761
New value of Q matrix: 3.80365
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2762
New value of Q matrix: 3.80364
New value of Value function: 3.812
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 3.81181
New value of Value function: 3.81187
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2763
New value of Q matrix: 3.80363
New value of Value function: 3.81187
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 3.80678
New value of Value function: 3.81187
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2764
New value of Q matrix: 3.80362
New value of Value function: 3.81187
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 3.8117
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2765
New value of Q matrix: 3.80361
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2766
New value of Q matrix: 3.8036
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2767
New value of Q matrix: 3.80359
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 3.80664
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2768
New value of Q matrix: 3.80358
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2769
New value of Q matrix: 3.80357
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2770
New value of Q matrix: 3.80356
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2771
New value of Q matrix: 3.80354
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2772
New value of Q matrix: 3.80353
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2773
New value of Q matrix: 3.80352
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2774
New value of Q matrix: 3.80351
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2775
New value of Q matrix: 3.8035
New value of Value function: 3.81181
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 3.81163
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2776
New value of Q matrix: 3.80349
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2777
New value of Q matrix: 3.80348
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2778
New value of Q matrix: 3.80347
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2779
New value of Q matrix: 3.80346
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2780
New value of Q matrix: 3.80345
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2781
New value of Q matrix: 3.80344
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2782
New value of Q matrix: 3.80343
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2783
New value of Q matrix: 3.80342
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2784
New value of Q matrix: 3.8034
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2785
New value of Q matrix: 3.80339
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2786
New value of Q matrix: 3.80338
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2787
New value of Q matrix: 3.80337
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 3.8065
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2788
New value of Q matrix: 3.80336
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2789
New value of Q matrix: 3.80335
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2790
New value of Q matrix: 3.80334
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2791
New value of Q matrix: 3.80333
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2792
New value of Q matrix: 3.80332
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 3.77071
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2793
New value of Q matrix: 3.80331
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2794
New value of Q matrix: 3.8033
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2795
New value of Q matrix: 3.80329
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2796
New value of Q matrix: 3.80328
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 3.81144
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2797
New value of Q matrix: 3.80327
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2798
New value of Q matrix: 3.80326
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2799
New value of Q matrix: 3.80324
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2800
New value of Q matrix: 3.80323
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2801
New value of Q matrix: 3.80322
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2802
New value of Q matrix: 3.80321
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2803
New value of Q matrix: 3.8032
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 3.77073
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2804
New value of Q matrix: 3.80319
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2805
New value of Q matrix: 3.80318
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2806
New value of Q matrix: 3.80317
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2807
New value of Q matrix: 3.80316
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2808
New value of Q matrix: 3.80315
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2809
New value of Q matrix: 3.80314
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2810
New value of Q matrix: 3.80313
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 3.80636
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2811
New value of Q matrix: 3.80312
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2812
New value of Q matrix: 3.80311
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2813
New value of Q matrix: 3.8031
New value of Value function: 3.8117
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 3.81154
New value of Value function: 3.81154
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 3.81137
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2814
New value of Q matrix: 3.80309
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2815
New value of Q matrix: 3.80308
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2816
New value of Q matrix: 3.80307
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2817
New value of Q matrix: 3.80306
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2818
New value of Q matrix: 3.80304
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2819
New value of Q matrix: 3.80303
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 3.77074
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2820
New value of Q matrix: 3.80302
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2821
New value of Q matrix: 3.80301
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2822
New value of Q matrix: 3.803
New value of Value function: 3.81144
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 3.81126
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2823
New value of Q matrix: 3.80299
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2824
New value of Q matrix: 3.80298
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2825
New value of Q matrix: 3.80297
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2826
New value of Q matrix: 3.80296
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2827
New value of Q matrix: 3.80295
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2828
New value of Q matrix: 3.80294
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2829
New value of Q matrix: 3.80293
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2830
New value of Q matrix: 3.80292
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2831
New value of Q matrix: 3.80291
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2832
New value of Q matrix: 3.8029
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 3.81107
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2833
New value of Q matrix: 3.80289
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2834
New value of Q matrix: 3.80288
New value of Value function: 3.81137
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 3.81121
New value of Value function: 3.81121
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 3.80621
New value of Value function: 3.81121
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2835
New value of Q matrix: 3.80287
New value of Value function: 3.81121
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 3.81089
New value of Value function: 3.81121
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 3.81104
New value of Value function: 3.81104
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 3.81088
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2836
New value of Q matrix: 3.80286
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2837
New value of Q matrix: 3.80284
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2838
New value of Q matrix: 3.80283
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2839
New value of Q matrix: 3.80282
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2840
New value of Q matrix: 3.80281
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2841
New value of Q matrix: 3.8028
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2842
New value of Q matrix: 3.80279
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2843
New value of Q matrix: 3.80278
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2844
New value of Q matrix: 3.80277
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2845
New value of Q matrix: 3.80276
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2846
New value of Q matrix: 3.80275
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2847
New value of Q matrix: 3.80274
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2848
New value of Q matrix: 3.80273
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 3.81072
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2849
New value of Q matrix: 3.80272
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2850
New value of Q matrix: 3.80271
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 3.80607
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2851
New value of Q matrix: 3.8027
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 3.81055
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2852
New value of Q matrix: 3.80269
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 3.81039
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2853
New value of Q matrix: 3.80268
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2854
New value of Q matrix: 3.80267
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2855
New value of Q matrix: 3.80266
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2856
New value of Q matrix: 3.80264
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2857
New value of Q matrix: 3.80263
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2858
New value of Q matrix: 3.80262
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2859
New value of Q matrix: 3.80261
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2860
New value of Q matrix: 3.8026
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2861
New value of Q matrix: 3.80259
New value of Value function: 3.81089
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 3.81071
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2862
New value of Q matrix: 3.80258
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2863
New value of Q matrix: 3.80257
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2864
New value of Q matrix: 3.80256
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2865
New value of Q matrix: 3.80255
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2866
New value of Q matrix: 3.80254
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2867
New value of Q matrix: 3.80253
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 3.81024
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2868
New value of Q matrix: 3.80252
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2869
New value of Q matrix: 3.80251
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 3.80593
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2870
New value of Q matrix: 3.8025
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2871
New value of Q matrix: 3.80249
New value of Value function: 3.81071
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 3.81053
New value of Value function: 3.81053
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2872
New value of Q matrix: 3.80248
New value of Value function: 3.81053
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 3.81035
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2873
New value of Q matrix: 3.80247
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2874
New value of Q matrix: 3.80246
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2875
New value of Q matrix: 3.80245
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2876
New value of Q matrix: 3.80244
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2877
New value of Q matrix: 3.80243
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 3.81008
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2878
New value of Q matrix: 3.80241
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2879
New value of Q matrix: 3.8024
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2880
New value of Q matrix: 3.80239
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2881
New value of Q matrix: 3.80238
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2882
New value of Q matrix: 3.80237
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 3.80992
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2883
New value of Q matrix: 3.80236
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2884
New value of Q matrix: 3.80235
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2885
New value of Q matrix: 3.80234
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2886
New value of Q matrix: 3.80233
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2887
New value of Q matrix: 3.80232
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2888
New value of Q matrix: 3.80231
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 3.80976
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 3.8096
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2889
New value of Q matrix: 3.8023
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2890
New value of Q matrix: 3.80229
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2891
New value of Q matrix: 3.80228
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2892
New value of Q matrix: 3.80227
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2893
New value of Q matrix: 3.80226
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 3.77074
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 3.77075
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2894
New value of Q matrix: 3.80225
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2895
New value of Q matrix: 3.80224
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 3.80945
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2896
New value of Q matrix: 3.80223
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2897
New value of Q matrix: 3.80222
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2898
New value of Q matrix: 3.80221
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2899
New value of Q matrix: 3.8022
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2900
New value of Q matrix: 3.80219
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2901
New value of Q matrix: 3.80218
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2902
New value of Q matrix: 3.80217
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2903
New value of Q matrix: 3.80215
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2904
New value of Q matrix: 3.80214
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2905
New value of Q matrix: 3.80213
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 3.8093
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2906
New value of Q matrix: 3.80222
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 117
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.06448
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 118
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: -1.13691
New value of Value function: 1.07523
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 119
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.925989
New value of Value function: 1.94048
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 120
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.959065
New value of Value function: 1.82397
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 121
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.46088
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 122
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.53642
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 123
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 1.68194
New value of Value function: 3.325
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 124
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 4.93469
New value of Value function: 4.95842
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 125
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.55483
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 126
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 3.08243
New value of Value function: 4.95842
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 127
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 2.18333
New value of Value function: 2.438
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 128
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 1.69918
New value of Value function: 2.28264
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 129
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 4.58776
New value of Value function: 4.64416
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 130
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 4.05236
New value of Value function: 4.05236
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 131
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.43225
New value of Value function: 0.43225
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 132
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.495806
New value of Value function: 0.495806
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 133
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.495558
New value of Value function: 0.495558
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 134
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 0.508734
New value of Value function: 0.508734
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2907
New value of Q matrix: 3.80221
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2908
New value of Q matrix: 3.8022
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2909
New value of Q matrix: 3.80219
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2910
New value of Q matrix: 3.80218
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2911
New value of Q matrix: 3.80217
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2912
New value of Q matrix: 3.80216
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 3.80915
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2913
New value of Q matrix: 3.80215
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2914
New value of Q matrix: 3.80214
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2915
New value of Q matrix: 3.80213
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2916
New value of Q matrix: 3.80212
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2917
New value of Q matrix: 3.80211
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2918
New value of Q matrix: 3.8021
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2919
New value of Q matrix: 3.80209
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2920
New value of Q matrix: 3.80208
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2921
New value of Q matrix: 3.80207
New value of Value function: 3.81035
New value of Policy matrix: 4

=======================================
Simulation: 35
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2922
New value of Q matrix: 3.80206
New value of Value function: 3.81035
New value of Policy matrix: 4

