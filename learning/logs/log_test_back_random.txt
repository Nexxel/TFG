=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 1.34164
New value of Value function: 1.34164
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 18
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 19
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 20
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -1.67178
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.03949
New value of Value function: 4.03949
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 22
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 23
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.999097
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.51152
New value of Value function: 4.03949
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 3.6466
New value of Value function: 3.6466
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 26
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.610135
New value of Value function: 0.610135
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 3.41799
New value of Value function: 3.41799
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 42
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 46
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.39597
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 49
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.489652
New value of Value function: 0.610135
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 50
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 51
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.39597
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 52
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.450101
New value of Value function: 0.450101
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 3.27866
New value of Value function: 3.27866
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 54
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 55
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.245875
New value of Value function: 0.245875
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 3.19054
New value of Value function: 3.19054
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 57
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 58
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.158636
New value of Value function: 0.158636
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 4.62557
New value of Value function: 4.62557
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 60
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.11105
New value of Value function: 5.11105
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 61
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.16321
New value of Value function: 1.16321
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 4.48874
New value of Value function: 4.48874
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 63
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.32524
New value of Value function: 1.32524
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 4.43972
New value of Value function: 4.43972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 65
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2273
	Distance: 3
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 4
New value of Q matrix: -2.33738
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 66
----------
State: 2273
	Distance: 3
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.39532
New value of Value function: 1.39532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 3.82673
New value of Value function: 4.43972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 68
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.04694
New value of Value function: 5.04694
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 69
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 70
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 71
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.00353375
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 72
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.02347
New value of Value function: 5.02347
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 73
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 74
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 75
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.88675
New value of Value function: 2.88675
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 76
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.39532
New value of Value function: 1.39532
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 4.50378
New value of Value function: 4.50378
New value of Policy matrix: 3

=======================================
Simulation: 1
Iteration: 78
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.63406
New value of Value function: 4.63406
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 79
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.44017
New value of Value function: 1.44017
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 4.02825
New value of Value function: 4.43972
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 81
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.39532
New value of Value function: 1.39532
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 4.42412
New value of Value function: 4.42412
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 83
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.3844
New value of Value function: 1.3844
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.37988
New value of Value function: 4.42412
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 4.41029
New value of Value function: 4.41029
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 86
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.37056
New value of Value function: 1.3844
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2269
	Distance: 3
	Angle: 11
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: -2.87898
New value of Value function: 1.37056
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 88
----------
State: 2269
	Distance: 3
	Angle: 11
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 7.35685
New value of Value function: 7.35685
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 89
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 90
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.5437
New value of Value function: 4.5437
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 92
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.501733
New value of Value function: 1.44017
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 93
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.63031
New value of Value function: 5.63031
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 94
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.39746
New value of Value function: 1.39746
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 4.05772
New value of Value function: 4.37988
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 96
----------
State: 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.33608
New value of Value function: 1.33608
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.33608
New value of Value function: 4.37988
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.34891
New value of Value function: 4.34891
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.3238
New value of Value function: 4.33608
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.30542
New value of Value function: 4.3238
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.30218
New value of Value function: 4.30542
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.61102
New value of Value function: 4.30542
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.28057
New value of Value function: 4.30218
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.54728
New value of Value function: 4.30218
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.28294
New value of Value function: 4.28294
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.26546
New value of Value function: 4.28057
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.25916
New value of Value function: 4.26546
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.24934
New value of Value function: 4.25916
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.24012
New value of Value function: 4.24934
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.10047
New value of Value function: 4.24934
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.23431
New value of Value function: 4.24012
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.22281
New value of Value function: 4.23431
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.2202
New value of Value function: 4.22281
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.20684
New value of Value function: 4.2202
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.20685
New value of Value function: 4.20685
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.19417
New value of Value function: 4.20684
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.08369
New value of Value function: 4.20684
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.1028
New value of Value function: 4.20684
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.11702
New value of Value function: 4.20684
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.19197
New value of Value function: 4.19417
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.18206
New value of Value function: 4.19197
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.17318
New value of Value function: 4.19197
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.06497
New value of Value function: 4.19197
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.178
New value of Value function: 4.178
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.16479
New value of Value function: 4.17318
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.16203
New value of Value function: 4.16479
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.15199
New value of Value function: 4.16479
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.15223
New value of Value function: 4.15223
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.14024
New value of Value function: 4.15199
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.14161
New value of Value function: 4.14161
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.13156
New value of Value function: 4.14024
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.12876
New value of Value function: 4.13156
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.11847
New value of Value function: 4.13156
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.12183
New value of Value function: 4.12183
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.11237
New value of Value function: 4.11847
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.10783
New value of Value function: 4.11702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.10781
New value of Value function: 4.11237
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.09869
New value of Value function: 4.11237
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.10317
New value of Value function: 4.10781
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.09885
New value of Value function: 4.10317
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.06415
New value of Value function: 4.10317
New value of Policy matrix: 4

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.09422
New value of Value function: 4.09885
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 22
New value of Q matrix: 4.91992
New value of Value function: 4.91992
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 1
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 2
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 3
----------
State: 5013
	Distance: 8
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 5061
	Distance: 8
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 4
----------
State: 5061
	Distance: 8
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.915
New value of Value function: 9.915
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 5
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.788446
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 7
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 9
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 11
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0850018
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 12
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 13
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 14
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 15
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 16
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 17
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 18
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 19
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 20
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 21
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 22
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 2
Iteration: 23
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.10578
New value of Value function: 2.10578
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 24
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.06141
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 25
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 1.36332
New value of Value function: 1.36332
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 26
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.34969
New value of Value function: 1.34969
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 27
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 2.84799
New value of Value function: 2.84799
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 28
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 29
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 30
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.299964
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 31
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 32
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 33
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 34
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 35
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 2
Iteration: 36
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.23365
New value of Value function: 5.23365
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 37
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.10902
New value of Value function: 5.10902
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 38
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.82362
New value of Value function: 4.82362
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 39
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.67898
New value of Value function: 5.67898
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 40
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 1.39746
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 41
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 42
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 43
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 44
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 45
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 46
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 47
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 48
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 49
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 50
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 51
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 52
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 53
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 54
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 55
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 56
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.87072
New value of Value function: 1.87072
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.90966
New value of Value function: 4.90966
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.89964
New value of Value function: 4.89964
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.88984
New value of Value function: 4.88984
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 3.65085
New value of Value function: 4.88984
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.88025
New value of Value function: 4.88025
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.87085
New value of Value function: 4.87085
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.00401
New value of Value function: 4.87085
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.86165
New value of Value function: 4.86165
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.27194
New value of Value function: 4.86165
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.85262
New value of Value function: 4.85262
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.84376
New value of Value function: 4.84376
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.83506
New value of Value function: 4.83506
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.26456
New value of Value function: 4.83506
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.82651
New value of Value function: 4.82651
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.39128
New value of Value function: 4.82651
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.81811
New value of Value function: 4.81811
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.47815
New value of Value function: 4.81811
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.80985
New value of Value function: 4.80985
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.22275
New value of Value function: 4.80985
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.80172
New value of Value function: 4.80172
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.79372
New value of Value function: 4.79372
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.78584
New value of Value function: 4.78584
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.53625
New value of Value function: 4.78584
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.58027
New value of Value function: 4.78584
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.39108
New value of Value function: 4.78584
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.23147
New value of Value function: 4.78584
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.77807
New value of Value function: 4.77807
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.33548
New value of Value function: 4.77807
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.47867
New value of Value function: 4.77807
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.61225
New value of Value function: 4.77807
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.36352
New value of Value function: 4.77807
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.77042
New value of Value function: 4.77042
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.76288
New value of Value function: 4.76288
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.75544
New value of Value function: 4.75544
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.7481
New value of Value function: 4.7481
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.74086
New value of Value function: 4.74086
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.73371
New value of Value function: 4.73371
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 4.72666
New value of Value function: 4.72666
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 4.71969
New value of Value function: 4.71969
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 4.7128
New value of Value function: 4.7128
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 4.706
New value of Value function: 4.706
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 4.69928
New value of Value function: 4.69928
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 4.69263
New value of Value function: 4.69263
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.43894
New value of Value function: 4.69263
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.68606
New value of Value function: 4.68606
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 4.67956
New value of Value function: 4.67956
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 4.67314
New value of Value function: 4.67314
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.39487
New value of Value function: 4.67314
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 4.66678
New value of Value function: 4.66678
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 4.66048
New value of Value function: 4.66048
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 4.65426
New value of Value function: 4.65426
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 4.64809
New value of Value function: 4.64809
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.64199
New value of Value function: 4.64199
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 4.63594
New value of Value function: 4.63594
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 4.62996
New value of Value function: 4.62996
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 4.62403
New value of Value function: 4.62403
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 4.61816
New value of Value function: 4.61816
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 4.61234
New value of Value function: 4.61234
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 4.60658
New value of Value function: 4.61225
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.47178
New value of Value function: 4.61225
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.60264
New value of Value function: 4.60658
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 4.60086
New value of Value function: 4.60264
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.59324
New value of Value function: 4.60086
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 4.5952
New value of Value function: 4.5952
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.58958
New value of Value function: 4.59324
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.58405
New value of Value function: 4.58958
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.49492
New value of Value function: 4.58958
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.58402
New value of Value function: 4.58405
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.57506
New value of Value function: 4.58402
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.5785
New value of Value function: 4.5785
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.57303
New value of Value function: 4.57506
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.56626
New value of Value function: 4.57303
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.5676
New value of Value function: 4.5676
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.56222
New value of Value function: 4.56626
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 4.55735
New value of Value function: 4.56626
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.50115
New value of Value function: 4.56626
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.55763
New value of Value function: 4.55763
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.54917
New value of Value function: 4.55735
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.48178
New value of Value function: 4.55735
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.41825
New value of Value function: 4.55735
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.43659
New value of Value function: 4.55735
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 4.55205
New value of Value function: 4.55205
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 4.54679
New value of Value function: 4.54917
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.54086
New value of Value function: 4.54679
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 4.54158
New value of Value function: 4.54158
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 4.5364
New value of Value function: 4.54086
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.53271
New value of Value function: 4.5364
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.48402
New value of Value function: 4.5364
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 4.53126
New value of Value function: 4.53271
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.52469
New value of Value function: 4.53126
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 4.14732
New value of Value function: 4.53126
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 148
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 149
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.92964
New value of Value function: 4.92964
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 150
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.90075
New value of Value function: 4.90075
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 4.52617
New value of Value function: 4.52617
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.51707
New value of Value function: 4.52617
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 4.35554
New value of Value function: 4.51707
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 4
----------
State: 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 11
New value of Visit matrix: 1
New value of Q matrix: 11
New value of Value function: 11
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 5
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -11
New value of Visit matrix: 1
New value of Q matrix: -0.11
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 6
----------
State: 4585
	Distance: 7
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 7.46447
New value of Value function: 7.46447
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 7
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 1
New value of Q matrix: 10
New value of Value function: 10
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 8
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -0.1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 9
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 2
New value of Q matrix: 10
New value of Value function: 10
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 11
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 12
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 13
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 15
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 16
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 17
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 18
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 19
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 20
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 21
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 22
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 23
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 1.40543
New value of Value function: 1.40543
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 24
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 25
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 26
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.56482
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 27
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.9
New value of Value function: 4.9
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 28
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.97113
New value of Value function: 9.97113
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 29
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 30
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 31
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.07107
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 32
----------
State: 5065
	Distance: 8
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.9005
New value of Value function: 9.9005
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 33
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9005
New value of Value function: 4.95
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 34
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.92142
New value of Value function: 4.92142
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 35
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.89681
New value of Value function: 4.9005
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 36
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.97086
New value of Value function: 4.97086
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 37
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.105359
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 3
Iteration: 38
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.97071
New value of Value function: 4.97071
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 39
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 40
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 41
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 42
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 43
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 44
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.4719
New value of Value function: 1.4719
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.48117
New value of Value function: 4.51707
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.50932
New value of Value function: 4.50932
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.22003
New value of Value function: 4.50932
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.5017
New value of Value function: 4.5017
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.4942
New value of Value function: 4.4942
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 4.36595
New value of Value function: 4.4942
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.48681
New value of Value function: 4.48681
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.47953
New value of Value function: 4.48117
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.47088
New value of Value function: 4.47953
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.47236
New value of Value function: 4.47236
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.46529
New value of Value function: 4.47088
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 4.3726
New value of Value function: 4.47088
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.46089
New value of Value function: 4.46529
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.45831
New value of Value function: 4.46089
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.45115
New value of Value function: 4.45831
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.45143
New value of Value function: 4.45143
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.26182
New value of Value function: 4.45143
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.44465
New value of Value function: 4.45115
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.44166
New value of Value function: 4.44465
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.29202
New value of Value function: 4.44465
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.43302
New value of Value function: 4.44465
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.42959
New value of Value function: 4.44465
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.43795
New value of Value function: 4.43795
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.42496
New value of Value function: 4.43795
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 4.43133
New value of Value function: 4.43133
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 4.4248
New value of Value function: 4.42959
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.42121
New value of Value function: 4.42496
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.41611
New value of Value function: 4.4248
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 4.41834
New value of Value function: 4.42121
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.413
New value of Value function: 4.41834
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 4.41196
New value of Value function: 4.41611
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.40745
New value of Value function: 4.413
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.40495
New value of Value function: 4.41196
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.39828
New value of Value function: 4.41196
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 4.37208
New value of Value function: 4.41196
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 4.40566
New value of Value function: 4.40745
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.39897
New value of Value function: 4.40566
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.3918
New value of Value function: 4.40566
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 4.39943
New value of Value function: 4.39943
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.39327
New value of Value function: 4.39897
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.39066
New value of Value function: 4.39327
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 4.38718
New value of Value function: 4.3918
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 4.36944
New value of Value function: 4.3918
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.38415
New value of Value function: 4.39066
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.38251
New value of Value function: 4.38718
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.37535
New value of Value function: 4.38718
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 4.38115
New value of Value function: 4.38415
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.37664
New value of Value function: 4.38115
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 4.37519
New value of Value function: 4.37664
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.36924
New value of Value function: 4.37535
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.36749
New value of Value function: 4.37519
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 4.36929
New value of Value function: 4.36944
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 4.3647
New value of Value function: 4.36929
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 4.36345
New value of Value function: 4.36924
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.29916
New value of Value function: 4.36924
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.36196
New value of Value function: 4.36749
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.3043
New value of Value function: 4.36749
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 4.3582
New value of Value function: 4.36749
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.35977
New value of Value function: 4.3647
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.35332
New value of Value function: 4.3647
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 4.35999
New value of Value function: 4.36196
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.35479
New value of Value function: 4.35999
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 4.35532
New value of Value function: 4.35977
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.35218
New value of Value function: 4.35532
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 4.35068
New value of Value function: 4.35479
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.34772
New value of Value function: 4.35332
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 4.34766
New value of Value function: 4.35218
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.30519
New value of Value function: 4.35218
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.34472
New value of Value function: 4.35068
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 4.34606
New value of Value function: 4.34772
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.34076
New value of Value function: 4.34766
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 4.34204
New value of Value function: 4.34606
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 4.33699
New value of Value function: 4.34606
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 4.34148
New value of Value function: 4.34472
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.33737
New value of Value function: 4.34148
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 4.33693
New value of Value function: 4.34076
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 4.3328
New value of Value function: 4.34076
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.3339
New value of Value function: 4.33737
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.33014
New value of Value function: 4.33699
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.30288
New value of Value function: 4.33699
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 4.33149
New value of Value function: 4.3339
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.32713
New value of Value function: 4.3328
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 4.32831
New value of Value function: 4.33149
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 4.32603
New value of Value function: 4.33014
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.32302
New value of Value function: 4.32831
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 4.32385
New value of Value function: 4.32713
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 4.31974
New value of Value function: 4.32713
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.32045
New value of Value function: 4.32603
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 4.32062
New value of Value function: 4.32302
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.31601
New value of Value function: 4.32062
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 4.31526
New value of Value function: 4.32045
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.31386
New value of Value function: 4.31974
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.30969
New value of Value function: 4.31974
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 4.31534
New value of Value function: 4.31534
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.30758
New value of Value function: 4.31534
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 4.31095
New value of Value function: 4.31526
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 4.30995
New value of Value function: 4.31095
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.29601
New value of Value function: 4.31095
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 4.3066
New value of Value function: 4.30995
New value of Policy matrix: 2

=======================================
Simulation: 3
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.30469
New value of Value function: 4.30969
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.29035
New value of Value function: 4.30969
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.30288
New value of Value function: 4.30758
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.29981
New value of Value function: 4.30758
New value of Policy matrix: 4

=======================================
Simulation: 3
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 4.30116
New value of Value function: 4.3066
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 4.30227
New value of Value function: 4.30288
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.29616
New value of Value function: 4.30227
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 4.29797
New value of Value function: 4.30116
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 4.29401
New value of Value function: 4.30116
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 4.29482
New value of Value function: 4.29981
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.29464
New value of Value function: 4.29616
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.28333
New value of Value function: 4.29616
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.28953
New value of Value function: 4.29482
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.28379
New value of Value function: 4.29482
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 4.28855
New value of Value function: 4.29464
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.27745
New value of Value function: 4.29464
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.2895
New value of Value function: 4.29401
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 4.28975
New value of Value function: 4.28975
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 4.28553
New value of Value function: 4.2895
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.28441
New value of Value function: 4.28855
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 4.28236
New value of Value function: 4.28553
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 4.28133
New value of Value function: 4.28441
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.27936
New value of Value function: 4.28379
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.27733
New value of Value function: 4.28236
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.27053
New value of Value function: 4.28236
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 4.27624
New value of Value function: 4.28133
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 4.27715
New value of Value function: 4.27936
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 4.27435
New value of Value function: 4.27733
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 4.27095
New value of Value function: 4.27715
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 4.27299
New value of Value function: 4.27624
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 4.2702
New value of Value function: 4.27435
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 4.26939
New value of Value function: 4.27299
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 4.26886
New value of Value function: 4.27095
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 4.26465
New value of Value function: 4.27053
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.26286
New value of Value function: 4.2702
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.25661
New value of Value function: 4.2702
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.26422
New value of Value function: 4.26939
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 4.26446
New value of Value function: 4.26886
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 108
New value of Q matrix: 4.14677
New value of Value function: 4.26465
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 33
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 34
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 35
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 36
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 37
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 38
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 39
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: -4.96962
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 40
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 6
New value of Value function: 6
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 41
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 42
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 43
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0445299
New value of Value function: 0
New value of Policy matrix: 3

=======================================
Simulation: 4
Iteration: 44
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 45
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 46
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 47
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 5
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 48
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 49
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 50
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 51
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 52
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 53
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 54
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 55
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 56
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 57
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 58
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 59
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 60
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: -3.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 61
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 62
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 0.95
New value of Value function: 0.95
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 63
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.96464
New value of Value function: 4.96464
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 64
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.47774
New value of Value function: 4.96464
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 65
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -0.0595
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 66
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.92525
New value of Value function: 0.92525
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 67
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.93598
New value of Value function: 4.93598
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 68
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.9113
New value of Value function: 4.9113
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 69
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.88934
New value of Value function: 4.88934
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 70
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 2.4156
New value of Value function: 4.88934
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 71
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 72
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 73
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 74
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 75
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 76
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 77
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 78
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 79
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 80
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 81
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 3.53553
New value of Value function: 3.53553
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 82
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 83
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 84
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 85
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.525
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 86
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.38104
New value of Value function: 4.38104
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 87
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 88
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 89
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.33723
New value of Value function: 3.33723
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 90
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.69052
New value of Value function: 4.69052
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 91
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 92
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 93
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 94
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 95
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 96
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 97
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 98
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 99
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 100
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 101
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 102
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 103
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 104
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -0.299964
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 105
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 106
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 107
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: -6
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 108
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 109
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 2.995
New value of Value function: 2.995
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 110
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 1
New value of Q matrix: -2.05
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 111
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.14315
New value of Value function: 6.14315
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 112
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.561073
New value of Value function: 0.561073
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 113
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.98161
New value of Value function: 2.98161
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 114
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.96943
New value of Value function: 2.96943
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 115
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.95821
New value of Value function: 2.95821
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 116
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.94775
New value of Value function: 2.94775
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 117
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.93793
New value of Value function: 2.93793
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 118
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.92863
New value of Value function: 2.92863
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 119
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 3.85167
New value of Value function: 3.85167
New value of Policy matrix: 4

=======================================
Simulation: 4
Iteration: 120
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 121
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 122
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 123
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 124
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 125
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 126
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 127
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 128
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 129
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 4
Iteration: 130
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 131
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 132
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 133
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 134
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 135
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 136
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 137
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 4
Iteration: 138
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 139
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 140
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 4
Iteration: 141
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1414
	Distance: 2
	Angle: 5
	Height: 5
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 4.25959
New value of Value function: 4.26465
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 4.25843
New value of Value function: 4.26422
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 4.2583
New value of Value function: 4.25959
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.24971
New value of Value function: 4.25959
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 4.25473
New value of Value function: 4.25843
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 4.25229
New value of Value function: 4.2583
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 4.25245
New value of Value function: 4.25473
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 4.24991
New value of Value function: 4.25245
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 4.24667
New value of Value function: 4.25229
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 4.24621
New value of Value function: 4.24991
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 4.24513
New value of Value function: 4.24971
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.24242
New value of Value function: 4.24667
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 4.24094
New value of Value function: 4.24621
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 4.15222
New value of Value function: 4.24621
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 4.24021
New value of Value function: 4.24513
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 4.24039
New value of Value function: 4.24242
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.23525
New value of Value function: 4.24094
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 4.23527
New value of Value function: 4.24039
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 4.23568
New value of Value function: 4.24021
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.23427
New value of Value function: 4.23568
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 4.231
New value of Value function: 4.23527
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 4.22966
New value of Value function: 4.23525
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.22819
New value of Value function: 4.23427
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 4.2284
New value of Value function: 4.231
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 4.22635
New value of Value function: 4.22966
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.22411
New value of Value function: 4.2284
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 4.22259
New value of Value function: 4.22819
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 4.22194
New value of Value function: 4.22819
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.22124
New value of Value function: 4.22411
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 4.21861
New value of Value function: 4.22259
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 4.21684
New value of Value function: 4.22194
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 4.21736
New value of Value function: 4.22124
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.21439
New value of Value function: 4.21861
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 4.21316
New value of Value function: 4.21736
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 4.21281
New value of Value function: 4.21684
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.20803
New value of Value function: 4.21684
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 4.21116
New value of Value function: 4.21316
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 4.20777
New value of Value function: 4.21281
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 4.15398
New value of Value function: 4.21281
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 4.2083
New value of Value function: 4.21116
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 4.20553
New value of Value function: 4.2083
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 4.20381
New value of Value function: 4.20803
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.20138
New value of Value function: 4.20777
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 4.20243
New value of Value function: 4.20553
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 4.19996
New value of Value function: 4.20381
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 4.19936
New value of Value function: 4.20243
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 4.19713
New value of Value function: 4.20138
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.19482
New value of Value function: 4.19996
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 4.15436
New value of Value function: 4.19996
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.19445
New value of Value function: 4.19936
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 4.19216
New value of Value function: 4.19936
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 4.19493
New value of Value function: 4.19493
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 4.19053
New value of Value function: 4.19482
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 4.18903
New value of Value function: 4.19482
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.18835
New value of Value function: 4.19216
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 4.18633
New value of Value function: 4.19216
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 4.18696
New value of Value function: 4.18903
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 4.18362
New value of Value function: 4.18835
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.18196
New value of Value function: 4.18696
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 4.17869
New value of Value function: 4.18696
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.1764
New value of Value function: 4.18696
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 4.18205
New value of Value function: 4.18696
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 4.17442
New value of Value function: 4.18696
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 4.18181
New value of Value function: 4.18205
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 4.17774
New value of Value function: 4.18181
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 4.153
New value of Value function: 4.18181
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.1767
New value of Value function: 4.17774
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 4.17345
New value of Value function: 4.1767
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.17163
New value of Value function: 4.1764
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 4.15128
New value of Value function: 4.1764
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 4.16949
New value of Value function: 4.1764
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 4.17018
New value of Value function: 4.17442
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 4.16916
New value of Value function: 4.17163
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.16661
New value of Value function: 4.17018
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 4.16403
New value of Value function: 4.16949
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 4.16526
New value of Value function: 4.16916
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 4.15869
New value of Value function: 4.16916
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 4.16395
New value of Value function: 4.16661
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.16163
New value of Value function: 4.16526
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 4.16105
New value of Value function: 4.16395
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 4.15716
New value of Value function: 4.16395
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 4.15879
New value of Value function: 4.16163
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.15669
New value of Value function: 4.15879
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 4.15367
New value of Value function: 4.15869
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 4.15269
New value of Value function: 4.15716
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 4.153
New value of Value function: 4.15669
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.15179
New value of Value function: 4.15367
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.14859
New value of Value function: 4.153
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 4.14887
New value of Value function: 4.15269
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 4.14676
New value of Value function: 4.15179
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 4.14744
New value of Value function: 4.15179
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 4.14693
New value of Value function: 4.14887
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 4.14476
New value of Value function: 4.14859
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.14356
New value of Value function: 4.14744
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 4.14357
New value of Value function: 4.14693
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 4.14211
New value of Value function: 4.14676
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 4.1409
New value of Value function: 4.14476
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 4.14068
New value of Value function: 4.14357
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 4.13972
New value of Value function: 4.14356
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.13858
New value of Value function: 4.14211
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 4.13733
New value of Value function: 4.1409
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 4.1351
New value of Value function: 4.14068
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 4.13296
New value of Value function: 4.14068
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 4.13662
New value of Value function: 4.13972
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 4.13589
New value of Value function: 4.13858
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 4.13277
New value of Value function: 4.13858
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.13363
New value of Value function: 4.13589
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 4.13209
New value of Value function: 4.1351
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 4.12898
New value of Value function: 4.1351
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 4.12557
New value of Value function: 4.1351
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 4.12936
New value of Value function: 4.13363
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.12872
New value of Value function: 4.13296
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 4.12825
New value of Value function: 4.13209
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 4.12401
New value of Value function: 4.13209
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 4.1283
New value of Value function: 4.12936
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 4.12369
New value of Value function: 4.12872
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.12386
New value of Value function: 4.1283
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 4.12453
New value of Value function: 4.12557
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 4.1216
New value of Value function: 4.12453
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 4.12078
New value of Value function: 4.12401
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 4.11937
New value of Value function: 4.12386
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 4.11733
New value of Value function: 4.12386
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 4.11903
New value of Value function: 4.12369
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 4.11418
New value of Value function: 4.12369
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 4.11808
New value of Value function: 4.1216
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 4.11765
New value of Value function: 4.11937
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 4.11389
New value of Value function: 4.11937
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 4.11476
New value of Value function: 4.11903
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 4.11424
New value of Value function: 4.11808
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 4.11253
New value of Value function: 4.11476
New value of Policy matrix: 4

=======================================
Simulation: 5
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 4.11019
New value of Value function: 4.11424
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 4.11049
New value of Value function: 4.11424
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 4.10949
New value of Value function: 4.11389
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 4.10528
New value of Value function: 4.11389
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 4.10606
New value of Value function: 4.11389
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 4.10999
New value of Value function: 4.11253
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 4.10703
New value of Value function: 4.11049
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 4.10203
New value of Value function: 4.11049
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 4.10682
New value of Value function: 4.10999
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 4.09842
New value of Value function: 4.10999
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 4.1061
New value of Value function: 4.10703
New value of Policy matrix: 3

=======================================
Simulation: 5
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 4.10159
New value of Value function: 4.10682
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 4.09688
New value of Value function: 4.10682
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 4.10316
New value of Value function: 4.1061
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 4.09274
New value of Value function: 4.1061
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 4.10224
New value of Value function: 4.10528
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 4.1006
New value of Value function: 4.10316
New value of Policy matrix: 1

=======================================
Simulation: 5
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 4.09952
New value of Value function: 4.10224
New value of Policy matrix: 2

=======================================
Simulation: 5
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 4.0984
New value of Value function: 4.1006
New value of Policy matrix: 0

=======================================
Simulation: 5
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 4.09596
New value of Value function: 4.09952
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 4.09589
New value of Value function: 4.09842
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 4.09458
New value of Value function: 4.09842
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 4.09397
New value of Value function: 4.09596
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 4.09135
New value of Value function: 4.09589
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 4.08786
New value of Value function: 4.09589
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 4.08728
New value of Value function: 4.09589
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 4.09229
New value of Value function: 4.09458
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 4.09078
New value of Value function: 4.09397
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 4.08884
New value of Value function: 4.09397
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 4.08956
New value of Value function: 4.09078
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 4.08299
New value of Value function: 4.09078
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 4.08699
New value of Value function: 4.08956
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 4.08517
New value of Value function: 4.08884
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 4.07854
New value of Value function: 4.08884
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.08527
New value of Value function: 4.08728
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 4.08326
New value of Value function: 4.08728
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 4.08273
New value of Value function: 4.08527
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.08171
New value of Value function: 4.08517
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 4.08082
New value of Value function: 4.08326
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 4.07828
New value of Value function: 4.08326
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 4.07951
New value of Value function: 4.08171
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 4.07418
New value of Value function: 4.08171
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 4.07659
New value of Value function: 4.08171
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.07818
New value of Value function: 4.07951
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 4.07353
New value of Value function: 4.07951
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 4.07579
New value of Value function: 4.07818
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 4.07465
New value of Value function: 4.07659
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.07131
New value of Value function: 4.07659
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.06827
New value of Value function: 4.07659
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 4.06999
New value of Value function: 4.07659
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 4.06629
New value of Value function: 4.07659
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 4.07229
New value of Value function: 4.07579
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 4.06871
New value of Value function: 4.07579
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 4.07208
New value of Value function: 4.07229
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 4.06802
New value of Value function: 4.07208
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 4.0684
New value of Value function: 4.06871
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 4.06367
New value of Value function: 4.0684
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 4.06473
New value of Value function: 4.06827
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.06479
New value of Value function: 4.06802
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 4.06378
New value of Value function: 4.06629
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 4.0619
New value of Value function: 4.06479
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.06133
New value of Value function: 4.06473
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 4.05785
New value of Value function: 4.06473
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 4.06108
New value of Value function: 4.06378
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 4.05956
New value of Value function: 4.06367
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 4.05867
New value of Value function: 4.06133
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.05789
New value of Value function: 4.06108
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 4.05745
New value of Value function: 4.05956
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.0546
New value of Value function: 4.05956
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 4.05538
New value of Value function: 4.05867
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 4.05371
New value of Value function: 4.05785
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 4.04929
New value of Value function: 4.05785
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 4.05352
New value of Value function: 4.05745
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 4.05383
New value of Value function: 4.05538
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 4.05122
New value of Value function: 4.0546
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.05118
New value of Value function: 4.05383
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 4.05024
New value of Value function: 4.05352
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 4.04923
New value of Value function: 4.05122
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 4.04674
New value of Value function: 4.05122
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 4.04708
New value of Value function: 4.05118
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 4.04516
New value of Value function: 4.05118
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.04778
New value of Value function: 4.04929
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 4.04441
New value of Value function: 4.04778
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.0444
New value of Value function: 4.04708
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 4.04321
New value of Value function: 4.04708
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 4.04297
New value of Value function: 4.04516
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 4.04092
New value of Value function: 4.04441
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 4.03958
New value of Value function: 4.0444
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.04103
New value of Value function: 4.04321
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 4.03966
New value of Value function: 4.04297
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 4.03889
New value of Value function: 4.04103
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.03767
New value of Value function: 4.04092
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 4.03671
New value of Value function: 4.03966
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.03613
New value of Value function: 4.03958
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 4.03479
New value of Value function: 4.03889
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 4.03051
New value of Value function: 4.03889
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 4.03483
New value of Value function: 4.03767
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.03433
New value of Value function: 4.03671
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 4.03252
New value of Value function: 4.03613
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.03262
New value of Value function: 4.03483
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 4.03079
New value of Value function: 4.03433
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.031
New value of Value function: 4.03262
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.02912
New value of Value function: 4.03252
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 4.02836
New value of Value function: 4.031
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.02769
New value of Value function: 4.03079
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 4.02678
New value of Value function: 4.03051
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 4.02316
New value of Value function: 4.03051
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 4.02579
New value of Value function: 4.02912
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 4.02564
New value of Value function: 4.02836
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 4.02423
New value of Value function: 4.02769
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 4.01964
New value of Value function: 4.02769
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.02235
New value of Value function: 4.02769
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.02439
New value of Value function: 4.02579
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 4.02111
New value of Value function: 4.02439
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 4.01684
New value of Value function: 4.02439
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.0211
New value of Value function: 4.02423
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 4.02012
New value of Value function: 4.02235
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.01793
New value of Value function: 4.02235
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.0189
New value of Value function: 4.02012
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 4.01604
New value of Value function: 4.01964
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 4.0157
New value of Value function: 4.0189
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.01547
New value of Value function: 4.01793
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.01467
New value of Value function: 4.01684
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 4.01224
New value of Value function: 4.01604
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 4.01198
New value of Value function: 4.0157
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.01207
New value of Value function: 4.0157
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 4.01178
New value of Value function: 4.01467
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.01143
New value of Value function: 4.01224
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.00826
New value of Value function: 4.01224
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 4.00766
New value of Value function: 4.01207
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 4.00796
New value of Value function: 4.01207
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 4.00362
New value of Value function: 4.01207
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.00867
New value of Value function: 4.01178
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 4.00788
New value of Value function: 4.00867
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.00528
New value of Value function: 4.00826
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 79
New value of Q matrix: 3.99963
New value of Value function: 4.00826
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 4.00398
New value of Value function: 4.00826
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 4.00404
New value of Value function: 4.00826
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.00504
New value of Value function: 4.00528
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.00191
New value of Value function: 4.00504
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.00183
New value of Value function: 4.00404
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 4
New value of Value function: 4.00404
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 4.00019
New value of Value function: 4.00191
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 3.99855
New value of Value function: 4.00183
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.99864
New value of Value function: 4.00019
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.99636
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 3.99532
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.99289
New value of Value function: 4
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.99604
New value of Value function: 3.99963
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 80
New value of Q matrix: 3.99516
New value of Value function: 3.99864
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.99546
New value of Value function: 3.99604
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.99211
New value of Value function: 3.99546
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.99229
New value of Value function: 3.99532
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 3.992
New value of Value function: 3.99516
New value of Policy matrix: 3

=======================================
Simulation: 6
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 81
New value of Q matrix: 3.99072
New value of Value function: 3.99289
New value of Policy matrix: 4

=======================================
Simulation: 6
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.9891
New value of Value function: 3.99229
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.98913
New value of Value function: 3.99211
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 82
New value of Q matrix: 3.98647
New value of Value function: 3.99211
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.98819
New value of Value function: 3.992
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.9856
New value of Value function: 3.992
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 3.98868
New value of Value function: 3.98913
New value of Policy matrix: 1

=======================================
Simulation: 6
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.98599
New value of Value function: 3.98868
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 83
New value of Q matrix: 3.98233
New value of Value function: 3.98868
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.98214
New value of Value function: 3.98868
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 3.98538
New value of Value function: 3.98819
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.98303
New value of Value function: 3.98819
New value of Policy matrix: 0

=======================================
Simulation: 6
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.9843
New value of Value function: 3.98538
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.98009
New value of Value function: 3.98538
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 84
New value of Q matrix: 3.97831
New value of Value function: 3.98538
New value of Policy matrix: 2

=======================================
Simulation: 6
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 3.98209
New value of Value function: 3.9843
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.98043
New value of Value function: 3.98214
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.97714
New value of Value function: 3.98214
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.97841
New value of Value function: 3.98209
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 3.97882
New value of Value function: 3.98043
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.97658
New value of Value function: 3.97882
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 3.97556
New value of Value function: 3.97841
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.9747
New value of Value function: 3.97831
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.97414
New value of Value function: 3.97831
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 85
New value of Q matrix: 3.974
New value of Value function: 3.97658
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 3.9724
New value of Value function: 3.97658
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 3.97276
New value of Value function: 3.9747
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.97101
New value of Value function: 3.97414
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.97105
New value of Value function: 3.974
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.9682
New value of Value function: 3.974
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 3.96929
New value of Value function: 3.974
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 86
New value of Q matrix: 3.96971
New value of Value function: 3.97276
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.96549
New value of Value function: 3.97276
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.96299
New value of Value function: 3.97276
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 3.96895
New value of Value function: 3.97101
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.96734
New value of Value function: 3.96971
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.9639
New value of Value function: 3.96971
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 87
New value of Q matrix: 3.96546
New value of Value function: 3.96929
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 3.96607
New value of Value function: 3.96895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.96041
New value of Value function: 3.96895
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 3.96517
New value of Value function: 3.96607
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 3.96287
New value of Value function: 3.96546
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 88
New value of Q matrix: 3.96123
New value of Value function: 3.96517
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 3.9614
New value of Value function: 3.9639
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 3.95976
New value of Value function: 3.9639
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 3.95789
New value of Value function: 3.9639
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.96027
New value of Value function: 3.96123
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 89
New value of Q matrix: 3.95703
New value of Value function: 3.96041
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.95738
New value of Value function: 3.96027
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.95666
New value of Value function: 3.95976
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 3.95658
New value of Value function: 3.95789
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 3.95417
New value of Value function: 3.95738
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.95436
New value of Value function: 3.95703
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 90
New value of Q matrix: 3.95286
New value of Value function: 3.95666
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.95306
New value of Value function: 3.95658
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 3.95341
New value of Value function: 3.95436
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 3.95048
New value of Value function: 3.95436
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.95135
New value of Value function: 3.95341
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 3.95025
New value of Value function: 3.95306
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.94948
New value of Value function: 3.95286
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 91
New value of Q matrix: 3.94872
New value of Value function: 3.95135
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.94836
New value of Value function: 3.95048
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 3.9468
New value of Value function: 3.95025
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.94552
New value of Value function: 3.95025
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 3.94711
New value of Value function: 3.94948
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.94592
New value of Value function: 3.94872
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 92
New value of Q matrix: 3.9446
New value of Value function: 3.94711
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 3.94398
New value of Value function: 3.9468
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.94264
New value of Value function: 3.9468
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 3.94314
New value of Value function: 3.94592
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 3.94101
New value of Value function: 3.94592
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.94237
New value of Value function: 3.9446
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 93
New value of Q matrix: 3.94051
New value of Value function: 3.94314
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 3.93949
New value of Value function: 3.94264
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.93967
New value of Value function: 3.94237
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.93885
New value of Value function: 3.94101
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 3.93791
New value of Value function: 3.94051
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 94
New value of Q matrix: 3.93645
New value of Value function: 3.93967
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 3.93672
New value of Value function: 3.93949
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 3.93586
New value of Value function: 3.93885
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.93534
New value of Value function: 3.93791
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 95
New value of Q matrix: 3.93256
New value of Value function: 3.93791
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 3.93481
New value of Value function: 3.93672
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 3.93378
New value of Value function: 3.93586
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.93189
New value of Value function: 3.93586
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 3.93226
New value of Value function: 3.93481
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 3.93173
New value of Value function: 3.93378
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 3.93085
New value of Value function: 3.93256
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 3.92805
New value of Value function: 3.93256
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 96
New value of Q matrix: 3.92854
New value of Value function: 3.93226
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 3.92867
New value of Value function: 3.93189
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.92842
New value of Value function: 3.93173
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 3.92866
New value of Value function: 3.92867
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 3.92509
New value of Value function: 3.92866
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.92498
New value of Value function: 3.92866
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 3.9256
New value of Value function: 3.92854
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 97
New value of Q matrix: 3.92455
New value of Value function: 3.92805
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 3.92514
New value of Value function: 3.9256
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 3.92256
New value of Value function: 3.92514
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.92155
New value of Value function: 3.92514
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 3.92224
New value of Value function: 3.92509
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 3.91843
New value of Value function: 3.92509
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 3.92154
New value of Value function: 3.92455
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 98
New value of Q matrix: 3.92059
New value of Value function: 3.92256
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 3.91937
New value of Value function: 3.92256
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 3.91952
New value of Value function: 3.92154
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 3.91665
New value of Value function: 3.92154
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 3.918
New value of Value function: 3.92059
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 99
New value of Q matrix: 3.91665
New value of Value function: 3.91952
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 3.9165
New value of Value function: 3.91843
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 3.91502
New value of Value function: 3.918
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 3.91449
New value of Value function: 3.91665
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 3.91177
New value of Value function: 3.91665
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 100
New value of Q matrix: 3.91273
New value of Value function: 3.91665
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 3.91377
New value of Value function: 3.9165
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 3.91348
New value of Value function: 3.91449
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 3.91099
New value of Value function: 3.91377
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 3.91091
New value of Value function: 3.91348
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 3.91048
New value of Value function: 3.91273
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 101
New value of Q matrix: 3.90884
New value of Value function: 3.91177
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 3.90839
New value of Value function: 3.91099
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 3.9075
New value of Value function: 3.91091
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 3.90752
New value of Value function: 3.91091
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 102
New value of Q matrix: 3.90517
New value of Value function: 3.91091
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 3.90806
New value of Value function: 3.90839
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 3.90502
New value of Value function: 3.90806
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 3.90522
New value of Value function: 3.90752
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 3.90454
New value of Value function: 3.9075
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 3.90255
New value of Value function: 3.9075
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 3.90189
New value of Value function: 3.9075
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 3.90403
New value of Value function: 3.90517
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 103
New value of Q matrix: 3.90132
New value of Value function: 3.90454
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 3.90158
New value of Value function: 3.90403
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 3.90058
New value of Value function: 3.90255
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 3.89972
New value of Value function: 3.90189
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 3.89855
New value of Value function: 3.90158
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 3.89862
New value of Value function: 3.90132
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 104
New value of Q matrix: 3.8975
New value of Value function: 3.90058
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 3.89715
New value of Value function: 3.89972
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 3.89691
New value of Value function: 3.89862
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 3.89567
New value of Value function: 3.89855
New value of Policy matrix: 4

=======================================
Simulation: 7
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 3.89523
New value of Value function: 3.8975
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 105
New value of Q matrix: 3.89369
New value of Value function: 3.89715
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 106
New value of Q matrix: 3.89024
New value of Value function: 3.89715
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 193
New value of Q matrix: 4.17609
New value of Value function: 4.17609
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 130
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.14963
New value of Value function: 5.14963
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 131
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.83073
New value of Value function: 6.83073
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 132
----------
State: 2173
	Distance: 3
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.31196
New value of Value function: 4.31196
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 133
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.88467
New value of Value function: 4.88467
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 134
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0517773
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 135
----------
State: 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.19342
New value of Value function: 1.19342
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 3.91551
New value of Value function: 4.17609
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 194
New value of Q matrix: 4.17648
New value of Value function: 4.17648
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 138
----------
State: 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 1.15952
New value of Value function: 1.15952
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 195
New value of Q matrix: 4.17443
New value of Value function: 4.17443
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 140
----------
State: 2217
	Distance: 3
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 2.97
New value of Policy matrix: 3

=======================================
Simulation: 7
Iteration: 141
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.14315
New value of Value function: 4.14315
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 142
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 2.495
New value of Value function: 2.495
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 143
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 144
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 145
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 7
Iteration: 146
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 147
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 148
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 7
Iteration: 149
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 7
Iteration: 150
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 3.91354
New value of Value function: 4.17443
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.17145
New value of Value function: 4.17145
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.16848
New value of Value function: 4.16848
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 198
New value of Q matrix: 4.43473
New value of Value function: 4.43473
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 5
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 4.96464
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 6
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 7
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 8
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 9
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 6.40976
New value of Value function: 6.40976
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 10
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.83723
New value of Value function: 2.83723
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 11
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.80406
New value of Value function: 1.80406
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 12
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.75651
New value of Value function: 5.75651
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 13
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.345004
New value of Value function: 1.34969
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 14
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.59459
New value of Value function: 7.59459
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 15
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.87615
New value of Value function: 3.87615
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 16
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.13841
New value of Value function: 7.59459
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 17
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.31212
New value of Value function: 8.31212
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 18
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.36678
New value of Value function: 4.36678
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 19
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.3987
New value of Value function: 3.3987
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 199
New value of Q matrix: 4.57154
New value of Value function: 4.57154
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 21
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 3.3987
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 22
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.36472
New value of Value function: 3.36472
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 23
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.63411
New value of Value function: 2.63411
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 200
New value of Q matrix: 4.64482
New value of Value function: 4.64482
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 25
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 5.45524
New value of Value function: 5.45524
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 26
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.75921
New value of Value function: 5.75921
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 27
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 6.83073
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 28
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 29
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2.99
New value of Value function: 2.99
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 30
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 3.80014
New value of Value function: 3.80014
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 31
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 0.464466
New value of Value function: 0.464466
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 32
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 33
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 34
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 35
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 36
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 37
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 38
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 39
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 40
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 41
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 42
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 43
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 44
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 45
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 46
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 47
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 48
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 49
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 50
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 51
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 52
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 3.5
New value of Value function: 3.5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 53
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 54
----------
State: 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 55
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.465
New value of Value function: 1.465
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 56
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 3.4778
New value of Value function: 3.4778
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 57
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.414946
New value of Value function: 0.414946
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 58
----------
State: 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2.29048
New value of Value function: 2.29048
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 59
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -2.71137
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 60
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 61
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 62
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 63
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 4.96
New value of Value function: 4.96
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 64
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.93664
New value of Value function: 3.93664
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 65
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.91565
New value of Value function: 4.91565
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 66
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 3.89614
New value of Value function: 3.89614
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 67
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 4.88189
New value of Value function: 4.88189
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 68
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 3.86461
New value of Value function: 3.86461
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 69
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 0.440946
New value of Value function: 0.440946
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 70
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 71
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 9.82596
New value of Value function: 9.82596
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 72
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 1.88431
New value of Value function: 1.88431
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 73
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: -1.54511
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 74
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.86547
New value of Value function: 6.86547
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 75
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 0.706797
New value of Value function: 0.706797
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 76
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: -0.220407
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 77
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 0.0616886
New value of Value function: 0.0616886
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 78
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.79682
New value of Value function: 2.79682
New value of Policy matrix: 3

=======================================
Simulation: 8
Iteration: 79
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 6.79715
New value of Value function: 6.79715
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 80
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 81
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 82
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 83
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 84
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 7.79307
New value of Value function: 7.79307
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 85
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 6.40007
New value of Value function: 6.40007
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 86
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.98
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 87
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 88
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 5.98
New value of Value function: 5.98
New value of Policy matrix: 1

=======================================
Simulation: 8
Iteration: 89
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.70711
New value of Value function: 2.70711
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 90
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 91
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 8
Iteration: 92
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 2

=======================================
Simulation: 8
Iteration: 93
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1350
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 99
New value of Visit matrix: 1
New value of Q matrix: 99
New value of Value function: 99
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.64154
New value of Value function: 4.64154
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.63827
New value of Value function: 4.63827
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 3.96453
New value of Value function: 4.63827
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 3.95808
New value of Value function: 4.63827
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 4.63502
New value of Value function: 4.63502
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 4.63177
New value of Value function: 4.63177
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 4.62854
New value of Value function: 4.62854
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 4.62531
New value of Value function: 4.62531
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 4.6221
New value of Value function: 4.6221
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 4.61889
New value of Value function: 4.61889
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 4.6157
New value of Value function: 4.6157
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 4.61251
New value of Value function: 4.61251
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 4.60934
New value of Value function: 4.60934
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 4.60617
New value of Value function: 4.60617
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 4.60302
New value of Value function: 4.60302
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 4.00893
New value of Value function: 4.60302
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 4.59987
New value of Value function: 4.59987
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 4.59673
New value of Value function: 4.59673
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 4.59361
New value of Value function: 4.59361
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 3.96894
New value of Value function: 4.59361
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 107
New value of Q matrix: 3.9538
New value of Value function: 4.59361
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 108
New value of Q matrix: 4.01095
New value of Value function: 4.59361
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 4.59049
New value of Value function: 4.59049
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 4.58738
New value of Value function: 4.58738
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 4.58428
New value of Value function: 4.58428
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 4.58119
New value of Value function: 4.58119
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.01664
New value of Value function: 4.58119
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 4.57811
New value of Value function: 4.57811
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.00825
New value of Value function: 4.57811
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 4.57503
New value of Value function: 4.57503
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 4.57197
New value of Value function: 4.57197
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 109
New value of Q matrix: 4.0603
New value of Value function: 4.57197
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 4.56891
New value of Value function: 4.56891
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 4.56587
New value of Value function: 4.56587
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 4.56283
New value of Value function: 4.56283
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 4.5598
New value of Value function: 4.5598
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 4.55678
New value of Value function: 4.55678
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 4.55377
New value of Value function: 4.55377
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 4.55077
New value of Value function: 4.55077
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 4.54778
New value of Value function: 4.54778
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 4.54479
New value of Value function: 4.54479
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 4.54181
New value of Value function: 4.54181
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 4.53884
New value of Value function: 4.53884
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 4.53588
New value of Value function: 4.53588
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 4.53293
New value of Value function: 4.53293
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 4.52998
New value of Value function: 4.52998
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 4.52705
New value of Value function: 4.52705
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 4.52412
New value of Value function: 4.52412
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 4.5212
New value of Value function: 4.5212
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 4.51829
New value of Value function: 4.51829
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 4.51538
New value of Value function: 4.51538
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 4.51249
New value of Value function: 4.51249
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 4.5096
New value of Value function: 4.5096
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.05423
New value of Value function: 4.5096
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 110
New value of Q matrix: 4.09884
New value of Value function: 4.5096
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 4.50672
New value of Value function: 4.50672
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.0883
New value of Value function: 4.50672
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 4.50384
New value of Value function: 4.50384
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 247
New value of Q matrix: 4.93175
New value of Value function: 4.93175
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 60
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.81762
New value of Value function: 8.81762
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 61
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.68342
New value of Value function: 2.68342
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 62
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.4031
New value of Value function: 1.4031
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.08434
New value of Value function: 4.93175
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 4.92862
New value of Value function: 4.92862
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 249
New value of Q matrix: 5.14866
New value of Value function: 5.14866
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 66
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.7624
New value of Value function: 11.7624
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 67
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.76242
New value of Value function: 6.83073
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 68
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.40396
New value of Value function: 6.76242
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 69
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.03165
New value of Value function: 5.75921
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 70
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.08999
New value of Value function: 6.08999
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 71
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.7146
New value of Value function: 6.7146
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 72
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.67584
New value of Value function: 6.67584
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 73
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.64246
New value of Value function: 6.64246
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 74
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.61275
New value of Value function: 6.61275
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 75
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 5.88991
New value of Value function: 6.61275
New value of Policy matrix: 4

=======================================
Simulation: 9
Iteration: 76
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.79875
New value of Value function: 5.79875
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 77
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 3.11664
New value of Value function: 3.11664
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 78
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.44233
New value of Value function: 2.44233
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 79
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 80
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 81
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 82
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 3.10172
New value of Value function: 3.10172
New value of Policy matrix: 3

=======================================
Simulation: 9
Iteration: 83
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 4.8066
New value of Value function: 4.8066
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 84
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 2.71637
New value of Value function: 2.71637
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 85
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 3.85788
New value of Value function: 3.85788
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 86
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 5.33607
New value of Value function: 5.33607
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 87
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.33607
New value of Value function: 6.40007
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 88
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.13906
New value of Value function: 7.13906
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 89
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.01936
New value of Value function: 4.01936
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 90
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.06871
New value of Value function: 2.06871
New value of Policy matrix: 2

=======================================
Simulation: 9
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 5.1454
New value of Value function: 5.1454
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 5.14215
New value of Value function: 5.14215
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 5.13891
New value of Value function: 5.13891
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 5.13568
New value of Value function: 5.13568
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 111
New value of Q matrix: 4.19238
New value of Value function: 5.13568
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 5.13246
New value of Value function: 5.13246
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 5.12925
New value of Value function: 5.12925
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 112
New value of Q matrix: 4.27606
New value of Value function: 5.12925
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 5.12604
New value of Value function: 5.12604
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 5.12284
New value of Value function: 5.12284
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 5.11965
New value of Value function: 5.11965
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 5.11647
New value of Value function: 5.11647
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 5.1133
New value of Value function: 5.1133
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 5.11013
New value of Value function: 5.11013
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 5.10698
New value of Value function: 5.10698
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 5.10383
New value of Value function: 5.10383
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.16832
New value of Value function: 5.10383
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 113
New value of Q matrix: 4.34913
New value of Value function: 5.10383
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.16867
New value of Value function: 5.10383
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 5.10069
New value of Value function: 5.10069
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 5.09755
New value of Value function: 5.09755
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 5.09443
New value of Value function: 5.09443
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.24132
New value of Value function: 5.09443
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.30771
New value of Value function: 5.09443
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 5.09131
New value of Value function: 5.09131
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 5.0882
New value of Value function: 5.0882
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 5.0851
New value of Value function: 5.0851
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 5.082
New value of Value function: 5.082
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 5.07892
New value of Value function: 5.07892
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 5.07584
New value of Value function: 5.07584
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 5.07276
New value of Value function: 5.07276
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 5.0697
New value of Value function: 5.0697
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 134
New value of Q matrix: 4.2418
New value of Value function: 5.0697
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 5.06664
New value of Value function: 5.06664
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 4.0842
New value of Value function: 5.06664
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 5.06359
New value of Value function: 5.06359
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 5.06055
New value of Value function: 5.06055
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.36563
New value of Value function: 5.06055
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 5.05752
New value of Value function: 5.05752
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 5.05449
New value of Value function: 5.05449
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 4.15276
New value of Value function: 5.05449
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.4181
New value of Value function: 5.05449
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.3074
New value of Value function: 5.05449
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 5.05147
New value of Value function: 5.05147
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 5.04845
New value of Value function: 5.04845
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 4.21558
New value of Value function: 5.04845
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 5.04545
New value of Value function: 5.04545
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 5.04245
New value of Value function: 5.04245
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 114
New value of Q matrix: 4.40934
New value of Value function: 5.04245
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 5.03946
New value of Value function: 5.03946
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.46487
New value of Value function: 5.03946
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 5.03647
New value of Value function: 5.03647
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 5.03349
New value of Value function: 5.03349
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 5.03052
New value of Value function: 5.03052
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 5.02756
New value of Value function: 5.02756
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 5.0246
New value of Value function: 5.0246
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 5.02165
New value of Value function: 5.02165
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 4.27161
New value of Value function: 5.02165
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 5.01871
New value of Value function: 5.01871
New value of Policy matrix: 1

=======================================
Simulation: 9
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 5.01577
New value of Value function: 5.01577
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 293
New value of Q matrix: 5.18549
New value of Value function: 5.18549
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 2
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.84044
New value of Value function: 9.84044
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 3
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 3.1828
New value of Value function: 4.88934
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 4
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.71473
New value of Value function: 6.71473
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 5
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 7.30043
New value of Value function: 7.30043
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 6
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.04658
New value of Value function: 3.04658
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 7
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.74135
New value of Value function: 6.74135
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 8
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 2.09591
New value of Value function: 3.04658
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 9
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 6.55893
New value of Value function: 6.55893
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 10
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 4.16858
New value of Value function: 4.16858
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 11
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.706612
New value of Value function: 0.706612
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 12
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 3.84055
New value of Value function: 3.84055
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 13
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.8299
New value of Value function: 3.8299
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 14
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 2.12748
New value of Value function: 3.8299
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 15
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 0.749107
New value of Value function: 0.749107
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 16
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 2.39114
New value of Value function: 3.8299
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 17
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 0.971132
New value of Value function: 0.971132
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 18
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 19
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 20
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: -0.0188982
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 21
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4.99
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 22
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 1
New value of Value function: 1
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 23
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 2.82843
New value of Value function: 2.82843
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 24
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 3.71514
New value of Value function: 3.71514
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 25
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 7.79307
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 26
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.61666
New value of Value function: 6.61666
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 27
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 6.94007
New value of Value function: 6.94007
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 28
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.29289
New value of Value function: 4.29289
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 29
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 30
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 31
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 32
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 33
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 34
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.32201
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 35
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 3.71514
New value of Value function: 3.71514
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 36
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 7.67799
New value of Value function: 7.79307
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 37
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.71782
New value of Value function: 3.71514
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 38
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 1.78883
New value of Value function: 5.95
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 39
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.24367
New value of Value function: 9.24367
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 40
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 7.30903
New value of Value function: 7.30903
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 41
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 3.71514
New value of Value function: 3.71514
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 42
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.63421
New value of Value function: 8.63421
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 43
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4.12379
New value of Value function: 4.12379
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 44
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 45
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 46
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 47
----------
State: 1845
	Distance: 3
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.13364
New value of Value function: 2.13364
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 5.18247
New value of Value function: 5.18247
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 5.17945
New value of Value function: 5.17945
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 5.17644
New value of Value function: 5.17644
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 5.17344
New value of Value function: 5.17344
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 5.17044
New value of Value function: 5.17044
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 5.16745
New value of Value function: 5.16745
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.37672
New value of Value function: 5.16745
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.51802
New value of Value function: 5.16745
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 5.16447
New value of Value function: 5.16447
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 4.33379
New value of Value function: 5.16447
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 5.16149
New value of Value function: 5.16149
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 5.15852
New value of Value function: 5.15852
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 5.15556
New value of Value function: 5.15556
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 5.1526
New value of Value function: 5.1526
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 115
New value of Q matrix: 4.47384
New value of Value function: 5.1526
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 5.14965
New value of Value function: 5.14965
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 5.14671
New value of Value function: 5.14671
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 5.14377
New value of Value function: 5.14377
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.43786
New value of Value function: 5.14377
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 5.14084
New value of Value function: 5.14084
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 5.13791
New value of Value function: 5.13791
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 5.135
New value of Value function: 5.135
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.49283
New value of Value function: 5.135
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 5.13208
New value of Value function: 5.13208
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 5.12918
New value of Value function: 5.12918
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 5.12628
New value of Value function: 5.12628
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 5.12339
New value of Value function: 5.12339
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 5.1205
New value of Value function: 5.1205
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 5.11762
New value of Value function: 5.11762
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.54148
New value of Value function: 5.11762
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 5.11474
New value of Value function: 5.11474
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 5.11188
New value of Value function: 5.11188
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 5.10901
New value of Value function: 5.10901
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 4.38718
New value of Value function: 5.10901
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.56195
New value of Value function: 5.10901
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 5.10616
New value of Value function: 5.10616
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 5.10331
New value of Value function: 5.10331
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 5.10046
New value of Value function: 5.10046
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 5.09763
New value of Value function: 5.09763
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 5.09479
New value of Value function: 5.09479
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 5.09197
New value of Value function: 5.09197
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 5.08915
New value of Value function: 5.08915
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 5.08633
New value of Value function: 5.08633
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 5.08353
New value of Value function: 5.08353
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 5.08072
New value of Value function: 5.08072
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 5.07793
New value of Value function: 5.07793
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 5.07513
New value of Value function: 5.07513
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 5.07235
New value of Value function: 5.07235
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 5.06957
New value of Value function: 5.06957
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 5.0668
New value of Value function: 5.0668
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 5.06403
New value of Value function: 5.06403
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 5.06126
New value of Value function: 5.06126
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 4.43301
New value of Value function: 5.06126
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 5.05851
New value of Value function: 5.05851
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 4.47517
New value of Value function: 5.05851
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 5.05576
New value of Value function: 5.05576
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 5.05301
New value of Value function: 5.05301
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 5.05027
New value of Value function: 5.05027
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 5.04753
New value of Value function: 5.04753
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 5.04481
New value of Value function: 5.04481
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 5.04208
New value of Value function: 5.04208
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 5.03936
New value of Value function: 5.03936
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 5.03665
New value of Value function: 5.03665
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 5.03394
New value of Value function: 5.03394
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 5.03124
New value of Value function: 5.03124
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 116
New value of Q matrix: 4.52093
New value of Value function: 5.03124
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 5.02854
New value of Value function: 5.02854
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 349
New value of Q matrix: 4.99431
New value of Value function: 4.99431
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 116
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.94437
New value of Value function: 1.94437
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 350
New value of Q matrix: 4.9906
New value of Value function: 4.9906
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 118
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.94177
New value of Value function: 1.94177
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 351
New value of Q matrix: 4.98696
New value of Value function: 4.98696
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 120
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 3.47977
New value of Value function: 3.47977
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 121
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.93709
New value of Value function: 1.93709
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 352
New value of Q matrix: 5.06467
New value of Value function: 5.06467
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 123
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.19875
New value of Value function: 5.19875
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 124
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: -3.67528
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 125
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.01403
New value of Value function: 2.01403
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 353
New value of Q matrix: 4.95478
New value of Value function: 4.95478
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 127
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 128
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 129
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 130
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 131
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 132
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 133
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 134
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 135
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 136
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 137
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.873101
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 138
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.81077
New value of Value function: 4.81077
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 139
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 1.73848
New value of Value function: 1.73848
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 140
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 4.60354
New value of Value function: 4.60354
New value of Policy matrix: 1

=======================================
Simulation: 10
Iteration: 141
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.10217
New value of Value function: 8.10217
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 142
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.0619
New value of Value function: 4.0619
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 143
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 5.95
New value of Value function: 5.95
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 144
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4.29289
New value of Value function: 4.29289
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 145
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 146
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 10
Iteration: 147
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 0

=======================================
Simulation: 10
Iteration: 148
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1405
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 10
Iteration: 149
----------
State: 1405
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1406
	Distance: 2
	Angle: 5
	Height: 3
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 1
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.96775
New value of Value function: 5.33607
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 2
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.459821
New value of Value function: 0.464466
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 3
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.381044
New value of Value function: 0.459821
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 4
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 5
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 6
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 7
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 8
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 9
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 10
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 11
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 12
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 13
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 14
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 15
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1.45522
New value of Value function: 1.45522
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 16
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.2827
New value of Value function: 10.2827
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 17
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 5.85339
New value of Value function: 5.85339
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 18
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 5.06953
New value of Value function: 6.33607
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 19
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 20
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 21
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 22
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 23
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 3.85201
New value of Value function: 3.85201
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 24
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 1.89512
New value of Value function: 1.89512
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 4.95215
New value of Value function: 4.95215
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 4.94952
New value of Value function: 4.94952
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 4.58938
New value of Value function: 4.94952
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 4.9469
New value of Value function: 4.9469
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 4.94428
New value of Value function: 4.94428
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 4.50586
New value of Value function: 4.94428
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 4.94167
New value of Value function: 4.94167
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 4.93906
New value of Value function: 4.93906
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 4.93645
New value of Value function: 4.93645
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 4.93386
New value of Value function: 4.93386
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 4.93126
New value of Value function: 4.93126
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 4.92867
New value of Value function: 4.92867
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 4.92609
New value of Value function: 4.92609
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 4.92351
New value of Value function: 4.92351
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 4.92094
New value of Value function: 4.92094
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 4.91837
New value of Value function: 4.91837
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 4.91581
New value of Value function: 4.91581
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 117
New value of Q matrix: 4.55289
New value of Value function: 4.91581
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 4.91325
New value of Value function: 4.91325
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 118
New value of Q matrix: 4.58154
New value of Value function: 4.91325
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 4.91069
New value of Value function: 4.91069
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 4.61138
New value of Value function: 4.91069
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 4.90814
New value of Value function: 4.90814
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 119
New value of Q matrix: 4.60698
New value of Value function: 4.90814
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 4.56832
New value of Value function: 4.90814
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 4.9056
New value of Value function: 4.9056
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 4.90306
New value of Value function: 4.90306
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 4.90052
New value of Value function: 4.90052
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 4.63073
New value of Value function: 4.90052
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 4.89799
New value of Value function: 4.89799
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 4.64827
New value of Value function: 4.89799
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 4.89547
New value of Value function: 4.89547
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 4.89295
New value of Value function: 4.89295
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 4.89043
New value of Value function: 4.89043
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 4.88792
New value of Value function: 4.88792
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 4.88541
New value of Value function: 4.88541
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 381
New value of Q matrix: 4.88291
New value of Value function: 4.88291
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 382
New value of Q matrix: 4.88041
New value of Value function: 4.88041
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 4.87791
New value of Value function: 4.87791
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 384
New value of Q matrix: 4.87543
New value of Value function: 4.87543
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 4.87294
New value of Value function: 4.87294
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 4.87046
New value of Value function: 4.87046
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 4.86798
New value of Value function: 4.86798
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 4.86551
New value of Value function: 4.86551
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 4.86305
New value of Value function: 4.86305
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 4.86058
New value of Value function: 4.86058
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 120
New value of Q matrix: 4.62569
New value of Value function: 4.86058
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 4.85813
New value of Value function: 4.85813
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 141
New value of Q matrix: 4.58864
New value of Value function: 4.85813
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 4.85567
New value of Value function: 4.85567
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 4.85322
New value of Value function: 4.85322
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 4.85078
New value of Value function: 4.85078
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 121
New value of Q matrix: 4.64175
New value of Value function: 4.85078
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 4.84834
New value of Value function: 4.84834
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 4.8459
New value of Value function: 4.8459
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 4.84347
New value of Value function: 4.84347
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 122
New value of Q matrix: 4.65562
New value of Value function: 4.84347
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 4.66002
New value of Value function: 4.84347
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 4.84104
New value of Value function: 4.84104
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 4.83862
New value of Value function: 4.83862
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 400
New value of Q matrix: 4.74669
New value of Value function: 4.74669
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 86
----------
State: 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 87
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 88
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 89
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.82868
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 90
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 3.56616
New value of Value function: 3.56616
New value of Policy matrix: 3

=======================================
Simulation: 11
Iteration: 91
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 4.8066
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 92
----------
State: 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.74077
New value of Value function: 5.74077
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 93
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.74106
New value of Value function: 5.74106
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 94
----------
State: 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.68336
New value of Value function: 5.74077
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 95
----------
State: 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.70038
New value of Value function: 5.70038
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 96
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.69737
New value of Value function: 5.69737
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 97
----------
State: 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.66575
New value of Value function: 5.68336
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 98
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.66845
New value of Value function: 5.66845
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 99
----------
State: 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.64317
New value of Value function: 5.66575
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 100
----------
State: 2749
	Distance: 4
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.97
New value of Value function: 5.66575
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 101
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 5.09311
New value of Value function: 5.09311
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 102
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 4.9502
New value of Value function: 4.9502
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 103
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 8.06084
New value of Value function: 8.06084
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 104
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 10.2756
New value of Value function: 10.2756
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 105
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.29127
New value of Value function: 6.29127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 106
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.55933
New value of Value function: 6.29127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 107
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 8.32665
New value of Value function: 8.32665
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 108
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 10.2483
New value of Value function: 10.2483
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 109
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 6.14586
New value of Value function: 6.29127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 110
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 6.62417
New value of Value function: 6.62417
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 111
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 8.22836
New value of Value function: 8.22836
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 112
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 6.60477
New value of Value function: 6.60477
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 113
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 5.67171
New value of Value function: 5.67171
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 114
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 6.61067
New value of Value function: 6.61067
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 115
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 5.60814
New value of Value function: 5.60814
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 116
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 6.58137
New value of Value function: 6.58137
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 117
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.20015
New value of Value function: 5.60814
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 118
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 8.36445
New value of Value function: 8.36445
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 119
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 6.56826
New value of Value function: 6.56826
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 120
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 5.56093
New value of Value function: 5.56093
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 121
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 6.54257
New value of Value function: 6.54257
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 122
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.50532
New value of Value function: 5.56093
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 123
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.50532
New value of Value function: 5.56093
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 124
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 5.52672
New value of Value function: 5.52672
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 125
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 6.51569
New value of Value function: 6.51569
New value of Policy matrix: 0

=======================================
Simulation: 11
Iteration: 126
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 5.49793
New value of Value function: 5.50532
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 127
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 5.72554
New value of Value function: 6.29127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 128
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 9.12539
New value of Value function: 9.12539
New value of Policy matrix: 2

=======================================
Simulation: 11
Iteration: 129
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 5.96711
New value of Value function: 6.29127
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 130
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.47354
New value of Value function: 5.49793
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 131
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 5.40262
New value of Value function: 5.47354
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 132
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.25495
New value of Value function: 6.25495
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 133
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 6.22367
New value of Value function: 6.22367
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 134
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 6.19584
New value of Value function: 6.19584
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 135
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.17054
New value of Value function: 6.17054
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 136
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.14722
New value of Value function: 6.14722
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 137
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 3.56228
New value of Value function: 6.14722
New value of Policy matrix: 4

=======================================
Simulation: 11
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 4.74432
New value of Value function: 4.74432
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 4.74195
New value of Value function: 4.74195
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 403
New value of Q matrix: 4.73959
New value of Value function: 4.73959
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 404
New value of Q matrix: 4.73723
New value of Value function: 4.73723
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 405
New value of Q matrix: 4.73488
New value of Value function: 4.73488
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 406
New value of Q matrix: 4.73253
New value of Value function: 4.73253
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 407
New value of Q matrix: 4.73018
New value of Value function: 4.73018
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 408
New value of Q matrix: 4.72784
New value of Value function: 4.72784
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 409
New value of Q matrix: 4.7255
New value of Value function: 4.7255
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 4.66147
New value of Value function: 4.7255
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 410
New value of Q matrix: 4.72317
New value of Value function: 4.72317
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 411
New value of Q matrix: 4.72084
New value of Value function: 4.72084
New value of Policy matrix: 1

=======================================
Simulation: 11
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 412
New value of Q matrix: 4.71851
New value of Value function: 4.71851
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 413
New value of Q matrix: 4.71619
New value of Value function: 4.71619
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 414
New value of Q matrix: 4.71387
New value of Value function: 4.71387
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 415
New value of Q matrix: 4.71156
New value of Value function: 4.71156
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 416
New value of Q matrix: 4.70925
New value of Value function: 4.70925
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 417
New value of Q matrix: 4.70694
New value of Value function: 4.70694
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 418
New value of Q matrix: 4.70464
New value of Value function: 4.70464
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 4.51692
New value of Value function: 4.70464
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 4.52716
New value of Value function: 4.70464
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 419
New value of Q matrix: 4.70234
New value of Value function: 4.70234
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 123
New value of Q matrix: 4.6556
New value of Value function: 4.70234
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 420
New value of Q matrix: 4.70005
New value of Value function: 4.70005
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 421
New value of Q matrix: 4.69776
New value of Value function: 4.69776
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 4.66062
New value of Value function: 4.69776
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 422
New value of Q matrix: 4.69547
New value of Value function: 4.69547
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 423
New value of Q matrix: 4.69319
New value of Value function: 4.69319
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 424
New value of Q matrix: 4.69091
New value of Value function: 4.69091
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 425
New value of Q matrix: 4.68863
New value of Value function: 4.68863
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 426
New value of Q matrix: 4.68636
New value of Value function: 4.68636
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 427
New value of Q matrix: 4.68409
New value of Value function: 4.68409
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 4.65877
New value of Value function: 4.68409
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 4.65707
New value of Value function: 4.68409
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 4.53514
New value of Value function: 4.68409
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 428
New value of Q matrix: 4.68183
New value of Value function: 4.68183
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 4.59253
New value of Value function: 4.68183
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 4.59608
New value of Value function: 4.68183
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 429
New value of Q matrix: 4.67957
New value of Value function: 4.67957
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 430
New value of Q matrix: 4.67731
New value of Value function: 4.67731
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 431
New value of Q matrix: 4.67506
New value of Value function: 4.67506
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 432
New value of Q matrix: 4.67281
New value of Value function: 4.67281
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 433
New value of Q matrix: 4.67056
New value of Value function: 4.67056
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 434
New value of Q matrix: 4.66832
New value of Value function: 4.66832
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 4.5414
New value of Value function: 4.66832
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 435
New value of Q matrix: 4.66608
New value of Value function: 4.66608
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 4.59803
New value of Value function: 4.66608
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 436
New value of Q matrix: 4.66385
New value of Value function: 4.66385
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 437
New value of Q matrix: 4.66162
New value of Value function: 4.66162
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 438
New value of Q matrix: 4.65939
New value of Value function: 4.65939
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 439
New value of Q matrix: 4.65717
New value of Value function: 4.65717
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 440
New value of Q matrix: 4.65495
New value of Value function: 4.65707
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 4.6534
New value of Value function: 4.6556
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 124
New value of Q matrix: 4.65142
New value of Value function: 4.65495
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 441
New value of Q matrix: 4.65273
New value of Value function: 4.6534
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 4.64974
New value of Value function: 4.65273
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 442
New value of Q matrix: 4.65052
New value of Value function: 4.65142
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 125
New value of Q matrix: 4.64725
New value of Value function: 4.65052
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 4.54592
New value of Value function: 4.65052
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 443
New value of Q matrix: 4.64831
New value of Value function: 4.64974
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 4.6461
New value of Value function: 4.64831
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 444
New value of Q matrix: 4.6461
New value of Value function: 4.64725
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 4.59825
New value of Value function: 4.64725
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 126
New value of Q matrix: 4.64311
New value of Value function: 4.6461
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 445
New value of Q matrix: 4.6439
New value of Value function: 4.6461
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 4.54979
New value of Value function: 4.6461
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 4.64247
New value of Value function: 4.6439
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 446
New value of Q matrix: 4.6417
New value of Value function: 4.64311
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 127
New value of Q matrix: 4.63899
New value of Value function: 4.64247
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 4.63886
New value of Value function: 4.6417
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 447
New value of Q matrix: 4.6395
New value of Value function: 4.6395
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 4.63531
New value of Value function: 4.6395
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 128
New value of Q matrix: 4.63494
New value of Value function: 4.6395
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 4.5529
New value of Value function: 4.6395
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 4.59783
New value of Value function: 4.6395
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 448
New value of Q matrix: 4.63731
New value of Value function: 4.63731
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 449
New value of Q matrix: 4.63512
New value of Value function: 4.63531
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 4.63172
New value of Value function: 4.63512
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 450
New value of Q matrix: 4.63294
New value of Value function: 4.63494
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 451
New value of Q matrix: 4.63085
New value of Value function: 4.63494
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 129
New value of Q matrix: 4.63086
New value of Value function: 4.63172
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 4.62814
New value of Value function: 4.63086
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 130
New value of Q matrix: 4.6268
New value of Value function: 4.63085
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 131
New value of Q matrix: 4.6231
New value of Value function: 4.63085
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 452
New value of Q matrix: 4.62867
New value of Value function: 4.62867
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 4.62462
New value of Value function: 4.62867
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 453
New value of Q matrix: 4.6265
New value of Value function: 4.6265
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 454
New value of Q matrix: 4.62432
New value of Value function: 4.62462
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 4.62108
New value of Value function: 4.62432
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 455
New value of Q matrix: 4.62216
New value of Value function: 4.6231
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 132
New value of Q matrix: 4.61908
New value of Value function: 4.62216
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 456
New value of Q matrix: 4.61999
New value of Value function: 4.62108
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 4.61754
New value of Value function: 4.61999
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 457
New value of Q matrix: 4.61783
New value of Value function: 4.61908
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 133
New value of Q matrix: 4.61508
New value of Value function: 4.61783
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 458
New value of Q matrix: 4.99745
New value of Value function: 4.99745
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 84
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.74204
New value of Value function: 9.84044
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 85
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 9.84044
New value of Value function: 9.84044
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 86
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.86938
New value of Value function: 4.86938
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 87
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.85097
New value of Value function: 4.85097
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 88
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.83382
New value of Value function: 4.83382
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 89
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.81771
New value of Value function: 4.81771
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 90
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 3.60573
New value of Value function: 4.81771
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 91
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 1
New value of Q matrix: -0.25796
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 92
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.98762
New value of Value function: 9.84044
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 93
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.976032
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 4.58115
New value of Value function: 4.99745
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 459
New value of Q matrix: 4.90422
New value of Value function: 4.90422
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 96
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 97
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.73782
New value of Value function: 2.73782
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 98
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.7995
New value of Value function: 9.7995
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 99
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 4.80247
New value of Value function: 4.80247
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 100
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 4.78799
New value of Value function: 4.78799
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 101
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 4.17494
New value of Value function: 4.78799
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 102
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.28956
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 103
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 3.86891
New value of Value function: 3.86891
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 104
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 105
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.198412
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 106
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 4.77417
New value of Value function: 4.77417
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 107
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 4.76093
New value of Value function: 4.76093
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 108
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 4.74821
New value of Value function: 4.74821
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 109
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0788514
New value of Value function: 4.74821
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 110
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.70165
New value of Value function: 7.70165
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 111
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 4.73595
New value of Value function: 4.73595
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 112
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 4.72411
New value of Value function: 4.72411
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 113
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.8328
New value of Value function: 4.72411
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 114
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.68926
New value of Value function: 8.68926
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 115
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 4.71265
New value of Value function: 4.71265
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 116
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 4.70154
New value of Value function: 4.70154
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 117
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.20775
New value of Value function: 4.70154
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 118
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.60236
New value of Value function: 9.7995
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 119
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.12094
New value of Value function: 9.12094
New value of Policy matrix: 2

=======================================
Simulation: 12
Iteration: 120
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 4.69076
New value of Value function: 4.69076
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 121
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 4.37396
New value of Value function: 4.69076
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 122
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.72168
New value of Value function: 9.74204
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 123
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 4.68027
New value of Value function: 4.68027
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 124
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 4.67005
New value of Value function: 4.67005
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 125
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 4.6601
New value of Value function: 4.6601
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 126
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 4.65038
New value of Value function: 4.65038
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 127
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 4.64089
New value of Value function: 4.64089
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 128
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 4.63161
New value of Value function: 4.63161
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 129
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.92618
New value of Value function: 4.63161
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 130
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.67315
New value of Value function: 9.72168
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 131
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.66068
New value of Value function: 9.67315
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 132
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 4.62252
New value of Value function: 4.62252
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 133
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.18172
New value of Value function: 4.62252
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 134
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 4.18532
New value of Value function: 4.18532
New value of Policy matrix: 3

=======================================
Simulation: 12
Iteration: 135
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.6173
New value of Value function: 9.66068
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 136
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 9.62623
New value of Value function: 9.62623
New value of Policy matrix: 1

=======================================
Simulation: 12
Iteration: 137
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 4.61363
New value of Value function: 4.61363
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 138
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 4.60491
New value of Value function: 4.60491
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 139
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 4.59636
New value of Value function: 4.59636
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 140
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 4.58796
New value of Value function: 4.58796
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 141
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 4.57972
New value of Value function: 4.57972
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 142
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 4.57163
New value of Value function: 4.57163
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 143
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 4.56367
New value of Value function: 4.56367
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 144
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 4.55584
New value of Value function: 4.55584
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 145
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 4.54814
New value of Value function: 4.54814
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 146
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 4.54056
New value of Value function: 4.54056
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 147
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 3.64342
New value of Value function: 4.54056
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 148
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 9.57669
New value of Value function: 9.6173
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 149
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 4.5331
New value of Value function: 4.5331
New value of Policy matrix: 4

=======================================
Simulation: 12
Iteration: 150
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 4.52574
New value of Value function: 4.52574
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 460
New value of Q matrix: 4.90193
New value of Value function: 4.90193
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 461
New value of Q matrix: 4.89965
New value of Value function: 4.89965
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 462
New value of Q matrix: 4.89737
New value of Value function: 4.89737
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 463
New value of Q matrix: 4.89509
New value of Value function: 4.89509
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 464
New value of Q matrix: 4.89282
New value of Value function: 4.89282
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 465
New value of Q matrix: 4.89055
New value of Value function: 4.89055
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 466
New value of Q matrix: 5.20736
New value of Value function: 5.20736
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 8
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.67299
New value of Value function: 5.67299
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 9
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 3.7549
New value of Value function: 3.7549
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 10
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.132553
New value of Value function: 2.68342
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 11
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 2.53378
New value of Value function: 2.53378
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 12
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.50216
New value of Value function: 2.68342
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 13
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 6.48279
New value of Value function: 6.48279
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 14
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.0705
New value of Value function: 6.0705
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 15
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.80055
New value of Value function: 5.80055
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 16
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.0461
New value of Value function: 5.0461
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 17
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.33584
New value of Value function: 5.45524
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 18
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.25082
New value of Value function: 5.25082
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 19
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 4.28853
New value of Value function: 5.33584
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 467
New value of Q matrix: 5.34966
New value of Value function: 5.34966
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 21
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.44123
New value of Value function: 8.44123
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 22
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.58575
New value of Value function: 6.58575
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 23
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.56086
New value of Value function: 6.56086
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 24
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 4.04218
New value of Value function: 6.56086
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 25
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 6.71407
New value of Value function: 6.71407
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 26
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.85429
New value of Value function: 7.85429
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 27
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.98023
New value of Value function: 8.06084
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 28
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 9.04748
New value of Value function: 9.04748
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 29
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 3.43117
New value of Value function: 9.12539
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 30
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 9.31246
New value of Value function: 9.31246
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 31
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 8.2308
New value of Value function: 8.2308
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 32
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.02909
New value of Value function: 6.02909
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 33
----------
State: 2225
	Distance: 3
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.22508
New value of Value function: 6.22508
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 34
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.53767
New value of Value function: 6.53767
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 35
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.51587
New value of Value function: 6.51587
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 36
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 4.69199
New value of Value function: 6.51587
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 468
New value of Q matrix: 5.62734
New value of Value function: 5.62734
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 38
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 9.78711
New value of Value function: 9.78711
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 39
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.49527
New value of Value function: 6.49527
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 40
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 6.47568
New value of Value function: 6.47568
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 41
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.45699
New value of Value function: 6.45699
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 42
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.43908
New value of Value function: 6.43908
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 43
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 3.31476
New value of Value function: 6.43908
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 44
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 10.4352
New value of Value function: 10.4352
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 45
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.42187
New value of Value function: 6.42187
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 46
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.40529
New value of Value function: 6.40529
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 47
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 6.38928
New value of Value function: 6.38928
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 48
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 6.37378
New value of Value function: 6.37378
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 49
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 6.35876
New value of Value function: 6.35876
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 50
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 6.34417
New value of Value function: 6.34417
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 51
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 6.32999
New value of Value function: 6.32999
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 52
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 6.31617
New value of Value function: 6.31617
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 53
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 6.30271
New value of Value function: 6.30271
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 54
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 6.28956
New value of Value function: 6.28956
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 55
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 6.27673
New value of Value function: 6.27673
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 56
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 6.26417
New value of Value function: 6.26417
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 57
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 6.25189
New value of Value function: 6.25189
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 58
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 6.23986
New value of Value function: 6.23986
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 59
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.152664
New value of Value function: 6.23986
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 60
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.79085
New value of Value function: 7.79085
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 61
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 9.40631
New value of Value function: 9.40631
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 62
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 8.47124
New value of Value function: 8.47124
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 63
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 9.04576
New value of Value function: 9.04576
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 64
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 10.6469
New value of Value function: 10.6469
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 65
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.64693
New value of Value function: 6.71407
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 66
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.74491
New value of Value function: 8.74491
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 67
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 7.9688
New value of Value function: 7.9688
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 68
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.5839
New value of Value function: 4.8066
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 469
New value of Q matrix: 5.76515
New value of Value function: 5.76515
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 70
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 5.86084
New value of Value function: 5.86084
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 71
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 6.22806
New value of Value function: 6.22806
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 72
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 6.2165
New value of Value function: 6.2165
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 73
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 6.20515
New value of Value function: 6.20515
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 74
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 6.194
New value of Value function: 6.194
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 75
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 6.18305
New value of Value function: 6.18305
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 76
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 6.17229
New value of Value function: 6.17229
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 77
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 6.1617
New value of Value function: 6.1617
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 78
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 6.15129
New value of Value function: 6.15129
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 79
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 6.14104
New value of Value function: 6.14104
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 80
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 4.35651
New value of Value function: 6.14104
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 81
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 9.70382
New value of Value function: 9.70382
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 82
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.7711
New value of Value function: 7.85429
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 83
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.03936
New value of Value function: 4.03936
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 84
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 9.09266
New value of Value function: 9.09266
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 85
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.76185
New value of Value function: 8.2308
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 86
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.00438
New value of Value function: 9.00438
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 87
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 5.44617
New value of Value function: 5.44617
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 88
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 5.42181
New value of Value function: 5.42181
New value of Policy matrix: 4

=======================================
Simulation: 13
Iteration: 89
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.50018
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 90
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3.58579
New value of Value function: 3.58579
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 91
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 92
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 93
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 94
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 13
Iteration: 95
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 96
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 97
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.97
New value of Value function: 4.97
New value of Policy matrix: 1

=======================================
Simulation: 13
Iteration: 98
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.41421
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 13
Iteration: 99
----------
State: 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1450
	Distance: 2
	Angle: 6
	Height: 2
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 1
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: -3.26519
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 2
----------
State: 4921
	Distance: 8
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.608628
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 3
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.58669
New value of Value function: 5.58669
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 4
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.34237
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 5
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 3
New value of Q matrix: 9.73995
New value of Value function: 9.73995
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 6
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.63609
New value of Value function: 3.63609
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 7
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.84361
New value of Value function: 5.58669
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 8
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 8.59973
New value of Value function: 8.59973
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 9
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.37598
New value of Value function: 6.37598
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 10
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 3.48844
New value of Value function: 3.48844
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 11
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 6.37598
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 12
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.97
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 13
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 7.46341
New value of Value function: 7.46341
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.24038
New value of Value function: 7.24038
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 15
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.49334
New value of Value function: 6.55893
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 16
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 6.49334
New value of Value function: 6.55893
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 17
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 6.50624
New value of Value function: 6.50624
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 18
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.09211
New value of Value function: 3.48844
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 19
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 3.02159
New value of Value function: 3.02159
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 20
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 7.52423
New value of Value function: 7.52423
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 21
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 3.01152
New value of Value function: 3.01152
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 22
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 3.64033
New value of Value function: 3.64033
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 23
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 24
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.95
New value of Value function: 6.95
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 25
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.2084
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 26
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 3.81966
New value of Value function: 3.81966
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 27
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 3.8098
New value of Value function: 3.8098
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 28
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 3.42429
New value of Value function: 3.8098
New value of Policy matrix: 4

=======================================
Simulation: 14
Iteration: 29
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 30
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 1.95
New value of Value function: 1.95
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 31
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.70004
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 32
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.0695
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 33
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2.68539
New value of Value function: 2.68539
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 34
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.643035
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 35
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.64304
New value of Value function: 5.70004
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 36
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.86745
New value of Value function: 5.86745
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 37
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.760229
New value of Value function: 1
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 38
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5.92872
New value of Value function: 5.92872
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 39
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 3.84347
New value of Value function: 3.84347
New value of Policy matrix: 1

=======================================
Simulation: 14
Iteration: 40
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.38207
New value of Value function: 6.38207
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 41
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 61.2815
New value of Value function: 61.2815
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 42
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.49982
New value of Value function: 100
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 43
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 75.0036
New value of Value function: 75.0036
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 44
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 26.4609
New value of Value function: 26.4609
New value of Policy matrix: 0

=======================================
Simulation: 14
Iteration: 45
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.31825
New value of Value function: 1.31825
New value of Policy matrix: 3

=======================================
Simulation: 14
Iteration: 46
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 30.5857
New value of Value function: 30.5857
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 47
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 82.6407
New value of Value function: 82.6407
New value of Policy matrix: 2

=======================================
Simulation: 14
Iteration: 48
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1986
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 2
New value of Q matrix: 96.4645
New value of Value function: 96.4645
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 1
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.42801
New value of Value function: 9.42801
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 2
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 9.4281
New value of Value function: 9.4281
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 3
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 10.4746
New value of Value function: 10.4746
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 4
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 1
New value of Q matrix: 3.33382
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 5
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 10.162
New value of Value function: 10.162
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 6
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 11.4045
New value of Value function: 11.4045
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 7
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 2.97
New value of Value function: 8.50018
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 8
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 3
New value of Q matrix: 1.33893
New value of Value function: 3.85788
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 9
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 10.6053
New value of Value function: 10.6053
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 10
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 10.9146
New value of Value function: 10.9146
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 11
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 7.8193
New value of Value function: 11.4045
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 12
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 6.63653
New value of Value function: 6.63653
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 13
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.5289
New value of Value function: 8.5289
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 14
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 4.39651
New value of Value function: 4.39651
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 15
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -1.12132
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 16
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 17
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 18
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 19
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 20
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 21
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 22
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 23
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 24
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 25
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 26
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 27
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 28
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 29
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 30
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 31
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 32
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 33
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 34
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 1.9202
New value of Value function: 1.9202
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 35
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 5.9202
New value of Value function: 5.98
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 36
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2509
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 1.04439
New value of Value function: 5.9202
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 37
----------
State: 2509
	Distance: 4
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 38
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.14607
New value of Value function: 3.14607
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 39
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.12752
New value of Value function: 8.12752
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 40
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 5.77372
New value of Value function: 6.14722
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 41
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 3.94777
New value of Value function: 3.94777
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 42
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1833
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 1.89512
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 43
----------
State: 1833
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 4.08575
New value of Value function: 4.08575
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 44
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.12549
New value of Value function: 6.12549
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 45
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 6.95847
New value of Value function: 6.95847
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 46
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 3.91575
New value of Value function: 3.91575
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 47
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1833
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.13983
New value of Value function: 1.89512
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 48
----------
State: 1833
	Distance: 3
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 4.65365
New value of Value function: 4.65365
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 49
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 6.04624
New value of Value function: 6.95847
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 50
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.5671
New value of Value function: 8.5671
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 51
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.94102
New value of Value function: 6.95847
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 52
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -3.95682
New value of Value function: 9.31246
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 53
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 1.43641
New value of Value function: 1.43641
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 54
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.40088
New value of Value function: 8.40088
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 55
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 2.67105
New value of Value function: 5.95
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 56
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.64569
New value of Value function: 9.64569
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 57
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.0801712
New value of Value function: 2.67105
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 58
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 3.80735
New value of Value function: 3.80735
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 59
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.54923
New value of Value function: 9.64569
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 60
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.75066
New value of Value function: 9.54923
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 61
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 1.22016
New value of Value function: 1.22016
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 62
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 5.27667
New value of Value function: 5.27667
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 63
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.48171
New value of Value function: 9.48171
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 64
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.42697
New value of Value function: 9.42697
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 65
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.37983
New value of Value function: 9.37983
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 66
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 9.33789
New value of Value function: 9.33789
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 67
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 9.29976
New value of Value function: 9.29976
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 68
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 9.26461
New value of Value function: 9.26461
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 69
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 9.23186
New value of Value function: 9.23186
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 70
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 9.20109
New value of Value function: 9.20109
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 71
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 9.17199
New value of Value function: 9.17199
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 72
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 9.14433
New value of Value function: 9.14433
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 73
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 9.11794
New value of Value function: 9.11794
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 74
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 9.09265
New value of Value function: 9.09265
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 75
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 8.32168
New value of Value function: 8.75066
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 76
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: -1.11436
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 77
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 78
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 79
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 80
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 81
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 82
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 83
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 6.2239
New value of Value function: 6.2239
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 84
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 4.89174
New value of Value function: 4.89174
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 85
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 86
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 87
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 88
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 89
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 0.836048
New value of Value function: 0.836048
New value of Policy matrix: 3

=======================================
Simulation: 15
Iteration: 90
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.55736
New value of Value function: 8.32168
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 91
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.8889
New value of Value function: 11.8889
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 92
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 5.20539
New value of Value function: 6.12549
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 93
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 6.48142
New value of Value function: 6.48142
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 94
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 8.41661
New value of Value function: 8.5671
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 95
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.48142
New value of Value function: 6.48142
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 96
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 8.31566
New value of Value function: 8.41661
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 97
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.10507
New value of Value function: 6.10507
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 98
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.08576
New value of Value function: 6.08576
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 99
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 6.06741
New value of Value function: 6.06741
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 100
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 6.0499
New value of Value function: 6.0499
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 101
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 5.50846
New value of Value function: 6.0499
New value of Policy matrix: 4

=======================================
Simulation: 15
Iteration: 102
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.61407
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 103
----------
State: 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 81.2535
New value of Value function: 81.2535
New value of Policy matrix: 0

=======================================
Simulation: 15
Iteration: 104
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 34.6147
New value of Value function: 34.6147
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 105
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.43751
New value of Value function: 2.43751
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 470
New value of Q matrix: 5.76249
New value of Value function: 5.76249
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 471
New value of Q matrix: 5.75983
New value of Value function: 5.75983
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 134
New value of Q matrix: 4.63763
New value of Value function: 5.75983
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 109
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 2.36111
New value of Value function: 2.36111
New value of Policy matrix: 2

=======================================
Simulation: 15
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 472
New value of Q matrix: 5.75718
New value of Value function: 5.75718
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 473
New value of Q matrix: 5.75453
New value of Value function: 5.75453
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 474
New value of Q matrix: 5.75189
New value of Value function: 5.75189
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 475
New value of Q matrix: 5.74925
New value of Value function: 5.74925
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 4.66048
New value of Value function: 5.74925
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 476
New value of Q matrix: 5.74661
New value of Value function: 5.74661
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 477
New value of Q matrix: 5.74398
New value of Value function: 5.74398
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 478
New value of Q matrix: 5.74136
New value of Value function: 5.74136
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 479
New value of Q matrix: 5.73873
New value of Value function: 5.73873
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 4.73322
New value of Value function: 5.73873
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 480
New value of Q matrix: 5.73611
New value of Value function: 5.73611
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 4.68698
New value of Value function: 5.73611
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 481
New value of Q matrix: 5.7335
New value of Value function: 5.7335
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 482
New value of Q matrix: 5.73089
New value of Value function: 5.73089
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 483
New value of Q matrix: 5.72828
New value of Value function: 5.72828
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 4.69787
New value of Value function: 5.72828
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 484
New value of Q matrix: 5.72568
New value of Value function: 5.72568
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 4.77166
New value of Value function: 5.72568
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 4.76766
New value of Value function: 5.72568
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 485
New value of Q matrix: 5.72308
New value of Value function: 5.72308
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 486
New value of Q matrix: 5.72048
New value of Value function: 5.72048
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 487
New value of Q matrix: 5.71789
New value of Value function: 5.71789
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 4.83906
New value of Value function: 5.71789
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 4.90117
New value of Value function: 5.71789
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 488
New value of Q matrix: 5.7153
New value of Value function: 5.7153
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 489
New value of Q matrix: 5.71271
New value of Value function: 5.71271
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 4.79877
New value of Value function: 5.71271
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 490
New value of Q matrix: 5.71013
New value of Value function: 5.71013
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 491
New value of Q matrix: 5.70756
New value of Value function: 5.70756
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 492
New value of Q matrix: 5.70498
New value of Value function: 5.70498
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 4.83977
New value of Value function: 5.70498
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 493
New value of Q matrix: 5.70241
New value of Value function: 5.70241
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 494
New value of Q matrix: 5.69985
New value of Value function: 5.69985
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 495
New value of Q matrix: 5.69729
New value of Value function: 5.69729
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 4.95688
New value of Value function: 5.69729
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 135
New value of Q matrix: 4.72393
New value of Value function: 5.69729
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 496
New value of Q matrix: 5.69473
New value of Value function: 5.69473
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 497
New value of Q matrix: 5.69217
New value of Value function: 5.69217
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 150
New value of Q matrix: 4.90472
New value of Value function: 5.69217
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 498
New value of Q matrix: 5.68962
New value of Value function: 5.68962
New value of Policy matrix: 1

=======================================
Simulation: 15
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 499
New value of Q matrix: 5.68708
New value of Value function: 5.68708
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 1
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 2
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 3
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 4
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 5
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 6
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 7
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 8
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 9
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: -0.05
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 10
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 2.95
New value of Value function: 2.95
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 11
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.965
New value of Value function: 5
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 12
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: -0.05
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 13
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.97113
New value of Value function: 4.97113
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 14
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 4.9205
New value of Value function: 4.97113
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 15
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 2
New value of Q matrix: -4.08571
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 16
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.92142
New value of Value function: 9.92142
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 17
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.96082
New value of Value function: 4.965
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 18
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -0.0496464
New value of Value function: -0.0496464
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 19
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0493598
New value of Value function: -0.0493598
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 20
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.049113
New value of Value function: -0.049113
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 21
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: -0.0488934
New value of Value function: -0.0488934
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 22
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0486938
New value of Value function: -0.0486938
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 23
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0485097
New value of Value function: -0.0485097
New value of Policy matrix: 4

=======================================
Simulation: 16
Iteration: 24
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: -0.0612879
New value of Value function: -0.05
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 25
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.95663
New value of Value function: 4.96082
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 26
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -3
New value of Value function: -0.05
New value of Policy matrix: 3

=======================================
Simulation: 16
Iteration: 27
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 28
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 29
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 30
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 31
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 32
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 33
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 34
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 35
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 36
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 37
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 38
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 39
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 40
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 41
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 42
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 43
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 44
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 45
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 46
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 47
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 48
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 49
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 50
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 51
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 52
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.44302
New value of Value function: 1.44302
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 53
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 3.45771
New value of Value function: 3.45771
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 54
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.458161
New value of Value function: 1.44302
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 55
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 3.4467
New value of Value function: 3.4467
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 56
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 2.63021
New value of Value function: 2.63021
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 500
New value of Q matrix: 5.68453
New value of Value function: 5.68453
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 501
New value of Q matrix: 5.68199
New value of Value function: 5.68199
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 502
New value of Q matrix: 5.67946
New value of Value function: 5.67946
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 503
New value of Q matrix: 5.67692
New value of Value function: 5.67692
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 504
New value of Q matrix: 5.6744
New value of Value function: 5.6744
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 5.00655
New value of Value function: 5.6744
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 505
New value of Q matrix: 5.67187
New value of Value function: 5.67187
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 506
New value of Q matrix: 5.66935
New value of Value function: 5.66935
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 4.96233
New value of Value function: 5.66935
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 507
New value of Q matrix: 5.66683
New value of Value function: 5.66683
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 508
New value of Q matrix: 5.66432
New value of Value function: 5.66432
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 509
New value of Q matrix: 5.66181
New value of Value function: 5.66181
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 510
New value of Q matrix: 5.6593
New value of Value function: 5.6593
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 5.05123
New value of Value function: 5.6593
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 511
New value of Q matrix: 5.6568
New value of Value function: 5.6568
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 5.01407
New value of Value function: 5.6568
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 512
New value of Q matrix: 5.6543
New value of Value function: 5.6543
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 513
New value of Q matrix: 5.6518
New value of Value function: 5.6518
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 4.85523
New value of Value function: 5.6518
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 5.06106
New value of Value function: 5.6518
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 514
New value of Q matrix: 5.64931
New value of Value function: 5.64931
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 515
New value of Q matrix: 5.64682
New value of Value function: 5.64682
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 4.90721
New value of Value function: 5.64682
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 4.9554
New value of Value function: 5.64682
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 516
New value of Q matrix: 5.64433
New value of Value function: 5.64433
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 517
New value of Q matrix: 5.64185
New value of Value function: 5.64185
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 518
New value of Q matrix: 5.63937
New value of Value function: 5.63937
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 519
New value of Q matrix: 5.6369
New value of Value function: 5.6369
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 5.09079
New value of Value function: 5.6369
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 136
New value of Q matrix: 4.79738
New value of Value function: 5.6369
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 5.10292
New value of Value function: 5.6369
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 520
New value of Q matrix: 5.63442
New value of Value function: 5.63442
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 4.99921
New value of Value function: 5.63442
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 521
New value of Q matrix: 5.63195
New value of Value function: 5.63195
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 522
New value of Q matrix: 5.62949
New value of Value function: 5.62949
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 523
New value of Q matrix: 5.62703
New value of Value function: 5.62703
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 524
New value of Q matrix: 5.62457
New value of Value function: 5.62457
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 137
New value of Q matrix: 4.86325
New value of Value function: 5.62457
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 525
New value of Q matrix: 5.62212
New value of Value function: 5.62212
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 526
New value of Q matrix: 5.61966
New value of Value function: 5.61966
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 5.13991
New value of Value function: 5.61966
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 5.12603
New value of Value function: 5.61966
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 527
New value of Q matrix: 5.61722
New value of Value function: 5.61722
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 5.15836
New value of Value function: 5.61722
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 528
New value of Q matrix: 5.61477
New value of Value function: 5.61477
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 529
New value of Q matrix: 5.61233
New value of Value function: 5.61233
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 530
New value of Q matrix: 5.60989
New value of Value function: 5.60989
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 531
New value of Q matrix: 5.60746
New value of Value function: 5.60746
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 532
New value of Q matrix: 5.60503
New value of Value function: 5.60503
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 533
New value of Q matrix: 5.6026
New value of Value function: 5.6026
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 5.18714
New value of Value function: 5.6026
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 534
New value of Q matrix: 5.60017
New value of Value function: 5.60017
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 5.21353
New value of Value function: 5.60017
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 138
New value of Q matrix: 4.92121
New value of Value function: 5.60017
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 535
New value of Q matrix: 5.59775
New value of Value function: 5.59775
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 5.17209
New value of Value function: 5.59775
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 536
New value of Q matrix: 5.59534
New value of Value function: 5.59534
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 5.23755
New value of Value function: 5.59534
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 537
New value of Q matrix: 5.59292
New value of Value function: 5.59292
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 538
New value of Q matrix: 5.59051
New value of Value function: 5.59051
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 539
New value of Q matrix: 5.5881
New value of Value function: 5.5881
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 139
New value of Q matrix: 4.97304
New value of Value function: 5.5881
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 540
New value of Q matrix: 5.5857
New value of Value function: 5.5857
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 541
New value of Q matrix: 5.5833
New value of Value function: 5.5833
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 140
New value of Q matrix: 5.01989
New value of Value function: 5.5833
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 542
New value of Q matrix: 5.5809
New value of Value function: 5.5809
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 543
New value of Q matrix: 5.5785
New value of Value function: 5.5785
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 544
New value of Q matrix: 5.57611
New value of Value function: 5.57611
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 545
New value of Q matrix: 5.57372
New value of Value function: 5.57372
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 546
New value of Q matrix: 5.57134
New value of Value function: 5.57134
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 547
New value of Q matrix: 5.73581
New value of Value function: 5.73581
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 128
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.19384
New value of Value function: 8.19384
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 129
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 5.69202
New value of Value function: 5.69202
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 130
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.146758
New value of Value function: 0.146758
New value of Policy matrix: 0

=======================================
Simulation: 16
Iteration: 131
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.856535
New value of Value function: 5.19875
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 132
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 10.1468
New value of Value function: 10.1468
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 133
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.07163
New value of Value function: 4.07163
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 5.04688
New value of Value function: 5.73581
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 548
New value of Q matrix: 5.79113
New value of Value function: 5.79113
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 136
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 3.52523
New value of Value function: 3.52523
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 5.09493
New value of Value function: 5.79113
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 549
New value of Q matrix: 5.78866
New value of Value function: 5.78866
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 550
New value of Q matrix: 5.88082
New value of Value function: 5.88082
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 140
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 141
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 142
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 143
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 144
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 145
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 146
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 147
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 148
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 16
Iteration: 149
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.85471
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 16
Iteration: 150
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.54316
New value of Value function: 3.54316
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 551
New value of Q matrix: 5.87831
New value of Value function: 5.87831
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 552
New value of Q matrix: 5.87581
New value of Value function: 5.87581
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 553
New value of Q matrix: 6.09847
New value of Value function: 6.09847
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 4
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.05696
New value of Value function: 9.05696
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 5
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 4.95801
New value of Value function: 4.95801
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 6
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.55379
New value of Value function: 3.52523
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 7
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.34078
New value of Value function: 9.34078
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 8
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 0.687946
New value of Value function: 4.95801
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 9
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 4.98
New value of Value function: 4.98
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 10
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.35696
New value of Value function: 6.35696
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 11
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.7277
New value of Value function: 6.2239
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 12
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 10.545
New value of Value function: 10.545
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 13
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 12
New value of Q matrix: 3.17651
New value of Value function: 3.17651
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 14
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 10.8255
New value of Value function: 10.8255
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 15
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 8.3002
New value of Value function: 8.3002
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 16
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 11.0394
New value of Value function: 11.0394
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 17
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 11.4954
New value of Value function: 11.4954
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 18
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 0.343848
New value of Value function: 8.31566
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 19
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.4166
New value of Value function: 11.4166
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 20
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 6.33771
New value of Value function: 6.33771
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 21
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 8.16975
New value of Value function: 8.16975
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 22
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 6.03312
New value of Value function: 6.04624
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 23
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 6.07581
New value of Value function: 6.07581
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 24
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.33482
New value of Value function: 8.16975
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 25
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 8.1066
New value of Value function: 8.1066
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 26
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 3.25641
New value of Value function: 6.07581
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 27
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 10.8015
New value of Value function: 10.8015
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 28
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 12.0193
New value of Value function: 12.0193
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 29
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 8.20275
New value of Value function: 8.20275
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 30
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 4.52706
New value of Value function: 4.52706
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 31
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 2.7375
New value of Value function: 2.7375
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 141
New value of Q matrix: 5.07802
New value of Value function: 6.09847
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 33
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.71012
New value of Value function: 2.7375
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 34
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.87166
New value of Value function: 2.87166
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 5.29636
New value of Value function: 6.09847
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 554
New value of Q matrix: 6.09588
New value of Value function: 6.09588
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 555
New value of Q matrix: 6.09329
New value of Value function: 6.09329
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 556
New value of Q matrix: 6.09071
New value of Value function: 6.09071
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 557
New value of Q matrix: 6.08813
New value of Value function: 6.08813
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 558
New value of Q matrix: 6.08555
New value of Value function: 6.08555
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 559
New value of Q matrix: 6.08298
New value of Value function: 6.08298
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 5.23993
New value of Value function: 6.08298
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 560
New value of Q matrix: 6.08041
New value of Value function: 6.08041
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 561
New value of Q matrix: 6.07784
New value of Value function: 6.07784
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 562
New value of Q matrix: 6.07528
New value of Value function: 6.07528
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 563
New value of Q matrix: 6.07272
New value of Value function: 6.07272
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 5.34884
New value of Value function: 6.07272
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 564
New value of Q matrix: 6.07016
New value of Value function: 6.07016
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 565
New value of Q matrix: 6.06761
New value of Value function: 6.06761
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 566
New value of Q matrix: 6.06506
New value of Value function: 6.06506
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 567
New value of Q matrix: 6.06251
New value of Value function: 6.06251
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 568
New value of Q matrix: 6.05996
New value of Value function: 6.05996
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 569
New value of Q matrix: 6.05742
New value of Value function: 6.05742
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 570
New value of Q matrix: 6.05489
New value of Value function: 6.05489
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 571
New value of Q matrix: 6.05235
New value of Value function: 6.05235
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 572
New value of Q matrix: 6.04982
New value of Value function: 6.04982
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 5.39567
New value of Value function: 6.04982
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 142
New value of Q matrix: 5.1545
New value of Value function: 6.04982
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 573
New value of Q matrix: 6.04729
New value of Value function: 6.04729
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 574
New value of Q matrix: 6.04477
New value of Value function: 6.04477
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 575
New value of Q matrix: 6.04225
New value of Value function: 6.04225
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 576
New value of Q matrix: 6.03973
New value of Value function: 6.03973
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 577
New value of Q matrix: 6.03722
New value of Value function: 6.03722
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 5.43806
New value of Value function: 6.03722
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 578
New value of Q matrix: 6.03471
New value of Value function: 6.03471
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 579
New value of Q matrix: 6.0322
New value of Value function: 6.0322
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 580
New value of Q matrix: 6.02969
New value of Value function: 6.02969
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 581
New value of Q matrix: 6.02719
New value of Value function: 6.02719
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 582
New value of Q matrix: 6.02469
New value of Value function: 6.02469
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 583
New value of Q matrix: 6.0222
New value of Value function: 6.0222
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 584
New value of Q matrix: 6.01971
New value of Value function: 6.01971
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 585
New value of Q matrix: 6.01722
New value of Value function: 6.01722
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 586
New value of Q matrix: 6.01473
New value of Value function: 6.01473
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 587
New value of Q matrix: 6.01225
New value of Value function: 6.01225
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 588
New value of Q matrix: 6.00977
New value of Value function: 6.00977
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 589
New value of Q matrix: 6.00729
New value of Value function: 6.00729
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 590
New value of Q matrix: 6.00482
New value of Value function: 6.00482
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 591
New value of Q matrix: 6.00235
New value of Value function: 6.00235
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 592
New value of Q matrix: 5.99988
New value of Value function: 5.99988
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 593
New value of Q matrix: 5.99742
New value of Value function: 5.99742
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 594
New value of Q matrix: 5.99496
New value of Value function: 5.99496
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 595
New value of Q matrix: 5.9925
New value of Value function: 5.9925
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 5.47403
New value of Value function: 5.9925
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 596
New value of Q matrix: 5.99005
New value of Value function: 5.99005
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 597
New value of Q matrix: 5.9876
New value of Value function: 5.9876
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 598
New value of Q matrix: 5.98515
New value of Value function: 5.98515
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 5.50677
New value of Value function: 5.98515
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 599
New value of Q matrix: 5.9827
New value of Value function: 5.9827
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 600
New value of Q matrix: 5.98026
New value of Value function: 5.98026
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 601
New value of Q matrix: 5.97782
New value of Value function: 5.97782
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 602
New value of Q matrix: 5.97538
New value of Value function: 5.97538
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 603
New value of Q matrix: 5.97295
New value of Value function: 5.97295
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 5.29349
New value of Value function: 5.97295
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 604
New value of Q matrix: 5.97052
New value of Value function: 5.97052
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 605
New value of Q matrix: 5.96809
New value of Value function: 5.96809
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 606
New value of Q matrix: 6.0486
New value of Value function: 6.0486
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 97
----------
State: 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 98
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 99
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 100
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 101
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 102
----------
State: 1637
	Distance: 2
	Angle: 10
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 103
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 1.97
New value of Value function: 1.97
New value of Policy matrix: 3

=======================================
Simulation: 17
Iteration: 104
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 105
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 106
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 107
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 108
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 109
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 110
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 111
----------
State: 1593
	Distance: 2
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 112
----------
State: 1545
	Distance: 2
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -2.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 113
----------
State: 2121
	Distance: 3
	Angle: 8
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.47918
New value of Value function: 6.47918
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 114
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.9203
New value of Value function: 4.97
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 115
----------
State: 2073
	Distance: 3
	Angle: 7
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.96
New value of Value function: 5.96
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 116
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.09011
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 117
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.82909
New value of Value function: 4.41421
New value of Policy matrix: 2

=======================================
Simulation: 17
Iteration: 118
----------
State: 2025
	Distance: 3
	Angle: 6
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 3.59772
New value of Value function: 3.82909
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 119
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 120
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 121
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 17
Iteration: 122
----------
State: 1493
	Distance: 2
	Angle: 7
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 70.5391
New value of Value function: 70.5391
New value of Policy matrix: 1

=======================================
Simulation: 17
Iteration: 123
----------
State: 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 99.01
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 124
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 99
New value of Policy matrix: 4

=======================================
Simulation: 17
Iteration: 125
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1398
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 101
New value of Visit matrix: 1
New value of Q matrix: 101
New value of Value function: 101
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 607
New value of Q matrix: 6.04615
New value of Value function: 6.04615
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 608
New value of Q matrix: 6.04369
New value of Value function: 6.04369
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 143
New value of Q matrix: 5.2238
New value of Value function: 6.04369
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 144
New value of Q matrix: 5.28709
New value of Value function: 6.04369
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 609
New value of Q matrix: 6.04125
New value of Value function: 6.04125
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 610
New value of Q matrix: 6.0388
New value of Value function: 6.0388
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 611
New value of Q matrix: 6.03636
New value of Value function: 6.03636
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 612
New value of Q matrix: 6.03392
New value of Value function: 6.03392
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 613
New value of Q matrix: 6.03148
New value of Value function: 6.03148
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 614
New value of Q matrix: 6.02905
New value of Value function: 6.02905
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 5.5402
New value of Value function: 6.02905
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 615
New value of Q matrix: 6.02661
New value of Value function: 6.02661
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 616
New value of Q matrix: 6.02419
New value of Value function: 6.02419
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 617
New value of Q matrix: 6.02176
New value of Value function: 6.02176
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 145
New value of Q matrix: 5.3431
New value of Value function: 6.02176
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 618
New value of Q matrix: 6.01934
New value of Value function: 6.01934
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 619
New value of Q matrix: 6.01692
New value of Value function: 6.01692
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 620
New value of Q matrix: 6.0145
New value of Value function: 6.0145
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 5.57009
New value of Value function: 6.0145
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 146
New value of Q matrix: 5.39369
New value of Value function: 6.0145
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 621
New value of Q matrix: 6.01209
New value of Value function: 6.01209
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 622
New value of Q matrix: 6.00968
New value of Value function: 6.00968
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 623
New value of Q matrix: 6.00727
New value of Value function: 6.00727
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 624
New value of Q matrix: 6.00487
New value of Value function: 6.00487
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 5.15429
New value of Value function: 6.00487
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 625
New value of Q matrix: 6.00246
New value of Value function: 6.00246
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 5.59689
New value of Value function: 6.00246
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 147
New value of Q matrix: 5.43895
New value of Value function: 6.00246
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 626
New value of Q matrix: 6.00006
New value of Value function: 6.00006
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 5.20904
New value of Value function: 6.00006
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 627
New value of Q matrix: 5.99767
New value of Value function: 5.99767
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 628
New value of Q matrix: 5.99528
New value of Value function: 5.99528
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 629
New value of Q matrix: 5.99288
New value of Value function: 5.99288
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 630
New value of Q matrix: 5.9905
New value of Value function: 5.9905
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 631
New value of Q matrix: 5.98811
New value of Value function: 5.98811
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 5.62068
New value of Value function: 5.98811
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 632
New value of Q matrix: 5.98573
New value of Value function: 5.98573
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 633
New value of Q matrix: 5.98335
New value of Value function: 5.98335
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 634
New value of Q matrix: 5.98098
New value of Value function: 5.98098
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 635
New value of Q matrix: 5.9786
New value of Value function: 5.9786
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 636
New value of Q matrix: 5.97623
New value of Value function: 5.97623
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 637
New value of Q matrix: 5.97386
New value of Value function: 5.97386
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 638
New value of Q matrix: 5.9715
New value of Value function: 5.9715
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 639
New value of Q matrix: 5.96914
New value of Value function: 5.96914
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 640
New value of Q matrix: 5.96678
New value of Value function: 5.96678
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 641
New value of Q matrix: 5.96442
New value of Value function: 5.96442
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 148
New value of Q matrix: 5.47724
New value of Value function: 5.96442
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 642
New value of Q matrix: 5.96207
New value of Value function: 5.96207
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 643
New value of Q matrix: 5.95971
New value of Value function: 5.95971
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 644
New value of Q matrix: 5.95737
New value of Value function: 5.95737
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 645
New value of Q matrix: 5.95502
New value of Value function: 5.95502
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 5.25675
New value of Value function: 5.95502
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 646
New value of Q matrix: 5.95268
New value of Value function: 5.95268
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 5.64019
New value of Value function: 5.95268
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 647
New value of Q matrix: 5.95034
New value of Value function: 5.95034
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 648
New value of Q matrix: 5.948
New value of Value function: 5.948
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 649
New value of Q matrix: 5.94566
New value of Value function: 5.94566
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 650
New value of Q matrix: 5.94333
New value of Value function: 5.94333
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 651
New value of Q matrix: 5.941
New value of Value function: 5.941
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 652
New value of Q matrix: 5.93868
New value of Value function: 5.93868
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 653
New value of Q matrix: 5.93635
New value of Value function: 5.93635
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 654
New value of Q matrix: 5.93403
New value of Value function: 5.93403
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 159
New value of Q matrix: 5.33959
New value of Value function: 5.93403
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 655
New value of Q matrix: 5.93171
New value of Value function: 5.93171
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 656
New value of Q matrix: 5.9294
New value of Value function: 5.9294
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 657
New value of Q matrix: 5.92708
New value of Value function: 5.92708
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 658
New value of Q matrix: 5.92477
New value of Value function: 5.92477
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 5.38116
New value of Value function: 5.92477
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 659
New value of Q matrix: 5.92246
New value of Value function: 5.92246
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 660
New value of Q matrix: 5.92016
New value of Value function: 5.92016
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 661
New value of Q matrix: 5.91786
New value of Value function: 5.91786
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 5.29849
New value of Value function: 5.91786
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 662
New value of Q matrix: 5.91556
New value of Value function: 5.91556
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 663
New value of Q matrix: 5.91326
New value of Value function: 5.91326
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 5.41844
New value of Value function: 5.91326
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 664
New value of Q matrix: 5.91096
New value of Value function: 5.91096
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 665
New value of Q matrix: 5.90867
New value of Value function: 5.90867
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 5.33661
New value of Value function: 5.90867
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 666
New value of Q matrix: 6.18521
New value of Value function: 6.18521
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 80
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.78606
New value of Value function: 10.1468
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 81
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.18046
New value of Value function: 5.18046
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 667
New value of Q matrix: 6.26046
New value of Value function: 6.26046
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 83
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 7.09121
New value of Value function: 7.09121
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 84
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 3.40149
New value of Value function: 3.40149
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 668
New value of Q matrix: 6.2646
New value of Value function: 6.2646
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 86
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.36748
New value of Value function: 3.40149
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 87
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 3.33095
New value of Value function: 3.36748
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 669
New value of Q matrix: 6.26728
New value of Value function: 6.26728
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 89
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.34367
New value of Value function: 3.34367
New value of Policy matrix: 4

=======================================
Simulation: 18
Iteration: 90
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 3.32436
New value of Value function: 3.33095
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 91
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 5.5373
New value of Value function: 5.5373
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 92
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 4.39078
New value of Value function: 4.39078
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 93
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.00719
New value of Value function: 4.00719
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 94
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 4.23065
New value of Value function: 4.23065
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 95
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.09777
New value of Value function: 4.09777
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 96
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 4.16918
New value of Value function: 4.16918
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 97
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 4.11106
New value of Value function: 4.11106
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 98
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 0.296823
New value of Value function: 4.16918
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 670
New value of Q matrix: 6.30051
New value of Value function: 6.30051
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 100
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.23751
New value of Value function: 4.16918
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 671
New value of Q matrix: 6.33244
New value of Value function: 6.33244
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 102
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 4.44612
New value of Value function: 4.44612
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 103
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 104
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 105
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 2.53553
New value of Value function: 2.53553
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 106
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 107
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 108
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1597
	Distance: 2
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -4
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 18
Iteration: 109
----------
State: 1597
	Distance: 2
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 2

=======================================
Simulation: 18
Iteration: 110
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1597
	Distance: 2
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 111
----------
State: 1597
	Distance: 2
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 4
New value of Value function: 4
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 112
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 113
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 114
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 115
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 116
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 18
Iteration: 117
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1554
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 672
New value of Q matrix: 6.32999
New value of Value function: 6.32999
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 5.40079
New value of Value function: 6.32999
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 673
New value of Q matrix: 6.32755
New value of Value function: 6.32755
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 149
New value of Q matrix: 5.54172
New value of Value function: 6.32755
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 674
New value of Q matrix: 6.32512
New value of Value function: 6.32512
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 675
New value of Q matrix: 6.32268
New value of Value function: 6.32268
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 676
New value of Q matrix: 6.56108
New value of Value function: 6.56108
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 8
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.56922
New value of Value function: 9.57669
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 9
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 9.54268
New value of Value function: 9.56922
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 4.5185
New value of Value function: 4.5185
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 11
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 4.51135
New value of Value function: 4.51135
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 4.50431
New value of Value function: 4.50431
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 13
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 4.49736
New value of Value function: 4.49736
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 14
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 4.4905
New value of Value function: 4.4905
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 15
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 3.1012
New value of Value function: 4.4905
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 16
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 9.25348
New value of Value function: 9.25348
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 17
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 3.98231
New value of Value function: 4.4905
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 18
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 9.52642
New value of Value function: 9.54268
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 19
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 9.51032
New value of Value function: 9.52642
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 20
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 4.48373
New value of Value function: 4.48373
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 21
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 4.61656
New value of Value function: 4.61656
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 22
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 9.18714
New value of Value function: 9.18714
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 23
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 7.90596
New value of Value function: 7.90596
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 24
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 3.58028
New value of Value function: 3.58028
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 25
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 6.52334
New value of Value function: 6.52334
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 26
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 5.41906
New value of Value function: 5.41906
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 27
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2.87868
New value of Value function: 2.87868
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 28
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.40166
New value of Value function: 4.40166
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 29
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.06995
New value of Value function: 4.44612
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 30
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 8.35764
New value of Value function: 8.35764
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 31
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 1.85065
New value of Value function: 4.40166
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 32
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 8.35764
New value of Value function: 8.35764
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 33
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.35764
New value of Value function: 4.40166
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 34
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.40166
New value of Value function: 4.40166
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 35
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 1.89615
New value of Value function: 4.44612
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 677
New value of Q matrix: 6.52069
New value of Value function: 6.52069
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 37
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 3.01018
New value of Value function: 3.01018
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 38
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.40166
New value of Value function: 4.40166
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 39
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.39164
New value of Value function: 4.44612
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 150
New value of Q matrix: 5.78178
New value of Value function: 6.52069
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 41
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.75932
New value of Value function: 6.75932
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 42
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 2.59351
New value of Value function: 4.44612
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 678
New value of Q matrix: 6.70325
New value of Value function: 6.70325
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 44
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 8.35764
New value of Value function: 8.35764
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 45
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 4.19087
New value of Value function: 4.35764
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 46
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -0.32417
New value of Value function: 3.01018
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 47
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.56366
New value of Value function: 5.56366
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 48
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 3.16212
New value of Value function: 3.16212
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 49
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.32683
New value of Value function: 4.32683
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 50
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 5.65854
New value of Value function: 5.65854
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 51
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.48652
New value of Value function: 4.48652
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 52
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 19.6839
New value of Value function: 19.6839
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 53
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 18.487
New value of Value function: 30.5857
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 54
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.70615
New value of Value function: 19.6839
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 55
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 12.9868
New value of Value function: 12.9868
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 56
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 25.4819
New value of Value function: 25.4819
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 57
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 51.8381
New value of Value function: 51.8381
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 58
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 46.1299
New value of Value function: 46.1299
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 59
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 60
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 61
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.63621
New value of Value function: 3.63621
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 679
New value of Q matrix: 6.75109
New value of Value function: 6.75109
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 63
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.54548
New value of Value function: 7.54548
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 64
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -1.91453
New value of Value function: 3.63621
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 65
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 5.56881
New value of Value function: 5.56881
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 66
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 3.66971
New value of Value function: 3.66971
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 680
New value of Q matrix: 6.74656
New value of Value function: 6.74656
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 68
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.67513
New value of Value function: 3.67513
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 681
New value of Q matrix: 6.88925
New value of Value function: 6.88925
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 70
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 8.17646
New value of Value function: 8.17646
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 71
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.723817
New value of Value function: 3.67513
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 72
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.40742
New value of Value function: 8.40742
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 73
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.49924
New value of Value function: 3.49924
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 74
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 8.43283
New value of Value function: 8.43283
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 75
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.301737
New value of Value function: 0.723817
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 76
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5.71658
New value of Value function: 5.71658
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 77
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.686633
New value of Value function: 0.686633
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 78
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5.69055
New value of Value function: 5.69055
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 79
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 0.660138
New value of Value function: 0.660138
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 80
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.66918
New value of Value function: 5.66918
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 81
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 0.638829
New value of Value function: 0.638829
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 82
----------
State: 1645
	Distance: 2
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5.66918
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 83
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 84
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 85
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 86
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.601952
New value of Value function: 0.601952
New value of Policy matrix: 3

=======================================
Simulation: 19
Iteration: 87
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 12.8699
New value of Value function: 12.8699
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 88
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 12.8569
New value of Value function: 12.9868
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 89
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 19.3552
New value of Value function: 19.3552
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 90
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 37.4841
New value of Value function: 37.4841
New value of Policy matrix: 1

=======================================
Simulation: 19
Iteration: 91
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 2.67799
New value of Value function: 51.8381
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 92
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 31.777
New value of Value function: 31.777
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 93
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 51.4246
New value of Value function: 51.4246
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 94
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 39.625
New value of Value function: 39.625
New value of Policy matrix: 2

=======================================
Simulation: 19
Iteration: 95
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 66.8979
New value of Value function: 66.8979
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 96
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 65.2289
New value of Value function: 96.4645
New value of Policy matrix: 4

=======================================
Simulation: 19
Iteration: 97
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 81.6989
New value of Value function: 81.6989
New value of Policy matrix: 0

=======================================
Simulation: 19
Iteration: 98
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 98.5057
New value of Value function: 98.5057
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 682
New value of Q matrix: 6.88661
New value of Value function: 6.88661
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 5.52838
New value of Value function: 6.88661
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 5.49834
New value of Value function: 6.88661
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 683
New value of Q matrix: 6.88397
New value of Value function: 6.88397
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 684
New value of Q matrix: 6.88134
New value of Value function: 6.88134
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 685
New value of Q matrix: 6.87871
New value of Value function: 6.87871
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 686
New value of Q matrix: 6.87609
New value of Value function: 6.87609
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 687
New value of Q matrix: 6.87346
New value of Value function: 6.87346
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 688
New value of Q matrix: 6.87084
New value of Value function: 6.87084
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 5.62815
New value of Value function: 6.87084
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 689
New value of Q matrix: 6.86822
New value of Value function: 6.86822
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 690
New value of Q matrix: 6.86561
New value of Value function: 6.86561
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 691
New value of Q matrix: 6.863
New value of Value function: 6.863
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 5.58735
New value of Value function: 6.863
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 5.71921
New value of Value function: 6.863
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 692
New value of Q matrix: 6.86039
New value of Value function: 6.86039
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 693
New value of Q matrix: 6.85778
New value of Value function: 6.85778
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 694
New value of Q matrix: 6.85518
New value of Value function: 6.85518
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 151
New value of Q matrix: 5.86356
New value of Value function: 6.85518
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 695
New value of Q matrix: 6.85258
New value of Value function: 6.85258
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 696
New value of Q matrix: 6.84998
New value of Value function: 6.84998
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 697
New value of Q matrix: 6.84739
New value of Value function: 6.84739
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 698
New value of Q matrix: 6.8448
New value of Value function: 6.8448
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 699
New value of Q matrix: 6.84221
New value of Value function: 6.84221
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 700
New value of Q matrix: 6.83962
New value of Value function: 6.83962
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 701
New value of Q matrix: 6.83704
New value of Value function: 6.83704
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 702
New value of Q matrix: 6.83446
New value of Value function: 6.83446
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 703
New value of Q matrix: 6.83188
New value of Value function: 6.83188
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 5.72043
New value of Value function: 6.83188
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 704
New value of Q matrix: 6.8293
New value of Value function: 6.8293
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 5.80032
New value of Value function: 6.8293
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 705
New value of Q matrix: 6.82673
New value of Value function: 6.82673
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 706
New value of Q matrix: 6.82416
New value of Value function: 6.82416
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 707
New value of Q matrix: 6.8216
New value of Value function: 6.8216
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 152
New value of Q matrix: 5.93573
New value of Value function: 6.8216
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 708
New value of Q matrix: 6.81903
New value of Value function: 6.81903
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 166
New value of Q matrix: 5.87409
New value of Value function: 6.81903
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 709
New value of Q matrix: 6.81647
New value of Value function: 6.81647
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 710
New value of Q matrix: 6.81391
New value of Value function: 6.81391
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 711
New value of Q matrix: 6.81136
New value of Value function: 6.81136
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 712
New value of Q matrix: 6.80881
New value of Value function: 6.80881
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 713
New value of Q matrix: 6.80626
New value of Value function: 6.80626
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 5.6662
New value of Value function: 6.80626
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 714
New value of Q matrix: 6.80371
New value of Value function: 6.80371
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 715
New value of Q matrix: 6.80116
New value of Value function: 6.80116
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 716
New value of Q matrix: 6.79862
New value of Value function: 6.79862
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 717
New value of Q matrix: 6.79608
New value of Value function: 6.79608
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 5.73879
New value of Value function: 6.79608
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 718
New value of Q matrix: 6.79355
New value of Value function: 6.79355
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 719
New value of Q matrix: 6.79101
New value of Value function: 6.79101
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 720
New value of Q matrix: 6.78848
New value of Value function: 6.78848
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 721
New value of Q matrix: 6.78595
New value of Value function: 6.78595
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 722
New value of Q matrix: 6.78343
New value of Value function: 6.78343
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 723
New value of Q matrix: 6.78091
New value of Value function: 6.78091
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 724
New value of Q matrix: 6.77839
New value of Value function: 6.77839
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 725
New value of Q matrix: 6.77587
New value of Value function: 6.77587
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 153
New value of Q matrix: 5.99817
New value of Value function: 6.77587
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 726
New value of Q matrix: 6.77335
New value of Value function: 6.77335
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 5.79062
New value of Value function: 6.77335
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 727
New value of Q matrix: 6.77084
New value of Value function: 6.77084
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 728
New value of Q matrix: 6.76833
New value of Value function: 6.76833
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 729
New value of Q matrix: 6.76583
New value of Value function: 6.76583
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 730
New value of Q matrix: 6.97551
New value of Value function: 6.97551
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 64
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 9.52931
New value of Value function: 9.52931
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 65
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 7.00136
New value of Value function: 7.00136
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 66
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 7.27514
New value of Value function: 7.27514
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 67
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 4.70013
New value of Value function: 4.70013
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 68
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.64362
New value of Value function: 7.90596
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 69
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 6.51568
New value of Value function: 6.51568
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 70
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.80028
New value of Value function: 3.80028
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 71
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 3.79106
New value of Value function: 3.79106
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 72
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 3.78213
New value of Value function: 3.78213
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 73
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 3.77345
New value of Value function: 3.77345
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 74
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 3.76501
New value of Value function: 3.76501
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 75
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 3.75679
New value of Value function: 3.75679
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 76
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 1.92083
New value of Value function: 3.75679
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 77
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 7.65313
New value of Value function: 7.65313
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 78
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.98428
New value of Value function: 4.70013
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 79
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.30122
New value of Value function: 7.90596
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 80
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.43674
New value of Value function: 9.18714
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 81
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 8.5892
New value of Value function: 8.5892
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 82
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 7.41801
New value of Value function: 7.41801
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 83
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 4.19949
New value of Value function: 4.19949
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 84
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 8.32314
New value of Value function: 8.32314
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 85
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 4.1473
New value of Value function: 4.19949
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 86
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 5
New value of Q matrix: 2.4474
New value of Value function: 3.75679
New value of Policy matrix: 4

=======================================
Simulation: 20
Iteration: 87
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.23991
New value of Value function: 8.32314
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 88
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.58698
New value of Value function: 8.58698
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 89
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 5.14202
New value of Value function: 5.14202
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 90
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.84989
New value of Value function: 2.87868
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 91
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 5.18913
New value of Value function: 5.18913
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 92
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 33.2256
New value of Value function: 33.2256
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 93
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 0.82328
New value of Value function: 37.4841
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 94
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 22.1092
New value of Value function: 22.1092
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 95
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 43.3736
New value of Value function: 43.3736
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 96
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 49.026
New value of Value function: 49.026
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 97
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: -1
New value of Value function: 39.625
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 98
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -0.02
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 99
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 2
New value of Value function: 2
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 100
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 101
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 1.81349
New value of Value function: 1.81349
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 102
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 3.79535
New value of Value function: 3.85201
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 103
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.81349
New value of Value function: 1.81349
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 104
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.81195
New value of Value function: 3.81195
New value of Policy matrix: 2

=======================================
Simulation: 20
Iteration: 105
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 1.79059
New value of Value function: 1.79059
New value of Policy matrix: 0

=======================================
Simulation: 20
Iteration: 106
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 3.78928
New value of Value function: 3.79535
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 107
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.90575
New value of Value function: 3.90575
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 731
New value of Q matrix: 6.97293
New value of Value function: 6.97293
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 5.86969
New value of Value function: 6.97293
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 732
New value of Q matrix: 6.97035
New value of Value function: 6.97035
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 733
New value of Q matrix: 6.96778
New value of Value function: 6.96778
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 734
New value of Q matrix: 6.96521
New value of Value function: 6.96521
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 735
New value of Q matrix: 6.96264
New value of Value function: 6.96264
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 736
New value of Q matrix: 6.96007
New value of Value function: 6.96007
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 737
New value of Q matrix: 6.95751
New value of Value function: 6.95751
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 738
New value of Q matrix: 6.95494
New value of Value function: 6.95494
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 739
New value of Q matrix: 6.95239
New value of Value function: 6.95239
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 5.81682
New value of Value function: 6.95239
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 740
New value of Q matrix: 6.94983
New value of Value function: 6.94983
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 741
New value of Q matrix: 6.94728
New value of Value function: 6.94728
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 742
New value of Q matrix: 6.94473
New value of Value function: 6.94473
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 743
New value of Q matrix: 6.94218
New value of Value function: 6.94218
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 744
New value of Q matrix: 6.93963
New value of Value function: 6.93963
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 745
New value of Q matrix: 6.93709
New value of Value function: 6.93709
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 746
New value of Q matrix: 6.93455
New value of Value function: 6.93455
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 747
New value of Q matrix: 6.93201
New value of Value function: 6.93201
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 748
New value of Q matrix: 6.92948
New value of Value function: 6.92948
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 154
New value of Q matrix: 6.06764
New value of Value function: 6.92948
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 749
New value of Q matrix: 6.92695
New value of Value function: 6.92695
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 155
New value of Q matrix: 6.13109
New value of Value function: 6.92695
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 5.88764
New value of Value function: 6.92695
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 750
New value of Q matrix: 6.92442
New value of Value function: 6.92442
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 751
New value of Q matrix: 6.92189
New value of Value function: 6.92189
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 752
New value of Q matrix: 6.91937
New value of Value function: 6.91937
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 753
New value of Q matrix: 6.91685
New value of Value function: 6.91685
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 5.93902
New value of Value function: 6.91685
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 156
New value of Q matrix: 6.18847
New value of Value function: 6.91685
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 157
New value of Q matrix: 6.24108
New value of Value function: 6.91685
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 754
New value of Q matrix: 6.91433
New value of Value function: 6.91433
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 755
New value of Q matrix: 6.91181
New value of Value function: 6.91181
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 5.94905
New value of Value function: 6.91181
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 6.00292
New value of Value function: 6.91181
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 6.01799
New value of Value function: 6.91181
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 756
New value of Q matrix: 6.9093
New value of Value function: 6.9093
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 757
New value of Q matrix: 6.90679
New value of Value function: 6.90679
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 758
New value of Q matrix: 6.90428
New value of Value function: 6.90428
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 5.95197
New value of Value function: 6.90428
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 759
New value of Q matrix: 6.90177
New value of Value function: 6.90177
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 760
New value of Q matrix: 6.89927
New value of Value function: 6.89927
New value of Policy matrix: 1

=======================================
Simulation: 20
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 761
New value of Q matrix: 6.89677
New value of Value function: 6.89677
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 1
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 5.70082
New value of Value function: 5.70082
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 2
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 6.22206
New value of Value function: 6.22206
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 3
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.08379
New value of Value function: 8.08379
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 4
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 3.49737
New value of Value function: 6.22206
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 5
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0698
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 6
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 7.97
New value of Value function: 7.97
New value of Policy matrix: 3

=======================================
Simulation: 21
Iteration: 7
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 26.2591
New value of Value function: 26.2591
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 8
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.29339
New value of Value function: 33.2256
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 9
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 7.3989
New value of Value function: 7.3989
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 10
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 4.75371
New value of Value function: 4.75371
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 11
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 6.56128
New value of Value function: 6.56128
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 12
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 0.412814
New value of Value function: 11.4954
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 13
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 6.83333
New value of Value function: 6.83333
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 14
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 3.91314
New value of Value function: 8.1066
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 15
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: -1.39121
New value of Value function: 8.1066
New value of Policy matrix: 0

=======================================
Simulation: 21
Iteration: 16
----------
State: 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.64824
New value of Value function: 8.64824
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 17
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.8278
New value of Value function: 11.4166
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 762
New value of Q matrix: 6.89427
New value of Value function: 6.89427
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 763
New value of Q matrix: 6.89177
New value of Value function: 6.89177
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 6.06075
New value of Value function: 6.89177
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 764
New value of Q matrix: 6.88928
New value of Value function: 6.88928
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 765
New value of Q matrix: 6.88679
New value of Value function: 6.88679
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 766
New value of Q matrix: 6.8843
New value of Value function: 6.8843
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 767
New value of Q matrix: 6.88181
New value of Value function: 6.88181
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 768
New value of Q matrix: 6.87933
New value of Value function: 6.87933
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 6.11351
New value of Value function: 6.87933
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 769
New value of Q matrix: 6.87685
New value of Value function: 6.87685
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 6.16226
New value of Value function: 6.87685
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 770
New value of Q matrix: 6.87437
New value of Value function: 6.87437
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 771
New value of Q matrix: 6.8719
New value of Value function: 6.8719
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 6.07839
New value of Value function: 6.8719
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 772
New value of Q matrix: 6.86942
New value of Value function: 6.86942
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 773
New value of Q matrix: 6.86695
New value of Value function: 6.86695
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 6.1336
New value of Value function: 6.86695
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 774
New value of Q matrix: 6.86448
New value of Value function: 6.86448
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 775
New value of Q matrix: 6.86202
New value of Value function: 6.86202
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 776
New value of Q matrix: 6.85955
New value of Value function: 6.85955
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 6.18387
New value of Value function: 6.85955
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 777
New value of Q matrix: 6.85709
New value of Value function: 6.85709
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 778
New value of Q matrix: 6.85464
New value of Value function: 6.85464
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 779
New value of Q matrix: 6.85218
New value of Value function: 6.85218
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 780
New value of Q matrix: 6.84973
New value of Value function: 6.84973
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 781
New value of Q matrix: 6.84728
New value of Value function: 6.84728
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 782
New value of Q matrix: 6.84483
New value of Value function: 6.84483
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 6.22905
New value of Value function: 6.84483
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 783
New value of Q matrix: 6.84238
New value of Value function: 6.84238
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 784
New value of Q matrix: 6.83994
New value of Value function: 6.83994
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 785
New value of Q matrix: 6.8375
New value of Value function: 6.8375
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 786
New value of Q matrix: 6.83506
New value of Value function: 6.83506
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 787
New value of Q matrix: 6.83262
New value of Value function: 6.83262
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 788
New value of Q matrix: 6.83019
New value of Value function: 6.83019
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 789
New value of Q matrix: 6.82775
New value of Value function: 6.82775
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 790
New value of Q matrix: 6.82533
New value of Value function: 6.82533
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 791
New value of Q matrix: 6.8229
New value of Value function: 6.8229
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 792
New value of Q matrix: 6.82047
New value of Value function: 6.82047
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 793
New value of Q matrix: 6.81805
New value of Value function: 6.81805
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 794
New value of Q matrix: 6.81563
New value of Value function: 6.81563
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 795
New value of Q matrix: 6.81322
New value of Value function: 6.81322
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 796
New value of Q matrix: 6.8108
New value of Value function: 6.8108
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 797
New value of Q matrix: 6.80839
New value of Value function: 6.80839
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 798
New value of Q matrix: 6.80598
New value of Value function: 6.80598
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 158
New value of Q matrix: 6.2806
New value of Value function: 6.80598
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 6.0052
New value of Value function: 6.80598
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 799
New value of Q matrix: 6.80357
New value of Value function: 6.80357
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 800
New value of Q matrix: 6.80116
New value of Value function: 6.80116
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 801
New value of Q matrix: 6.79876
New value of Value function: 6.79876
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 802
New value of Q matrix: 6.79636
New value of Value function: 6.79636
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 803
New value of Q matrix: 6.79396
New value of Value function: 6.79396
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 6.05391
New value of Value function: 6.79396
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 804
New value of Q matrix: 6.79157
New value of Value function: 6.79157
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 805
New value of Q matrix: 6.78917
New value of Value function: 6.78917
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 806
New value of Q matrix: 6.78678
New value of Value function: 6.78678
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 807
New value of Q matrix: 6.78439
New value of Value function: 6.78439
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 808
New value of Q matrix: 6.78201
New value of Value function: 6.78201
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 809
New value of Q matrix: 6.77962
New value of Value function: 6.77962
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 810
New value of Q matrix: 6.77724
New value of Value function: 6.77724
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 811
New value of Q matrix: 6.77486
New value of Value function: 6.77486
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 812
New value of Q matrix: 6.77248
New value of Value function: 6.77248
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 813
New value of Q matrix: 6.77011
New value of Value function: 6.77011
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 6.20007
New value of Value function: 6.77011
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 814
New value of Q matrix: 6.76773
New value of Value function: 6.76773
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 815
New value of Q matrix: 6.76536
New value of Value function: 6.76536
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3425
	Distance: 5
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 159
New value of Q matrix: 6.02043
New value of Value function: 6.76536
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 84
----------
State: 3425
	Distance: 5
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 11
New value of Visit matrix: 1
New value of Q matrix: 17.6917
New value of Value function: 17.6917
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 85
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3425
	Distance: 5
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -11
New value of Visit matrix: 3
New value of Q matrix: 4.58201
New value of Value function: 6.75932
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 86
----------
State: 3425
	Distance: 5
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 11
New value of Visit matrix: 2
New value of Q matrix: 17.6917
New value of Value function: 17.6917
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 87
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 5.83621
New value of Value function: 5.83621
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 816
New value of Q matrix: 6.91371
New value of Value function: 6.91371
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 89
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 3.84457
New value of Value function: 8.08379
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 817
New value of Q matrix: 7.05677
New value of Value function: 7.05677
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 91
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 9.03116
New value of Value function: 9.03116
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 92
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 3.67623
New value of Value function: 6.14104
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 93
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 9.64879
New value of Value function: 9.64879
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 94
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 6.13094
New value of Value function: 6.13094
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 95
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 6.121
New value of Value function: 6.121
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 96
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 4.94849
New value of Value function: 6.121
New value of Policy matrix: 4

=======================================
Simulation: 21
Iteration: 97
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 24.3291
New value of Value function: 24.3291
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 98
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 31.8214
New value of Value function: 31.8214
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 99
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 27.8346
New value of Value function: 27.8346
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 100
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 17.13
New value of Value function: 22.1092
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 101
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 17.8066
New value of Value function: 17.8066
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 102
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 7.20119
New value of Value function: 7.20119
New value of Policy matrix: 1

=======================================
Simulation: 21
Iteration: 103
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 12.3373
New value of Value function: 12.3373
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 104
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 8.32754
New value of Value function: 8.32754
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 105
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 4.70581
New value of Value function: 4.70581
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 106
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.04
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 107
----------
State: 1977
	Distance: 3
	Angle: 5
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 74.0106
New value of Value function: 74.0106
New value of Policy matrix: 2

=======================================
Simulation: 21
Iteration: 108
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1402
	Distance: 2
	Angle: 5
	Height: 2
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 99.7071
New value of Value function: 99.7071
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 818
New value of Q matrix: 7.05431
New value of Value function: 7.05431
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 819
New value of Q matrix: 7.05184
New value of Value function: 7.05184
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 820
New value of Q matrix: 7.04938
New value of Value function: 7.04938
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 6.11627
New value of Value function: 7.04938
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 6.28606
New value of Value function: 7.04938
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 821
New value of Q matrix: 7.04692
New value of Value function: 7.04692
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 822
New value of Q matrix: 7.04446
New value of Value function: 7.04446
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 823
New value of Q matrix: 7.042
New value of Value function: 7.042
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 824
New value of Q matrix: 7.03955
New value of Value function: 7.03955
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 825
New value of Q matrix: 7.0371
New value of Value function: 7.0371
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 826
New value of Q matrix: 7.03465
New value of Value function: 7.03465
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 827
New value of Q matrix: 7.03221
New value of Value function: 7.03221
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 6.25328
New value of Value function: 7.03221
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 6.33729
New value of Value function: 7.03221
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 828
New value of Q matrix: 7.02976
New value of Value function: 7.02976
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 829
New value of Q matrix: 7.02732
New value of Value function: 7.02732
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 830
New value of Q matrix: 7.02488
New value of Value function: 7.02488
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 831
New value of Q matrix: 7.02244
New value of Value function: 7.02244
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 6.30198
New value of Value function: 7.02244
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 832
New value of Q matrix: 7.02001
New value of Value function: 7.02001
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 833
New value of Q matrix: 7.01758
New value of Value function: 7.01758
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 6.34684
New value of Value function: 7.01758
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 834
New value of Q matrix: 7.01515
New value of Value function: 7.01515
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 835
New value of Q matrix: 7.01272
New value of Value function: 7.01272
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 836
New value of Q matrix: 7.01029
New value of Value function: 7.01029
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 837
New value of Q matrix: 7.00787
New value of Value function: 7.00787
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 838
New value of Q matrix: 7.00545
New value of Value function: 7.00545
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 839
New value of Q matrix: 7.00303
New value of Value function: 7.00303
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 840
New value of Q matrix: 7.00061
New value of Value function: 7.00061
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 841
New value of Q matrix: 6.9982
New value of Value function: 6.9982
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 842
New value of Q matrix: 6.99579
New value of Value function: 6.99579
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 6.38178
New value of Value function: 6.99579
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 6.38698
New value of Value function: 6.99579
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 843
New value of Q matrix: 6.99338
New value of Value function: 6.99338
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 844
New value of Q matrix: 6.99097
New value of Value function: 6.99097
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 845
New value of Q matrix: 6.98857
New value of Value function: 6.98857
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 6.42376
New value of Value function: 6.98857
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 846
New value of Q matrix: 6.98616
New value of Value function: 6.98616
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 847
New value of Q matrix: 6.98376
New value of Value function: 6.98376
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 848
New value of Q matrix: 6.98137
New value of Value function: 6.98137
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 849
New value of Q matrix: 6.97897
New value of Value function: 6.97897
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 850
New value of Q matrix: 6.97658
New value of Value function: 6.97658
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 851
New value of Q matrix: 6.97418
New value of Value function: 6.97418
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 852
New value of Q matrix: 6.9718
New value of Value function: 6.9718
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 853
New value of Q matrix: 6.96941
New value of Value function: 6.96941
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 854
New value of Q matrix: 6.96702
New value of Value function: 6.96702
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 855
New value of Q matrix: 6.96464
New value of Value function: 6.96464
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 856
New value of Q matrix: 6.96226
New value of Value function: 6.96226
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 857
New value of Q matrix: 6.95988
New value of Value function: 6.95988
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 858
New value of Q matrix: 6.95751
New value of Value function: 6.95751
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 859
New value of Q matrix: 6.95513
New value of Value function: 6.95513
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 860
New value of Q matrix: 6.95276
New value of Value function: 6.95276
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 861
New value of Q matrix: 6.95039
New value of Value function: 6.95039
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 862
New value of Q matrix: 6.94802
New value of Value function: 6.94802
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 863
New value of Q matrix: 6.94566
New value of Value function: 6.94566
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 864
New value of Q matrix: 6.9433
New value of Value function: 6.9433
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 6.41887
New value of Value function: 6.9433
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 865
New value of Q matrix: 6.94093
New value of Value function: 6.94093
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 866
New value of Q matrix: 6.93858
New value of Value function: 6.93858
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 867
New value of Q matrix: 6.93622
New value of Value function: 6.93622
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 6.45434
New value of Value function: 6.93622
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 868
New value of Q matrix: 6.80262
New value of Value function: 6.80262
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 63
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 64
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 65
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 22
Iteration: 66
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 10.8714
New value of Value function: 10.8714
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 67
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 4
New value of Q matrix: 14.2372
New value of Value function: 14.2372
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 68
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -10
New value of Visit matrix: 7
New value of Q matrix: 4.02484
New value of Value function: 8.5892
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 69
----------
State: 4537
	Distance: 7
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 14.1609
New value of Value function: 14.2372
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 70
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 10.8598
New value of Value function: 10.8598
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 71
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 8.41457
New value of Value function: 8.41457
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 72
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 10.3441
New value of Value function: 10.3441
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 73
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 8.56109
New value of Value function: 8.56109
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 74
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 9.00262
New value of Value function: 9.00262
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 75
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 6.39082
New value of Value function: 6.39082
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 76
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 9.96515
New value of Value function: 9.96515
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 77
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 25.5562
New value of Value function: 25.5562
New value of Policy matrix: 3

=======================================
Simulation: 22
Iteration: 78
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 23.7316
New value of Value function: 23.7316
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 79
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 29.1959
New value of Value function: 29.1959
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 80
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 45.7027
New value of Value function: 45.7027
New value of Policy matrix: 1

=======================================
Simulation: 22
Iteration: 81
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 48.5358
New value of Value function: 49.026
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 82
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 47.509
New value of Value function: 48.5358
New value of Policy matrix: 4

=======================================
Simulation: 22
Iteration: 83
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 63.3973
New value of Value function: 63.3973
New value of Policy matrix: 2

=======================================
Simulation: 22
Iteration: 84
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1990
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 4
New value of Q matrix: 96.7529
New value of Value function: 96.7529
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 1
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 26.2258
New value of Value function: 26.2258
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 2
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 29.1578
New value of Value function: 29.1578
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 3
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 16.6129
New value of Value function: 23.7316
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 4
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 26.9392
New value of Value function: 26.9392
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 5
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 36.6381
New value of Value function: 36.6381
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 6
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 46.8863
New value of Value function: 46.8863
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 7
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 22.3223
New value of Value function: 48.5358
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 8
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 40.4137
New value of Value function: 40.4137
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 9
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.04425
New value of Value function: 48.5358
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 10
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 30.8423
New value of Value function: 30.8423
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 11
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 48.1926
New value of Value function: 48.1926
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 12
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 47.9143
New value of Value function: 47.9143
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 13
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 47.6747
New value of Value function: 47.6747
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 14
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 47.4615
New value of Value function: 47.509
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 15
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 36.1666
New value of Value function: 47.4615
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 16
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 24.3683
New value of Value function: 24.3683
New value of Policy matrix: 3

=======================================
Simulation: 23
Iteration: 17
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 43.8006
New value of Value function: 43.8006
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 18
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 47.2678
New value of Value function: 47.2678
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 19
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 47.0891
New value of Value function: 47.0891
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 20
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 33.8925
New value of Value function: 47.0891
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 21
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 45.3591
New value of Value function: 45.3591
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 22
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 46.9226
New value of Value function: 46.9226
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 23
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 46.7662
New value of Value function: 46.7662
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 24
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 46.6183
New value of Value function: 46.6183
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 25
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 46.4778
New value of Value function: 46.4778
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 26
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 38.899
New value of Value function: 46.4778
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 27
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 44.9055
New value of Value function: 45.3591
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 28
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 45.9842
New value of Value function: 45.9842
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 29
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 46.3436
New value of Value function: 46.3436
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 30
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 46.2151
New value of Value function: 46.2151
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 31
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 46.0916
New value of Value function: 46.0916
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 32
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 45.9726
New value of Value function: 45.9726
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 33
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 37.5297
New value of Value function: 45.9726
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 34
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 46.7618
New value of Value function: 46.7618
New value of Policy matrix: 1

=======================================
Simulation: 23
Iteration: 35
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 45.8576
New value of Value function: 45.8576
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 36
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 15.1833
New value of Value function: 45.8576
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 37
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 39.5883
New value of Value function: 39.5883
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 38
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 45.7464
New value of Value function: 45.7464
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 39
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 45.2878
New value of Value function: 45.7464
New value of Policy matrix: 4

=======================================
Simulation: 23
Iteration: 40
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 62.7634
New value of Value function: 63.3973
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 41
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 70.9933
New value of Value function: 70.9933
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 42
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 16.2643
New value of Value function: 81.6989
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 43
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 60.2483
New value of Value function: 60.2483
New value of Policy matrix: 2

=======================================
Simulation: 23
Iteration: 44
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 88.4457
New value of Value function: 88.4457
New value of Policy matrix: 0

=======================================
Simulation: 23
Iteration: 45
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1990
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 95
New value of Visit matrix: 5
New value of Q matrix: 95.969
New value of Value function: 95.969
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 1
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 8.49056
New value of Value function: 8.49056
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 2
----------
State: 5017
	Distance: 8
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 4
New value of Q matrix: 13.3263
New value of Value function: 13.3263
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 3
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 3.51373
New value of Value function: 9.00262
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 4
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 12.3565
New value of Value function: 12.3565
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 5
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 9.64727
New value of Value function: 9.64727
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 6
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 5.94455
New value of Value function: 5.94455
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 7
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 9.97809
New value of Value function: 9.97809
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 8
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 3.39375
New value of Value function: 5.94455
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 9
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 7.9367
New value of Value function: 7.9367
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 10
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 5.69324
New value of Value function: 5.69324
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 11
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 10.148
New value of Value function: 10.148
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 12
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.36195
New value of Value function: 5.69324
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 13
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 8.34834
New value of Value function: 8.34834
New value of Policy matrix: 0

=======================================
Simulation: 24
Iteration: 14
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 7.7975
New value of Value function: 7.7975
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 15
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 16.314
New value of Value function: 16.314
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 16
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 25.0366
New value of Value function: 25.0366
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 17
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 41.5235
New value of Value function: 41.5235
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 18
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 18.4658
New value of Value function: 46.7618
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 19
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 44.6133
New value of Value function: 44.6133
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 20
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 46.6123
New value of Value function: 46.6123
New value of Policy matrix: 1

=======================================
Simulation: 24
Iteration: 21
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 45.6386
New value of Value function: 45.6386
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 22
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 45.5339
New value of Value function: 45.5339
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 23
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 45.4321
New value of Value function: 45.4321
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 24
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 24.6879
New value of Value function: 45.4321
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 25
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 43.8298
New value of Value function: 43.8298
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 26
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 45.3329
New value of Value function: 45.3329
New value of Policy matrix: 4

=======================================
Simulation: 24
Iteration: 27
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 45.2363
New value of Value function: 45.2878
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 28
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 53.6071
New value of Value function: 53.6071
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 29
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 77.8493
New value of Value function: 77.8493
New value of Policy matrix: 2

=======================================
Simulation: 24
Iteration: 30
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 869
New value of Q matrix: 6.80031
New value of Value function: 6.80031
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 870
New value of Q matrix: 6.798
New value of Value function: 6.798
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 871
New value of Q matrix: 6.7957
New value of Value function: 6.7957
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 872
New value of Q matrix: 6.7934
New value of Value function: 6.7934
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 873
New value of Q matrix: 6.9843
New value of Value function: 6.9843
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 6
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 10.6981
New value of Value function: 10.6981
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 7
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 4.45448
New value of Value function: 8.49056
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 8
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 9
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 1.8824
New value of Value function: 1.8824
New value of Policy matrix: 3

=======================================
Simulation: 25
Iteration: 10
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 4.42618
New value of Value function: 8.49056
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 11
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.7599
New value of Value function: 11.7599
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 8.72777
New value of Value function: 8.72777
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 13
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 11.5527
New value of Value function: 11.5527
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 10.7909
New value of Value function: 10.7909
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 15
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 7.32468
New value of Value function: 7.32468
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 16
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 11.1451
New value of Value function: 11.1451
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 6.16274
New value of Value function: 6.16274
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 18
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 28.8663
New value of Value function: 28.8663
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 19
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 29.3868
New value of Value function: 29.3868
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 20
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 34.7889
New value of Value function: 34.7889
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 21
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 39.5397
New value of Value function: 39.5397
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 22
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 29.2349
New value of Value function: 29.2349
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 23
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 42.8902
New value of Value function: 42.8902
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 24
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 48.8612
New value of Value function: 48.8612
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 25
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 61.2143
New value of Value function: 61.2143
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 26
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 54.4961
New value of Value function: 62.7634
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 27
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 96.0093
New value of Value function: 96.0093
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 28
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -2.12132
New value of Value function: 95.969
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 29
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 30
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.03
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 31
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 25
Iteration: 32
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 96
New value of Value function: 96
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 33
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1597
	Distance: 2
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: -0.04
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 34
----------
State: 1597
	Distance: 2
	Angle: 9
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 74.0036
New value of Value function: 74.0036
New value of Policy matrix: 2

=======================================
Simulation: 25
Iteration: 35
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 40.4166
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 25
Iteration: 36
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1554
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 874
New value of Q matrix: 6.98194
New value of Value function: 6.98194
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 875
New value of Q matrix: 6.97958
New value of Value function: 6.97958
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 876
New value of Q matrix: 6.97722
New value of Value function: 6.97722
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 877
New value of Q matrix: 7.03803
New value of Value function: 7.03803
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 5
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 1.86357
New value of Value function: 5.83621
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 6
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 2.76145
New value of Value function: 2.76145
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 7
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 9.67137
New value of Value function: 9.67137
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 8
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 8.32484
New value of Value function: 8.32484
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 9
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 9.35823
New value of Value function: 9.35823
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 10
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 21.0699
New value of Value function: 21.0699
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 11
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 24.9944
New value of Value function: 24.9944
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 12
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 6
New value of Q matrix: 32.4714
New value of Value function: 32.4714
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 13
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 29.4411
New value of Value function: 29.4411
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 14
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 29.1467
New value of Value function: 34.7889
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 15
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 34.3498
New value of Value function: 34.3498
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 16
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 38.4448
New value of Value function: 38.4448
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 17
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.25957
New value of Value function: 42.8902
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 18
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 2.5219
New value of Value function: 3.75679
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 19
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 10.6094
New value of Value function: 10.6094
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 20
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 12.7989
New value of Value function: 12.7989
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 21
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 27.4917
New value of Value function: 27.4917
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 22
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 40.5719
New value of Value function: 40.5719
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 23
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -1.27181
New value of Value function: 42.8902
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 24
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 3.74879
New value of Value function: 3.74879
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 25
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 13.7842
New value of Value function: 13.7842
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 26
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 20.484
New value of Value function: 20.484
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 27
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 15.3464
New value of Value function: 15.3464
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 28
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 25.0382
New value of Value function: 25.0382
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 29
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 33.4894
New value of Value function: 33.4894
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 30
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 6.9518
New value of Value function: 40.5719
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 31
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 18.2347
New value of Value function: 18.2347
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 32
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 5.37511
New value of Value function: 25.0382
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 33
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 8.74288
New value of Value function: 13.7842
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 34
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: -0.132553
New value of Value function: 8.10217
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 35
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 5.01058
New value of Value function: 5.01058
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 36
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 1.91396
New value of Value function: 8.10217
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 37
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 6.80416
New value of Value function: 6.80416
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 38
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 3.62328
New value of Value function: 8.10217
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 39
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 7.70924
New value of Value function: 7.70924
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 40
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.82369
New value of Value function: 8.10217
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 41
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 25.0127
New value of Value function: 25.0127
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 42
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 43.6533
New value of Value function: 44.9055
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 43
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 52.059
New value of Value function: 52.059
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 44
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 52.6706
New value of Value function: 52.6706
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 45
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 38.0951
New value of Value function: 38.0951
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 46
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 49.9315
New value of Value function: 49.9315
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 47
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 14.2546
New value of Value function: 38.0951
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 48
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 41.7637
New value of Value function: 41.7637
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 49
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 46.1112
New value of Value function: 49.9315
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 50
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 48.8193
New value of Value function: 48.8193
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 51
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 42.9119
New value of Value function: 42.9119
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 52
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 48.2686
New value of Value function: 48.2686
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 53
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -2
New value of Value function: 42.9119
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 54
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 55
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 56
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 57
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 58
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 59
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 60
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 61
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 62
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 63
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 64
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 65
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 66
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 67
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 68
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 69
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 70
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 71
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 72
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 73
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 74
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 75
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 76
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 77
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 44.4828
New value of Value function: 44.4828
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 78
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 24.2348
New value of Value function: 42.9119
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 79
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 41.5012
New value of Value function: 41.5012
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 80
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 44.588
New value of Value function: 44.588
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 81
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 44.3306
New value of Value function: 44.3306
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 82
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 44.1089
New value of Value function: 44.1089
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 83
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 47.0379
New value of Value function: 47.0379
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 84
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 43.4952
New value of Value function: 43.4952
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 85
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 41.5263
New value of Value function: 41.5263
New value of Policy matrix: 3

=======================================
Simulation: 26
Iteration: 86
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 46.3466
New value of Value function: 46.3466
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 87
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 43.1419
New value of Value function: 43.1419
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 88
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 45.9793
New value of Value function: 45.9793
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 89
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 42.8307
New value of Value function: 42.8307
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 90
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 45.6909
New value of Value function: 45.6909
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 91
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 42.5638
New value of Value function: 42.5638
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 92
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 45.4437
New value of Value function: 45.4437
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 93
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 42.3293
New value of Value function: 42.3293
New value of Policy matrix: 0

=======================================
Simulation: 26
Iteration: 94
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 45.3642
New value of Value function: 45.4437
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 95
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 52.597
New value of Value function: 52.597
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 96
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 62.7634
New value of Policy matrix: 4

=======================================
Simulation: 26
Iteration: 97
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 63.1357
New value of Value function: 63.1357
New value of Policy matrix: 1

=======================================
Simulation: 26
Iteration: 98
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 68.2188
New value of Value function: 68.2188
New value of Policy matrix: 2

=======================================
Simulation: 26
Iteration: 99
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 97.6146
New value of Value function: 97.6146
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 1
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 2.965
New value of Value function: 2.965
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 2
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0723965
New value of Value function: -0.0612879
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 3
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 6.35557
New value of Value function: 6.35557
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 4
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.56533
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 5
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.10011
New value of Value function: 7.10011
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 6
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.578438
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 7
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0610836
New value of Value function: -0.0610836
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 8
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0608904
New value of Value function: -0.0608904
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 9
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0607068
New value of Value function: -0.0607068
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 10
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0605316
New value of Value function: -0.0605316
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 11
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0603637
New value of Value function: -0.0603637
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 12
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.0602024
New value of Value function: -0.0602024
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 13
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: -0.113249
New value of Value function: -0.0602024
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 14
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 10.1512
New value of Value function: 10.1512
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 15
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 18.42
New value of Value function: 18.42
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 16
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 4.85165
New value of Value function: 25.0127
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 17
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 14.5328
New value of Value function: 14.5328
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 18
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 34.075
New value of Value function: 34.075
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 19
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -7
New value of Visit matrix: 6
New value of Q matrix: 26.7954
New value of Value function: 45.3642
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 20
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 6.83333
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 21
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 1.765
New value of Value function: 1.765
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 22
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.80467
New value of Value function: 6.80467
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 23
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.75251
New value of Value function: 1.75251
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 24
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.7424
New value of Value function: 1.7424
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 25
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.73368
New value of Value function: 1.73368
New value of Policy matrix: 4

=======================================
Simulation: 27
Iteration: 26
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.38047
New value of Value function: 8.38047
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 27
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 33.6744
New value of Value function: 33.6744
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 28
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 46.0517
New value of Value function: 46.0517
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 29
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 53.831
New value of Value function: 53.831
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 30
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 50.9231
New value of Value function: 50.9231
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 31
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 41.1957
New value of Value function: 41.1957
New value of Policy matrix: 3

=======================================
Simulation: 27
Iteration: 32
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 47.6685
New value of Value function: 47.6685
New value of Policy matrix: 0

=======================================
Simulation: 27
Iteration: 33
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 55.6396
New value of Value function: 55.6396
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 34
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 78.2593
New value of Value function: 78.2593
New value of Policy matrix: 2

=======================================
Simulation: 27
Iteration: 35
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 28
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 878
New value of Q matrix: 7.03565
New value of Value function: 7.03565
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 879
New value of Q matrix: 7.03328
New value of Value function: 7.03328
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 160
New value of Q matrix: 6.09495
New value of Value function: 7.03328
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 177
New value of Q matrix: 6.45977
New value of Value function: 7.03328
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 880
New value of Q matrix: 7.03091
New value of Value function: 7.03091
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 6.48919
New value of Value function: 7.03091
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 881
New value of Q matrix: 7.0871
New value of Value function: 7.0871
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 8
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 8.97613
New value of Value function: 8.97613
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 9
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 5.15374
New value of Value function: 5.15374
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 10
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.62627
New value of Value function: 9.62627
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 11
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: -1
New value of Value function: 5.15374
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 12
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 13
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 14
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 1
New value of Q matrix: 15.3249
New value of Value function: 15.3249
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 15
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.41922
New value of Value function: 7.41922
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 16
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 8.91928
New value of Value function: 8.91928
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 17
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 7.83009
New value of Value function: 7.83009
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 18
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 8.83553
New value of Value function: 8.83553
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 19
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -1.24215
New value of Value function: 6.79715
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 20
----------
State: 4869
	Distance: 8
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 11.7292
New value of Value function: 11.7292
New value of Policy matrix: 3

=======================================
Simulation: 28
Iteration: 21
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 6.7579
New value of Value function: 6.7579
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 22
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.12678
New value of Value function: 9.12678
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 23
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.03552
New value of Value function: 6.56128
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 24
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 5.18519
New value of Value function: 9.12678
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 25
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 5
New value of Q matrix: 10.4724
New value of Value function: 10.4724
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 26
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 14
New value of Q matrix: 6.06843
New value of Value function: 6.06843
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 27
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 13.772
New value of Value function: 13.772
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 28
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 11.0004
New value of Value function: 11.0004
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 29
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 9.73662
New value of Value function: 11.0004
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 30
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 8.77188
New value of Value function: 8.77188
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 31
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 16.5092
New value of Value function: 16.5092
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 32
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 26.5092
New value of Value function: 26.5092
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 33
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 13.3923
New value of Value function: 13.3923
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 34
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 16.2584
New value of Value function: 16.2584
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 35
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 11.5999
New value of Value function: 11.5999
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 36
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 6.02829
New value of Value function: 6.07581
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 37
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 8.04347
New value of Value function: 8.04347
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 38
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 11.0823
New value of Value function: 11.0823
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 39
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 8.50747
New value of Value function: 8.50747
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 40
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 10.8833
New value of Value function: 10.8833
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 41
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 8.62688
New value of Value function: 8.62688
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 42
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 10.7844
New value of Value function: 10.7844
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 43
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 8.64716
New value of Value function: 8.64716
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 44
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 10.7223
New value of Value function: 10.7223
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 45
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 8.63505
New value of Value function: 8.63505
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 46
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 10.6759
New value of Value function: 10.6759
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 47
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 8.61176
New value of Value function: 8.61176
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 48
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 2
New value of Value function: 10.6759
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 49
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 8.56918
New value of Value function: 8.56918
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 50
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 10.6371
New value of Value function: 10.6371
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 51
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 8.58476
New value of Value function: 8.58476
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 52
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 10.6026
New value of Value function: 10.6026
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 53
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 8.55686
New value of Value function: 8.55686
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 54
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 10.5707
New value of Value function: 10.5707
New value of Policy matrix: 0

=======================================
Simulation: 28
Iteration: 55
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 7.00344
New value of Value function: 8.55686
New value of Policy matrix: 1

=======================================
Simulation: 28
Iteration: 56
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.74599
New value of Value function: 8.74599
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 57
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 4.19825
New value of Value function: 4.19825
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 58
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 99.99
New value of Value function: 99.99
New value of Policy matrix: 2

=======================================
Simulation: 28
Iteration: 59
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1542
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 97
New value of Visit matrix: 2
New value of Q matrix: 98.1716
New value of Value function: 98.1716
New value of Policy matrix: 4

=======================================
Simulation: 29
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 161
New value of Q matrix: 6.16755
New value of Value function: 7.0871
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 6.17681
New value of Value function: 7.0871
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 882
New value of Q matrix: 7.08472
New value of Value function: 7.08472
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 883
New value of Q matrix: 7.08233
New value of Value function: 7.08233
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 884
New value of Q matrix: 7.07995
New value of Value function: 7.07995
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 885
New value of Q matrix: 7.07757
New value of Value function: 7.07757
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 886
New value of Q matrix: 7.07519
New value of Value function: 7.07519
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 6.50059
New value of Value function: 7.07519
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 6.53825
New value of Value function: 7.07519
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 6.23235
New value of Value function: 7.07519
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 887
New value of Q matrix: 7.07282
New value of Value function: 7.07282
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 6.57283
New value of Value function: 7.07282
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 888
New value of Q matrix: 7.07044
New value of Value function: 7.07044
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 889
New value of Q matrix: 7.06807
New value of Value function: 7.06807
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 890
New value of Q matrix: 7.0657
New value of Value function: 7.0657
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 6.60421
New value of Value function: 7.0657
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 6.28343
New value of Value function: 7.0657
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 891
New value of Q matrix: 7.06334
New value of Value function: 7.06334
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 892
New value of Q matrix: 7.06097
New value of Value function: 7.06097
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 893
New value of Q matrix: 7.05861
New value of Value function: 7.05861
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 894
New value of Q matrix: 7.05625
New value of Value function: 7.05625
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 895
New value of Q matrix: 7.05389
New value of Value function: 7.05389
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 6.52313
New value of Value function: 7.05389
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 896
New value of Q matrix: 7.05153
New value of Value function: 7.05153
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 6.5545
New value of Value function: 7.05153
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 897
New value of Q matrix: 7.04918
New value of Value function: 7.04918
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 898
New value of Q matrix: 7.04683
New value of Value function: 7.04683
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 162
New value of Q matrix: 6.2311
New value of Value function: 7.04683
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 899
New value of Q matrix: 7.04448
New value of Value function: 7.04448
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 900
New value of Q matrix: 7.04213
New value of Value function: 7.04213
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 6.58302
New value of Value function: 7.04213
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 901
New value of Q matrix: 7.03978
New value of Value function: 7.03978
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 902
New value of Q matrix: 7.03744
New value of Value function: 7.03744
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 903
New value of Q matrix: 7.0351
New value of Value function: 7.0351
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 6.32895
New value of Value function: 7.0351
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 904
New value of Q matrix: 7.03276
New value of Value function: 7.03276
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 905
New value of Q matrix: 7.03042
New value of Value function: 7.03042
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 906
New value of Q matrix: 7.02808
New value of Value function: 7.02808
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 907
New value of Q matrix: 7.02575
New value of Value function: 7.02575
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 6.37072
New value of Value function: 7.02575
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 908
New value of Q matrix: 7.02342
New value of Value function: 7.02342
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 909
New value of Q matrix: 7.02109
New value of Value function: 7.02109
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 910
New value of Q matrix: 7.01876
New value of Value function: 7.01876
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 911
New value of Q matrix: 7.01644
New value of Value function: 7.01644
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 912
New value of Q matrix: 7.01411
New value of Value function: 7.01411
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 913
New value of Q matrix: 7.01179
New value of Value function: 7.01179
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 163
New value of Q matrix: 6.28676
New value of Value function: 7.01179
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 914
New value of Q matrix: 7.00947
New value of Value function: 7.00947
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 915
New value of Q matrix: 7.00715
New value of Value function: 7.00715
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 916
New value of Q matrix: 7.00484
New value of Value function: 7.00484
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 917
New value of Q matrix: 7.00253
New value of Value function: 7.00253
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 918
New value of Q matrix: 7.00021
New value of Value function: 7.00021
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 919
New value of Q matrix: 6.99791
New value of Value function: 6.99791
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 6.60655
New value of Value function: 6.99791
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 920
New value of Q matrix: 6.9956
New value of Value function: 6.9956
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 921
New value of Q matrix: 6.99329
New value of Value function: 6.99329
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 6.62787
New value of Value function: 6.99329
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 6.6281
New value of Value function: 6.99329
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 922
New value of Q matrix: 6.99099
New value of Value function: 6.99099
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 923
New value of Q matrix: 6.98869
New value of Value function: 6.98869
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 924
New value of Q matrix: 6.98639
New value of Value function: 6.98639
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 925
New value of Q matrix: 6.98409
New value of Value function: 6.98409
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 926
New value of Q matrix: 6.9818
New value of Value function: 6.9818
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 927
New value of Q matrix: 6.9795
New value of Value function: 6.9795
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 928
New value of Q matrix: 6.97721
New value of Value function: 6.97721
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 929
New value of Q matrix: 6.97492
New value of Value function: 6.97492
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 930
New value of Q matrix: 6.97264
New value of Value function: 6.97264
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 931
New value of Q matrix: 6.97035
New value of Value function: 6.97035
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 932
New value of Q matrix: 7.18722
New value of Value function: 7.18722
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 70
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 10.9706
New value of Value function: 10.9706
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 71
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 12.6981
New value of Value function: 12.6981
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 72
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 4.89924
New value of Value function: 9.67137
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 73
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 11.9702
New value of Value function: 11.9702
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 74
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 9.89244
New value of Value function: 9.89244
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 75
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 12.5656
New value of Value function: 12.5656
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 76
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 11.1189
New value of Value function: 11.1189
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 77
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 13.8566
New value of Value function: 13.8566
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 78
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 5.87202
New value of Value function: 18.2347
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 79
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 7.26804
New value of Value function: 13.8566
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 80
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 14.135
New value of Value function: 14.135
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 81
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 15.9128
New value of Value function: 15.9128
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 82
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 20.5005
New value of Value function: 20.5005
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 83
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 21.9573
New value of Value function: 21.9573
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 84
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 21.7008
New value of Value function: 21.7008
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 85
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 23.4007
New value of Value function: 23.4007
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 86
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 27.0003
New value of Value function: 27.0003
New value of Policy matrix: 3

=======================================
Simulation: 29
Iteration: 87
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 9.27407
New value of Value function: 34.3498
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 88
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.27407
New value of Value function: 8.35764
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 89
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 20.682
New value of Value function: 20.682
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 90
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 37.4669
New value of Value function: 37.4669
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 91
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 41.8684
New value of Value function: 41.8684
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 92
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 45.7975
New value of Value function: 45.7975
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 93
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 18.7081
New value of Value function: 48.8612
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 94
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 36.7082
New value of Value function: 36.7082
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 95
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 27.9279
New value of Value function: 48.8612
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 96
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 67.5044
New value of Value function: 67.5044
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 97
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 73.9834
New value of Value function: 73.9834
New value of Policy matrix: 1

=======================================
Simulation: 29
Iteration: 98
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 85.1211
New value of Value function: 85.1211
New value of Policy matrix: 2

=======================================
Simulation: 29
Iteration: 99
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 30
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 6.6639
New value of Value function: 7.18722
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 933
New value of Q matrix: 7.18487
New value of Value function: 7.18487
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 934
New value of Q matrix: 7.18252
New value of Value function: 7.18252
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 935
New value of Q matrix: 7.18017
New value of Value function: 7.18017
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 936
New value of Q matrix: 7.17782
New value of Value function: 7.17782
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 6.41963
New value of Value function: 7.17782
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 164
New value of Q matrix: 6.35073
New value of Value function: 7.17782
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 937
New value of Q matrix: 7.17548
New value of Value function: 7.17548
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 938
New value of Q matrix: 7.17313
New value of Value function: 7.17313
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 939
New value of Q matrix: 7.17079
New value of Value function: 7.17079
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 940
New value of Q matrix: 7.16845
New value of Value function: 7.16845
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 941
New value of Q matrix: 7.16612
New value of Value function: 7.16612
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 6.65976
New value of Value function: 7.16612
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 942
New value of Q matrix: 7.16378
New value of Value function: 7.16378
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 943
New value of Q matrix: 7.16145
New value of Value function: 7.16145
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 944
New value of Q matrix: 7.15912
New value of Value function: 7.15912
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 945
New value of Q matrix: 7.15679
New value of Value function: 7.15679
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 946
New value of Q matrix: 7.15446
New value of Value function: 7.15446
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 947
New value of Q matrix: 7.15214
New value of Value function: 7.15214
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 948
New value of Q matrix: 7.14981
New value of Value function: 7.14981
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 6.68811
New value of Value function: 7.14981
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 6.46335
New value of Value function: 7.14981
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 949
New value of Q matrix: 7.14749
New value of Value function: 7.14749
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 950
New value of Q matrix: 7.14517
New value of Value function: 7.14517
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 951
New value of Q matrix: 7.14286
New value of Value function: 7.14286
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 952
New value of Q matrix: 7.14054
New value of Value function: 7.14054
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 6.71386
New value of Value function: 7.14054
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 953
New value of Q matrix: 7.13823
New value of Value function: 7.13823
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 954
New value of Q matrix: 7.13592
New value of Value function: 7.13592
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 955
New value of Q matrix: 7.13361
New value of Value function: 7.13361
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 956
New value of Q matrix: 7.1313
New value of Value function: 7.1313
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 6.73719
New value of Value function: 7.1313
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 957
New value of Q matrix: 7.129
New value of Value function: 7.129
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 958
New value of Q matrix: 7.12669
New value of Value function: 7.12669
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 959
New value of Q matrix: 7.12439
New value of Value function: 7.12439
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 960
New value of Q matrix: 7.12209
New value of Value function: 7.12209
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 961
New value of Q matrix: 7.1198
New value of Value function: 7.1198
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 962
New value of Q matrix: 7.1175
New value of Value function: 7.1175
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 963
New value of Q matrix: 7.11521
New value of Value function: 7.11521
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 964
New value of Q matrix: 7.11292
New value of Value function: 7.11292
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 965
New value of Q matrix: 7.11063
New value of Value function: 7.11063
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 966
New value of Q matrix: 7.10834
New value of Value function: 7.10834
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 967
New value of Q matrix: 7.10605
New value of Value function: 7.10605
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 968
New value of Q matrix: 7.10377
New value of Value function: 7.10377
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 969
New value of Q matrix: 7.10149
New value of Value function: 7.10149
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 970
New value of Q matrix: 7.09921
New value of Value function: 7.09921
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 971
New value of Q matrix: 7.09693
New value of Value function: 7.09693
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 6.50061
New value of Value function: 7.09693
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 6.69059
New value of Value function: 7.09693
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 972
New value of Q matrix: 7.09465
New value of Value function: 7.09465
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 973
New value of Q matrix: 7.09238
New value of Value function: 7.09238
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 974
New value of Q matrix: 7.0901
New value of Value function: 7.0901
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 975
New value of Q matrix: 7.08783
New value of Value function: 7.08783
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 976
New value of Q matrix: 7.08556
New value of Value function: 7.08556
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 977
New value of Q matrix: 7.0833
New value of Value function: 7.0833
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 978
New value of Q matrix: 7.08103
New value of Value function: 7.08103
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 165
New value of Q matrix: 6.40207
New value of Value function: 7.08103
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 979
New value of Q matrix: 7.32935
New value of Value function: 7.32935
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 59
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 12.7248
New value of Value function: 12.7248
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 60
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 5.7539
New value of Value function: 9.89244
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 61
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 3.67021
New value of Value function: 3.67021
New value of Policy matrix: 3

=======================================
Simulation: 30
Iteration: 62
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 10.544
New value of Value function: 10.544
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 63
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 10.0416
New value of Value function: 10.0416
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 64
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 18.2196
New value of Value function: 18.2196
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 65
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 28
New value of Q matrix: 20.0636
New value of Value function: 20.0636
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 66
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 19.636
New value of Value function: 19.636
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 67
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 21.5683
New value of Value function: 21.5683
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 68
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -8
New value of Visit matrix: 12
New value of Q matrix: 17.2059
New value of Value function: 17.2059
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 69
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 11
New value of Q matrix: 14.5619
New value of Value function: 14.5619
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 70
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 23.9299
New value of Value function: 23.9299
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 71
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 43.5985
New value of Value function: 43.5985
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 72
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 52.7548
New value of Value function: 52.7548
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 73
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 75.0981
New value of Value function: 75.0981
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 74
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 80.4997
New value of Value function: 80.4997
New value of Policy matrix: 1

=======================================
Simulation: 30
Iteration: 75
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 89.8995
New value of Value function: 89.8995
New value of Policy matrix: 2

=======================================
Simulation: 30
Iteration: 76
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 980
New value of Q matrix: 7.32701
New value of Value function: 7.32701
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 981
New value of Q matrix: 7.32467
New value of Value function: 7.32467
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 982
New value of Q matrix: 7.32233
New value of Value function: 7.32233
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 6.73166
New value of Value function: 7.32233
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 983
New value of Q matrix: 7.31999
New value of Value function: 7.31999
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 984
New value of Q matrix: 7.31766
New value of Value function: 7.31766
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 985
New value of Q matrix: 7.18009
New value of Value function: 7.18009
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 8
----------
State: 2853
	Distance: 4
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.10829
New value of Value function: 4.10829
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 986
New value of Q matrix: 7.23097
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 10
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.37034
New value of Value function: 5.83621
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 166
New value of Q matrix: 6.58647
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 12
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.11511
New value of Value function: 5.83621
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 13
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.01
New value of Value function: 4.01
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 14
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 5.35194
New value of Value function: 5.35194
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 6.76297
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 167
New value of Q matrix: 6.63075
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 6.7919
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 6.81865
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 6.5441
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 6.58462
New value of Value function: 7.23097
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 987
New value of Q matrix: 7.22867
New value of Value function: 7.22867
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 988
New value of Q matrix: 7.22637
New value of Value function: 7.22637
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 989
New value of Q matrix: 7.22407
New value of Value function: 7.22407
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 990
New value of Q matrix: 7.22178
New value of Value function: 7.22178
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 991
New value of Q matrix: 7.25598
New value of Value function: 7.25598
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 26
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 13
New value of Q matrix: 5.02785
New value of Value function: 5.02785
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 992
New value of Q matrix: 7.27889
New value of Value function: 7.27889
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 28
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.29689
New value of Value function: 5.02785
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 993
New value of Q matrix: 7.30106
New value of Value function: 7.30106
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 30
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.15097
New value of Value function: 5.02785
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 31
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 6.49249
New value of Value function: 6.49249
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 32
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 10.0596
New value of Value function: 10.0596
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 33
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 16.9015
New value of Value function: 20.682
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 34
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 25.1757
New value of Value function: 25.1757
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 35
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 17.2615
New value of Value function: 27.0003
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 36
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 29.2775
New value of Value function: 29.2775
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 37
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 40.3654
New value of Value function: 40.3654
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 38
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 46.8032
New value of Value function: 46.8032
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 39
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 59.6209
New value of Value function: 59.6209
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 40
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 34.125
New value of Value function: 48.8612
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 41
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 14.2631
New value of Value function: 14.2631
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 42
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 31.5981
New value of Value function: 31.5981
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 43
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 21.0473
New value of Value function: 40.3654
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 44
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 29.3016
New value of Value function: 29.3016
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 45
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 32.8694
New value of Value function: 32.8694
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 46
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 43.2019
New value of Value function: 43.2019
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 47
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 50.9086
New value of Value function: 50.9086
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 48
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.68727
New value of Value function: 59.6209
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 49
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -7
New value of Visit matrix: 6
New value of Q matrix: 6.57079
New value of Value function: 13.7842
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 50
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 21.0365
New value of Value function: 21.0365
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 51
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 21.5289
New value of Value function: 21.5289
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 52
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 22.8152
New value of Value function: 22.8152
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 53
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 28.5832
New value of Value function: 28.5832
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 54
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 43.147
New value of Value function: 43.147
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 55
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 58.0588
New value of Value function: 58.0588
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 56
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 59.4098
New value of Value function: 59.4098
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 57
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 85.2501
New value of Value function: 85.2501
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 58
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 50.0832
New value of Value function: 89.8995
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 59
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 5
New value of Q matrix: 36.6689
New value of Value function: 55.6396
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 60
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 17
New value of Q matrix: 58.7923
New value of Value function: 58.7923
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 61
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 42.1605
New value of Value function: 55.6396
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 62
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 50.0976
New value of Value function: 50.0976
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 63
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 63.8181
New value of Value function: 63.8181
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 64
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 67.9708
New value of Value function: 67.9708
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 65
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2081
	Distance: 3
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 0.113249
New value of Value function: 0.113249
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 66
----------
State: 2081
	Distance: 3
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -2.40407
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 67
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 28.9666
New value of Value function: 28.9666
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 68
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 48.7344
New value of Value function: 48.7344
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 69
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 72.8207
New value of Value function: 72.8207
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 70
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 77.6658
New value of Value function: 77.6658
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 71
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 76.7281
New value of Value function: 76.7281
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 72
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -2
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 31
Iteration: 73
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 0.866696
New value of Value function: 0.866696
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 74
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3.90575
New value of Policy matrix: 1

=======================================
Simulation: 31
Iteration: 75
----------
State: 1357
	Distance: 2
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -2.69493
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 31
Iteration: 76
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 41.5255
New value of Value function: 41.5255
New value of Policy matrix: 3

=======================================
Simulation: 31
Iteration: 77
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 67.3926
New value of Value function: 67.3926
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 78
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 83.1
New value of Value function: 83.1
New value of Policy matrix: 2

=======================================
Simulation: 31
Iteration: 79
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 5
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 32
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 994
New value of Q matrix: 7.29874
New value of Value function: 7.29874
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 995
New value of Q matrix: 7.29643
New value of Value function: 7.29643
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 996
New value of Q matrix: 7.29412
New value of Value function: 7.29412
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 997
New value of Q matrix: 7.29181
New value of Value function: 7.29181
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 6.76959
New value of Value function: 7.29181
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 998
New value of Q matrix: 7.2895
New value of Value function: 7.2895
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 999
New value of Q matrix: 7.28719
New value of Value function: 7.28719
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 6.84743
New value of Value function: 7.28719
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1000
New value of Q matrix: 7.28489
New value of Value function: 7.28489
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1001
New value of Q matrix: 7.28259
New value of Value function: 7.28259
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1002
New value of Q matrix: 7.28028
New value of Value function: 7.28028
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 6.87355
New value of Value function: 7.28028
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1003
New value of Q matrix: 7.27799
New value of Value function: 7.27799
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1004
New value of Q matrix: 7.27569
New value of Value function: 7.27569
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 6.89739
New value of Value function: 7.27569
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1005
New value of Q matrix: 7.27339
New value of Value function: 7.27339
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1006
New value of Q matrix: 7.2711
New value of Value function: 7.2711
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1007
New value of Q matrix: 7.26881
New value of Value function: 7.26881
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1008
New value of Q matrix: 7.26652
New value of Value function: 7.26652
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1009
New value of Q matrix: 7.26423
New value of Value function: 7.26423
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1010
New value of Q matrix: 7.26195
New value of Value function: 7.26195
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1011
New value of Q matrix: 7.25966
New value of Value function: 7.25966
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 6.62426
New value of Value function: 7.25966
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1012
New value of Q matrix: 7.25738
New value of Value function: 7.25738
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1013
New value of Q matrix: 7.2551
New value of Value function: 7.2551
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 6.79731
New value of Value function: 7.2551
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1014
New value of Q matrix: 7.25282
New value of Value function: 7.25282
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 168
New value of Q matrix: 6.67314
New value of Value function: 7.25282
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1015
New value of Q matrix: 7.25055
New value of Value function: 7.25055
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 169
New value of Q matrix: 6.71198
New value of Value function: 7.25055
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1016
New value of Q matrix: 7.24827
New value of Value function: 7.24827
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1017
New value of Q matrix: 7.246
New value of Value function: 7.246
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1018
New value of Q matrix: 7.24373
New value of Value function: 7.24373
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1019
New value of Q matrix: 7.24146
New value of Value function: 7.24146
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1020
New value of Q matrix: 7.23919
New value of Value function: 7.23919
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1021
New value of Q matrix: 7.23693
New value of Value function: 7.23693
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1022
New value of Q matrix: 7.23466
New value of Value function: 7.23466
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 6.82175
New value of Value function: 7.23466
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1023
New value of Q matrix: 7.2324
New value of Value function: 7.2324
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1024
New value of Q matrix: 7.23014
New value of Value function: 7.23014
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 6.65929
New value of Value function: 7.23014
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1025
New value of Q matrix: 7.22788
New value of Value function: 7.22788
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1026
New value of Q matrix: 7.22562
New value of Value function: 7.22562
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1027
New value of Q matrix: 7.22337
New value of Value function: 7.22337
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1028
New value of Q matrix: 7.22112
New value of Value function: 7.22112
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1029
New value of Q matrix: 7.21887
New value of Value function: 7.21887
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1030
New value of Q matrix: 7.21662
New value of Value function: 7.21662
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1031
New value of Q matrix: 7.21437
New value of Value function: 7.21437
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1032
New value of Q matrix: 7.21212
New value of Value function: 7.21212
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1033
New value of Q matrix: 7.20988
New value of Value function: 7.20988
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1034
New value of Q matrix: 7.20764
New value of Value function: 7.20764
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1035
New value of Q matrix: 7.2054
New value of Value function: 7.2054
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 6.91441
New value of Value function: 7.2054
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1036
New value of Q matrix: 7.20316
New value of Value function: 7.20316
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1037
New value of Q matrix: 7.20092
New value of Value function: 7.20092
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1038
New value of Q matrix: 7.19869
New value of Value function: 7.19869
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1039
New value of Q matrix: 7.19645
New value of Value function: 7.19645
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 6.84198
New value of Value function: 7.19645
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1040
New value of Q matrix: 7.19422
New value of Value function: 7.19422
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 6.92938
New value of Value function: 7.19422
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1041
New value of Q matrix: 7.19199
New value of Value function: 7.19199
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1042
New value of Q matrix: 7.18976
New value of Value function: 7.18976
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1043
New value of Q matrix: 7.18754
New value of Value function: 7.18754
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1044
New value of Q matrix: 7.18531
New value of Value function: 7.18531
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 170
New value of Q matrix: 6.74277
New value of Value function: 7.18531
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1045
New value of Q matrix: 7.18309
New value of Value function: 7.18309
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1046
New value of Q matrix: 7.18087
New value of Value function: 7.18087
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1047
New value of Q matrix: 7.2503
New value of Value function: 7.2503
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 69
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 5.89484
New value of Value function: 5.89484
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1048
New value of Q matrix: 7.29928
New value of Value function: 7.29928
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 71
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 5.4777
New value of Value function: 5.4777
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 6.8676
New value of Value function: 7.29928
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1049
New value of Q matrix: 7.33397
New value of Value function: 7.33397
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 74
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 7.77726
New value of Value function: 7.77726
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 75
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 15.5297
New value of Value function: 15.5297
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 76
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 0.52724
New value of Value function: 29.3016
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 77
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 14.6
New value of Value function: 14.6
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 78
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 32.0378
New value of Value function: 32.0378
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 79
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 34.602
New value of Value function: 34.602
New value of Policy matrix: 3

=======================================
Simulation: 32
Iteration: 80
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 46.2766
New value of Value function: 46.2766
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 81
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 53.4868
New value of Value function: 53.4868
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 82
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 63.1057
New value of Value function: 63.1057
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 83
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 76.5229
New value of Value function: 76.5229
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 84
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 79.9533
New value of Value function: 79.9533
New value of Policy matrix: 1

=======================================
Simulation: 32
Iteration: 85
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 87.4695
New value of Value function: 87.4695
New value of Policy matrix: 2

=======================================
Simulation: 32
Iteration: 86
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 98.5162
New value of Value function: 98.5162
New value of Policy matrix: 4

=======================================
Simulation: 33
Iteration: 1
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 11.1987
New value of Value function: 11.1987
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 2
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 17.5614
New value of Value function: 17.5614
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 3
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 17.1397
New value of Value function: 21.0365
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 4
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 22.3736
New value of Value function: 22.3736
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 5
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 22.7749
New value of Value function: 22.7749
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 6
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 24.6066
New value of Value function: 24.6066
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 7
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 34.9514
New value of Value function: 34.9514
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 8
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 51.9727
New value of Value function: 51.9727
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 9
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 54.2927
New value of Value function: 63.1057
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 10
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: 5.39215
New value of Value function: 53.831
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 11
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 22.7864
New value of Value function: 22.7864
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 12
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 25.5776
New value of Value function: 34.9514
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 13
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: -0.0301015
New value of Value function: 28.8663
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 14
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 4.65674
New value of Value function: 4.65674
New value of Policy matrix: 3

=======================================
Simulation: 33
Iteration: 15
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 13.0623
New value of Value function: 13.0623
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 16
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 18.2566
New value of Value function: 18.2566
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 11.511
New value of Value function: 24.6066
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 18
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 10.7871
New value of Value function: 22.3736
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 19
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 15.3797
New value of Value function: 15.3797
New value of Policy matrix: 0

=======================================
Simulation: 33
Iteration: 20
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 23.771
New value of Value function: 23.771
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 21
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 27.1783
New value of Value function: 27.1783
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 22
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 31.6902
New value of Value function: 31.6902
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 23
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 28.7325
New value of Value function: 28.7325
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 24
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 36.8469
New value of Value function: 36.8469
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 25
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 14
New value of Q matrix: 61.3098
New value of Value function: 61.3098
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 26
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 79.4071
New value of Value function: 79.4071
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 27
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 82.8415
New value of Value function: 82.8415
New value of Policy matrix: 1

=======================================
Simulation: 33
Iteration: 28
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 90.9249
New value of Value function: 90.9249
New value of Policy matrix: 2

=======================================
Simulation: 33
Iteration: 29
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 8
New value of Q matrix: 99.0408
New value of Value function: 99.0408
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1050
New value of Q matrix: 7.33171
New value of Value function: 7.33171
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1051
New value of Q matrix: 7.32945
New value of Value function: 7.32945
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 6.95284
New value of Value function: 7.32945
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1052
New value of Q matrix: 7.32719
New value of Value function: 7.32719
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 171
New value of Q matrix: 6.78186
New value of Value function: 7.32719
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1053
New value of Q matrix: 7.32493
New value of Value function: 7.32493
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1054
New value of Q matrix: 7.32268
New value of Value function: 7.32268
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 6.69795
New value of Value function: 7.32268
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1055
New value of Q matrix: 7.32042
New value of Value function: 7.32042
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1056
New value of Q matrix: 7.57513
New value of Value function: 7.57513
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 11
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 14.0692
New value of Value function: 14.0692
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 16
New value of Q matrix: 13.8931
New value of Value function: 13.8931
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 13
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 20.552
New value of Value function: 20.552
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 25.6683
New value of Value function: 25.6683
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 15
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 36
New value of Q matrix: 27.3457
New value of Value function: 27.3457
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 16
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 26.9007
New value of Value function: 26.9007
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 27.877
New value of Value function: 27.877
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 18
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 36.2129
New value of Value function: 36.2129
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 19
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 16.7848
New value of Value function: 34.602
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 20
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 34.2362
New value of Value function: 34.2362
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 21
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 36.6726
New value of Value function: 36.6726
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 22
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 51.3053
New value of Value function: 51.3053
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 23
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 62.1269
New value of Value function: 62.1269
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 24
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 61.1207
New value of Value function: 61.1207
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 25
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 60.2404
New value of Value function: 60.2404
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 26
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 53.0896
New value of Value function: 53.0896
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 27
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 4.40007
New value of Value function: 4.40007
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 28
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.845299
New value of Value function: 0.845299
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 29
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 14.1205
New value of Value function: 14.1205
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 30
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 11.8516
New value of Value function: 11.8516
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 31
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.35607
New value of Value function: 4.40007
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 32
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.07489
New value of Value function: 4.35607
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 33
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.836846
New value of Value function: 0.845299
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 34
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.5969
New value of Value function: 4.5969
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 35
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 7.28958
New value of Value function: 7.28958
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 36
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 1.28298
New value of Value function: 1.28298
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 37
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.61814
New value of Value function: 6.61814
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 38
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 5.97018
New value of Value function: 5.97018
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 39
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 6.36794
New value of Value function: 6.36794
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 40
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 6.09645
New value of Value function: 6.09645
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 41
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 6.33535
New value of Value function: 6.33535
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 42
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 1.27883
New value of Value function: 1.27883
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 43
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 6.31343
New value of Value function: 6.31343
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 44
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 1.26874
New value of Value function: 1.26874
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 45
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 6.29613
New value of Value function: 6.29613
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 46
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 1.25688
New value of Value function: 1.25688
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 47
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 6.28117
New value of Value function: 6.28117
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 48
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 1.2447
New value of Value function: 1.2447
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 49
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.49938
New value of Value function: 6.28117
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1057
New value of Q matrix: 7.62567
New value of Value function: 7.62567
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 51
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 6.26761
New value of Value function: 6.26761
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 52
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 1.23271
New value of Value function: 1.23271
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 53
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 6.25498
New value of Value function: 6.25498
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 54
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 1.22108
New value of Value function: 1.22108
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 55
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 6.24308
New value of Value function: 6.24308
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 56
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 1.20987
New value of Value function: 1.20987
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 57
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 6.23175
New value of Value function: 6.23175
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 58
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 1.19906
New value of Value function: 1.19906
New value of Policy matrix: 0

=======================================
Simulation: 34
Iteration: 59
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 6.22092
New value of Value function: 6.22092
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 60
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 27.6769
New value of Value function: 27.6769
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 61
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 1
New value of Q matrix: 2.03548
New value of Value function: 28.9666
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 62
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 15.3962
New value of Value function: 15.3962
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 63
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 27.6769
New value of Value function: 27.6769
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 64
----------
State: 2129
	Distance: 3
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 30.3172
New value of Value function: 30.3172
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 65
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 43.8931
New value of Value function: 43.8931
New value of Policy matrix: 3

=======================================
Simulation: 34
Iteration: 66
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 62.2226
New value of Value function: 62.2226
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 67
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 60.3242
New value of Value function: 60.3242
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 68
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 64.3974
New value of Value function: 64.3974
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 69
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 1.79792
New value of Value function: 82.8415
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 70
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 47.2804
New value of Value function: 47.2804
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 71
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 44.6641
New value of Value function: 44.6641
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 72
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 27.4001
New value of Value function: 27.6769
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 73
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 14.0718
New value of Value function: 27.4001
New value of Policy matrix: 4

=======================================
Simulation: 34
Iteration: 74
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 23.6654
New value of Value function: 23.6654
New value of Policy matrix: 1

=======================================
Simulation: 34
Iteration: 75
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 74.3029
New value of Value function: 74.3029
New value of Policy matrix: 2

=======================================
Simulation: 34
Iteration: 76
----------
State: 1549
	Distance: 2
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1554
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 35
Iteration: 1
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 23.7806
New value of Value function: 23.7806
New value of Policy matrix: 0

=======================================
Simulation: 35
Iteration: 2
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 30.0835
New value of Value function: 30.0835
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 3
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 18
New value of Q matrix: 34.0033
New value of Value function: 34.0033
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 4
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 9.74262
New value of Value function: 30.0835
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 5
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 31.4573
New value of Value function: 31.4573
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 6
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 41.0314
New value of Value function: 41.0314
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 7
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 61.7695
New value of Value function: 61.7695
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 8
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 61.3374
New value of Value function: 61.3374
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 9
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 61.5025
New value of Value function: 61.5025
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 10
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 69.0789
New value of Value function: 69.0789
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 11
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 63.3882
New value of Value function: 82.8415
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 12
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 74.2561
New value of Value function: 74.2561
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 13
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 82.0131
New value of Value function: 82.8415
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 14
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 85.7315
New value of Value function: 85.7315
New value of Policy matrix: 1

=======================================
Simulation: 35
Iteration: 15
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 93.6362
New value of Value function: 93.6362
New value of Policy matrix: 2

=======================================
Simulation: 35
Iteration: 16
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 9
New value of Q matrix: 99.3605
New value of Value function: 99.3605
New value of Policy matrix: 4

=======================================
Simulation: 36
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1058
New value of Q matrix: 7.91168
New value of Value function: 7.91168
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 2
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.45806
New value of Value function: 14.0692
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 3
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 15.2404
New value of Value function: 15.2404
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 4
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 6.16851
New value of Value function: 13.8931
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 5
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 16.0927
New value of Value function: 16.0927
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 6
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 17
New value of Q matrix: 15.2158
New value of Value function: 15.2158
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 7
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 23.4233
New value of Value function: 23.4233
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 8
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 28.6473
New value of Value function: 28.6473
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 9
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 40
New value of Q matrix: 28.8669
New value of Value function: 28.8669
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 10
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 21.9513
New value of Value function: 21.9513
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 11
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 31.4835
New value of Value function: 31.4835
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 12
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 45.6308
New value of Value function: 45.6308
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 13
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 62.3838
New value of Value function: 62.3838
New value of Policy matrix: 1

=======================================
Simulation: 36
Iteration: 14
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 65.1293
New value of Value function: 65.1293
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 15
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 54.3049
New value of Value function: 74.2561
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 16
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 73.5791
New value of Value function: 73.5791
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 17
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 95.6796
New value of Value function: 95.6796
New value of Policy matrix: 2

=======================================
Simulation: 36
Iteration: 18
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 6
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 37
Iteration: 1
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.24066
New value of Value function: 7.41922
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 2
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 4.8903
New value of Value function: 7.41922
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 3
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 8.77365
New value of Value function: 8.77365
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 4
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 7.10034
New value of Value function: 7.10034
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 5
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.70618
New value of Value function: 4.75371
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 6
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 5.18023
New value of Value function: 5.18023
New value of Policy matrix: 3

=======================================
Simulation: 37
Iteration: 7
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 6
New value of Q matrix: 11.0992
New value of Value function: 11.0992
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 8
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -6
New value of Visit matrix: 15
New value of Q matrix: 6.47273
New value of Value function: 6.47273
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 9
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 14.8312
New value of Value function: 14.8312
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 10
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 10.9637
New value of Value function: 10.9637
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 11
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 10.929
New value of Value function: 10.929
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 12
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 17.0543
New value of Value function: 17.0543
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 13
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 31.312
New value of Value function: 31.312
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 14
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 40.0444
New value of Value function: 40.0444
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 15
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 8.52917
New value of Value function: 8.52917
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 16
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 10.5408
New value of Value function: 10.5408
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 17
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 12
New value of Q matrix: 8.50211
New value of Value function: 8.50211
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 18
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 10.5124
New value of Value function: 10.5124
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 19
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 7.17612
New value of Value function: 8.50211
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 20
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 14.2424
New value of Value function: 14.2424
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 21
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 20
New value of Q matrix: 10.6438
New value of Value function: 10.6438
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 22
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 5.18873
New value of Value function: 14.2424
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 23
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 22.5231
New value of Value function: 22.5231
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 24
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 7.05804
New value of Value function: 31.312
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 25
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 11.7996
New value of Value function: 22.5231
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 26
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 26.2606
New value of Value function: 26.2606
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 27
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 13.8631
New value of Value function: 31.312
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 28
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 35.978
New value of Value function: 35.978
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 29
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 27.8265
New value of Value function: 27.8265
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 30
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 6.40801
New value of Value function: 6.47273
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 31
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 32.5483
New value of Value function: 32.5483
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 32
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 27.6445
New value of Value function: 27.6445
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 33
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 14.7591
New value of Value function: 32.5483
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 34
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 32.5098
New value of Value function: 32.5098
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 35
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 17
New value of Q matrix: 19.9556
New value of Value function: 32.5483
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 36
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 6
New value of Q matrix: 30.7596
New value of Value function: 30.7596
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 37
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 33.8944
New value of Value function: 33.8944
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 38
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 43.8819
New value of Value function: 43.8819
New value of Policy matrix: 0

=======================================
Simulation: 37
Iteration: 39
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 23
New value of Q matrix: 54.3042
New value of Value function: 54.3042
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 40
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 9.22369
New value of Value function: 12.3373
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 41
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 12.1292
New value of Value function: 12.1292
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 42
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 8.20439
New value of Value function: 8.20439
New value of Policy matrix: 1

=======================================
Simulation: 37
Iteration: 43
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 3.00688
New value of Value function: 8.74599
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 44
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 12.7037
New value of Value function: 12.7037
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 45
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.90106
New value of Value function: 8.90106
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 46
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 48.3793
New value of Value function: 48.3793
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 47
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 98.01
New value of Value function: 98.01
New value of Policy matrix: 2

=======================================
Simulation: 37
Iteration: 48
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1350
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 99.2272
New value of Value function: 99.2272
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 1
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 4.6985
New value of Value function: 4.6985
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 2
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: -0.0600469
New value of Value function: -0.0600469
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 3
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.0598968
New value of Value function: -0.0598968
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 4
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.0597515
New value of Value function: -0.0597515
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 5
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.0596107
New value of Value function: -0.0596107
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 6
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: -0.0594739
New value of Value function: -0.0594739
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 7
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 0.242729
New value of Value function: 0.242729
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 8
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 6.52643
New value of Value function: 6.52643
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 9
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 4.6985
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 10
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 11
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 4
New value of Visit matrix: 1
New value of Q matrix: 19.2259
New value of Value function: 19.2259
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 12
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 23.7823
New value of Value function: 23.7823
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 13
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 42
New value of Q matrix: 30.2301
New value of Value function: 30.2301
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 19.3073
New value of Value function: 28.6473
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 15
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 24.835
New value of Value function: 24.835
New value of Policy matrix: 0

=======================================
Simulation: 38
Iteration: 16
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 29.8136
New value of Value function: 29.8136
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 43
New value of Q matrix: 31.3923
New value of Value function: 31.3923
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 18
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 43.2804
New value of Value function: 43.2804
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 19
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 30.3578
New value of Value function: 43.8931
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 20
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 44.4657
New value of Value function: 44.4657
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 21
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 14.9313
New value of Value function: 51.3053
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 22
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 20.7318
New value of Value function: 20.7318
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 23
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 15.3521
New value of Value function: 21.9513
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 24
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 25.1924
New value of Value function: 25.1924
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 25
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 31.3449
New value of Value function: 31.3449
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 26
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 45
New value of Q matrix: 34.1519
New value of Value function: 34.1519
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 27
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 41.9602
New value of Value function: 41.9602
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 28
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 46
New value of Q matrix: 35.7289
New value of Value function: 35.7289
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 29
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 46.1507
New value of Value function: 46.1507
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 30
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 44.8486
New value of Value function: 44.8486
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 31
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 55.037
New value of Value function: 55.037
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 32
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 20.4732
New value of Value function: 62.3838
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 33
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 47
New value of Q matrix: 37.3059
New value of Value function: 37.3059
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 34
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 42.9068
New value of Value function: 42.9068
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 35
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 46.135
New value of Value function: 46.135
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 36
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 57.6356
New value of Value function: 57.6356
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 37
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 60.8228
New value of Value function: 60.8228
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 38
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 59.2459
New value of Value function: 59.2459
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 39
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 78.5878
New value of Value function: 78.5878
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 40
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 89.0619
New value of Value function: 89.0619
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 41
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 97.2403
New value of Value function: 97.2403
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 42
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -1.39328
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 43
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 56.6458
New value of Value function: 56.6458
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 44
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 79.8147
New value of Value function: 79.8147
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 45
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 30.6339
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 38
Iteration: 46
----------
State: 1313
	Distance: 2
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 15.7125
New value of Value function: 15.7125
New value of Policy matrix: 3

=======================================
Simulation: 38
Iteration: 47
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 5.26001
New value of Value function: 5.26001
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 48
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.56111
New value of Value function: 4.56111
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 6.93179
New value of Value function: 7.91168
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1059
New value of Q matrix: 7.90925
New value of Value function: 7.90925
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1060
New value of Q matrix: 7.90682
New value of Value function: 7.90682
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1061
New value of Q matrix: 7.90439
New value of Value function: 7.90439
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1062
New value of Q matrix: 7.90196
New value of Value function: 7.90196
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1063
New value of Q matrix: 7.89954
New value of Value function: 7.89954
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1064
New value of Q matrix: 7.89712
New value of Value function: 7.89712
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 6.77118
New value of Value function: 7.89712
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1065
New value of Q matrix: 7.8947
New value of Value function: 7.8947
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1066
New value of Q matrix: 7.89228
New value of Value function: 7.89228
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1067
New value of Q matrix: 7.88987
New value of Value function: 7.88987
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 7.01429
New value of Value function: 7.88987
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1068
New value of Q matrix: 7.88745
New value of Value function: 7.88745
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1069
New value of Q matrix: 7.88504
New value of Value function: 7.88504
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 6.8387
New value of Value function: 7.88504
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1070
New value of Q matrix: 7.88263
New value of Value function: 7.88263
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 7.07068
New value of Value function: 7.88263
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1071
New value of Q matrix: 7.88022
New value of Value function: 7.88022
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1072
New value of Q matrix: 7.87781
New value of Value function: 7.87781
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1073
New value of Q matrix: 7.87541
New value of Value function: 7.87541
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1074
New value of Q matrix: 7.873
New value of Value function: 7.873
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1075
New value of Q matrix: 7.8706
New value of Value function: 7.8706
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 6.98888
New value of Value function: 7.8706
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 7.04206
New value of Value function: 7.8706
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 7.12207
New value of Value function: 7.8706
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1076
New value of Q matrix: 7.8682
New value of Value function: 7.8682
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1077
New value of Q matrix: 7.86581
New value of Value function: 7.86581
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 172
New value of Q matrix: 6.85852
New value of Value function: 7.86581
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1078
New value of Q matrix: 7.86341
New value of Value function: 7.86341
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 7.09114
New value of Value function: 7.86341
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1079
New value of Q matrix: 7.86102
New value of Value function: 7.86102
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1080
New value of Q matrix: 7.85862
New value of Value function: 7.85862
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1081
New value of Q matrix: 7.85623
New value of Value function: 7.85623
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1082
New value of Q matrix: 7.85385
New value of Value function: 7.85385
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1083
New value of Q matrix: 7.85146
New value of Value function: 7.85146
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1084
New value of Q matrix: 7.84908
New value of Value function: 7.84908
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1085
New value of Q matrix: 7.84669
New value of Value function: 7.84669
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1086
New value of Q matrix: 7.84431
New value of Value function: 7.84431
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 7.13563
New value of Value function: 7.84431
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 7.16782
New value of Value function: 7.84431
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1087
New value of Q matrix: 7.84193
New value of Value function: 7.84193
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 6.8989
New value of Value function: 7.84193
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1088
New value of Q matrix: 7.83955
New value of Value function: 7.83955
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 6.95491
New value of Value function: 7.83955
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1089
New value of Q matrix: 7.83718
New value of Value function: 7.83718
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1090
New value of Q matrix: 7.8348
New value of Value function: 7.8348
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 173
New value of Q matrix: 6.92678
New value of Value function: 7.8348
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 7.20955
New value of Value function: 7.8348
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1091
New value of Q matrix: 7.83243
New value of Value function: 7.83243
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1092
New value of Q matrix: 7.83006
New value of Value function: 7.83006
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 7.00656
New value of Value function: 7.83006
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1093
New value of Q matrix: 7.82769
New value of Value function: 7.82769
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1094
New value of Q matrix: 7.82533
New value of Value function: 7.82533
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 7.17586
New value of Value function: 7.82533
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1095
New value of Q matrix: 7.82296
New value of Value function: 7.82296
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 7.21321
New value of Value function: 7.82296
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1096
New value of Q matrix: 7.8206
New value of Value function: 7.8206
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1097
New value of Q matrix: 7.81824
New value of Value function: 7.81824
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1098
New value of Q matrix: 7.81588
New value of Value function: 7.81588
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 7.05385
New value of Value function: 7.81588
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 7.098
New value of Value function: 7.81588
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1099
New value of Q matrix: 7.81352
New value of Value function: 7.81352
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1100
New value of Q matrix: 7.81117
New value of Value function: 7.81117
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1101
New value of Q matrix: 7.80881
New value of Value function: 7.80881
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1102
New value of Q matrix: 7.80646
New value of Value function: 7.80646
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1103
New value of Q matrix: 7.80411
New value of Value function: 7.80411
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1104
New value of Q matrix: 7.80176
New value of Value function: 7.80176
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1105
New value of Q matrix: 7.79941
New value of Value function: 7.79941
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 7.24574
New value of Value function: 7.79941
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1106
New value of Q matrix: 7.79707
New value of Value function: 7.79707
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 174
New value of Q matrix: 6.98685
New value of Value function: 7.79707
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1107
New value of Q matrix: 7.79472
New value of Value function: 7.79472
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1108
New value of Q matrix: 7.79238
New value of Value function: 7.79238
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1109
New value of Q matrix: 7.79004
New value of Value function: 7.79004
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 7.27864
New value of Value function: 7.79004
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1110
New value of Q matrix: 7.7877
New value of Value function: 7.7877
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1111
New value of Q matrix: 7.78537
New value of Value function: 7.78537
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1112
New value of Q matrix: 7.78303
New value of Value function: 7.78303
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1113
New value of Q matrix: 7.7807
New value of Value function: 7.7807
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1114
New value of Q matrix: 7.77837
New value of Value function: 7.77837
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1115
New value of Q matrix: 7.86585
New value of Value function: 7.86585
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 130
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 10.7464
New value of Value function: 10.7464
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 131
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 4.19736
New value of Value function: 15.5297
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1116
New value of Q matrix: 8.18042
New value of Value function: 8.18042
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 133
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 20.623
New value of Value function: 20.623
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 134
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 32.5886
New value of Value function: 34.2362
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 135
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 59.0761
New value of Value function: 59.0761
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 136
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 19
New value of Q matrix: 60.784
New value of Value function: 60.784
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 137
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 63.9571
New value of Value function: 63.9571
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 138
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 52.8649
New value of Value function: 78.5878
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 139
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 82.4854
New value of Value function: 82.4854
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 140
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 72.7731
New value of Value function: 89.0619
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 141
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 85.2445
New value of Value function: 85.2445
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 142
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 91.6569
New value of Value function: 91.6569
New value of Policy matrix: 1

=======================================
Simulation: 38
Iteration: 143
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 98.5178
New value of Value function: 98.5178
New value of Policy matrix: 2

=======================================
Simulation: 38
Iteration: 144
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 10
New value of Q matrix: 99.5628
New value of Value function: 99.5628
New value of Policy matrix: 4

=======================================
Simulation: 39
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1117
New value of Q matrix: 8.17797
New value of Value function: 8.17797
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1118
New value of Q matrix: 8.49959
New value of Value function: 8.49959
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 3
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 17.0286
New value of Value function: 17.0286
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 4
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 7.74994
New value of Value function: 15.2158
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 5
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 17.7249
New value of Value function: 17.7249
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 6
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 18
New value of Q matrix: 16.8594
New value of Value function: 16.8594
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 7
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 26.1646
New value of Value function: 26.1646
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 8
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 29.7591
New value of Value function: 29.7591
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 9
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 29.2529
New value of Value function: 29.2529
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 10
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 7.71809
New value of Value function: 25.1924
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 11
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 6.45244
New value of Value function: 16.8594
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 12
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 6.2529
New value of Value function: 6.2529
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1119
New value of Q matrix: 8.52024
New value of Value function: 8.52024
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 14
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 10.4505
New value of Value function: 10.4505
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 15
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.0525
New value of Value function: 10.7464
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 16
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 8.51667
New value of Value function: 10.7464
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 17
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 9.31883
New value of Value function: 10.7464
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 18
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 19
New value of Q matrix: 9.52792
New value of Value function: 9.52792
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1120
New value of Q matrix: 8.63714
New value of Value function: 8.63714
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 20
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 13.0808
New value of Value function: 13.0808
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 21
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 24.1698
New value of Value function: 24.1698
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 22
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 39.382
New value of Value function: 39.382
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 23
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 48.0994
New value of Value function: 48.0994
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 24
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 15.7279
New value of Value function: 59.0761
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 25
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 9
New value of Visit matrix: 6
New value of Q matrix: 25.184
New value of Value function: 25.184
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 26
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 23.6123
New value of Value function: 48.0994
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 27
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 49.4901
New value of Value function: 49.4901
New value of Policy matrix: 3

=======================================
Simulation: 39
Iteration: 28
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 60.1011
New value of Value function: 60.1011
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 29
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 20
New value of Q matrix: 61.7977
New value of Value function: 61.7977
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 30
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 68.9453
New value of Value function: 68.9453
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 31
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 87.8684
New value of Value function: 87.8684
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 32
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 93.73
New value of Value function: 93.73
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 33
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 94.0356
New value of Value function: 94.0356
New value of Policy matrix: 2

=======================================
Simulation: 39
Iteration: 34
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 97.0492
New value of Value function: 97.0492
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 35
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 98.5251
New value of Value function: 98.5251
New value of Policy matrix: 1

=======================================
Simulation: 39
Iteration: 36
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 11
New value of Q matrix: 99.6946
New value of Value function: 99.6946
New value of Policy matrix: 4

=======================================
Simulation: 40
Iteration: 1
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 3.84124
New value of Value function: 3.84124
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 2
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.69536
New value of Value function: 4.69536
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1121
New value of Q matrix: 8.63456
New value of Value function: 8.63456
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1122
New value of Q matrix: 8.63198
New value of Value function: 8.63198
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1123
New value of Q matrix: 8.62941
New value of Value function: 8.62941
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1124
New value of Q matrix: 8.62683
New value of Value function: 8.62683
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1125
New value of Q matrix: 8.62426
New value of Value function: 8.62426
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 7.36725
New value of Value function: 8.62426
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1126
New value of Q matrix: 8.62169
New value of Value function: 8.62169
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 7.29983
New value of Value function: 8.62169
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1127
New value of Q matrix: 8.61912
New value of Value function: 8.61912
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1128
New value of Q matrix: 8.61656
New value of Value function: 8.61656
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1129
New value of Q matrix: 8.61399
New value of Value function: 8.61399
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1130
New value of Q matrix: 8.61143
New value of Value function: 8.61143
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1131
New value of Q matrix: 8.60887
New value of Value function: 8.60887
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 7.44835
New value of Value function: 8.60887
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 7.37978
New value of Value function: 8.60887
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1132
New value of Q matrix: 8.60631
New value of Value function: 8.60631
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1133
New value of Q matrix: 8.60376
New value of Value function: 8.60376
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 7.52322
New value of Value function: 8.60376
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1134
New value of Q matrix: 8.6012
New value of Value function: 8.6012
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1135
New value of Q matrix: 8.59865
New value of Value function: 8.59865
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1136
New value of Q matrix: 8.5961
New value of Value function: 8.5961
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1137
New value of Q matrix: 8.59355
New value of Value function: 8.59355
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1138
New value of Q matrix: 8.591
New value of Value function: 8.591
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1139
New value of Q matrix: 8.58845
New value of Value function: 8.58845
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 7.18847
New value of Value function: 8.58845
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1140
New value of Q matrix: 8.58591
New value of Value function: 8.58591
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1141
New value of Q matrix: 8.58337
New value of Value function: 8.58337
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1142
New value of Q matrix: 8.58083
New value of Value function: 8.58083
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1143
New value of Q matrix: 8.57829
New value of Value function: 8.57829
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1144
New value of Q matrix: 8.57575
New value of Value function: 8.57575
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 175
New value of Q matrix: 7.10048
New value of Value function: 8.57575
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1145
New value of Q matrix: 8.57322
New value of Value function: 8.57322
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1146
New value of Q matrix: 8.57069
New value of Value function: 8.57069
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1147
New value of Q matrix: 8.56816
New value of Value function: 8.56816
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1148
New value of Q matrix: 8.56563
New value of Value function: 8.56563
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 7.27149
New value of Value function: 8.56563
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1149
New value of Q matrix: 8.5631
New value of Value function: 8.5631
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 7.34886
New value of Value function: 8.5631
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1150
New value of Q matrix: 8.56058
New value of Value function: 8.56058
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1151
New value of Q matrix: 8.55805
New value of Value function: 8.55805
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1152
New value of Q matrix: 8.55553
New value of Value function: 8.55553
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1153
New value of Q matrix: 8.55301
New value of Value function: 8.55301
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1154
New value of Q matrix: 8.55049
New value of Value function: 8.55049
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1155
New value of Q matrix: 8.54798
New value of Value function: 8.54798
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1156
New value of Q matrix: 8.54546
New value of Value function: 8.54546
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1157
New value of Q matrix: 8.54295
New value of Value function: 8.54295
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1158
New value of Q matrix: 8.54044
New value of Value function: 8.54044
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 176
New value of Q matrix: 7.20258
New value of Value function: 8.54044
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1159
New value of Q matrix: 8.53793
New value of Value function: 8.53793
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1160
New value of Q matrix: 8.53543
New value of Value function: 8.53543
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1161
New value of Q matrix: 8.53292
New value of Value function: 8.53292
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1162
New value of Q matrix: 8.53042
New value of Value function: 8.53042
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1163
New value of Q matrix: 8.52792
New value of Value function: 8.52792
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1164
New value of Q matrix: 8.52542
New value of Value function: 8.52542
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1165
New value of Q matrix: 8.52292
New value of Value function: 8.52292
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1166
New value of Q matrix: 8.52042
New value of Value function: 8.52042
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 7.58692
New value of Value function: 8.52042
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1167
New value of Q matrix: 8.51793
New value of Value function: 8.51793
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1168
New value of Q matrix: 8.51544
New value of Value function: 8.51544
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1169
New value of Q matrix: 8.51295
New value of Value function: 8.51295
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 7.64551
New value of Value function: 8.51295
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1170
New value of Q matrix: 8.51046
New value of Value function: 8.51046
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1171
New value of Q matrix: 8.50797
New value of Value function: 8.50797
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1172
New value of Q matrix: 8.50548
New value of Value function: 8.50548
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 7.69937
New value of Value function: 8.50548
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1173
New value of Q matrix: 8.503
New value of Value function: 8.503
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1174
New value of Q matrix: 8.50052
New value of Value function: 8.50052
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1175
New value of Q matrix: 8.64188
New value of Value function: 8.64188
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 71
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 13.5121
New value of Value function: 13.5121
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 72
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 21
New value of Q matrix: 11.4386
New value of Value function: 11.4386
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1176
New value of Q matrix: 8.80758
New value of Value function: 8.80758
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 74
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 22
New value of Q matrix: 9.2118
New value of Value function: 9.31883
New value of Policy matrix: 4

=======================================
Simulation: 40
Iteration: 75
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 4.63419
New value of Value function: 4.63419
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 177
New value of Q matrix: 7.58014
New value of Value function: 8.80758
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 77
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 9.28588
New value of Value function: 9.28588
New value of Policy matrix: 4

=======================================
Simulation: 40
Iteration: 78
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 9.25493
New value of Value function: 9.25493
New value of Policy matrix: 4

=======================================
Simulation: 40
Iteration: 79
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 9.22566
New value of Value function: 9.22566
New value of Policy matrix: 4

=======================================
Simulation: 40
Iteration: 80
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 9.19785
New value of Value function: 9.2118
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 81
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.87767
New value of Value function: 9.2118
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1177
New value of Q matrix: 9.77473
New value of Value function: 9.77473
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 83
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 29.6533
New value of Value function: 39.382
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 84
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 43.6869
New value of Value function: 43.6869
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 85
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 50.7426
New value of Value function: 50.7426
New value of Policy matrix: 3

=======================================
Simulation: 40
Iteration: 86
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 17
New value of Q matrix: 61.0903
New value of Value function: 61.0903
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 87
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 49.181
New value of Value function: 61.7977
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 88
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 18
New value of Q matrix: 61.8185
New value of Value function: 61.8185
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 89
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 63.6434
New value of Value function: 63.6434
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 90
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 73.3802
New value of Value function: 73.3802
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 91
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 38.93
New value of Value function: 87.8684
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 92
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 69.0444
New value of Value function: 69.0444
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 93
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 90.2754
New value of Value function: 90.2754
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 94
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 12
New value of Q matrix: 86.5458
New value of Value function: 86.5458
New value of Policy matrix: 1

=======================================
Simulation: 40
Iteration: 95
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 78.4823
New value of Value function: 78.4823
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 96
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 95.968
New value of Value function: 95.968
New value of Policy matrix: 2

=======================================
Simulation: 40
Iteration: 97
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 12
New value of Q matrix: 99.7828
New value of Value function: 99.7828
New value of Policy matrix: 4

=======================================
Simulation: 41
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1178
New value of Q matrix: 9.77188
New value of Value function: 9.77188
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1179
New value of Q matrix: 9.76904
New value of Value function: 9.76904
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1180
New value of Q matrix: 10.0828
New value of Value function: 10.0828
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 4
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 18.6117
New value of Value function: 18.6117
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 5
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 19
New value of Q matrix: 18.7047
New value of Value function: 18.7047
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 6
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 13.1437
New value of Value function: 26.1646
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 7
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 20
New value of Q matrix: 20.0907
New value of Value function: 20.0907
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 8
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 27.8377
New value of Value function: 27.8377
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 9
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 31.4944
New value of Value function: 31.4944
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 10
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 48
New value of Q matrix: 35.7
New value of Value function: 35.7
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 11
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 33.0347
New value of Value function: 33.0347
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 12
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 12.6671
New value of Value function: 35.7
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 13
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 11.8039
New value of Value function: 25.1924
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 14
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 22.0219
New value of Value function: 22.0219
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 15
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 28.5879
New value of Value function: 28.5879
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 16
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 49
New value of Q matrix: 37.3825
New value of Value function: 37.3825
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 17
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 11.1079
New value of Value function: 42.9068
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 18
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 27.5233
New value of Value function: 27.5233
New value of Policy matrix: 0

=======================================
Simulation: 41
Iteration: 19
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 50
New value of Q matrix: 38.8102
New value of Value function: 38.8102
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 20
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 37.6773
New value of Value function: 42.9068
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 21
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 50.2134
New value of Value function: 50.2134
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 22
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 40.6619
New value of Value function: 50.7426
New value of Policy matrix: 3

=======================================
Simulation: 41
Iteration: 23
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 65.9893
New value of Value function: 65.9893
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 24
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 77.3474
New value of Value function: 77.3474
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 25
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 90.3709
New value of Value function: 90.3709
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 26
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 99.0787
New value of Value function: 99.0787
New value of Policy matrix: 2

=======================================
Simulation: 41
Iteration: 27
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 98.8103
New value of Value function: 98.8103
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 28
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 99.2524
New value of Value function: 99.2524
New value of Policy matrix: 1

=======================================
Simulation: 41
Iteration: 29
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 13
New value of Q matrix: 99.843
New value of Value function: 99.843
New value of Policy matrix: 4

=======================================
Simulation: 42
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1181
New value of Q matrix: 10.0799
New value of Value function: 10.0799
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1182
New value of Q matrix: 10.077
New value of Value function: 10.077
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1183
New value of Q matrix: 10.074
New value of Value function: 10.074
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1184
New value of Q matrix: 10.0711
New value of Value function: 10.0711
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1185
New value of Q matrix: 10.0682
New value of Value function: 10.0682
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 7.85663
New value of Value function: 10.0682
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1186
New value of Q matrix: 10.0652
New value of Value function: 10.0652
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1187
New value of Q matrix: 10.0623
New value of Value function: 10.0623
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1188
New value of Q matrix: 10.0594
New value of Value function: 10.0594
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1189
New value of Q matrix: 10.0565
New value of Value function: 10.0565
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1190
New value of Q matrix: 10.0536
New value of Value function: 10.0536
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1191
New value of Q matrix: 10.0507
New value of Value function: 10.0507
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 178
New value of Q matrix: 7.75778
New value of Value function: 10.0507
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1192
New value of Q matrix: 10.0477
New value of Value function: 10.0477
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1193
New value of Q matrix: 10.0448
New value of Value function: 10.0448
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 179
New value of Q matrix: 7.92121
New value of Value function: 10.0448
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 7.51502
New value of Value function: 10.0448
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 180
New value of Q matrix: 8.07201
New value of Value function: 10.0448
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 181
New value of Q matrix: 8.21118
New value of Value function: 10.0448
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1194
New value of Q matrix: 10.0419
New value of Value function: 10.0419
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1195
New value of Q matrix: 10.039
New value of Value function: 10.039
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1196
New value of Q matrix: 10.0361
New value of Value function: 10.0361
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1197
New value of Q matrix: 10.0332
New value of Value function: 10.0332
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 8.00025
New value of Value function: 10.0332
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 182
New value of Q matrix: 8.3388
New value of Value function: 10.0332
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1198
New value of Q matrix: 10.0303
New value of Value function: 10.0303
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1199
New value of Q matrix: 10.0274
New value of Value function: 10.0274
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1200
New value of Q matrix: 10.0245
New value of Value function: 10.0245
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 7.66894
New value of Value function: 10.0245
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 8.13302
New value of Value function: 10.0245
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1201
New value of Q matrix: 10.0216
New value of Value function: 10.0216
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1202
New value of Q matrix: 10.0187
New value of Value function: 10.0187
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1203
New value of Q matrix: 10.0159
New value of Value function: 10.0159
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1204
New value of Q matrix: 10.013
New value of Value function: 10.013
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1205
New value of Q matrix: 10.0101
New value of Value function: 10.0101
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1206
New value of Q matrix: 10.0072
New value of Value function: 10.0072
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1207
New value of Q matrix: 10.0043
New value of Value function: 10.0043
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 8.25496
New value of Value function: 10.0043
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1208
New value of Q matrix: 10.0014
New value of Value function: 10.0014
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 7.54427
New value of Value function: 10.0014
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 7.69771
New value of Value function: 10.0014
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1209
New value of Q matrix: 9.99857
New value of Value function: 9.99857
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1210
New value of Q matrix: 9.9957
New value of Value function: 9.9957
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 183
New value of Q matrix: 8.4539
New value of Value function: 9.9957
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1211
New value of Q matrix: 9.99282
New value of Value function: 9.99282
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1212
New value of Q matrix: 9.98995
New value of Value function: 9.98995
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1213
New value of Q matrix: 9.98709
New value of Value function: 9.98709
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1214
New value of Q matrix: 9.98422
New value of Value function: 9.98422
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1215
New value of Q matrix: 9.98135
New value of Value function: 9.98135
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1216
New value of Q matrix: 9.97849
New value of Value function: 9.97849
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1217
New value of Q matrix: 9.97563
New value of Value function: 9.97563
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1218
New value of Q matrix: 9.97277
New value of Value function: 9.97277
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1219
New value of Q matrix: 9.96992
New value of Value function: 9.96992
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1220
New value of Q matrix: 9.96706
New value of Value function: 9.96706
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1221
New value of Q matrix: 9.96421
New value of Value function: 9.96421
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1222
New value of Q matrix: 9.96136
New value of Value function: 9.96136
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1223
New value of Q matrix: 9.95851
New value of Value function: 9.95851
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1224
New value of Q matrix: 9.95566
New value of Value function: 9.95566
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1225
New value of Q matrix: 9.95282
New value of Value function: 9.95282
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1226
New value of Q matrix: 9.94998
New value of Value function: 9.94998
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1227
New value of Q matrix: 9.94714
New value of Value function: 9.94714
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1228
New value of Q matrix: 9.9443
New value of Value function: 9.9443
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1229
New value of Q matrix: 9.94146
New value of Value function: 9.94146
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1230
New value of Q matrix: 10.0072
New value of Value function: 10.0072
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 65
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 15.8523
New value of Value function: 15.8523
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 66
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 18.5703
New value of Value function: 20.7318
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 67
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 9.49862
New value of Value function: 9.49862
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 68
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 7.11181
New value of Value function: 7.11181
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 69
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.00475
New value of Value function: 5.18023
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 70
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 22.14
New value of Value function: 22.14
New value of Policy matrix: 3

=======================================
Simulation: 42
Iteration: 71
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 33.6987
New value of Value function: 33.6987
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 72
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 33.0334
New value of Value function: 33.0334
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 73
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 23.6514
New value of Value function: 23.6514
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 74
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 8.81539
New value of Value function: 8.81539
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 75
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 5.4841
New value of Value function: 5.4841
New value of Policy matrix: 2

=======================================
Simulation: 42
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1231
New value of Q matrix: 10.0044
New value of Value function: 10.0044
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1232
New value of Q matrix: 10.0015
New value of Value function: 10.0015
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1233
New value of Q matrix: 9.99866
New value of Value function: 9.99866
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 8.36785
New value of Value function: 9.99866
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1234
New value of Q matrix: 9.99581
New value of Value function: 9.99581
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1235
New value of Q matrix: 9.99297
New value of Value function: 9.99297
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1236
New value of Q matrix: 9.99013
New value of Value function: 9.99013
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1237
New value of Q matrix: 9.98729
New value of Value function: 9.98729
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 184
New value of Q matrix: 8.55958
New value of Value function: 9.98729
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 185
New value of Q matrix: 8.6572
New value of Value function: 9.98729
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1238
New value of Q matrix: 9.98445
New value of Value function: 9.98445
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1239
New value of Q matrix: 9.98161
New value of Value function: 9.98161
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1240
New value of Q matrix: 9.97878
New value of Value function: 9.97878
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1241
New value of Q matrix: 9.97594
New value of Value function: 9.97594
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1242
New value of Q matrix: 9.97311
New value of Value function: 9.97311
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 8.47101
New value of Value function: 9.97311
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1243
New value of Q matrix: 9.97029
New value of Value function: 9.97029
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1244
New value of Q matrix: 9.96746
New value of Value function: 9.96746
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1245
New value of Q matrix: 9.96463
New value of Value function: 9.96463
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1246
New value of Q matrix: 9.96181
New value of Value function: 9.96181
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1247
New value of Q matrix: 9.95899
New value of Value function: 9.95899
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 7.8086
New value of Value function: 9.95899
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 186
New value of Q matrix: 8.74535
New value of Value function: 9.95899
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1248
New value of Q matrix: 9.95617
New value of Value function: 9.95617
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1249
New value of Q matrix: 9.95335
New value of Value function: 9.95335
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 8.56554
New value of Value function: 9.95335
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 8.6534
New value of Value function: 9.95335
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1250
New value of Q matrix: 9.95054
New value of Value function: 9.95054
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1251
New value of Q matrix: 9.94772
New value of Value function: 9.94772
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1252
New value of Q matrix: 9.94491
New value of Value function: 9.94491
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 187
New value of Q matrix: 8.8258
New value of Value function: 9.94491
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1253
New value of Q matrix: 9.9421
New value of Value function: 9.9421
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 7.93803
New value of Value function: 9.9421
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 188
New value of Q matrix: 8.89996
New value of Value function: 9.9421
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1254
New value of Q matrix: 9.9393
New value of Value function: 9.9393
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1255
New value of Q matrix: 9.93649
New value of Value function: 9.93649
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1256
New value of Q matrix: 9.93369
New value of Value function: 9.93369
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1257
New value of Q matrix: 9.93089
New value of Value function: 9.93089
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 8.05827
New value of Value function: 9.93089
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 8.17065
New value of Value function: 9.93089
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 8.27569
New value of Value function: 9.93089
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1258
New value of Q matrix: 9.92809
New value of Value function: 9.92809
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1259
New value of Q matrix: 9.92529
New value of Value function: 9.92529
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 7.83596
New value of Value function: 9.92529
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1260
New value of Q matrix: 9.92249
New value of Value function: 9.92249
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1261
New value of Q matrix: 9.9197
New value of Value function: 9.9197
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1262
New value of Q matrix: 9.9169
New value of Value function: 9.9169
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1263
New value of Q matrix: 9.91411
New value of Value function: 9.91411
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1264
New value of Q matrix: 9.91133
New value of Value function: 9.91133
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1265
New value of Q matrix: 9.90854
New value of Value function: 9.90854
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1266
New value of Q matrix: 9.90575
New value of Value function: 9.90575
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1267
New value of Q matrix: 9.90297
New value of Value function: 9.90297
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1268
New value of Q matrix: 9.90019
New value of Value function: 9.90019
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 7.96335
New value of Value function: 9.90019
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1269
New value of Q matrix: 9.89741
New value of Value function: 9.89741
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1270
New value of Q matrix: 9.89463
New value of Value function: 9.89463
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1271
New value of Q matrix: 9.89186
New value of Value function: 9.89186
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1272
New value of Q matrix: 9.88908
New value of Value function: 9.88908
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1273
New value of Q matrix: 9.88631
New value of Value function: 9.88631
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 8.08134
New value of Value function: 9.88631
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1274
New value of Q matrix: 9.88354
New value of Value function: 9.88354
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1275
New value of Q matrix: 9.88078
New value of Value function: 9.88078
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1276
New value of Q matrix: 9.87801
New value of Value function: 9.87801
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1277
New value of Q matrix: 9.87525
New value of Value function: 9.87525
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1278
New value of Q matrix: 9.87248
New value of Value function: 9.87248
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 216
New value of Q matrix: 8.72963
New value of Value function: 9.87248
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1279
New value of Q matrix: 9.86972
New value of Value function: 9.86972
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 189
New value of Q matrix: 8.96332
New value of Value function: 9.86972
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1280
New value of Q matrix: 9.86696
New value of Value function: 9.86696
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1281
New value of Q matrix: 9.86421
New value of Value function: 9.86421
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1282
New value of Q matrix: 9.86145
New value of Value function: 9.86145
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1283
New value of Q matrix: 9.8587
New value of Value function: 9.8587
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1284
New value of Q matrix: 9.85595
New value of Value function: 9.85595
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1285
New value of Q matrix: 9.8532
New value of Value function: 9.8532
New value of Policy matrix: 1

=======================================
Simulation: 42
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1286
New value of Q matrix: 9.66209
New value of Value function: 9.66209
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1287
New value of Q matrix: 9.6594
New value of Value function: 9.6594
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1288
New value of Q matrix: 9.65671
New value of Value function: 9.65671
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1289
New value of Q matrix: 9.65402
New value of Value function: 9.65402
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1290
New value of Q matrix: 9.63414
New value of Value function: 9.63414
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 5
----------
State: 3433
	Distance: 5
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 15.459
New value of Value function: 15.459
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 6
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 13.7418
New value of Value function: 13.7418
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 7
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 9.17528
New value of Value function: 9.2118
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 8
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 23
New value of Q matrix: 8.65423
New value of Value function: 9.17528
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1291
New value of Q matrix: 9.70231
New value of Value function: 9.70231
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 10
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 9.14983
New value of Value function: 9.14983
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 11
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 9.12538
New value of Value function: 9.12538
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 12
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 5.53065
New value of Value function: 9.12538
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 8.78907
New value of Value function: 9.70231
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1292
New value of Q matrix: 9.69961
New value of Value function: 9.69961
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 8.35945
New value of Value function: 9.69961
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 190
New value of Q matrix: 9.0097
New value of Value function: 9.69961
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1293
New value of Q matrix: 9.76453
New value of Value function: 9.76453
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 18
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 9.10182
New value of Value function: 9.10182
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 19
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 24
New value of Q matrix: 8.24857
New value of Value function: 9.10182
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1294
New value of Q matrix: 9.82698
New value of Value function: 9.82698
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 21
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 9.07906
New value of Value function: 9.07906
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 22
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 12.3845
New value of Value function: 12.3845
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 23
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 29.0963
New value of Value function: 29.0963
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 24
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 16.7331
New value of Value function: 43.6869
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 25
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 7
New value of Q matrix: 25.9812
New value of Value function: 25.9812
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 26
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 52.0663
New value of Value function: 52.0663
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 27
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 30.6002
New value of Value function: 61.8185
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 28
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 19
New value of Q matrix: 63.3122
New value of Value function: 63.3122
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 29
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 68.6134
New value of Value function: 68.6134
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 30
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 65.9272
New value of Value function: 77.3474
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 31
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 70.6465
New value of Value function: 70.6465
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 32
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 80.5265
New value of Value function: 80.5265
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 33
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 93.2883
New value of Value function: 93.2883
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 34
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 89.1702
New value of Value function: 99.0787
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 35
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 78.355
New value of Value function: 78.355
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 36
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 10.8172
New value of Value function: 10.8172
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 37
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 19.7344
New value of Value function: 19.7344
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 38
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.32527
New value of Value function: 4.32527
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 39
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.3003
New value of Value function: 4.3003
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 40
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 26.9412
New value of Value function: 26.9412
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 41
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 32.3502
New value of Value function: 32.3502
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 42
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 15.7058
New value of Value function: 15.7058
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 43
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 27.2064
New value of Value function: 27.2064
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 44
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 27.0493
New value of Value function: 27.0493
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 45
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 2.56843
New value of Value function: 27.0493
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1295
New value of Q matrix: 10.0693
New value of Value function: 10.0693
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 47
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 19.2999
New value of Value function: 19.2999
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 48
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 26.9141
New value of Value function: 26.9141
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 49
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 6.68161
New value of Value function: 26.9141
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 50
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 19.1069
New value of Value function: 19.1069
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 51
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 21.9938
New value of Value function: 21.9938
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 52
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 22.3792
New value of Value function: 22.3792
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 53
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 21.3375
New value of Value function: 21.3375
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 54
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 20.5333
New value of Value function: 20.5333
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 55
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 21.127
New value of Value function: 21.127
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 56
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 20.7541
New value of Value function: 20.7541
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 57
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 21.0085
New value of Value function: 21.0085
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 58
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 20.7763
New value of Value function: 20.7763
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 59
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 20.9665
New value of Value function: 20.9665
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 60
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 20.8885
New value of Value function: 20.8885
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 61
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 20.733
New value of Value function: 20.733
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 62
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 20.8187
New value of Value function: 20.8187
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 63
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 20.683
New value of Value function: 20.683
New value of Policy matrix: 0

=======================================
Simulation: 43
Iteration: 64
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 20.7539
New value of Value function: 20.7539
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 65
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 35.5942
New value of Value function: 35.5942
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 66
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 55.8078
New value of Value function: 55.8078
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 67
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 72.8615
New value of Value function: 72.8615
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 68
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 83.599
New value of Value function: 83.599
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 69
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 95.4796
New value of Value function: 95.4796
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 70
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 102.035
New value of Value function: 102.035
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 71
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 99.5485
New value of Value function: 99.5485
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 72
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 36.1103
New value of Value function: 99.843
New value of Policy matrix: 4

=======================================
Simulation: 43
Iteration: 73
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: 68.6606
New value of Value function: 68.6606
New value of Policy matrix: 3

=======================================
Simulation: 43
Iteration: 74
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 97.7786
New value of Value function: 97.7786
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 75
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 18.0958
New value of Value function: 102.035
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 76
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 58.9861
New value of Value function: 58.9861
New value of Policy matrix: 2

=======================================
Simulation: 43
Iteration: 77
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 14.4365
New value of Value function: 98.8103
New value of Policy matrix: 1

=======================================
Simulation: 43
Iteration: 78
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1554
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 44
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1296
New value of Q matrix: 10.0665
New value of Value function: 10.0665
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1297
New value of Q matrix: 10.0637
New value of Value function: 10.0637
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1298
New value of Q matrix: 10.061
New value of Value function: 10.061
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1299
New value of Q matrix: 10.1295
New value of Value function: 10.1295
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 5
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 7.98596
New value of Value function: 7.98596
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 6
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.9061
New value of Value function: 7.9061
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 7
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 7.91489
New value of Value function: 7.91489
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 8
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 7.85635
New value of Value function: 7.85635
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 9
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 1.96536
New value of Value function: 7.91489
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 10
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 2
New value of Q matrix: 13.5932
New value of Value function: 13.5932
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 11
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 12
New value of Q matrix: 4.46786
New value of Value function: 4.46786
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 12
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 8.20327
New value of Value function: 8.20327
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 13
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 13.3207
New value of Value function: 13.3207
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 14
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 8.19538
New value of Value function: 8.19538
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 15
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 13.2171
New value of Value function: 13.2171
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 16
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 8.14597
New value of Value function: 8.14597
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 17
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 5
New value of Q matrix: 13.7565
New value of Value function: 13.7565
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 18
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 2.15229
New value of Value function: 4.46786
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 19
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 8.33904
New value of Value function: 8.33904
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 20
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 13.552
New value of Value function: 13.552
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 21
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 8.36831
New value of Value function: 8.36831
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 22
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 13.4509
New value of Value function: 13.4509
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 23
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 8.34997
New value of Value function: 8.34997
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 24
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 13.3857
New value of Value function: 13.3857
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 25
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 7.7574
New value of Value function: 8.34997
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 26
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 13
New value of Q matrix: 4.13466
New value of Value function: 4.13466
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 27
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 8.17856
New value of Value function: 8.17856
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 28
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 5.59487
New value of Value function: 7.91489
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 29
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 13.2894
New value of Value function: 13.2894
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 30
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 8.17159
New value of Value function: 8.17159
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 31
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.02817
New value of Value function: 13.2894
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1300
New value of Q matrix: 10.2966
New value of Value function: 10.2966
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 33
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.19366
New value of Value function: 13.2894
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1301
New value of Q matrix: 10.4591
New value of Value function: 10.4591
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 35
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 13.2263
New value of Value function: 13.2263
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 36
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.35449
New value of Value function: 8.17159
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1302
New value of Q matrix: 10.4695
New value of Value function: 10.4695
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 38
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.50035
New value of Value function: 7.91489
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1303
New value of Q matrix: 10.6253
New value of Value function: 10.6253
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 40
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 13.1852
New value of Value function: 13.1852
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 41
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 8.30278
New value of Value function: 8.30278
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 42
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 3.89014
New value of Value function: 3.89014
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 43
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 8.51008
New value of Value function: 8.51008
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 44
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -10
New value of Visit matrix: 15
New value of Q matrix: 3.67407
New value of Value function: 3.67407
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 45
----------
State: 4533
	Distance: 7
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 12
New value of Q matrix: 13.3157
New value of Value function: 13.3157
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 46
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 3.66489
New value of Value function: 3.66489
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 47
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 8.96662
New value of Value function: 8.96662
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 48
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -10
New value of Visit matrix: 12
New value of Q matrix: 9.76059
New value of Value function: 20.7318
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 49
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 10
New value of Visit matrix: 6
New value of Q matrix: 17.1452
New value of Value function: 17.1452
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 50
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 8.81363
New value of Value function: 18.5703
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 51
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 12.365
New value of Value function: 12.365
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 52
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 10.454
New value of Value function: 18.5703
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 53
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 11.931
New value of Value function: 12.3845
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 54
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 35.5793
New value of Value function: 35.5793
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 55
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 20
New value of Q matrix: 65.9554
New value of Value function: 65.9554
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 56
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 75.1956
New value of Value function: 75.1956
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 57
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 31
New value of Q matrix: 69.8412
New value of Value function: 69.8412
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 58
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 6.33851
New value of Value function: 6.33851
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 59
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 8.77998
New value of Value function: 8.77998
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 60
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 5.69635
New value of Value function: 8.81539
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 61
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 9.11488
New value of Value function: 9.11488
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 62
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 6.07411
New value of Value function: 8.81539
New value of Policy matrix: 2

=======================================
Simulation: 44
Iteration: 63
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 4.71522
New value of Value function: 8.50211
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 64
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 65
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 66
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.48348
New value of Value function: 5.48348
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 67
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 8.46981
New value of Value function: 8.46981
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 68
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 5.41392
New value of Value function: 5.41392
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 69
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 8.40629
New value of Value function: 8.40629
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 70
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.36098
New value of Value function: 5.36098
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 71
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 8.32222
New value of Value function: 8.40629
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 72
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 8.35683
New value of Value function: 8.35683
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 73
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 5.31712
New value of Value function: 5.31712
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 74
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 8.31529
New value of Value function: 8.32222
New value of Policy matrix: 4

=======================================
Simulation: 44
Iteration: 75
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.28218
New value of Value function: 5.28218
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 76
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 8.53738
New value of Value function: 8.53738
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 77
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 21
New value of Q matrix: 10.5943
New value of Value function: 10.5943
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 78
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 8.49831
New value of Value function: 8.49831
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 79
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 22
New value of Q matrix: 10.5557
New value of Value function: 10.5557
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 80
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 8.48545
New value of Value function: 8.48545
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 81
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 10.5234
New value of Value function: 10.5234
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 82
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: 8.46808
New value of Value function: 8.46808
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 83
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 10.4948
New value of Value function: 10.4948
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 84
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: 8.44852
New value of Value function: 8.44852
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 85
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 10.4687
New value of Value function: 10.4687
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 86
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 17
New value of Q matrix: 8.42802
New value of Value function: 8.42802
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 87
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.80352
New value of Value function: 10.4687
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 88
----------
State: 1889
	Distance: 3
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 5.37086
New value of Value function: 5.37086
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 89
----------
State: 1837
	Distance: 3
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 8.41477
New value of Value function: 8.41477
New value of Policy matrix: 3

=======================================
Simulation: 44
Iteration: 90
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 8.07534
New value of Value function: 10.4687
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 91
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 7.35084
New value of Value function: 7.35084
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 92
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 5.5016
New value of Value function: 10.4687
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 93
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 7.80393
New value of Value function: 7.80393
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 94
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 10.4442
New value of Value function: 10.4442
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 95
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 18
New value of Q matrix: 8.40721
New value of Value function: 8.40721
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 96
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 10.4209
New value of Value function: 10.4209
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 97
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 19
New value of Q matrix: 8.38644
New value of Value function: 8.38644
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 98
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 10.3985
New value of Value function: 10.3985
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 99
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 20
New value of Q matrix: 8.36588
New value of Value function: 8.36588
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 100
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 7.61375
New value of Value function: 10.3985
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 101
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 7.72589
New value of Value function: 7.80393
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 102
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.51909
New value of Value function: 7.80393
New value of Policy matrix: 0

=======================================
Simulation: 44
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1304
New value of Q matrix: 10.6224
New value of Value function: 10.6224
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1305
New value of Q matrix: 10.6195
New value of Value function: 10.6195
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1306
New value of Q matrix: 10.6165
New value of Value function: 10.6165
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1307
New value of Q matrix: 10.6136
New value of Value function: 10.6136
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 191
New value of Q matrix: 9.11808
New value of Value function: 10.6136
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1308
New value of Q matrix: 10.6106
New value of Value function: 10.6106
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1309
New value of Q matrix: 10.6077
New value of Value function: 10.6077
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1310
New value of Q matrix: 10.6048
New value of Value function: 10.6048
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 8.90486
New value of Value function: 10.6048
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 192
New value of Q matrix: 9.21772
New value of Value function: 10.6048
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 9.01257
New value of Value function: 10.6048
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1311
New value of Q matrix: 10.6019
New value of Value function: 10.6019
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1312
New value of Q matrix: 10.5989
New value of Value function: 10.5989
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 8.23701
New value of Value function: 10.5989
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 220
New value of Q matrix: 9.11237
New value of Value function: 10.5989
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 193
New value of Q matrix: 9.30951
New value of Value function: 10.5989
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 194
New value of Q matrix: 9.39447
New value of Value function: 10.5989
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1313
New value of Q matrix: 10.596
New value of Value function: 10.596
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1314
New value of Q matrix: 10.5931
New value of Value function: 10.5931
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1315
New value of Q matrix: 10.5902
New value of Value function: 10.5902
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 8.38176
New value of Value function: 10.5902
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1316
New value of Q matrix: 10.5872
New value of Value function: 10.5872
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1317
New value of Q matrix: 10.5843
New value of Value function: 10.5843
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 8.51655
New value of Value function: 10.5843
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 9.20427
New value of Value function: 10.5843
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1318
New value of Q matrix: 10.5814
New value of Value function: 10.5814
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 195
New value of Q matrix: 9.47189
New value of Value function: 10.5814
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 8.64222
New value of Value function: 10.5814
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1319
New value of Q matrix: 10.5785
New value of Value function: 10.5785
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1320
New value of Q matrix: 10.5756
New value of Value function: 10.5756
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1321
New value of Q matrix: 10.5727
New value of Value function: 10.5727
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1322
New value of Q matrix: 10.5698
New value of Value function: 10.5698
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1323
New value of Q matrix: 10.5669
New value of Value function: 10.5669
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1324
New value of Q matrix: 10.564
New value of Value function: 10.564
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 196
New value of Q matrix: 9.54235
New value of Value function: 10.564
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1325
New value of Q matrix: 10.5611
New value of Value function: 10.5611
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1326
New value of Q matrix: 10.5582
New value of Value function: 10.5582
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 8.4913
New value of Value function: 10.5582
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1327
New value of Q matrix: 10.5553
New value of Value function: 10.5553
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1328
New value of Q matrix: 10.5524
New value of Value function: 10.5524
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1329
New value of Q matrix: 10.5495
New value of Value function: 10.5495
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 8.61406
New value of Value function: 10.5495
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1330
New value of Q matrix: 10.5466
New value of Value function: 10.5466
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1331
New value of Q matrix: 10.5437
New value of Value function: 10.5437
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1332
New value of Q matrix: 10.5408
New value of Value function: 10.5408
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1333
New value of Q matrix: 10.5379
New value of Value function: 10.5379
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 9.2867
New value of Value function: 10.5379
New value of Policy matrix: 1

=======================================
Simulation: 44
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1334
New value of Q matrix: 10.535
New value of Value function: 10.535
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 1
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.7597
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 2
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.242199
New value of Value function: 0.242199
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 3
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.241683
New value of Value function: 0.241683
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 4
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.241179
New value of Value function: 0.241179
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 5
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.240686
New value of Value function: 0.240686
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 6
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.240205
New value of Value function: 0.240205
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 7
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: -0.0502525
New value of Value function: 0.240205
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 8
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 9
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: -1.7622
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 10
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.239734
New value of Value function: 0.239734
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 11
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.239273
New value of Value function: 0.239273
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 12
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.23882
New value of Value function: 0.23882
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 13
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.238377
New value of Value function: 0.238377
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 14
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.237942
New value of Value function: 0.237942
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 15
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.237514
New value of Value function: 0.237514
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 16
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5.06107
New value of Value function: 5.06107
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 17
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.04972
New value of Value function: 7.04972
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 18
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 10.0497
New value of Value function: 10.1512
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 19
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.348486
New value of Value function: 10.1512
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 20
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 9.87411
New value of Value function: 9.87411
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 21
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.144799
New value of Value function: 10.0497
New value of Policy matrix: 4

=======================================
Simulation: 45
Iteration: 22
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 23
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 24
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 25
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 26
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 23.2358
New value of Value function: 23.2358
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 27
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 18.4067
New value of Value function: 18.4067
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 28
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 14.4231
New value of Value function: 14.4231
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 29
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 26.0898
New value of Value function: 26.0898
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 30
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 40.9769
New value of Value function: 40.9769
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 31
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 58.0298
New value of Value function: 58.0298
New value of Policy matrix: 0

=======================================
Simulation: 45
Iteration: 32
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: 52.3174
New value of Value function: 78.4823
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 33
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 75.4909
New value of Value function: 75.4909
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 34
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 99.5346
New value of Value function: 99.5346
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 35
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 102.912
New value of Value function: 102.912
New value of Policy matrix: 2

=======================================
Simulation: 45
Iteration: 36
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 99.6809
New value of Value function: 99.6809
New value of Policy matrix: 1

=======================================
Simulation: 45
Iteration: 37
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 14
New value of Q matrix: 99.885
New value of Value function: 99.885
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1335
New value of Q matrix: 10.5321
New value of Value function: 10.5321
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1336
New value of Q matrix: 10.5293
New value of Value function: 10.5293
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 8.72763
New value of Value function: 10.5293
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1337
New value of Q matrix: 10.5264
New value of Value function: 10.5264
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1338
New value of Q matrix: 10.5235
New value of Value function: 10.5235
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1339
New value of Q matrix: 10.5206
New value of Value function: 10.5206
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1340
New value of Q matrix: 10.5177
New value of Value function: 10.5177
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1341
New value of Q matrix: 10.5149
New value of Value function: 10.5149
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1342
New value of Q matrix: 10.512
New value of Value function: 10.512
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 9.36172
New value of Value function: 10.512
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1343
New value of Q matrix: 10.5091
New value of Value function: 10.5091
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1344
New value of Q matrix: 10.5063
New value of Value function: 10.5063
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1345
New value of Q matrix: 10.5034
New value of Value function: 10.5034
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1346
New value of Q matrix: 10.5005
New value of Value function: 10.5005
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1347
New value of Q matrix: 10.4977
New value of Value function: 10.4977
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1348
New value of Q matrix: 10.4948
New value of Value function: 10.4948
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1349
New value of Q matrix: 10.492
New value of Value function: 10.492
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1350
New value of Q matrix: 10.4891
New value of Value function: 10.4891
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 9.43003
New value of Value function: 10.4891
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 8.75374
New value of Value function: 10.4891
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 8.85791
New value of Value function: 10.4891
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 8.95522
New value of Value function: 10.4891
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1351
New value of Q matrix: 10.4863
New value of Value function: 10.4863
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1352
New value of Q matrix: 10.4834
New value of Value function: 10.4834
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1353
New value of Q matrix: 10.4806
New value of Value function: 10.4806
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 197
New value of Q matrix: 9.60173
New value of Value function: 10.4806
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1354
New value of Q matrix: 10.4777
New value of Value function: 10.4777
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 9.49289
New value of Value function: 10.4777
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1355
New value of Q matrix: 10.4749
New value of Value function: 10.4749
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1356
New value of Q matrix: 10.472
New value of Value function: 10.472
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1357
New value of Q matrix: 10.4692
New value of Value function: 10.4692
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1358
New value of Q matrix: 10.4663
New value of Value function: 10.4663
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1359
New value of Q matrix: 10.4635
New value of Value function: 10.4635
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 198
New value of Q matrix: 9.65554
New value of Value function: 10.4635
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1360
New value of Q matrix: 10.4607
New value of Value function: 10.4607
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1361
New value of Q matrix: 10.4578
New value of Value function: 10.4578
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 9.04417
New value of Value function: 10.4578
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1362
New value of Q matrix: 10.455
New value of Value function: 10.455
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1363
New value of Q matrix: 10.4521
New value of Value function: 10.4521
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1364
New value of Q matrix: 10.4493
New value of Value function: 10.4493
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1365
New value of Q matrix: 10.4465
New value of Value function: 10.4465
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1366
New value of Q matrix: 10.4437
New value of Value function: 10.4437
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1367
New value of Q matrix: 10.4408
New value of Value function: 10.4408
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1368
New value of Q matrix: 10.438
New value of Value function: 10.438
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1369
New value of Q matrix: 10.4352
New value of Value function: 10.4352
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1370
New value of Q matrix: 10.4324
New value of Value function: 10.4324
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1371
New value of Q matrix: 10.4296
New value of Value function: 10.4296
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 9.12552
New value of Value function: 10.4296
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1372
New value of Q matrix: 10.4267
New value of Value function: 10.4267
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1373
New value of Q matrix: 10.4239
New value of Value function: 10.4239
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1374
New value of Q matrix: 10.4211
New value of Value function: 10.4211
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 8.82715
New value of Value function: 10.4211
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1375
New value of Q matrix: 10.4183
New value of Value function: 10.4183
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1376
New value of Q matrix: 10.4155
New value of Value function: 10.4155
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 8.91991
New value of Value function: 10.4155
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1377
New value of Q matrix: 10.4127
New value of Value function: 10.4127
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1378
New value of Q matrix: 10.4099
New value of Value function: 10.4099
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1379
New value of Q matrix: 10.4071
New value of Value function: 10.4071
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1380
New value of Q matrix: 10.4043
New value of Value function: 10.4043
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1381
New value of Q matrix: 10.4015
New value of Value function: 10.4015
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1382
New value of Q matrix: 10.3987
New value of Value function: 10.3987
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1383
New value of Q matrix: 10.3959
New value of Value function: 10.3959
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 9.0055
New value of Value function: 10.3959
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1384
New value of Q matrix: 10.3931
New value of Value function: 10.3931
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1385
New value of Q matrix: 10.4511
New value of Value function: 10.4511
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 66
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 10.0561
New value of Value function: 10.0561
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 67
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 6.11119
New value of Value function: 6.11119
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 68
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 6.10153
New value of Value function: 6.10153
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 69
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 6.092
New value of Value function: 6.092
New value of Policy matrix: 4

=======================================
Simulation: 46
Iteration: 70
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 11.2709
New value of Value function: 11.2709
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 71
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 3
New value of Q matrix: 18.1386
New value of Value function: 18.1386
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 72
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 11.2533
New value of Value function: 11.2533
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 73
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 11.9944
New value of Value function: 11.9944
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 74
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 13.4688
New value of Value function: 13.4688
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 75
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 8.93549
New value of Value function: 8.93549
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 76
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 11.0195
New value of Value function: 12.7037
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 77
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 16.9186
New value of Value function: 16.9186
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 78
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 18.9919
New value of Value function: 22.14
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 79
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: 10.9633
New value of Value function: 23.6514
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 80
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 14.77
New value of Value function: 22.14
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 81
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 50.938
New value of Value function: 50.938
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 82
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 65.2654
New value of Value function: 65.9272
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 83
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 37.0783
New value of Value function: 37.0783
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 84
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 40.2317
New value of Value function: 40.2317
New value of Policy matrix: 3

=======================================
Simulation: 46
Iteration: 85
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 32.1891
New value of Value function: 32.1891
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 86
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 8
New value of Q matrix: 38.5154
New value of Value function: 38.5154
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 87
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 37.1016
New value of Value function: 37.1016
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 88
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 36.5871
New value of Value function: 36.5871
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 89
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 33.5553
New value of Value function: 33.5553
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 90
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 20.4982
New value of Value function: 20.4982
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 91
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 21
New value of Q matrix: 8.35031
New value of Value function: 8.35031
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 92
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 5.61864
New value of Value function: 10.3985
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 93
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 10.3741
New value of Value function: 10.3741
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 94
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.60627
New value of Value function: 8.35031
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 95
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 8.33326
New value of Value function: 8.33326
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 96
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 10.3514
New value of Value function: 10.3514
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 97
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 23
New value of Q matrix: 8.31546
New value of Value function: 8.31546
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 98
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 10.33
New value of Value function: 10.33
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 99
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 8.29734
New value of Value function: 8.29734
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 100
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 10.3096
New value of Value function: 10.3096
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 101
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 5.77477
New value of Value function: 8.29734
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 102
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 7.42926
New value of Value function: 7.42926
New value of Policy matrix: 0

=======================================
Simulation: 46
Iteration: 103
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 5.1019
New value of Value function: 5.1019
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 104
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 4.85386
New value of Value function: 4.85386
New value of Policy matrix: 2

=======================================
Simulation: 46
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1386
New value of Q matrix: 10.4483
New value of Value function: 10.4483
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1387
New value of Q matrix: 10.4455
New value of Value function: 10.4455
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1388
New value of Q matrix: 10.4427
New value of Value function: 10.4427
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1389
New value of Q matrix: 10.4399
New value of Value function: 10.4399
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 9.54894
New value of Value function: 10.4399
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1390
New value of Q matrix: 10.4371
New value of Value function: 10.4371
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1391
New value of Q matrix: 10.4343
New value of Value function: 10.4343
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1392
New value of Q matrix: 10.4315
New value of Value function: 10.4315
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 9.20168
New value of Value function: 10.4315
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1393
New value of Q matrix: 10.4287
New value of Value function: 10.4287
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 9.27268
New value of Value function: 10.4287
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 9.08761
New value of Value function: 10.4287
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1394
New value of Q matrix: 10.4259
New value of Value function: 10.4259
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1395
New value of Q matrix: 10.4231
New value of Value function: 10.4231
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 9.60005
New value of Value function: 10.4231
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1396
New value of Q matrix: 10.4203
New value of Value function: 10.4203
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1397
New value of Q matrix: 10.4175
New value of Value function: 10.4175
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 9.33837
New value of Value function: 10.4175
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1398
New value of Q matrix: 10.4148
New value of Value function: 10.4148
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1399
New value of Q matrix: 10.412
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 9.39944
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 9.16343
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1400
New value of Q matrix: 10.4092
New value of Value function: 10.4092
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 199
New value of Q matrix: 9.70158
New value of Value function: 10.4092
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1401
New value of Q matrix: 10.4064
New value of Value function: 10.4064
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1402
New value of Q matrix: 10.4036
New value of Value function: 10.4036
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 9.45603
New value of Value function: 10.4036
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1403
New value of Q matrix: 10.4009
New value of Value function: 10.4009
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 9.23372
New value of Value function: 10.4009
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1404
New value of Q matrix: 10.3981
New value of Value function: 10.3981
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1405
New value of Q matrix: 10.3953
New value of Value function: 10.3953
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1406
New value of Q matrix: 10.3925
New value of Value function: 10.3925
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1407
New value of Q matrix: 10.3898
New value of Value function: 10.3898
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1408
New value of Q matrix: 10.387
New value of Value function: 10.387
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1409
New value of Q matrix: 10.3842
New value of Value function: 10.3842
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1410
New value of Q matrix: 10.3815
New value of Value function: 10.3815
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1411
New value of Q matrix: 10.3787
New value of Value function: 10.3787
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1412
New value of Q matrix: 10.3759
New value of Value function: 10.3759
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1413
New value of Q matrix: 10.3732
New value of Value function: 10.3732
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1414
New value of Q matrix: 10.3704
New value of Value function: 10.3704
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1415
New value of Q matrix: 10.3677
New value of Value function: 10.3677
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1416
New value of Q matrix: 10.3649
New value of Value function: 10.3649
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1417
New value of Q matrix: 10.3621
New value of Value function: 10.3621
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 9.29716
New value of Value function: 10.3621
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1418
New value of Q matrix: 10.3594
New value of Value function: 10.3594
New value of Policy matrix: 1

=======================================
Simulation: 46
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 9.35638
New value of Value function: 10.3594
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 1
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 2
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 3
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 4
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 5
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 6
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 1.87092
New value of Value function: 1.87092
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 7
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 1
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 8
----------
State: 2373
	Distance: 4
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 0.852215
New value of Value function: 0.852215
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 9
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 1.86431
New value of Value function: 1.86431
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 10
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 1.8581
New value of Value function: 1.8581
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 11
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 1.85222
New value of Value function: 1.85222
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 12
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 1.84663
New value of Value function: 1.84663
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 13
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 1.8413
New value of Value function: 1.8413
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 14
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 1.8362
New value of Value function: 1.8362
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 15
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 1.83129
New value of Value function: 1.83129
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 16
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 1.82656
New value of Value function: 1.82656
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 17
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 1.82199
New value of Value function: 1.82199
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 18
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 1.81758
New value of Value function: 1.81758
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 19
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 1.81329
New value of Value function: 1.81329
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 20
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 1.80913
New value of Value function: 1.80913
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 21
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 1.80509
New value of Value function: 1.80509
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 22
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 1.80115
New value of Value function: 1.80115
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 23
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 1.79731
New value of Value function: 1.79731
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 24
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 1.79356
New value of Value function: 1.79356
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 25
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 1.7899
New value of Value function: 1.7899
New value of Policy matrix: 4

=======================================
Simulation: 47
Iteration: 26
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.2558
New value of Value function: 7.2558
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 228
New value of Q matrix: 9.63867
New value of Value function: 10.3594
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 28
----------
State: 3001
	Distance: 5
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.2558
New value of Value function: 7.2558
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 9.41184
New value of Value function: 10.3594
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1419
New value of Q matrix: 10.3566
New value of Value function: 10.3566
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1420
New value of Q matrix: 10.3539
New value of Value function: 10.3539
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1421
New value of Q matrix: 10.3511
New value of Value function: 10.3511
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1422
New value of Q matrix: 10.3484
New value of Value function: 10.3484
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1423
New value of Q matrix: 10.3457
New value of Value function: 10.3457
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1424
New value of Q matrix: 10.3429
New value of Value function: 10.3429
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 9.50519
New value of Value function: 10.3429
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1425
New value of Q matrix: 10.3402
New value of Value function: 10.3402
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1426
New value of Q matrix: 10.3374
New value of Value function: 10.3374
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1427
New value of Q matrix: 10.3347
New value of Value function: 10.3347
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 9.67784
New value of Value function: 10.3347
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 9.71433
New value of Value function: 10.3347
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1428
New value of Q matrix: 10.332
New value of Value function: 10.332
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1429
New value of Q matrix: 10.3292
New value of Value function: 10.3292
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1430
New value of Q matrix: 10.3265
New value of Value function: 10.3265
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1431
New value of Q matrix: 10.3238
New value of Value function: 10.3238
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1432
New value of Q matrix: 10.321
New value of Value function: 10.321
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1433
New value of Q matrix: 10.3183
New value of Value function: 10.3183
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1434
New value of Q matrix: 10.3156
New value of Value function: 10.3156
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1435
New value of Q matrix: 10.3129
New value of Value function: 10.3129
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1436
New value of Q matrix: 10.3102
New value of Value function: 10.3102
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1437
New value of Q matrix: 10.3074
New value of Value function: 10.3074
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1438
New value of Q matrix: 10.3047
New value of Value function: 10.3047
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1439
New value of Q matrix: 10.302
New value of Value function: 10.302
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1440
New value of Q matrix: 10.2993
New value of Value function: 10.2993
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1441
New value of Q matrix: 10.2966
New value of Value function: 10.2966
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1442
New value of Q matrix: 10.2939
New value of Value function: 10.2939
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1443
New value of Q matrix: 10.2911
New value of Value function: 10.2911
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1444
New value of Q matrix: 10.2884
New value of Value function: 10.2884
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1445
New value of Q matrix: 10.2857
New value of Value function: 10.2857
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1446
New value of Q matrix: 10.283
New value of Value function: 10.283
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1447
New value of Q matrix: 10.2803
New value of Value function: 10.2803
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1448
New value of Q matrix: 10.2776
New value of Value function: 10.2776
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1449
New value of Q matrix: 10.2749
New value of Value function: 10.2749
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1450
New value of Q matrix: 10.2722
New value of Value function: 10.2722
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1451
New value of Q matrix: 10.2695
New value of Value function: 10.2695
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1452
New value of Q matrix: 10.2668
New value of Value function: 10.2668
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1453
New value of Q matrix: 10.2641
New value of Value function: 10.2641
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1454
New value of Q matrix: 10.2614
New value of Value function: 10.2614
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1455
New value of Q matrix: 10.2588
New value of Value function: 10.2588
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1456
New value of Q matrix: 10.2561
New value of Value function: 10.2561
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 9.45749
New value of Value function: 10.2561
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1457
New value of Q matrix: 10.2534
New value of Value function: 10.2534
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1458
New value of Q matrix: 10.2507
New value of Value function: 10.2507
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1459
New value of Q matrix: 10.248
New value of Value function: 10.248
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 9.54529
New value of Value function: 10.248
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1460
New value of Q matrix: 10.2453
New value of Value function: 10.2453
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1461
New value of Q matrix: 10.2427
New value of Value function: 10.2427
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 9.58248
New value of Value function: 10.2427
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1462
New value of Q matrix: 10.24
New value of Value function: 10.24
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1463
New value of Q matrix: 10.2373
New value of Value function: 10.2373
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1464
New value of Q matrix: 10.2346
New value of Value function: 10.2346
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1465
New value of Q matrix: 10.2319
New value of Value function: 10.2319
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1466
New value of Q matrix: 10.2293
New value of Value function: 10.2293
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1467
New value of Q matrix: 10.2266
New value of Value function: 10.2266
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1468
New value of Q matrix: 10.2239
New value of Value function: 10.2239
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 200
New value of Q matrix: 9.73129
New value of Value function: 10.2239
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1469
New value of Q matrix: 10.2213
New value of Value function: 10.2213
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1470
New value of Q matrix: 10.3877
New value of Value function: 10.3877
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 89
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 14.9859
New value of Value function: 14.9859
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 90
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 26
New value of Q matrix: 11.3842
New value of Value function: 11.931
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1471
New value of Q matrix: 10.5031
New value of Value function: 10.5031
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 92
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 23.5772
New value of Value function: 23.5772
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 93
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 46.8182
New value of Value function: 46.8182
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 94
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 16.4565
New value of Value function: 65.9554
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 95
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 16
New value of Q matrix: 31.7964
New value of Value function: 31.7964
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 96
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 51
New value of Q matrix: 40.6167
New value of Value function: 40.6167
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 97
----------
State: 3289
	Distance: 5
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 54.3107
New value of Value function: 54.3107
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 98
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 28.0174
New value of Value function: 55.8078
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 99
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 48.3792
New value of Value function: 48.3792
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 100
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 41.4898
New value of Value function: 55.8078
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 101
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 19
New value of Q matrix: 56.8374
New value of Value function: 56.8374
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 102
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 21
New value of Q matrix: 68.4623
New value of Value function: 68.4623
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 103
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 31.4755
New value of Value function: 75.1956
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 104
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 30.871
New value of Value function: 42.9068
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 105
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 41.302
New value of Value function: 41.302
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 106
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 52
New value of Q matrix: 41.3478
New value of Value function: 41.3478
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 107
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 9.49912
New value of Value function: 41.302
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 108
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 12.307
New value of Value function: 12.307
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 109
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 32.9761
New value of Value function: 32.9761
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 110
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 54.8838
New value of Value function: 54.8838
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 111
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 71.8735
New value of Value function: 71.8735
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 112
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 44.947
New value of Value function: 44.947
New value of Policy matrix: 3

=======================================
Simulation: 47
Iteration: 113
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 61.8048
New value of Value function: 61.8048
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 114
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 49.5197
New value of Value function: 71.8735
New value of Policy matrix: 2

=======================================
Simulation: 47
Iteration: 115
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 33.6406
New value of Value function: 61.8048
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 116
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 6.51549
New value of Value function: 42.3293
New value of Policy matrix: 0

=======================================
Simulation: 47
Iteration: 117
----------
State: 1265
	Distance: 2
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.19902
New value of Value function: 6.19902
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1472
New value of Q matrix: 10.5004
New value of Value function: 10.5004
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1473
New value of Q matrix: 10.4976
New value of Value function: 10.4976
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1474
New value of Q matrix: 10.4949
New value of Value function: 10.4949
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1475
New value of Q matrix: 10.4922
New value of Value function: 10.4922
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1476
New value of Q matrix: 10.4894
New value of Value function: 10.4894
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 9.75843
New value of Value function: 10.4894
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1477
New value of Q matrix: 10.4867
New value of Value function: 10.4867
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1478
New value of Q matrix: 10.484
New value of Value function: 10.484
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 9.63217
New value of Value function: 10.484
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 9.67867
New value of Value function: 10.484
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 9.79918
New value of Value function: 10.484
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1479
New value of Q matrix: 10.4812
New value of Value function: 10.4812
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 9.51394
New value of Value function: 10.4812
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1480
New value of Q matrix: 10.4785
New value of Value function: 10.4785
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1481
New value of Q matrix: 10.4758
New value of Value function: 10.4758
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1482
New value of Q matrix: 10.4731
New value of Value function: 10.4731
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1483
New value of Q matrix: 10.4704
New value of Value function: 10.4704
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 9.56616
New value of Value function: 10.4704
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1484
New value of Q matrix: 10.4676
New value of Value function: 10.4676
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1485
New value of Q matrix: 10.4649
New value of Value function: 10.4649
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1486
New value of Q matrix: 10.4622
New value of Value function: 10.4622
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 201
New value of Q matrix: 9.77546
New value of Value function: 10.4622
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1487
New value of Q matrix: 10.4595
New value of Value function: 10.4595
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1488
New value of Q matrix: 10.4568
New value of Value function: 10.4568
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1489
New value of Q matrix: 10.4541
New value of Value function: 10.4541
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1490
New value of Q matrix: 10.4514
New value of Value function: 10.4514
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1491
New value of Q matrix: 10.4487
New value of Value function: 10.4487
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1492
New value of Q matrix: 10.4459
New value of Value function: 10.4459
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1493
New value of Q matrix: 10.4432
New value of Value function: 10.4432
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1494
New value of Q matrix: 10.4405
New value of Value function: 10.4405
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 9.71953
New value of Value function: 10.4405
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1495
New value of Q matrix: 10.4378
New value of Value function: 10.4378
New value of Policy matrix: 1

=======================================
Simulation: 47
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1496
New value of Q matrix: 10.4351
New value of Value function: 10.4351
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1497
New value of Q matrix: 10.4324
New value of Value function: 10.4324
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1498
New value of Q matrix: 10.4298
New value of Value function: 10.4298
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 202
New value of Q matrix: 9.81416
New value of Value function: 10.4298
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 9.61263
New value of Value function: 10.4298
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1499
New value of Q matrix: 10.4271
New value of Value function: 10.4271
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1500
New value of Q matrix: 10.5132
New value of Value function: 10.5132
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 7
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 20.4557
New value of Value function: 20.4557
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 8
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -6
New value of Visit matrix: 5
New value of Q matrix: 11.6016
New value of Value function: 18.6117
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 9
----------
State: 4009
	Distance: 6
	Angle: 11
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 22.7477
New value of Value function: 22.7477
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 10
----------
State: 3961
	Distance: 6
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 17.2935
New value of Value function: 17.2935
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 11
----------
State: 4489
	Distance: 7
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 17.1581
New value of Value function: 17.1581
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 22
New value of Q matrix: 22.9893
New value of Value function: 22.9893
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 13
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 30.0195
New value of Value function: 30.0195
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 31.9517
New value of Value function: 31.9517
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 15
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 14
New value of Q matrix: 31.2523
New value of Value function: 31.2523
New value of Policy matrix: 1

=======================================
Simulation: 48
Iteration: 16
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 34.3152
New value of Value function: 34.3152
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 17
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 53
New value of Q matrix: 39.6479
New value of Value function: 39.6479
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 18
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 22.947
New value of Value function: 34.3152
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 19
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 24.0035
New value of Value function: 24.835
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 20
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 33.4256
New value of Value function: 33.4256
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 21
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 31.3478
New value of Value function: 31.3478
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 22
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 34.9318
New value of Value function: 34.9318
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 23
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 40.1981
New value of Value function: 40.1981
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 24
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 58.1419
New value of Value function: 58.1419
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 25
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 64.4772
New value of Value function: 64.4772
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 26
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 27
New value of Q matrix: 67.3748
New value of Value function: 67.3748
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 27
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 30.989
New value of Value function: 44.947
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 28
----------
State: 1941
	Distance: 3
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 10
New value of Q matrix: 49.3379
New value of Value function: 49.3379
New value of Policy matrix: 3

=======================================
Simulation: 48
Iteration: 29
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 23.973
New value of Value function: 64.4772
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 30
----------
State: 2469
	Distance: 4
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 49.0051
New value of Value function: 49.0051
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 31
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 16
New value of Q matrix: 65.2831
New value of Value function: 65.2831
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 32
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 27.9423
New value of Value function: 67.3748
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 33
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 34.1827
New value of Value function: 34.1827
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 34
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 74.9283
New value of Value function: 74.9283
New value of Policy matrix: 0

=======================================
Simulation: 48
Iteration: 35
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 23
New value of Q matrix: 96.206
New value of Value function: 96.206
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 36
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 83.2685
New value of Value function: 83.2685
New value of Policy matrix: 2

=======================================
Simulation: 48
Iteration: 37
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 88.4016
New value of Value function: 99.885
New value of Policy matrix: 4

=======================================
Simulation: 48
Iteration: 38
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 93.1162
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 48
Iteration: 39
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 15
New value of Q matrix: 99.9147
New value of Value function: 99.9147
New value of Policy matrix: 4

=======================================
Simulation: 49
Iteration: 1
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 2
----------
State: 3573
	Distance: 6
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.95
New value of Value function: 9.95
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 3
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.70275
New value of Value function: 6.70275
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 9.76223
New value of Value function: 10.5132
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1501
New value of Q matrix: 10.5105
New value of Value function: 10.5105
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1502
New value of Q matrix: 10.5078
New value of Value function: 10.5078
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1503
New value of Q matrix: 10.505
New value of Value function: 10.505
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1504
New value of Q matrix: 10.5023
New value of Value function: 10.5023
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1505
New value of Q matrix: 10.4996
New value of Value function: 10.4996
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1506
New value of Q matrix: 10.4969
New value of Value function: 10.4969
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1507
New value of Q matrix: 10.4942
New value of Value function: 10.4942
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 203
New value of Q matrix: 9.85453
New value of Value function: 10.4942
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1508
New value of Q matrix: 10.4915
New value of Value function: 10.4915
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 204
New value of Q matrix: 9.89178
New value of Value function: 10.4915
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 205
New value of Q matrix: 9.92634
New value of Value function: 10.4915
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1509
New value of Q matrix: 10.4888
New value of Value function: 10.4888
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 233
New value of Q matrix: 9.83749
New value of Value function: 10.4888
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1510
New value of Q matrix: 10.4861
New value of Value function: 10.4861
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1511
New value of Q matrix: 10.4834
New value of Value function: 10.4834
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1512
New value of Q matrix: 10.4807
New value of Value function: 10.4807
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1513
New value of Q matrix: 10.478
New value of Value function: 10.478
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 9.80005
New value of Value function: 10.478
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1514
New value of Q matrix: 10.4753
New value of Value function: 10.4753
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 206
New value of Q matrix: 9.95729
New value of Value function: 10.4753
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1515
New value of Q matrix: 10.4726
New value of Value function: 10.4726
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1516
New value of Q matrix: 10.47
New value of Value function: 10.47
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 9.6586
New value of Value function: 10.47
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1517
New value of Q matrix: 10.4673
New value of Value function: 10.4673
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1518
New value of Q matrix: 10.4646
New value of Value function: 10.4646
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 9.87164
New value of Value function: 10.4646
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1519
New value of Q matrix: 10.4619
New value of Value function: 10.4619
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1520
New value of Q matrix: 10.4592
New value of Value function: 10.4592
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1521
New value of Q matrix: 10.4565
New value of Value function: 10.4565
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1522
New value of Q matrix: 10.4539
New value of Value function: 10.4539
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1523
New value of Q matrix: 10.4512
New value of Value function: 10.4512
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1524
New value of Q matrix: 10.4485
New value of Value function: 10.4485
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 207
New value of Q matrix: 9.98417
New value of Value function: 10.4485
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 9.90246
New value of Value function: 10.4485
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1525
New value of Q matrix: 10.4458
New value of Value function: 10.4458
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1526
New value of Q matrix: 10.4431
New value of Value function: 10.4431
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1527
New value of Q matrix: 10.4405
New value of Value function: 10.4405
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1528
New value of Q matrix: 10.4378
New value of Value function: 10.4378
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1529
New value of Q matrix: 10.4351
New value of Value function: 10.4351
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1530
New value of Q matrix: 10.4325
New value of Value function: 10.4325
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1531
New value of Q matrix: 10.4298
New value of Value function: 10.4298
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1532
New value of Q matrix: 10.4271
New value of Value function: 10.4271
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1533
New value of Q matrix: 10.4245
New value of Value function: 10.4245
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1534
New value of Q matrix: 10.4218
New value of Value function: 10.4218
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1535
New value of Q matrix: 10.4192
New value of Value function: 10.4192
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1536
New value of Q matrix: 10.4165
New value of Value function: 10.4165
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1537
New value of Q matrix: 10.4138
New value of Value function: 10.4138
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1538
New value of Q matrix: 10.4112
New value of Value function: 10.4112
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1539
New value of Q matrix: 10.4085
New value of Value function: 10.4085
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 9.69798
New value of Value function: 10.4085
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 9.83121
New value of Value function: 10.4085
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1540
New value of Q matrix: 10.4059
New value of Value function: 10.4059
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 208
New value of Q matrix: 10.0062
New value of Value function: 10.4059
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 209
New value of Q matrix: 10.0266
New value of Value function: 10.4059
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 210
New value of Q matrix: 10.0456
New value of Value function: 10.4059
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1541
New value of Q matrix: 10.4032
New value of Value function: 10.4032
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1542
New value of Q matrix: 10.4006
New value of Value function: 10.4006
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1543
New value of Q matrix: 10.3979
New value of Value function: 10.3979
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1544
New value of Q matrix: 10.3953
New value of Value function: 10.3953
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 9.92777
New value of Value function: 10.3953
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1545
New value of Q matrix: 10.3926
New value of Value function: 10.3926
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1546
New value of Q matrix: 10.39
New value of Value function: 10.39
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1547
New value of Q matrix: 10.3874
New value of Value function: 10.3874
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1548
New value of Q matrix: 10.3847
New value of Value function: 10.3847
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 9.73345
New value of Value function: 10.3847
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 9.76671
New value of Value function: 10.3847
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1549
New value of Q matrix: 10.3821
New value of Value function: 10.3821
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1550
New value of Q matrix: 10.3794
New value of Value function: 10.3794
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1551
New value of Q matrix: 10.4448
New value of Value function: 10.4448
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 74
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 23.3415
New value of Value function: 23.3415
New value of Policy matrix: 4

=======================================
Simulation: 49
Iteration: 75
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 33.7615
New value of Value function: 33.7615
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 76
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 34.6704
New value of Value function: 34.6704
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 77
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 4
New value of Q matrix: 45.9711
New value of Value function: 45.9711
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 78
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 73.6699
New value of Value function: 73.6699
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 79
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 69.467
New value of Value function: 69.467
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 80
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 28
New value of Q matrix: 66.7077
New value of Value function: 66.7077
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 81
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 40.0675
New value of Value function: 40.0675
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 82
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 39.916
New value of Value function: 39.916
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 83
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 10.3791
New value of Value function: 39.916
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 84
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 21.7278
New value of Value function: 21.7278
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 85
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 33.4285
New value of Value function: 33.4285
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 86
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 35.342
New value of Value function: 35.342
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 87
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 28.9011
New value of Value function: 28.9011
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 88
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 5.05056
New value of Value function: 8.81539
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 89
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 12.5729
New value of Value function: 12.5729
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 90
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 8.27917
New value of Value function: 8.27917
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 91
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 6.80321
New value of Value function: 10.3096
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 92
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 10.2899
New value of Value function: 10.2899
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 93
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 26
New value of Q matrix: 8.26108
New value of Value function: 8.26108
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 94
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 4.19501
New value of Value function: 10.2899
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 95
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 13.187
New value of Value function: 14.2424
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 96
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 34
New value of Q matrix: 10.4288
New value of Value function: 10.4288
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 97
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 13.7124
New value of Value function: 13.7124
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 98
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 35
New value of Q matrix: 10.4536
New value of Value function: 10.4536
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 99
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 18.0887
New value of Value function: 18.0887
New value of Policy matrix: 3

=======================================
Simulation: 49
Iteration: 100
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 36.9684
New value of Value function: 36.9684
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 101
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 35.3259
New value of Value function: 35.3259
New value of Policy matrix: 0

=======================================
Simulation: 49
Iteration: 102
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 35.9071
New value of Value function: 35.9071
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 103
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 25.1077
New value of Value function: 25.1077
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 104
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 6.02899
New value of Value function: 8.81539
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 105
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 12.871
New value of Value function: 12.871
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 106
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 6.77125
New value of Value function: 8.81539
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 107
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 8.89389
New value of Value function: 8.89389
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 108
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 5.33624
New value of Value function: 5.33624
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 109
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 4.69601
New value of Value function: 4.69601
New value of Policy matrix: 2

=======================================
Simulation: 49
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1552
New value of Q matrix: 10.4422
New value of Value function: 10.4422
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1553
New value of Q matrix: 10.4395
New value of Value function: 10.4395
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1554
New value of Q matrix: 10.4369
New value of Value function: 10.4369
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1555
New value of Q matrix: 10.4343
New value of Value function: 10.4343
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1556
New value of Q matrix: 10.4316
New value of Value function: 10.4316
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1557
New value of Q matrix: 10.429
New value of Value function: 10.429
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1558
New value of Q matrix: 10.4263
New value of Value function: 10.4263
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1559
New value of Q matrix: 10.4237
New value of Value function: 10.4237
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1560
New value of Q matrix: 10.421
New value of Value function: 10.421
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 9.86115
New value of Value function: 10.421
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1561
New value of Q matrix: 10.4184
New value of Value function: 10.4184
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1562
New value of Q matrix: 10.4158
New value of Value function: 10.4158
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1563
New value of Q matrix: 10.4131
New value of Value function: 10.4131
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1564
New value of Q matrix: 10.4105
New value of Value function: 10.4105
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1565
New value of Q matrix: 10.4079
New value of Value function: 10.4079
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1566
New value of Q matrix: 10.4052
New value of Value function: 10.4052
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1567
New value of Q matrix: 10.4026
New value of Value function: 10.4026
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1568
New value of Q matrix: 10.4
New value of Value function: 10.4
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1569
New value of Q matrix: 10.3974
New value of Value function: 10.3974
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 9.95152
New value of Value function: 10.3974
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 211
New value of Q matrix: 10.0627
New value of Value function: 10.3974
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 9.79864
New value of Value function: 10.3974
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1570
New value of Q matrix: 10.3947
New value of Value function: 10.3947
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 212
New value of Q matrix: 10.0784
New value of Value function: 10.3947
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1571
New value of Q matrix: 10.3921
New value of Value function: 10.3921
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1572
New value of Q matrix: 10.3895
New value of Value function: 10.3895
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 9.88728
New value of Value function: 10.3895
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1573
New value of Q matrix: 10.3869
New value of Value function: 10.3869
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1574
New value of Q matrix: 10.3843
New value of Value function: 10.3843
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1575
New value of Q matrix: 10.3816
New value of Value function: 10.3816
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1576
New value of Q matrix: 10.379
New value of Value function: 10.379
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 9.9725
New value of Value function: 10.379
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 9.91111
New value of Value function: 10.379
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1577
New value of Q matrix: 10.3764
New value of Value function: 10.3764
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 9.93328
New value of Value function: 10.3764
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1578
New value of Q matrix: 10.3738
New value of Value function: 10.3738
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1579
New value of Q matrix: 10.3712
New value of Value function: 10.3712
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1580
New value of Q matrix: 10.3686
New value of Value function: 10.3686
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 9.99141
New value of Value function: 10.3686
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 213
New value of Q matrix: 10.0911
New value of Value function: 10.3686
New value of Policy matrix: 1

=======================================
Simulation: 49
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 214
New value of Q matrix: 10.103
New value of Value function: 10.3686
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1581
New value of Q matrix: 10.366
New value of Value function: 10.366
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1582
New value of Q matrix: 10.3634
New value of Value function: 10.3634
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1583
New value of Q matrix: 10.3608
New value of Value function: 10.3608
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 10.0086
New value of Value function: 10.3608
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 215
New value of Q matrix: 10.1135
New value of Value function: 10.3608
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1584
New value of Q matrix: 10.3582
New value of Value function: 10.3582
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1585
New value of Q matrix: 10.5997
New value of Value function: 10.5997
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 8
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 13.8493
New value of Value function: 13.8493
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 9
----------
State: 4485
	Distance: 7
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 11.597
New value of Value function: 11.597
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 10
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 12.3366
New value of Value function: 12.3366
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 11
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 13.0873
New value of Value function: 13.0873
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 12
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 22.9292
New value of Value function: 22.9292
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 13
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 11
New value of Q matrix: 37.6376
New value of Value function: 37.6376
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 14
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 9.52681
New value of Value function: 45.9711
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 15
----------
State: 4437
	Distance: 7
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2
New value of Q matrix: 6.60988
New value of Value function: 6.60988
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 16
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 23.5105
New value of Value function: 23.5105
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 17
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 17.5939
New value of Value function: 17.5939
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 18
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 23.1788
New value of Value function: 23.1788
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 19
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 34.0828
New value of Value function: 34.0828
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 20
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 25.9891
New value of Value function: 25.9891
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 21
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 33.1147
New value of Value function: 33.1147
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 22
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 18
New value of Q matrix: 22.7339
New value of Value function: 22.7339
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 23
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 8.27801
New value of Value function: 8.27801
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 24
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 7.92174
New value of Value function: 10.4536
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 25
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 12.3424
New value of Value function: 12.3424
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 26
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.50112
New value of Value function: 7.80393
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 216
New value of Q matrix: 10.4609
New value of Value function: 10.5997
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 28
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 9.543
New value of Value function: 9.543
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1586
New value of Q matrix: 10.597
New value of Value function: 10.597
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1587
New value of Q matrix: 10.5944
New value of Value function: 10.5944
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1588
New value of Q matrix: 10.5917
New value of Value function: 10.5917
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1589
New value of Q matrix: 10.589
New value of Value function: 10.589
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1590
New value of Q matrix: 10.5864
New value of Value function: 10.5864
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1591
New value of Q matrix: 10.5837
New value of Value function: 10.5837
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1592
New value of Q matrix: 10.5811
New value of Value function: 10.5811
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1593
New value of Q matrix: 10.5784
New value of Value function: 10.5784
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1594
New value of Q matrix: 10.5758
New value of Value function: 10.5758
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1595
New value of Q matrix: 10.5731
New value of Value function: 10.5731
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1596
New value of Q matrix: 10.5705
New value of Value function: 10.5705
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1597
New value of Q matrix: 10.5678
New value of Value function: 10.5678
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1598
New value of Q matrix: 10.5652
New value of Value function: 10.5652
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1599
New value of Q matrix: 10.5626
New value of Value function: 10.5626
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1600
New value of Q matrix: 10.5599
New value of Value function: 10.5599
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1601
New value of Q matrix: 10.5573
New value of Value function: 10.5573
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1602
New value of Q matrix: 10.5546
New value of Value function: 10.5546
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1603
New value of Q matrix: 10.552
New value of Value function: 10.552
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1604
New value of Q matrix: 10.5494
New value of Value function: 10.5494
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1605
New value of Q matrix: 10.5467
New value of Value function: 10.5467
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 10.0364
New value of Value function: 10.5467
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1606
New value of Q matrix: 10.5441
New value of Value function: 10.5441
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1607
New value of Q matrix: 10.5415
New value of Value function: 10.5415
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1608
New value of Q matrix: 10.5388
New value of Value function: 10.5388
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1609
New value of Q matrix: 10.5362
New value of Value function: 10.5362
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1610
New value of Q matrix: 10.5336
New value of Value function: 10.5336
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 10.0616
New value of Value function: 10.5336
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1611
New value of Q matrix: 10.531
New value of Value function: 10.531
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1612
New value of Q matrix: 10.5283
New value of Value function: 10.5283
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1613
New value of Q matrix: 10.5257
New value of Value function: 10.5257
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1614
New value of Q matrix: 10.5231
New value of Value function: 10.5231
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1615
New value of Q matrix: 10.5205
New value of Value function: 10.5205
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1616
New value of Q matrix: 10.5179
New value of Value function: 10.5179
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1617
New value of Q matrix: 10.5152
New value of Value function: 10.5152
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1618
New value of Q matrix: 10.5126
New value of Value function: 10.5126
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1619
New value of Q matrix: 10.51
New value of Value function: 10.51
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1620
New value of Q matrix: 10.5074
New value of Value function: 10.5074
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1621
New value of Q matrix: 10.5048
New value of Value function: 10.5048
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1622
New value of Q matrix: 10.5022
New value of Value function: 10.5022
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1623
New value of Q matrix: 10.4996
New value of Value function: 10.4996
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1624
New value of Q matrix: 10.497
New value of Value function: 10.497
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 10.0828
New value of Value function: 10.497
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1625
New value of Q matrix: 10.4944
New value of Value function: 10.4944
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 10.1024
New value of Value function: 10.4944
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1626
New value of Q matrix: 10.4918
New value of Value function: 10.4918
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 10.1206
New value of Value function: 10.4918
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1627
New value of Q matrix: 10.4892
New value of Value function: 10.4892
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 217
New value of Q matrix: 10.4557
New value of Value function: 10.4892
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 218
New value of Q matrix: 10.4509
New value of Value function: 10.4892
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1628
New value of Q matrix: 10.4866
New value of Value function: 10.4866
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1629
New value of Q matrix: 10.484
New value of Value function: 10.484
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1630
New value of Q matrix: 10.4814
New value of Value function: 10.4814
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 9.83362
New value of Value function: 10.4814
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 10.1369
New value of Value function: 10.4814
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 9.9604
New value of Value function: 10.4814
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1631
New value of Q matrix: 10.4788
New value of Value function: 10.4788
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 10.152
New value of Value function: 10.4788
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1632
New value of Q matrix: 10.4762
New value of Value function: 10.4762
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1633
New value of Q matrix: 10.4736
New value of Value function: 10.4736
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1634
New value of Q matrix: 10.471
New value of Value function: 10.471
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 219
New value of Q matrix: 10.4452
New value of Value function: 10.471
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1635
New value of Q matrix: 10.4684
New value of Value function: 10.4684
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1636
New value of Q matrix: 10.4658
New value of Value function: 10.4658
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 9.86549
New value of Value function: 10.4658
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1637
New value of Q matrix: 10.4632
New value of Value function: 10.4632
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1638
New value of Q matrix: 10.4607
New value of Value function: 10.4607
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 10.165
New value of Value function: 10.4607
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1639
New value of Q matrix: 10.4581
New value of Value function: 10.4581
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1640
New value of Q matrix: 10.4172
New value of Value function: 10.4452
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 98
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 18.0151
New value of Value function: 18.0151
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 99
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 18.5993
New value of Value function: 20.683
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 100
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 6.87373
New value of Value function: 11.2709
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 101
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 10.8095
New value of Value function: 10.8095
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 102
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 7
New value of Q matrix: 12.3954
New value of Value function: 12.3954
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 103
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 16.0149
New value of Value function: 16.0149
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 104
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 35.5994
New value of Value function: 35.5994
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 105
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 30.194
New value of Value function: 30.194
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 106
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 17.418
New value of Value function: 17.5939
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 107
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 19.7116
New value of Value function: 19.7116
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 108
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 29.1412
New value of Value function: 29.1412
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 109
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 1
New value of Q matrix: 28.8921
New value of Value function: 33.1147
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 110
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 16.4583
New value of Value function: 30.194
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 111
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 7.50219
New value of Value function: 22.7339
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 112
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 20.6855
New value of Value function: 20.6855
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 113
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 9.0169
New value of Value function: 9.0169
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 114
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 6.03358
New value of Value function: 6.03358
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 115
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 7
New value of Q matrix: 5.69561
New value of Value function: 5.69561
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1881
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 220
New value of Q matrix: 9.9432
New value of Value function: 10.4172
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 117
----------
State: 1881
	Distance: 3
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 5.19523
New value of Value function: 5.19523
New value of Policy matrix: 3

=======================================
Simulation: 50
Iteration: 118
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 28
New value of Q matrix: 21.5376
New value of Value function: 21.5376
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 119
----------
State: 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 40.2899
New value of Value function: 40.2899
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 120
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 29
New value of Q matrix: 24.5736
New value of Value function: 24.5736
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 121
----------
State: 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 32.2289
New value of Value function: 32.2289
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 122
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 11.0367
New value of Value function: 24.5736
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 123
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: 25.5473
New value of Value function: 25.5473
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 124
----------
State: 2461
	Distance: 4
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 7
New value of Visit matrix: 4
New value of Q matrix: 59.1227
New value of Value function: 59.1227
New value of Policy matrix: 0

=======================================
Simulation: 50
Iteration: 125
----------
State: 1937
	Distance: 3
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 50.0087
New value of Value function: 50.0087
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 126
----------
State: 1257
	Distance: 2
	Angle: 2
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 5.95362
New value of Value function: 5.95362
New value of Policy matrix: 2

=======================================
Simulation: 50
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1641
New value of Q matrix: 10.4146
New value of Value function: 10.4146
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 9.89232
New value of Value function: 10.4146
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 9.98179
New value of Value function: 10.4146
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 10.0018
New value of Value function: 10.4146
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1642
New value of Q matrix: 10.412
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 10.174
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 10.1825
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 10.0205
New value of Value function: 10.412
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1643
New value of Q matrix: 10.4095
New value of Value function: 10.4095
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1644
New value of Q matrix: 10.4069
New value of Value function: 10.4069
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1645
New value of Q matrix: 10.4043
New value of Value function: 10.4043
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1646
New value of Q matrix: 10.4018
New value of Value function: 10.4018
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1647
New value of Q matrix: 10.3992
New value of Value function: 10.3992
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1648
New value of Q matrix: 10.3966
New value of Value function: 10.3966
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1649
New value of Q matrix: 10.3941
New value of Value function: 10.3941
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1650
New value of Q matrix: 10.3915
New value of Value function: 10.3915
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1651
New value of Q matrix: 10.389
New value of Value function: 10.389
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1652
New value of Q matrix: 10.3864
New value of Value function: 10.3864
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 10.1888
New value of Value function: 10.3864
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1653
New value of Q matrix: 10.3839
New value of Value function: 10.3839
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1654
New value of Q matrix: 10.3813
New value of Value function: 10.3813
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1655
New value of Q matrix: 10.3788
New value of Value function: 10.3788
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 10.1942
New value of Value function: 10.3788
New value of Policy matrix: 1

=======================================
Simulation: 50
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1656
New value of Q matrix: 10.3762
New value of Value function: 10.3762
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1657
New value of Q matrix: 10.3737
New value of Value function: 10.3737
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1658
New value of Q matrix: 10.3711
New value of Value function: 10.3711
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 221
New value of Q matrix: 9.96501
New value of Value function: 10.3711
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1659
New value of Q matrix: 10.3686
New value of Value function: 10.3686
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1660
New value of Q matrix: 10.366
New value of Value function: 10.366
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 222
New value of Q matrix: 9.98497
New value of Value function: 10.366
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1661
New value of Q matrix: 10.7423
New value of Value function: 10.7423
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 8
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 28.5099
New value of Value function: 28.5099
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 9
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 39.6219
New value of Value function: 39.6219
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 10
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 29.9025
New value of Value function: 29.9025
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 11
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 16.4779
New value of Value function: 16.4779
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 12
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 33.5379
New value of Value function: 33.5379
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 13
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 36.5659
New value of Value function: 36.5659
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 14
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 25.5794
New value of Value function: 25.5794
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 15
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 17.2175
New value of Value function: 17.2175
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 16
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 23.4877
New value of Value function: 23.4877
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 17
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 18.97
New value of Value function: 18.97
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 18
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 22.8841
New value of Value function: 22.8841
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 19
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 19.3126
New value of Value function: 19.3126
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 20
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 22.6292
New value of Value function: 22.6292
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 21
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 11.6801
New value of Value function: 19.3126
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 22
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 5
New value of Q matrix: 19.353
New value of Value function: 19.353
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 23
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 22.4806
New value of Value function: 22.4806
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 24
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 15.0249
New value of Value function: 19.353
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 25
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 6
New value of Q matrix: 19.3133
New value of Value function: 19.3133
New value of Policy matrix: 0

=======================================
Simulation: 51
Iteration: 26
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 22.372
New value of Value function: 22.372
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 27
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 23.098
New value of Value function: 23.098
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 28
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 28.9875
New value of Value function: 28.9875
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 29
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 25.5041
New value of Value function: 25.5041
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 30
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 14
New value of Q matrix: 33.2741
New value of Value function: 33.2741
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 31
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 26.8644
New value of Value function: 26.8644
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 32
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 24.1961
New value of Value function: 24.1961
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 33
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 18.5109
New value of Value function: 18.5109
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 34
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 15
New value of Q matrix: 31.2916
New value of Value function: 31.2916
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 35
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 37.6557
New value of Value function: 37.6557
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 36
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 22
New value of Q matrix: 58.315
New value of Value function: 58.315
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 37
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 25.6312
New value of Value function: 25.6312
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 38
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 24.6237
New value of Value function: 24.6237
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 39
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 22.9176
New value of Value function: 22.9176
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 40
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 32.4077
New value of Value function: 32.4077
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 41
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 30.9968
New value of Value function: 30.9968
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 42
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 17.1093
New value of Value function: 20.6855
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 43
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 2
New value of Q matrix: 24.9927
New value of Value function: 30.9968
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 44
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 24.5526
New value of Value function: 24.5526
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 45
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -7
New value of Visit matrix: 13
New value of Q matrix: 22.2569
New value of Value function: 22.2569
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 46
----------
State: 4389
	Distance: 7
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 27.4165
New value of Value function: 27.4165
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 47
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 19.2463
New value of Value function: 22.2569
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 48
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 21.0359
New value of Value function: 21.0359
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 49
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 25.8256
New value of Value function: 25.8256
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 50
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 15
New value of Q matrix: 20.9149
New value of Value function: 20.9149
New value of Policy matrix: 3

=======================================
Simulation: 51
Iteration: 51
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 23.1804
New value of Value function: 25.8256
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 52
----------
State: 4341
	Distance: 7
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 25.7409
New value of Value function: 25.7409
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 53
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 4
New value of Q matrix: 23.5377
New value of Value function: 23.5377
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 54
----------
State: 4293
	Distance: 7
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 33.567
New value of Value function: 33.567
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 55
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 29.522
New value of Value function: 29.522
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 56
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: 14.6231
New value of Value function: 20.6855
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 57
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 26.5292
New value of Value function: 26.5292
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 58
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 28.478
New value of Value function: 28.478
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 59
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 21.2462
New value of Value function: 21.2462
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 60
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 27.8669
New value of Value function: 27.8669
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 61
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 19.649
New value of Value function: 19.649
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 62
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 6.67655
New value of Value function: 9.0169
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 63
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 13.1349
New value of Value function: 13.1349
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 64
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 11
New value of Q matrix: 8.71137
New value of Value function: 8.71137
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 65
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 10.3012
New value of Value function: 13.1349
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 66
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 4
New value of Q matrix: 6.77124
New value of Value function: 8.71137
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 67
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 8.95701
New value of Value function: 8.95701
New value of Policy matrix: 1

=======================================
Simulation: 51
Iteration: 68
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 13.2536
New value of Value function: 13.2536
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 69
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 21.4662
New value of Value function: 21.4662
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 70
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 6
New value of Q matrix: 70.3658
New value of Value function: 70.3658
New value of Policy matrix: 2

=======================================
Simulation: 51
Iteration: 71
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1351
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 1
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 99.6136
New value of Value function: 99.6136
New value of Policy matrix: 4

=======================================
Simulation: 52
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 223
New value of Q matrix: 10.0285
New value of Value function: 10.7423
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1662
New value of Q matrix: 10.7396
New value of Value function: 10.7396
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1663
New value of Q matrix: 10.737
New value of Value function: 10.737
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1664
New value of Q matrix: 10.7344
New value of Value function: 10.7344
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 10.2215
New value of Value function: 10.7344
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 10.2469
New value of Value function: 10.7344
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1665
New value of Q matrix: 10.7317
New value of Value function: 10.7317
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 224
New value of Q matrix: 10.0683
New value of Value function: 10.7317
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 10.0571
New value of Value function: 10.7317
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 10.0915
New value of Value function: 10.7317
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1666
New value of Q matrix: 10.7291
New value of Value function: 10.7291
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1667
New value of Q matrix: 10.7265
New value of Value function: 10.7265
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 9.93608
New value of Value function: 10.7265
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1668
New value of Q matrix: 10.7238
New value of Value function: 10.7238
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1669
New value of Q matrix: 10.7212
New value of Value function: 10.7212
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1670
New value of Q matrix: 10.7186
New value of Value function: 10.7186
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1671
New value of Q matrix: 10.716
New value of Value function: 10.716
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 10.2696
New value of Value function: 10.716
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1672
New value of Q matrix: 10.7134
New value of Value function: 10.7134
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 225
New value of Q matrix: 10.1042
New value of Value function: 10.7134
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1673
New value of Q matrix: 10.7107
New value of Value function: 10.7107
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1674
New value of Q matrix: 10.7081
New value of Value function: 10.7081
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1675
New value of Q matrix: 10.7055
New value of Value function: 10.7055
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1676
New value of Q matrix: 10.7029
New value of Value function: 10.7029
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1677
New value of Q matrix: 10.7003
New value of Value function: 10.7003
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1678
New value of Q matrix: 10.6977
New value of Value function: 10.6977
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 226
New value of Q matrix: 10.1365
New value of Value function: 10.6977
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1679
New value of Q matrix: 10.695
New value of Value function: 10.695
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 10.1216
New value of Value function: 10.695
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1680
New value of Q matrix: 10.6924
New value of Value function: 10.6924
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1681
New value of Q matrix: 10.6898
New value of Value function: 10.6898
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1682
New value of Q matrix: 10.6872
New value of Value function: 10.6872
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1683
New value of Q matrix: 10.6846
New value of Value function: 10.6846
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1684
New value of Q matrix: 10.682
New value of Value function: 10.682
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 227
New value of Q matrix: 10.1656
New value of Value function: 10.682
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1685
New value of Q matrix: 10.6794
New value of Value function: 10.6794
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1686
New value of Q matrix: 10.6768
New value of Value function: 10.6768
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1687
New value of Q matrix: 10.6742
New value of Value function: 10.6742
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1688
New value of Q matrix: 10.6716
New value of Value function: 10.6716
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1689
New value of Q matrix: 10.669
New value of Value function: 10.669
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1690
New value of Q matrix: 10.6664
New value of Value function: 10.6664
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1691
New value of Q matrix: 10.6638
New value of Value function: 10.6638
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1692
New value of Q matrix: 10.6612
New value of Value function: 10.6612
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1693
New value of Q matrix: 10.6586
New value of Value function: 10.6586
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 10.1476
New value of Value function: 10.6586
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 10.172
New value of Value function: 10.6586
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 10.1949
New value of Value function: 10.6586
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1694
New value of Q matrix: 10.6561
New value of Value function: 10.6561
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1695
New value of Q matrix: 10.6535
New value of Value function: 10.6535
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1696
New value of Q matrix: 10.6509
New value of Value function: 10.6509
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1697
New value of Q matrix: 10.6483
New value of Value function: 10.6483
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1698
New value of Q matrix: 10.6457
New value of Value function: 10.6457
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1699
New value of Q matrix: 10.6431
New value of Value function: 10.6431
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1700
New value of Q matrix: 10.6405
New value of Value function: 10.6405
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1701
New value of Q matrix: 10.638
New value of Value function: 10.638
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1702
New value of Q matrix: 10.6354
New value of Value function: 10.6354
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1703
New value of Q matrix: 10.6328
New value of Value function: 10.6328
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1704
New value of Q matrix: 10.6302
New value of Value function: 10.6302
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1705
New value of Q matrix: 10.6277
New value of Value function: 10.6277
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1706
New value of Q matrix: 10.6251
New value of Value function: 10.6251
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1707
New value of Q matrix: 10.6225
New value of Value function: 10.6225
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1708
New value of Q matrix: 10.6199
New value of Value function: 10.6199
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1709
New value of Q matrix: 10.4596
New value of Value function: 10.4596
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 64
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 2
New value of Q matrix: 21.4737
New value of Value function: 21.4737
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 65
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 14
New value of Q matrix: 27.3451
New value of Value function: 27.3451
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 66
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 10.2848
New value of Value function: 31.2916
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 67
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 15
New value of Q matrix: 29.5743
New value of Value function: 29.5743
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 68
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 11.4187
New value of Value function: 31.2916
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 69
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 22.235
New value of Value function: 22.235
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 70
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 14
New value of Q matrix: 14.1488
New value of Value function: 31.2916
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 71
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 31.1754
New value of Value function: 31.1754
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 72
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 16
New value of Q matrix: 38.9016
New value of Value function: 38.9016
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 73
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 1
New value of Q matrix: 11.7014
New value of Value function: 58.315
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 74
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 11.6213
New value of Value function: 11.6213
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 75
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 17.205
New value of Value function: 17.205
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 76
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 13.2719
New value of Value function: 13.2719
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 77
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 7
New value of Q matrix: 34.2103
New value of Value function: 34.2103
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 78
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 25.8871
New value of Value function: 69.467
New value of Policy matrix: 0

=======================================
Simulation: 52
Iteration: 79
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 9.45809
New value of Value function: 13.2536
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 80
----------
State: 3089
	Distance: 5
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 5
New value of Q matrix: 20.5482
New value of Value function: 20.5482
New value of Policy matrix: 3

=======================================
Simulation: 52
Iteration: 81
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 27.0388
New value of Value function: 27.0388
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 82
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 22
New value of Q matrix: 21.7048
New value of Value function: 21.7048
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 83
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 11.6009
New value of Value function: 25.5473
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 84
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 5
New value of Q matrix: 7.26148
New value of Value function: 21.4662
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 85
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 12.9655
New value of Value function: 12.9655
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 86
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 36.2201
New value of Value function: 36.2201
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 87
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 7
New value of Q matrix: 81.9557
New value of Value function: 81.9557
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 88
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 2.56706
New value of Value function: 98.01
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 89
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 2
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -3
New value of Value function: 5.69561
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 90
----------
State: 1253
	Distance: 2
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 7.35498
New value of Value function: 7.35498
New value of Policy matrix: 2

=======================================
Simulation: 52
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1710
New value of Q matrix: 10.457
New value of Value function: 10.457
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1711
New value of Q matrix: 10.4545
New value of Value function: 10.4545
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1712
New value of Q matrix: 10.452
New value of Value function: 10.452
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1713
New value of Q matrix: 10.4495
New value of Value function: 10.4495
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 256
New value of Q matrix: 10.2743
New value of Value function: 10.4495
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1714
New value of Q matrix: 10.4469
New value of Value function: 10.4469
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 9.96049
New value of Value function: 10.4469
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1715
New value of Q matrix: 10.4444
New value of Value function: 10.4444
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1716
New value of Q matrix: 10.4419
New value of Value function: 10.4419
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 228
New value of Q matrix: 10.177
New value of Value function: 10.4419
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1717
New value of Q matrix: 10.4394
New value of Value function: 10.4394
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1718
New value of Q matrix: 10.4369
New value of Value function: 10.4369
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 9.9828
New value of Value function: 10.4369
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1719
New value of Q matrix: 10.4343
New value of Value function: 10.4343
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1720
New value of Q matrix: 10.4318
New value of Value function: 10.4318
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1721
New value of Q matrix: 10.4293
New value of Value function: 10.4293
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1722
New value of Q matrix: 10.4268
New value of Value function: 10.4268
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1723
New value of Q matrix: 10.4243
New value of Value function: 10.4243
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 10.003
New value of Value function: 10.4243
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1724
New value of Q matrix: 10.4218
New value of Value function: 10.4218
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1725
New value of Q matrix: 10.4193
New value of Value function: 10.4193
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1726
New value of Q matrix: 10.4168
New value of Value function: 10.4168
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 10.2767
New value of Value function: 10.4168
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1727
New value of Q matrix: 10.4142
New value of Value function: 10.4142
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1728
New value of Q matrix: 10.4117
New value of Value function: 10.4117
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1729
New value of Q matrix: 10.4092
New value of Value function: 10.4092
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1730
New value of Q matrix: 10.4067
New value of Value function: 10.4067
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1731
New value of Q matrix: 10.4042
New value of Value function: 10.4042
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1732
New value of Q matrix: 10.4017
New value of Value function: 10.4017
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1733
New value of Q matrix: 10.3992
New value of Value function: 10.3992
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1734
New value of Q matrix: 10.3967
New value of Value function: 10.3967
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1735
New value of Q matrix: 10.3942
New value of Value function: 10.3942
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1736
New value of Q matrix: 10.3917
New value of Value function: 10.3917
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 10.2005
New value of Value function: 10.3917
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1737
New value of Q matrix: 10.3893
New value of Value function: 10.3893
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1738
New value of Q matrix: 10.3868
New value of Value function: 10.3868
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1739
New value of Q matrix: 10.3843
New value of Value function: 10.3843
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1740
New value of Q matrix: 10.3818
New value of Value function: 10.3818
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 10.0194
New value of Value function: 10.3818
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1741
New value of Q matrix: 10.3793
New value of Value function: 10.3793
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1742
New value of Q matrix: 10.3768
New value of Value function: 10.3768
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1743
New value of Q matrix: 10.3743
New value of Value function: 10.3743
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 229
New value of Q matrix: 10.1832
New value of Value function: 10.3743
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1744
New value of Q matrix: 10.3718
New value of Value function: 10.3718
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1745
New value of Q matrix: 10.3694
New value of Value function: 10.3694
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1746
New value of Q matrix: 10.3669
New value of Value function: 10.3669
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1747
New value of Q matrix: 10.3644
New value of Value function: 10.3644
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1748
New value of Q matrix: 10.3619
New value of Value function: 10.3619
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 10.0337
New value of Value function: 10.3619
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1749
New value of Q matrix: 10.3594
New value of Value function: 10.3594
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1750
New value of Q matrix: 10.357
New value of Value function: 10.357
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 230
New value of Q matrix: 10.1878
New value of Value function: 10.357
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1751
New value of Q matrix: 10.3545
New value of Value function: 10.3545
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1752
New value of Q matrix: 10.352
New value of Value function: 10.352
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 10.0465
New value of Value function: 10.352
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1753
New value of Q matrix: 10.3495
New value of Value function: 10.3495
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1754
New value of Q matrix: 10.3471
New value of Value function: 10.3471
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1755
New value of Q matrix: 10.3446
New value of Value function: 10.3446
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1756
New value of Q matrix: 10.3421
New value of Value function: 10.3421
New value of Policy matrix: 1

=======================================
Simulation: 52
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1757
New value of Q matrix: 10.3397
New value of Value function: 10.3397
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1758
New value of Q matrix: 10.3372
New value of Value function: 10.3372
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1759
New value of Q matrix: 10.3347
New value of Value function: 10.3347
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 231
New value of Q matrix: 10.1907
New value of Value function: 10.3347
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1760
New value of Q matrix: 10.3323
New value of Value function: 10.3323
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 232
New value of Q matrix: 10.1932
New value of Value function: 10.3323
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 10.0573
New value of Value function: 10.3323
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1761
New value of Q matrix: 10.6641
New value of Value function: 10.6641
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 8
----------
State: 3429
	Distance: 5
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 3
New value of Q matrix: 30.3591
New value of Value function: 30.3591
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 9
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 9.10531
New value of Value function: 31.1754
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 10
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 17
New value of Q matrix: 34.1676
New value of Value function: 34.1676
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 11
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 17
New value of Q matrix: 38.2656
New value of Value function: 38.2656
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 12
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 48.8701
New value of Value function: 48.8701
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 13
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 23
New value of Q matrix: 60.5514
New value of Value function: 60.5514
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 14
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 29
New value of Q matrix: 58.6404
New value of Value function: 58.6404
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 15
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 6
New value of Q matrix: 26.9205
New value of Value function: 26.9205
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 16
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 25.6985
New value of Value function: 25.6985
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 17
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 14
New value of Q matrix: 29.2053
New value of Value function: 29.2053
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 18
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 6.7856
New value of Value function: 6.7856
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 19
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.35389
New value of Value function: 6.35389
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1762
New value of Q matrix: 10.6616
New value of Value function: 10.6616
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 10.2217
New value of Value function: 10.6616
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 10.2417
New value of Value function: 10.6616
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1763
New value of Q matrix: 10.6591
New value of Value function: 10.6591
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 10.2938
New value of Value function: 10.6591
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1764
New value of Q matrix: 10.6565
New value of Value function: 10.6565
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1765
New value of Q matrix: 10.654
New value of Value function: 10.654
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1766
New value of Q matrix: 10.6514
New value of Value function: 10.6514
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1253
	Distance: 2
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 233
New value of Q matrix: 10.199
New value of Value function: 10.6514
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 29
----------
State: 1253
	Distance: 2
	Angle: 2
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.4893
New value of Value function: 7.4893
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1767
New value of Q matrix: 10.6489
New value of Value function: 10.6489
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1768
New value of Q matrix: 10.6464
New value of Value function: 10.6464
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1769
New value of Q matrix: 10.6439
New value of Value function: 10.6439
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1770
New value of Q matrix: 10.6413
New value of Value function: 10.6413
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1771
New value of Q matrix: 10.6388
New value of Value function: 10.6388
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1772
New value of Q matrix: 10.6363
New value of Value function: 10.6363
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 10.3085
New value of Value function: 10.6363
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1773
New value of Q matrix: 10.6337
New value of Value function: 10.6337
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 10.2587
New value of Value function: 10.6337
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1774
New value of Q matrix: 10.6312
New value of Value function: 10.6312
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 10.3219
New value of Value function: 10.6312
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1775
New value of Q matrix: 10.6287
New value of Value function: 10.6287
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1776
New value of Q matrix: 10.6262
New value of Value function: 10.6262
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1777
New value of Q matrix: 10.6236
New value of Value function: 10.6236
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1778
New value of Q matrix: 10.6211
New value of Value function: 10.6211
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1779
New value of Q matrix: 10.6186
New value of Value function: 10.6186
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1780
New value of Q matrix: 10.6161
New value of Value function: 10.6161
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1781
New value of Q matrix: 10.6136
New value of Value function: 10.6136
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1782
New value of Q matrix: 10.6111
New value of Value function: 10.6111
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1783
New value of Q matrix: 10.6086
New value of Value function: 10.6086
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 234
New value of Q matrix: 10.2188
New value of Value function: 10.6086
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1784
New value of Q matrix: 10.606
New value of Value function: 10.606
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1785
New value of Q matrix: 10.6035
New value of Value function: 10.6035
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1786
New value of Q matrix: 10.601
New value of Value function: 10.601
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1787
New value of Q matrix: 10.5985
New value of Value function: 10.5985
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 10.2727
New value of Value function: 10.5985
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1788
New value of Q matrix: 10.596
New value of Value function: 10.596
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 10.2856
New value of Value function: 10.596
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 10.2978
New value of Value function: 10.596
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1789
New value of Q matrix: 10.5935
New value of Value function: 10.5935
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 10.309
New value of Value function: 10.5935
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 10.3322
New value of Value function: 10.5935
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1790
New value of Q matrix: 10.591
New value of Value function: 10.591
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1791
New value of Q matrix: 10.5885
New value of Value function: 10.5885
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 10.3415
New value of Value function: 10.5885
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1792
New value of Q matrix: 10.586
New value of Value function: 10.586
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1793
New value of Q matrix: 10.5835
New value of Value function: 10.5835
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1794
New value of Q matrix: 10.581
New value of Value function: 10.581
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1795
New value of Q matrix: 10.5785
New value of Value function: 10.5785
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1796
New value of Q matrix: 10.576
New value of Value function: 10.576
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 235
New value of Q matrix: 10.2352
New value of Value function: 10.576
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1797
New value of Q matrix: 10.5735
New value of Value function: 10.5735
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1798
New value of Q matrix: 10.571
New value of Value function: 10.571
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1799
New value of Q matrix: 10.5685
New value of Value function: 10.5685
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1800
New value of Q matrix: 10.566
New value of Value function: 10.566
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 10.318
New value of Value function: 10.566
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1801
New value of Q matrix: 10.5635
New value of Value function: 10.5635
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1802
New value of Q matrix: 10.5611
New value of Value function: 10.5611
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1803
New value of Q matrix: 10.5586
New value of Value function: 10.5586
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1804
New value of Q matrix: 10.5561
New value of Value function: 10.5561
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1805
New value of Q matrix: 10.5536
New value of Value function: 10.5536
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1806
New value of Q matrix: 10.5511
New value of Value function: 10.5511
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1807
New value of Q matrix: 10.5486
New value of Value function: 10.5486
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1808
New value of Q matrix: 10.5461
New value of Value function: 10.5461
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1809
New value of Q matrix: 10.5437
New value of Value function: 10.5437
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1810
New value of Q matrix: 10.5412
New value of Value function: 10.5412
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1811
New value of Q matrix: 10.5387
New value of Value function: 10.5387
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 236
New value of Q matrix: 10.2481
New value of Value function: 10.5387
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 10.0796
New value of Value function: 10.5387
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1812
New value of Q matrix: 10.5362
New value of Value function: 10.5362
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 10.3247
New value of Value function: 10.5362
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1813
New value of Q matrix: 10.5338
New value of Value function: 10.5338
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1814
New value of Q matrix: 10.5313
New value of Value function: 10.5313
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1815
New value of Q matrix: 10.5288
New value of Value function: 10.5288
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1816
New value of Q matrix: 10.5263
New value of Value function: 10.5263
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1817
New value of Q matrix: 10.5239
New value of Value function: 10.5239
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1818
New value of Q matrix: 10.5214
New value of Value function: 10.5214
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 10.0996
New value of Value function: 10.5214
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1819
New value of Q matrix: 10.5189
New value of Value function: 10.5189
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1820
New value of Q matrix: 10.5165
New value of Value function: 10.5165
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 10.3298
New value of Value function: 10.5165
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1821
New value of Q matrix: 10.514
New value of Value function: 10.514
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1822
New value of Q matrix: 10.5115
New value of Value function: 10.5115
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1823
New value of Q matrix: 10.5091
New value of Value function: 10.5091
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1824
New value of Q matrix: 10.5066
New value of Value function: 10.5066
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 10.3452
New value of Value function: 10.5066
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1825
New value of Q matrix: 10.5042
New value of Value function: 10.5042
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 10.1173
New value of Value function: 10.5042
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1826
New value of Q matrix: 10.5017
New value of Value function: 10.5017
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1827
New value of Q matrix: 10.4993
New value of Value function: 10.4993
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1828
New value of Q matrix: 10.4968
New value of Value function: 10.4968
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1829
New value of Q matrix: 10.4943
New value of Value function: 10.4943
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1830
New value of Q matrix: 10.4919
New value of Value function: 10.4919
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1831
New value of Q matrix: 10.4894
New value of Value function: 10.4894
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 237
New value of Q matrix: 10.257
New value of Value function: 10.4894
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 10.3476
New value of Value function: 10.4894
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1832
New value of Q matrix: 10.487
New value of Value function: 10.487
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 10.3497
New value of Value function: 10.487
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1833
New value of Q matrix: 10.4845
New value of Value function: 10.4845
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1834
New value of Q matrix: 10.4821
New value of Value function: 10.4821
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1835
New value of Q matrix: 10.4796
New value of Value function: 10.4796
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1836
New value of Q matrix: 10.7213
New value of Value function: 10.7213
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 122
----------
State: 2221
	Distance: 3
	Angle: 10
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 20.5021
New value of Value function: 20.5021
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 123
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 12.5522
New value of Value function: 20.683
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 124
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 8
New value of Q matrix: 11.8044
New value of Value function: 11.8044
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 125
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 9.75854
New value of Value function: 13.2719
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 126
----------
State: 2705
	Distance: 4
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 11.0891
New value of Value function: 11.0891
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 127
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 21.4244
New value of Value function: 21.4244
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 128
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 28.6254
New value of Value function: 28.6254
New value of Policy matrix: 3

=======================================
Simulation: 53
Iteration: 129
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 28.6293
New value of Value function: 28.6293
New value of Policy matrix: 1

=======================================
Simulation: 53
Iteration: 130
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 27.3754
New value of Value function: 27.3754
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 131
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 15
New value of Q matrix: 24.4319
New value of Value function: 24.4319
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 132
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 13
New value of Q matrix: 7.48029
New value of Value function: 7.48029
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 133
----------
State: 1305
	Distance: 2
	Angle: 3
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 1
New value of Q matrix: 99.0299
New value of Value function: 99.0299
New value of Policy matrix: 0

=======================================
Simulation: 53
Iteration: 134
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 98.3607
New value of Value function: 98.3607
New value of Policy matrix: 2

=======================================
Simulation: 53
Iteration: 135
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1350
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 5
New value of Q matrix: 99.7864
New value of Value function: 99.7864
New value of Policy matrix: 4

=======================================
Simulation: 54
Iteration: 1
----------
State: 4249
	Distance: 7
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 12.1438
New value of Value function: 12.1438
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 2
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 9.97865
New value of Value function: 9.97865
New value of Policy matrix: 4

=======================================
Simulation: 54
Iteration: 3
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 9.92104
New value of Value function: 9.92104
New value of Policy matrix: 4

=======================================
Simulation: 54
Iteration: 4
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 9.87144
New value of Value function: 9.87144
New value of Policy matrix: 4

=======================================
Simulation: 54
Iteration: 5
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 3
New value of Q matrix: 17.718
New value of Value function: 17.718
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 6
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 12.2377
New value of Value function: 34.9318
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 7
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 31.4178
New value of Value function: 31.4178
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 8
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 54
New value of Q matrix: 38.1951
New value of Value function: 38.1951
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 9
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 5
New value of Q matrix: 27.4892
New value of Value function: 34.3152
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 10
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 31.6137
New value of Value function: 31.6137
New value of Policy matrix: 0

=======================================
Simulation: 54
Iteration: 11
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 26.8578
New value of Value function: 34.3152
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 12
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 35.7315
New value of Value function: 35.7315
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 13
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 38.1436
New value of Value function: 38.1436
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 14
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 56
New value of Q matrix: 39.1786
New value of Value function: 39.1786
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 15
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 44.7654
New value of Value function: 44.7654
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 16
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 20
New value of Q matrix: 56.4144
New value of Value function: 56.4144
New value of Policy matrix: 3

=======================================
Simulation: 54
Iteration: 17
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 22.2427
New value of Value function: 60.5514
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 18
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 20.9185
New value of Value function: 31.7964
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 19
----------
State: 3865
	Distance: 6
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 17
New value of Q matrix: 36.7736
New value of Value function: 36.7736
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 20
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 47.4231
New value of Value function: 47.4231
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 21
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 60.8554
New value of Value function: 60.8554
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 22
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 34
New value of Q matrix: 71.2641
New value of Value function: 71.2641
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 23
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 98.3853
New value of Value function: 98.3853
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 24
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 4
New value of Q matrix: 101.867
New value of Value function: 101.867
New value of Policy matrix: 2

=======================================
Simulation: 54
Iteration: 25
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 99.8921
New value of Value function: 99.8921
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 26
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 99.7767
New value of Value function: 99.7767
New value of Policy matrix: 1

=======================================
Simulation: 54
Iteration: 27
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 16
New value of Q matrix: 99.936
New value of Value function: 99.936
New value of Policy matrix: 4

=======================================
Simulation: 55
Iteration: 1
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 12
New value of Q matrix: 51.4296
New value of Value function: 51.4296
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 2
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 43.724
New value of Value function: 60.5514
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 3
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 46.4549
New value of Value function: 60.5514
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 4
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 22.3568
New value of Value function: 56.4144
New value of Policy matrix: 3

=======================================
Simulation: 55
Iteration: 5
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 13.9793
New value of Value function: 19.7344
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 6
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 17.9506
New value of Value function: 17.9506
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 7
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 23.3802
New value of Value function: 23.3802
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 8
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 42.35
New value of Value function: 42.35
New value of Policy matrix: 1

=======================================
Simulation: 55
Iteration: 9
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 73.8403
New value of Value function: 73.8403
New value of Policy matrix: 2

=======================================
Simulation: 55
Iteration: 10
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1554
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 56
Iteration: 1
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 3
New value of Q matrix: 49.6075
New value of Value function: 60.5514
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 2
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 53.7651
New value of Value function: 53.7651
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 3
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 21
New value of Q matrix: 56.094
New value of Value function: 56.094
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 4
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 55.0703
New value of Value function: 60.5514
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 5
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 22
New value of Q matrix: 55.8492
New value of Value function: 55.8492
New value of Policy matrix: 3

=======================================
Simulation: 56
Iteration: 6
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 24
New value of Q matrix: 61.1016
New value of Value function: 61.1016
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 7
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 31
New value of Q matrix: 62.956
New value of Value function: 62.956
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 8
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 64.1897
New value of Value function: 71.2641
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 9
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 32
New value of Q matrix: 64.6523
New value of Value function: 64.6523
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 10
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 35
New value of Q matrix: 76.5273
New value of Value function: 76.5273
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 11
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 99.8779
New value of Value function: 99.8779
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 12
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 5
New value of Q matrix: 102.722
New value of Value function: 102.722
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 13
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 7
New value of Q matrix: 99.8371
New value of Value function: 99.8371
New value of Policy matrix: 1

=======================================
Simulation: 56
Iteration: 14
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 55.1058
New value of Value function: 99.936
New value of Policy matrix: 4

=======================================
Simulation: 56
Iteration: 15
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 103.937
New value of Value function: 103.937
New value of Policy matrix: 2

=======================================
Simulation: 56
Iteration: 16
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 17
New value of Q matrix: 99.9515
New value of Value function: 99.9515
New value of Policy matrix: 4

=======================================
Simulation: 57
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1837
New value of Q matrix: 10.7188
New value of Value function: 10.7188
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1838
New value of Q matrix: 10.7163
New value of Value function: 10.7163
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1839
New value of Q matrix: 10.7138
New value of Value function: 10.7138
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 10.1462
New value of Value function: 10.7138
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1840
New value of Q matrix: 10.7113
New value of Value function: 10.7113
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1841
New value of Q matrix: 10.7088
New value of Value function: 10.7088
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1842
New value of Q matrix: 10.7063
New value of Value function: 10.7063
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 10.1729
New value of Value function: 10.7063
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 238
New value of Q matrix: 10.2792
New value of Value function: 10.7063
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1843
New value of Q matrix: 10.6342
New value of Value function: 10.6342
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 11
----------
State: 3337
	Distance: 5
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 9.60907
New value of Value function: 9.60907
New value of Policy matrix: 3

=======================================
Simulation: 57
Iteration: 12
----------
State: 3913
	Distance: 6
	Angle: 9
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 23
New value of Q matrix: 24.4386
New value of Value function: 24.4386
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 13
----------
State: 4441
	Distance: 7
	Angle: 8
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 33.0912
New value of Value function: 33.0912
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 37.0558
New value of Value function: 37.0558
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 15
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 57
New value of Q matrix: 40.8701
New value of Value function: 40.8701
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 16
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 26
New value of Q matrix: 49.3583
New value of Value function: 49.3583
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 17
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 23
New value of Q matrix: 55.7744
New value of Value function: 55.7744
New value of Policy matrix: 3

=======================================
Simulation: 57
Iteration: 18
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 25
New value of Q matrix: 62.2824
New value of Value function: 62.2824
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 19
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 33
New value of Q matrix: 66.9344
New value of Value function: 66.9344
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 20
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 36
New value of Q matrix: 81.0859
New value of Value function: 81.0859
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 21
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 26
New value of Q matrix: 85.0257
New value of Value function: 85.0257
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 22
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 30.51
New value of Value function: 30.51
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 23
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 52.1496
New value of Value function: 52.1496
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 24
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 49.5257
New value of Value function: 69.0444
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 25
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 34
New value of Q matrix: 69.5653
New value of Value function: 69.5653
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 26
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 11.9879
New value of Value function: 81.0859
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 27
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 8.64872
New value of Value function: 27.5233
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 28
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 17.1839
New value of Value function: 27.5233
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 29
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 32.5379
New value of Value function: 32.5379
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 30
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 25.0603
New value of Value function: 49.3583
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 31
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 20.5332
New value of Value function: 40.8701
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 32
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 38.4194
New value of Value function: 38.4194
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 33
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 58
New value of Q matrix: 39.8413
New value of Value function: 39.8413
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 34
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 39.3839
New value of Value function: 39.3839
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 35
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 59
New value of Q matrix: 41.667
New value of Value function: 41.667
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 36
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 53.9763
New value of Value function: 53.9763
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 37
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 15
New value of Q matrix: 71.1696
New value of Value function: 71.1696
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 38
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 37
New value of Q matrix: 82.4159
New value of Value function: 82.4159
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 39
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 27
New value of Q matrix: 74.6679
New value of Value function: 74.6679
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 40
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 38.0834
New value of Value function: 38.0834
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 41
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 7
New value of Q matrix: 61.2027
New value of Value function: 61.2027
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 42
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 51.7361
New value of Value function: 51.7361
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1844
New value of Q matrix: 10.5633
New value of Value function: 10.5633
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 44
----------
State: 2277
	Distance: 3
	Angle: 11
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.2643
New value of Value function: 6.2643
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1845
New value of Q matrix: 10.8009
New value of Value function: 10.8009
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 46
----------
State: 1653
	Distance: 2
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 29.3544
New value of Value function: 29.3544
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 47
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 14.2502
New value of Value function: 38.0834
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 48
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 45.7354
New value of Value function: 45.7354
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 49
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 58.7335
New value of Value function: 58.7335
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 50
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 55.1462
New value of Value function: 55.1462
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 51
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 20.5464
New value of Value function: 58.7335
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 52
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 20.7024
New value of Value function: 20.7024
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 53
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 20.6121
New value of Value function: 20.6121
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 54
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 20.6482
New value of Value function: 20.6482
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 55
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 20.5519
New value of Value function: 20.5519
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 56
----------
State: 1649
	Distance: 2
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 20.594
New value of Value function: 20.594
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 57
----------
State: 2177
	Distance: 3
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 2
New value of Q matrix: 43.6511
New value of Value function: 43.6511
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 58
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 50.2167
New value of Value function: 58.7335
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 59
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 24
New value of Q matrix: 58.0392
New value of Value function: 58.0392
New value of Policy matrix: 3

=======================================
Simulation: 57
Iteration: 60
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 41.2968
New value of Value function: 69.5653
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 61
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 58.0359
New value of Value function: 58.0359
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 62
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -8
New value of Visit matrix: 1
New value of Q matrix: 53.6596
New value of Value function: 71.1696
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 63
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 8
New value of Visit matrix: 26
New value of Q matrix: 65.4547
New value of Value function: 65.4547
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 64
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 16
New value of Q matrix: 73.0251
New value of Value function: 73.0251
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 65
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 16.1766
New value of Value function: 82.4159
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 66
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 31.2317
New value of Value function: 31.2317
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 67
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 26.0269
New value of Value function: 41.667
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 68
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 40.4696
New value of Value function: 40.4696
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 69
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 41.6132
New value of Value function: 41.6132
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 70
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 5
New value of Q matrix: 19.9476
New value of Value function: 41.6132
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 71
----------
State: 3193
	Distance: 5
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 6
New value of Q matrix: 31.1899
New value of Value function: 32.5379
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 72
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 64.4848
New value of Value function: 64.4848
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 73
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 5
New value of Q matrix: 75.225
New value of Value function: 75.225
New value of Policy matrix: 0

=======================================
Simulation: 57
Iteration: 74
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 38
New value of Q matrix: 81.849
New value of Value function: 81.849
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 75
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 80.7204
New value of Value function: 80.7204
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 76
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 103.178
New value of Value function: 103.178
New value of Policy matrix: 2

=======================================
Simulation: 57
Iteration: 77
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 99.8778
New value of Value function: 99.8778
New value of Policy matrix: 1

=======================================
Simulation: 57
Iteration: 78
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 18
New value of Q matrix: 99.9629
New value of Value function: 99.9629
New value of Policy matrix: 4

=======================================
Simulation: 58
Iteration: 1
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 0.0104637
New value of Value function: 7.04972
New value of Policy matrix: 0

=======================================
Simulation: 58
Iteration: 2
----------
State: 3625
	Distance: 6
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 8.52015
New value of Value function: 8.52015
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 3
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 12.3467
New value of Value function: 12.3467
New value of Policy matrix: 0

=======================================
Simulation: 58
Iteration: 4
----------
State: 3673
	Distance: 6
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 4
New value of Q matrix: 29.2571
New value of Value function: 29.2571
New value of Policy matrix: 0

=======================================
Simulation: 58
Iteration: 5
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 33.5892
New value of Value function: 33.5892
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 6
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 19.3665
New value of Value function: 19.3665
New value of Policy matrix: 0

=======================================
Simulation: 58
Iteration: 7
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 43.7652
New value of Value function: 43.7652
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 8
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 68.8115
New value of Value function: 68.8115
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 9
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 6
New value of Q matrix: 75.1456
New value of Value function: 75.1456
New value of Policy matrix: 0

=======================================
Simulation: 58
Iteration: 10
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 54.023
New value of Value function: 81.849
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 11
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 39
New value of Q matrix: 82.3396
New value of Value function: 82.3396
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 12
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 29
New value of Q matrix: 85.6275
New value of Value function: 85.6275
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 13
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 7
New value of Q matrix: 103.853
New value of Value function: 103.853
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 14
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 79.8115
New value of Value function: 99.9629
New value of Policy matrix: 4

=======================================
Simulation: 58
Iteration: 15
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 103.956
New value of Value function: 103.956
New value of Policy matrix: 2

=======================================
Simulation: 58
Iteration: 16
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 19
New value of Q matrix: 99.9714
New value of Value function: 99.9714
New value of Policy matrix: 4

=======================================
Simulation: 59
Iteration: 1
----------
State: 3049
	Distance: 5
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 17.4425
New value of Value function: 17.4425
New value of Policy matrix: 0

=======================================
Simulation: 59
Iteration: 2
----------
State: 3097
	Distance: 5
	Angle: 4
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 10
New value of Q matrix: 25.6788
New value of Value function: 25.6788
New value of Policy matrix: 0

=======================================
Simulation: 59
Iteration: 3
----------
State: 3721
	Distance: 6
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 51.9077
New value of Value function: 51.9077
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 4
----------
State: 3145
	Distance: 5
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -1
New value of Visit matrix: 13
New value of Q matrix: 59.1489
New value of Value function: 59.1489
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 5
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 33.1477
New value of Value function: 33.1477
New value of Policy matrix: 0

=======================================
Simulation: 59
Iteration: 6
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 37.7791
New value of Value function: 37.7791
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 7
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 7
New value of Q matrix: 75.2857
New value of Value function: 75.2857
New value of Policy matrix: 0

=======================================
Simulation: 59
Iteration: 8
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 40
New value of Q matrix: 83.5147
New value of Value function: 83.5147
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 9
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 6
New value of Visit matrix: 30
New value of Q matrix: 86.1403
New value of Value function: 86.1403
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 10
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -6
New value of Visit matrix: 2
New value of Q matrix: 70.7276
New value of Value function: 83.2685
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 11
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 31
New value of Q matrix: 90.033
New value of Value function: 90.033
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 12
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 35.3453
New value of Value function: 103.853
New value of Policy matrix: 2

=======================================
Simulation: 59
Iteration: 13
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 55.1462
New value of Value function: 55.1462
New value of Policy matrix: 0

=======================================
Simulation: 59
Iteration: 14
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 2
New value of Q matrix: 22.3913
New value of Value function: 58.7335
New value of Policy matrix: 1

=======================================
Simulation: 59
Iteration: 15
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 22.2878
New value of Value function: 22.2878
New value of Policy matrix: 4

=======================================
Simulation: 59
Iteration: 16
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 22.2036
New value of Value function: 22.2036
New value of Policy matrix: 4

=======================================
Simulation: 59
Iteration: 17
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 22.1251
New value of Value function: 22.1251
New value of Policy matrix: 4

=======================================
Simulation: 59
Iteration: 18
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 22.0514
New value of Value function: 22.0514
New value of Policy matrix: 4

=======================================
Simulation: 59
Iteration: 19
----------
State: 1601
	Distance: 2
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 4
New value of Q matrix: 58.5359
New value of Value function: 58.5359
New value of Policy matrix: 1

=======================================
Simulation: 59
Iteration: 20
----------
State: 1553
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1555
	Distance: 2
	Angle: 8
	Height: 4
	Object picked: 1
	Arm folded: 1
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1846
New value of Q matrix: 11.1572
New value of Value function: 11.1572
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 2
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 23.1764
New value of Value function: 23.1764
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 3
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 23.0426
New value of Value function: 23.0426
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 4
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 6.81515
New value of Value function: 23.0426
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1847
New value of Q matrix: 11.4982
New value of Value function: 11.4982
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 6
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 22.9274
New value of Value function: 22.9274
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 7
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 22.8249
New value of Value function: 22.8249
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 8
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -6
New value of Visit matrix: 3
New value of Q matrix: -0.58368
New value of Value function: 22.8249
New value of Policy matrix: 4

=======================================
Simulation: 60
Iteration: 9
----------
State: 2849
	Distance: 4
	Angle: 11
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 6
New value of Visit matrix: 1
New value of Q matrix: 39.4239
New value of Value function: 39.4239
New value of Policy matrix: 3

=======================================
Simulation: 60
Iteration: 10
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 17.722
New value of Value function: 33.7615
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 11
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 36.2218
New value of Value function: 36.2218
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 12
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 19.4861
New value of Value function: 38.2656
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 13
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 37.75
New value of Value function: 37.75
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 14
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 4
New value of Q matrix: 21.8956
New value of Value function: 38.2656
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 15
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 38.8978
New value of Value function: 38.8978
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 16
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 18
New value of Q matrix: 40.4142
New value of Value function: 40.4142
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 17
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 48.6706
New value of Value function: 48.6706
New value of Policy matrix: 2

=======================================
Simulation: 60
Iteration: 18
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 56.6568
New value of Value function: 56.6568
New value of Policy matrix: 2

=======================================
Simulation: 60
Iteration: 19
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 5
New value of Q matrix: 36.1156
New value of Value function: 65.4547
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 20
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 9
New value of Q matrix: 11.916
New value of Value function: 11.916
New value of Policy matrix: 3

=======================================
Simulation: 60
Iteration: 21
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 9
New value of Q matrix: 21.1373
New value of Value function: 21.1373
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 22
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 32.8417
New value of Value function: 32.8417
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 23
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 30.5132
New value of Value function: 30.5132
New value of Policy matrix: 0

=======================================
Simulation: 60
Iteration: 24
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 9
New value of Q matrix: 32.6305
New value of Value function: 32.6305
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 25
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: 30.3654
New value of Value function: 30.3654
New value of Policy matrix: 0

=======================================
Simulation: 60
Iteration: 26
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 32.4506
New value of Value function: 32.4506
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 27
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: 30.2273
New value of Value function: 30.2273
New value of Policy matrix: 0

=======================================
Simulation: 60
Iteration: 28
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 32.1261
New value of Value function: 32.4506
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 29
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 32.2921
New value of Value function: 32.2921
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 30
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: 30.0982
New value of Value function: 30.0982
New value of Policy matrix: 0

=======================================
Simulation: 60
Iteration: 31
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 32.1493
New value of Value function: 32.1493
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 32
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 15.9901
New value of Value function: 30.0982
New value of Policy matrix: 0

=======================================
Simulation: 60
Iteration: 33
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 16.4937
New value of Value function: 16.4937
New value of Policy matrix: 1

=======================================
Simulation: 60
Iteration: 34
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 16
New value of Q matrix: 39.8579
New value of Value function: 39.8579
New value of Policy matrix: 2

=======================================
Simulation: 60
Iteration: 35
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 8
New value of Q matrix: 88.8222
New value of Value function: 88.8222
New value of Policy matrix: 2

=======================================
Simulation: 60
Iteration: 36
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 98.5746
New value of Value function: 98.5746
New value of Policy matrix: 2

=======================================
Simulation: 60
Iteration: 37
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1398
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 101
New value of Visit matrix: 6
New value of Q matrix: 100.282
New value of Value function: 100.282
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 1
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 22.7317
New value of Value function: 22.7317
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 2
----------
State: 2801
	Distance: 4
	Angle: 10
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 13
New value of Q matrix: 11.9256
New value of Value function: 22.7317
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 3
----------
State: 2753
	Distance: 4
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -1
New value of Visit matrix: 10
New value of Q matrix: 14.449
New value of Value function: 14.449
New value of Policy matrix: 3

=======================================
Simulation: 61
Iteration: 4
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 10
New value of Q matrix: 25.4666
New value of Value function: 25.4666
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 5
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 13
New value of Q matrix: 32.0516
New value of Value function: 32.1261
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 6
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: 29.967
New value of Value function: 29.967
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 7
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 31.899
New value of Value function: 32.0516
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 8
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 14
New value of Q matrix: 31.9489
New value of Value function: 31.9489
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 9
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 6
New value of Q matrix: 29.8292
New value of Value function: 29.8292
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 10
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 22.212
New value of Value function: 31.9489
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 11
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 11
New value of Q matrix: 28.2293
New value of Value function: 28.2293
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 12
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 24.146
New value of Value function: 31.9489
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 13
----------
State: 3281
	Distance: 5
	Angle: 8
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 30.0769
New value of Value function: 30.0769
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 14
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 15
New value of Q matrix: 31.841
New value of Value function: 31.899
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 15
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 7
New value of Q matrix: 29.735
New value of Value function: 29.735
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 16
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 18.4169
New value of Value function: 31.899
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 17
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 10
New value of Q matrix: 23.0097
New value of Value function: 23.0097
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 18
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 8
New value of Q matrix: 29.6802
New value of Value function: 29.6802
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 19
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 31.7148
New value of Value function: 31.841
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 20
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 16
New value of Q matrix: 31.7266
New value of Value function: 31.7266
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 21
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 29.5899
New value of Value function: 29.5899
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 22
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 17
New value of Q matrix: 31.6217
New value of Value function: 31.7148
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 23
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 10
New value of Q matrix: 29.5291
New value of Value function: 29.5291
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 24
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 31.5562
New value of Value function: 31.6217
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 25
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 18
New value of Q matrix: 31.5303
New value of Value function: 31.5562
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 26
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 23.0088
New value of Value function: 29.5291
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 27
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 29.4421
New value of Value function: 29.4421
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 28
----------
State: 3233
	Distance: 5
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 27.7796
New value of Value function: 31.5562
New value of Policy matrix: 4

=======================================
Simulation: 61
Iteration: 29
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 22.7796
New value of Value function: 23.0097
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 30
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 11
New value of Q matrix: 23.9559
New value of Value function: 23.9559
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 31
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 18.6594
New value of Value function: 29.4421
New value of Policy matrix: 0

=======================================
Simulation: 61
Iteration: 32
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 13
New value of Q matrix: 23.1406
New value of Value function: 23.1406
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 33
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 17
New value of Q matrix: 32.1606
New value of Value function: 32.1606
New value of Policy matrix: 2

=======================================
Simulation: 61
Iteration: 34
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 18.8127
New value of Value function: 18.8127
New value of Policy matrix: 2

=======================================
Simulation: 61
Iteration: 35
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 6
New value of Q matrix: 13.2414
New value of Value function: 32.1606
New value of Policy matrix: 2

=======================================
Simulation: 61
Iteration: 36
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 25.7326
New value of Value function: 25.7326
New value of Policy matrix: 1

=======================================
Simulation: 61
Iteration: 37
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 46.485
New value of Value function: 46.485
New value of Policy matrix: 2

=======================================
Simulation: 61
Iteration: 38
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 9
New value of Q matrix: 93.0778
New value of Value function: 93.0778
New value of Policy matrix: 2

=======================================
Simulation: 61
Iteration: 39
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1355
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 1
	Arm folded: 1
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 1
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 62
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1848
New value of Q matrix: 11.4955
New value of Value function: 11.4955
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1849
New value of Q matrix: 11.4928
New value of Value function: 11.4928
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 239
New value of Q matrix: 10.3502
New value of Value function: 11.4928
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1850
New value of Q matrix: 11.4902
New value of Value function: 11.4902
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1851
New value of Q matrix: 11.4875
New value of Value function: 11.4875
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1852
New value of Q matrix: 11.4848
New value of Value function: 11.4848
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1853
New value of Q matrix: 11.4821
New value of Value function: 11.4821
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1854
New value of Q matrix: 11.4795
New value of Value function: 11.4795
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 10.412
New value of Value function: 11.4795
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1855
New value of Q matrix: 11.4768
New value of Value function: 11.4768
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1856
New value of Q matrix: 11.4742
New value of Value function: 11.4742
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 10.4699
New value of Value function: 11.4742
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1857
New value of Q matrix: 11.4715
New value of Value function: 11.4715
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 240
New value of Q matrix: 10.4152
New value of Value function: 11.4715
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1858
New value of Q matrix: 11.4688
New value of Value function: 11.4688
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1859
New value of Q matrix: 11.4662
New value of Value function: 11.4662
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1860
New value of Q matrix: 11.4635
New value of Value function: 11.4635
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 241
New value of Q matrix: 10.4754
New value of Value function: 11.4635
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1861
New value of Q matrix: 11.4609
New value of Value function: 11.4609
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1862
New value of Q matrix: 11.4582
New value of Value function: 11.4582
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1863
New value of Q matrix: 11.4555
New value of Value function: 11.4555
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1864
New value of Q matrix: 11.4529
New value of Value function: 11.4529
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1865
New value of Q matrix: 11.4502
New value of Value function: 11.4502
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1866
New value of Q matrix: 11.4476
New value of Value function: 11.4476
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1867
New value of Q matrix: 11.4449
New value of Value function: 11.4449
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1868
New value of Q matrix: 11.4423
New value of Value function: 11.4423
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 10.2408
New value of Value function: 11.4423
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1869
New value of Q matrix: 11.4396
New value of Value function: 11.4396
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1870
New value of Q matrix: 11.437
New value of Value function: 11.437
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1871
New value of Q matrix: 11.4344
New value of Value function: 11.4344
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1872
New value of Q matrix: 11.4317
New value of Value function: 11.4317
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 10.388
New value of Value function: 11.4317
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1873
New value of Q matrix: 11.4291
New value of Value function: 11.4291
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1874
New value of Q matrix: 11.4264
New value of Value function: 11.4264
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 10.5214
New value of Value function: 11.4264
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1875
New value of Q matrix: 11.4238
New value of Value function: 11.4238
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1876
New value of Q matrix: 11.4212
New value of Value function: 11.4212
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1877
New value of Q matrix: 11.4185
New value of Value function: 11.4185
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1878
New value of Q matrix: 11.4159
New value of Value function: 11.4159
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1879
New value of Q matrix: 11.4132
New value of Value function: 11.4132
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1880
New value of Q matrix: 11.4106
New value of Value function: 11.4106
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1881
New value of Q matrix: 11.408
New value of Value function: 11.408
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 10.4413
New value of Value function: 11.408
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 10.5685
New value of Value function: 11.408
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1882
New value of Q matrix: 11.4054
New value of Value function: 11.4054
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1883
New value of Q matrix: 11.4027
New value of Value function: 11.4027
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 10.6123
New value of Value function: 11.4027
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1884
New value of Q matrix: 11.4001
New value of Value function: 11.4001
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1885
New value of Q matrix: 11.3975
New value of Value function: 11.3975
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1886
New value of Q matrix: 11.3948
New value of Value function: 11.3948
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1887
New value of Q matrix: 11.3922
New value of Value function: 11.3922
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1888
New value of Q matrix: 11.3896
New value of Value function: 11.3896
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1889
New value of Q matrix: 11.387
New value of Value function: 11.387
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1890
New value of Q matrix: 11.3844
New value of Value function: 11.3844
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1891
New value of Q matrix: 11.3817
New value of Value function: 11.3817
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1892
New value of Q matrix: 11.3791
New value of Value function: 11.3791
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1893
New value of Q matrix: 11.3765
New value of Value function: 11.3765
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1894
New value of Q matrix: 11.3739
New value of Value function: 11.3739
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 10.3007
New value of Value function: 11.3739
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1895
New value of Q matrix: 11.3713
New value of Value function: 11.3713
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1896
New value of Q matrix: 11.3687
New value of Value function: 11.3687
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1897
New value of Q matrix: 11.3661
New value of Value function: 11.3661
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1898
New value of Q matrix: 11.3635
New value of Value function: 11.3635
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 10.651
New value of Value function: 11.3635
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1899
New value of Q matrix: 11.3608
New value of Value function: 11.3608
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1900
New value of Q matrix: 11.3582
New value of Value function: 11.3582
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1901
New value of Q matrix: 11.3556
New value of Value function: 11.3556
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1902
New value of Q matrix: 11.353
New value of Value function: 11.353
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1903
New value of Q matrix: 11.3504
New value of Value function: 11.3504
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1904
New value of Q matrix: 11.3478
New value of Value function: 11.3478
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1905
New value of Q matrix: 11.3452
New value of Value function: 11.3452
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1906
New value of Q matrix: 11.3426
New value of Value function: 11.3426
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 10.3551
New value of Value function: 11.3426
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1907
New value of Q matrix: 11.34
New value of Value function: 11.34
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 10.4061
New value of Value function: 11.34
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 10.454
New value of Value function: 11.34
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 10.4991
New value of Value function: 11.34
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 10.4874
New value of Value function: 11.34
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1908
New value of Q matrix: 11.3374
New value of Value function: 11.3374
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1909
New value of Q matrix: 11.3348
New value of Value function: 11.3348
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1910
New value of Q matrix: 11.3322
New value of Value function: 11.3322
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 242
New value of Q matrix: 10.5232
New value of Value function: 11.3322
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1911
New value of Q matrix: 11.3297
New value of Value function: 11.3297
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1912
New value of Q matrix: 11.3271
New value of Value function: 11.3271
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1913
New value of Q matrix: 11.3245
New value of Value function: 11.3245
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1914
New value of Q matrix: 11.3219
New value of Value function: 11.3219
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 243
New value of Q matrix: 10.5671
New value of Value function: 11.3219
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1915
New value of Q matrix: 11.3193
New value of Value function: 11.3193
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 244
New value of Q matrix: 10.608
New value of Value function: 11.3193
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1916
New value of Q matrix: 11.3167
New value of Value function: 11.3167
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 245
New value of Q matrix: 10.6461
New value of Value function: 11.3167
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1917
New value of Q matrix: 11.3141
New value of Value function: 11.3141
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 246
New value of Q matrix: 10.6815
New value of Value function: 11.3141
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 247
New value of Q matrix: 10.7145
New value of Value function: 11.3141
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1918
New value of Q matrix: 11.3115
New value of Value function: 11.3115
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1919
New value of Q matrix: 11.309
New value of Value function: 11.309
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1920
New value of Q matrix: 11.3064
New value of Value function: 11.3064
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 10.6839
New value of Value function: 11.3064
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1921
New value of Q matrix: 11.3038
New value of Value function: 11.3038
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1922
New value of Q matrix: 11.3012
New value of Value function: 11.3012
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1923
New value of Q matrix: 11.4246
New value of Value function: 11.4246
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 102
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 8
New value of Q matrix: 18.5033
New value of Value function: 18.5033
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 103
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 9.39251
New value of Value function: 22.235
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 104
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 21.3397
New value of Value function: 21.3397
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 105
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 26.984
New value of Value function: 26.984
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 106
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 19
New value of Q matrix: 43.7811
New value of Value function: 43.7811
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 107
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 52.3033
New value of Value function: 52.3033
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 108
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 20
New value of Q matrix: 45.3462
New value of Value function: 45.3462
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 109
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 9
New value of Q matrix: 58.1356
New value of Value function: 58.1356
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 110
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 27
New value of Q matrix: 57.3564
New value of Value function: 57.3564
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 111
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 10
New value of Q matrix: 27.1212
New value of Value function: 27.1212
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 112
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 8
New value of Q matrix: 28.3249
New value of Value function: 28.3249
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 113
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 18
New value of Q matrix: 30.6598
New value of Value function: 30.6598
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 114
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 26
New value of Q matrix: 36.1146
New value of Value function: 36.1146
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 115
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: 22.4584
New value of Value function: 22.4584
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 116
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 7.68966
New value of Value function: 10.4536
New value of Policy matrix: 0

=======================================
Simulation: 62
Iteration: 117
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 12.7503
New value of Value function: 12.7503
New value of Policy matrix: 0

=======================================
Simulation: 62
Iteration: 118
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 12
New value of Q matrix: 7.09696
New value of Value function: 22.4584
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 119
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.24639
New value of Value function: 7.42926
New value of Policy matrix: 0

=======================================
Simulation: 62
Iteration: 120
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 2
New value of Q matrix: 8.82666
New value of Value function: 8.82666
New value of Policy matrix: 0

=======================================
Simulation: 62
Iteration: 121
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 1
New value of Q matrix: 6.7384
New value of Value function: 7.48029
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 122
----------
State: 1885
	Distance: 3
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 3
New value of Q matrix: 9.16085
New value of Value function: 9.16085
New value of Policy matrix: 0

=======================================
Simulation: 62
Iteration: 123
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 14
New value of Q matrix: 7.70213
New value of Value function: 7.70213
New value of Policy matrix: 2

=======================================
Simulation: 62
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1924
New value of Q matrix: 11.422
New value of Value function: 11.422
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1925
New value of Q matrix: 11.4194
New value of Value function: 11.4194
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1926
New value of Q matrix: 11.4168
New value of Value function: 11.4168
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1927
New value of Q matrix: 11.4142
New value of Value function: 11.4142
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1928
New value of Q matrix: 11.4116
New value of Value function: 11.4116
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1929
New value of Q matrix: 11.409
New value of Value function: 11.409
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1930
New value of Q matrix: 11.4064
New value of Value function: 11.4064
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1931
New value of Q matrix: 11.4038
New value of Value function: 11.4038
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1932
New value of Q matrix: 11.4012
New value of Value function: 11.4012
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1933
New value of Q matrix: 11.3986
New value of Value function: 11.3986
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1934
New value of Q matrix: 11.396
New value of Value function: 11.396
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1935
New value of Q matrix: 11.3934
New value of Value function: 11.3934
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1936
New value of Q matrix: 11.3908
New value of Value function: 11.3908
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1937
New value of Q matrix: 11.3882
New value of Value function: 11.3882
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1938
New value of Q matrix: 11.3856
New value of Value function: 11.3856
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 10.5334
New value of Value function: 11.3856
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1939
New value of Q matrix: 11.3831
New value of Value function: 11.3831
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1940
New value of Q matrix: 11.3805
New value of Value function: 11.3805
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1941
New value of Q matrix: 11.3779
New value of Value function: 11.3779
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1942
New value of Q matrix: 11.3753
New value of Value function: 11.3753
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 10.5435
New value of Value function: 11.3753
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1943
New value of Q matrix: 11.3727
New value of Value function: 11.3727
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1944
New value of Q matrix: 11.3702
New value of Value function: 11.3702
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1945
New value of Q matrix: 11.3676
New value of Value function: 11.3676
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1946
New value of Q matrix: 11.365
New value of Value function: 11.365
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 10.7183
New value of Value function: 11.365
New value of Policy matrix: 1

=======================================
Simulation: 62
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 10.7505
New value of Value function: 11.365
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1947
New value of Q matrix: 11.3624
New value of Value function: 11.3624
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1948
New value of Q matrix: 11.3598
New value of Value function: 11.3598
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1949
New value of Q matrix: 11.3573
New value of Value function: 11.3573
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1950
New value of Q matrix: 11.3547
New value of Value function: 11.3547
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1951
New value of Q matrix: 11.3521
New value of Value function: 11.3521
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1952
New value of Q matrix: 11.3496
New value of Value function: 11.3496
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1953
New value of Q matrix: 11.347
New value of Value function: 11.347
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 10.7796
New value of Value function: 11.347
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1954
New value of Q matrix: 11.3444
New value of Value function: 11.3444
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 248
New value of Q matrix: 10.7473
New value of Value function: 11.3444
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 10.5834
New value of Value function: 11.3444
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1955
New value of Q matrix: 11.3419
New value of Value function: 11.3419
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1956
New value of Q matrix: 11.3393
New value of Value function: 11.3393
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1957
New value of Q matrix: 11.3367
New value of Value function: 11.3367
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1958
New value of Q matrix: 11.3342
New value of Value function: 11.3342
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1959
New value of Q matrix: 11.3316
New value of Value function: 11.3316
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 249
New value of Q matrix: 10.7772
New value of Value function: 11.3316
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1960
New value of Q matrix: 11.3291
New value of Value function: 11.3291
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1961
New value of Q matrix: 11.3265
New value of Value function: 11.3265
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1962
New value of Q matrix: 11.3239
New value of Value function: 11.3239
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1963
New value of Q matrix: 11.3214
New value of Value function: 11.3214
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1964
New value of Q matrix: 11.3188
New value of Value function: 11.3188
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1965
New value of Q matrix: 11.3163
New value of Value function: 11.3163
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1966
New value of Q matrix: 11.3137
New value of Value function: 11.3137
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 250
New value of Q matrix: 10.8039
New value of Value function: 11.3137
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 10.8049
New value of Value function: 11.3137
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 10.8287
New value of Value function: 11.3137
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1967
New value of Q matrix: 11.3112
New value of Value function: 11.3112
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1968
New value of Q matrix: 11.3086
New value of Value function: 11.3086
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1969
New value of Q matrix: 11.3061
New value of Value function: 11.3061
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1970
New value of Q matrix: 11.3035
New value of Value function: 11.3035
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1971
New value of Q matrix: 11.301
New value of Value function: 11.301
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1972
New value of Q matrix: 11.2984
New value of Value function: 11.2984
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1973
New value of Q matrix: 11.2959
New value of Value function: 11.2959
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1974
New value of Q matrix: 11.2933
New value of Value function: 11.2933
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1975
New value of Q matrix: 11.2908
New value of Value function: 11.2908
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1976
New value of Q matrix: 11.2883
New value of Value function: 11.2883
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 10.5709
New value of Value function: 11.2883
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 251
New value of Q matrix: 10.8274
New value of Value function: 11.2883
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1977
New value of Q matrix: 11.2857
New value of Value function: 11.2857
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 252
New value of Q matrix: 10.8491
New value of Value function: 11.2857
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1978
New value of Q matrix: 11.2832
New value of Value function: 11.2832
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1979
New value of Q matrix: 11.2807
New value of Value function: 11.2807
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1980
New value of Q matrix: 11.2781
New value of Value function: 11.2781
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1981
New value of Q matrix: 11.2756
New value of Value function: 11.2756
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1982
New value of Q matrix: 11.2731
New value of Value function: 11.2731
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1983
New value of Q matrix: 11.2705
New value of Value function: 11.2705
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1984
New value of Q matrix: 11.268
New value of Value function: 11.268
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1985
New value of Q matrix: 11.2655
New value of Value function: 11.2655
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 10.8481
New value of Value function: 11.2655
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1986
New value of Q matrix: 11.2629
New value of Value function: 11.2629
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1987
New value of Q matrix: 11.2604
New value of Value function: 11.2604
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 10.8661
New value of Value function: 11.2604
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1988
New value of Q matrix: 11.2579
New value of Value function: 11.2579
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1989
New value of Q matrix: 11.2554
New value of Value function: 11.2554
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1990
New value of Q matrix: 11.2528
New value of Value function: 11.2528
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 253
New value of Q matrix: 10.8675
New value of Value function: 11.2528
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1991
New value of Q matrix: 11.2503
New value of Value function: 11.2503
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1992
New value of Q matrix: 11.2478
New value of Value function: 11.2478
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 10.6155
New value of Value function: 11.2478
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1993
New value of Q matrix: 11.2453
New value of Value function: 11.2453
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1994
New value of Q matrix: 11.2428
New value of Value function: 11.2428
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 254
New value of Q matrix: 10.8839
New value of Value function: 11.2428
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 10.8819
New value of Value function: 11.2428
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1995
New value of Q matrix: 11.2402
New value of Value function: 11.2402
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 10.6035
New value of Value function: 11.2402
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1996
New value of Q matrix: 11.2377
New value of Value function: 11.2377
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 255
New value of Q matrix: 10.8991
New value of Value function: 11.2377
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1997
New value of Q matrix: 11.2352
New value of Value function: 11.2352
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 10.6338
New value of Value function: 11.2352
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1998
New value of Q matrix: 11.3829
New value of Value function: 11.3829
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 72
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 9
New value of Q matrix: 12.7469
New value of Value function: 12.7469
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1999
New value of Q matrix: 11.4776
New value of Value function: 11.4776
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 74
----------
State: 3385
	Distance: 5
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 20.8667
New value of Value function: 20.8667
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 75
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 8
New value of Q matrix: 6.53198
New value of Value function: 33.7615
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2000
New value of Q matrix: 11.2881
New value of Value function: 11.2881
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 77
----------
State: 2809
	Distance: 4
	Angle: 10
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.17519
New value of Value function: 8.17519
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 256
New value of Q matrix: 12.4944
New value of Value function: 12.4944
New value of Policy matrix: 3

=======================================
Simulation: 63
Iteration: 79
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 38.3058
New value of Value function: 38.3058
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 80
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 48.7148
New value of Value function: 48.7148
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 81
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 28
New value of Q matrix: 60.0992
New value of Value function: 60.0992
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 82
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 35
New value of Q matrix: 72.1201
New value of Value function: 72.1201
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 83
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 7
New value of Q matrix: 19.859
New value of Value function: 83.5147
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 84
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 11
New value of Q matrix: 33.6333
New value of Value function: 33.6333
New value of Policy matrix: 0

=======================================
Simulation: 63
Iteration: 85
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 61
New value of Q matrix: 44.2818
New value of Value function: 44.2818
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 86
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: 33.0154
New value of Value function: 58.0359
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 87
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 62
New value of Q matrix: 46.5899
New value of Value function: 46.5899
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 88
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 60.5174
New value of Value function: 60.5174
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 89
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 36
New value of Q matrix: 74.2133
New value of Value function: 74.2133
New value of Policy matrix: 1

=======================================
Simulation: 63
Iteration: 90
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 41
New value of Q matrix: 85.1729
New value of Value function: 85.1729
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 91
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 32
New value of Q matrix: 93.1763
New value of Value function: 93.1763
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 92
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 14
New value of Q matrix: 87.6376
New value of Value function: 103.853
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 93
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 28
New value of Q matrix: 87.181
New value of Value function: 87.181
New value of Policy matrix: 2

=======================================
Simulation: 63
Iteration: 94
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 93.9432
New value of Value function: 99.9714
New value of Policy matrix: 4

=======================================
Simulation: 63
Iteration: 95
----------
State: 1361
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1362
	Distance: 2
	Angle: 4
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 7
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 64
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 257
New value of Q matrix: 12.4866
New value of Value function: 12.4866
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 258
New value of Q matrix: 12.4788
New value of Value function: 12.4788
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 259
New value of Q matrix: 12.471
New value of Value function: 12.471
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 260
New value of Q matrix: 12.4633
New value of Value function: 12.4633
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 261
New value of Q matrix: 12.4556
New value of Value function: 12.4556
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 262
New value of Q matrix: 12.4479
New value of Value function: 12.4479
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 263
New value of Q matrix: 12.4402
New value of Value function: 12.4402
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 264
New value of Q matrix: 12.4326
New value of Value function: 12.4326
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 265
New value of Q matrix: 12.4249
New value of Value function: 12.4249
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 10.7131
New value of Value function: 12.4249
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 266
New value of Q matrix: 12.4173
New value of Value function: 12.4173
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 267
New value of Q matrix: 12.4097
New value of Value function: 12.4097
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 268
New value of Q matrix: 12.4021
New value of Value function: 12.4021
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 269
New value of Q matrix: 12.3946
New value of Value function: 12.3946
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 270
New value of Q matrix: 12.387
New value of Value function: 12.387
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 271
New value of Q matrix: 12.3795
New value of Value function: 12.3795
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 272
New value of Q matrix: 12.372
New value of Value function: 12.372
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 273
New value of Q matrix: 12.3645
New value of Value function: 12.3645
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 274
New value of Q matrix: 12.357
New value of Value function: 12.357
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 10.801
New value of Value function: 12.357
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 275
New value of Q matrix: 12.3496
New value of Value function: 12.3496
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 10.9621
New value of Value function: 12.3496
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 276
New value of Q matrix: 12.3422
New value of Value function: 12.3422
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 277
New value of Q matrix: 12.3347
New value of Value function: 12.3347
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 278
New value of Q matrix: 12.3273
New value of Value function: 12.3273
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 279
New value of Q matrix: 12.32
New value of Value function: 12.32
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 280
New value of Q matrix: 12.3126
New value of Value function: 12.3126
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 281
New value of Q matrix: 12.3053
New value of Value function: 12.3053
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 10.8808
New value of Value function: 12.3053
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 10.7239
New value of Value function: 12.3053
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 12.2979
New value of Value function: 12.2979
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 282
New value of Q matrix: 11.0343
New value of Value function: 12.2979
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 12.2906
New value of Value function: 12.2906
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 10.8078
New value of Value function: 12.2906
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 12.2833
New value of Value function: 12.2833
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 12.276
New value of Value function: 12.276
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 12.2688
New value of Value function: 12.2688
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 12.2615
New value of Value function: 12.2615
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 10.8851
New value of Value function: 12.2615
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 12.2543
New value of Value function: 12.2543
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 12.2471
New value of Value function: 12.2471
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2001
New value of Q matrix: 11.3068
New value of Value function: 12.2471
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 10.9569
New value of Value function: 12.2471
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 12.2399
New value of Value function: 12.2399
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 10.952
New value of Value function: 12.2399
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 12.2327
New value of Value function: 12.2327
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 12.2256
New value of Value function: 12.2256
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2002
New value of Q matrix: 11.3246
New value of Value function: 12.2256
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 12.2184
New value of Value function: 12.2184
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 12.2113
New value of Value function: 12.2113
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 12.2042
New value of Value function: 12.2042
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 12.1971
New value of Value function: 12.1971
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 12.19
New value of Value function: 12.19
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 12.183
New value of Value function: 12.183
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2003
New value of Q matrix: 11.341
New value of Value function: 12.183
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 12.1759
New value of Value function: 12.1759
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 11.0155
New value of Value function: 12.1759
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 12.1689
New value of Value function: 12.1689
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 12.1619
New value of Value function: 12.1619
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 12.1549
New value of Value function: 12.1549
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 12.1479
New value of Value function: 12.1479
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 12.1409
New value of Value function: 12.1409
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 12.134
New value of Value function: 12.134
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 12.1271
New value of Value function: 12.1271
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2004
New value of Q matrix: 11.3559
New value of Value function: 12.1271
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 12.1201
New value of Value function: 12.1201
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 11.0172
New value of Value function: 12.1201
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 12.1132
New value of Value function: 12.1132
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 283
New value of Q matrix: 11.0912
New value of Value function: 12.1132
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 12.1063
New value of Value function: 12.1063
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 12.0995
New value of Value function: 12.0995
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 12.0926
New value of Value function: 12.0926
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 12.0857
New value of Value function: 12.0857
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 12.0789
New value of Value function: 12.0789
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 12.0721
New value of Value function: 12.0721
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 12.0653
New value of Value function: 12.0653
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 12.0585
New value of Value function: 12.0585
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 12.0517
New value of Value function: 12.0517
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 12.045
New value of Value function: 12.045
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 12.0382
New value of Value function: 12.0382
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 320
New value of Q matrix: 12.0315
New value of Value function: 12.0315
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 321
New value of Q matrix: 12.0248
New value of Value function: 12.0248
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 322
New value of Q matrix: 12.0181
New value of Value function: 12.0181
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 323
New value of Q matrix: 12.0114
New value of Value function: 12.0114
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 324
New value of Q matrix: 12.0047
New value of Value function: 12.0047
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 325
New value of Q matrix: 11.9981
New value of Value function: 11.9981
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 326
New value of Q matrix: 11.9914
New value of Value function: 11.9914
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 327
New value of Q matrix: 11.9848
New value of Value function: 11.9848
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 328
New value of Q matrix: 11.9782
New value of Value function: 11.9782
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 329
New value of Q matrix: 11.9716
New value of Value function: 11.9716
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 330
New value of Q matrix: 11.965
New value of Value function: 11.965
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 331
New value of Q matrix: 11.9584
New value of Value function: 11.9584
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 332
New value of Q matrix: 11.9518
New value of Value function: 11.9518
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 333
New value of Q matrix: 11.9453
New value of Value function: 11.9453
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 284
New value of Q matrix: 11.1348
New value of Value function: 11.9453
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 334
New value of Q matrix: 11.9388
New value of Value function: 11.9388
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 335
New value of Q matrix: 11.9322
New value of Value function: 11.9322
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 336
New value of Q matrix: 11.9257
New value of Value function: 11.9257
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 337
New value of Q matrix: 11.9192
New value of Value function: 11.9192
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 338
New value of Q matrix: 11.9127
New value of Value function: 11.9127
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2005
New value of Q matrix: 11.3657
New value of Value function: 11.9127
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 339
New value of Q matrix: 11.9063
New value of Value function: 11.9063
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 340
New value of Q matrix: 11.8998
New value of Value function: 11.8998
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 341
New value of Q matrix: 11.8934
New value of Value function: 11.8934
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 342
New value of Q matrix: 11.8869
New value of Value function: 11.8869
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 343
New value of Q matrix: 11.8805
New value of Value function: 11.8805
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 344
New value of Q matrix: 11.8741
New value of Value function: 11.8741
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2006
New value of Q matrix: 11.3744
New value of Value function: 11.8741
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 11.0598
New value of Value function: 11.8741
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 345
New value of Q matrix: 11.8677
New value of Value function: 11.8677
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 346
New value of Q matrix: 11.8613
New value of Value function: 11.8613
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 347
New value of Q matrix: 11.855
New value of Value function: 11.855
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 285
New value of Q matrix: 11.1705
New value of Value function: 11.855
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 348
New value of Q matrix: 11.8486
New value of Value function: 11.8486
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 349
New value of Q matrix: 11.8423
New value of Value function: 11.8423
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 350
New value of Q matrix: 11.836
New value of Value function: 11.836
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 351
New value of Q matrix: 11.8296
New value of Value function: 11.8296
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 352
New value of Q matrix: 11.8233
New value of Value function: 11.8233
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 353
New value of Q matrix: 11.817
New value of Value function: 11.817
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 354
New value of Q matrix: 11.8108
New value of Value function: 11.8108
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 355
New value of Q matrix: 11.8045
New value of Value function: 11.8045
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 356
New value of Q matrix: 11.7982
New value of Value function: 11.7982
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 357
New value of Q matrix: 11.792
New value of Value function: 11.792
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 358
New value of Q matrix: 11.7858
New value of Value function: 11.7858
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 359
New value of Q matrix: 11.7795
New value of Value function: 11.7795
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 360
New value of Q matrix: 11.7733
New value of Value function: 11.7733
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 361
New value of Q matrix: 11.7671
New value of Value function: 11.7671
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 362
New value of Q matrix: 11.7609
New value of Value function: 11.7609
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 363
New value of Q matrix: 11.7548
New value of Value function: 11.7548
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 364
New value of Q matrix: 11.7486
New value of Value function: 11.7486
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 11.0508
New value of Value function: 11.7486
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 365
New value of Q matrix: 11.7425
New value of Value function: 11.7425
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 366
New value of Q matrix: 11.7363
New value of Value function: 11.7363
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 367
New value of Q matrix: 11.7302
New value of Value function: 11.7302
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 368
New value of Q matrix: 11.7241
New value of Value function: 11.7241
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 369
New value of Q matrix: 11.718
New value of Value function: 11.718
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 370
New value of Q matrix: 11.7119
New value of Value function: 11.7119
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 371
New value of Q matrix: 11.7058
New value of Value function: 11.7058
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 372
New value of Q matrix: 11.6997
New value of Value function: 11.6997
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 373
New value of Q matrix: 11.6937
New value of Value function: 11.6937
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 374
New value of Q matrix: 11.6876
New value of Value function: 11.6876
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 286
New value of Q matrix: 11.1941
New value of Value function: 11.6876
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 375
New value of Q matrix: 11.6816
New value of Value function: 11.6816
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 287
New value of Q matrix: 11.216
New value of Value function: 11.6816
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 376
New value of Q matrix: 11.6756
New value of Value function: 11.6756
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 377
New value of Q matrix: 11.6696
New value of Value function: 11.6696
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2007
New value of Q matrix: 11.3783
New value of Value function: 11.6696
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 378
New value of Q matrix: 11.6636
New value of Value function: 11.6636
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 379
New value of Q matrix: 11.6576
New value of Value function: 11.6576
New value of Policy matrix: 3

=======================================
Simulation: 64
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 380
New value of Q matrix: 11.6516
New value of Value function: 11.6516
New value of Policy matrix: 3

=======================================
Simulation: 65
Iteration: 1
----------
State: 3329
	Distance: 5
	Angle: 9
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 5
New value of Q matrix: 37.908
New value of Value function: 37.908
New value of Policy matrix: 1

=======================================
Simulation: 65
Iteration: 2
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 29
New value of Q matrix: 63.1394
New value of Value function: 63.1394
New value of Policy matrix: 1

=======================================
Simulation: 65
Iteration: 3
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 76.2038
New value of Value function: 76.2038
New value of Policy matrix: 1

=======================================
Simulation: 65
Iteration: 4
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 42
New value of Q matrix: 76.7329
New value of Value function: 76.7329
New value of Policy matrix: 2

=======================================
Simulation: 65
Iteration: 5
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 15
New value of Q matrix: 31.229
New value of Value function: 31.229
New value of Policy matrix: 1

=======================================
Simulation: 65
Iteration: 6
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 58.1077
New value of Value function: 58.1077
New value of Policy matrix: 2

=======================================
Simulation: 65
Iteration: 7
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 10
New value of Q matrix: 96.2155
New value of Value function: 96.2155
New value of Policy matrix: 2

=======================================
Simulation: 65
Iteration: 8
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1355
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 1
	Arm folded: 1
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 2
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 66
Iteration: 1
----------
State: 4821
	Distance: 8
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 3
New value of Value function: 3
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 2
----------
State: 4197
	Distance: 7
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 3
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 66
Iteration: 4
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 66
Iteration: 5
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 11.6829
New value of Value function: 11.6829
New value of Policy matrix: 0

=======================================
Simulation: 66
Iteration: 6
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 14.7126
New value of Value function: 14.7126
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 7
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 11.5999
New value of Value function: 11.5999
New value of Policy matrix: 0

=======================================
Simulation: 66
Iteration: 8
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 23.7572
New value of Value function: 23.7572
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 9
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 15
New value of Q matrix: 26.8948
New value of Value function: 26.8948
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 10
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 8.13163
New value of Value function: 8.13163
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 11
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 6.91222
New value of Value function: 6.91222
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 381
New value of Q matrix: 11.5483
New value of Value function: 11.5483
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 13
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 9.67053
New value of Value function: 9.67053
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 14
----------
State: 2421
	Distance: 4
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 7.67252
New value of Value function: 7.67252
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 382
New value of Q matrix: 11.6008
New value of Value function: 11.6008
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 16
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 4
New value of Q matrix: 9.07765
New value of Value function: 9.07765
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2008
New value of Q matrix: 11.3807
New value of Value function: 11.6008
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 383
New value of Q matrix: 11.5949
New value of Value function: 11.5949
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 384
New value of Q matrix: 11.1562
New value of Value function: 11.3807
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 20
----------
State: 2949
	Distance: 5
	Angle: 1
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: 8.26691
New value of Value function: 8.26691
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2009
New value of Q matrix: 11.3782
New value of Value function: 11.3782
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2010
New value of Q matrix: 11.3756
New value of Value function: 11.3756
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2011
New value of Q matrix: 11.3731
New value of Value function: 11.3731
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2012
New value of Q matrix: 11.3706
New value of Value function: 11.3706
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2013
New value of Q matrix: 11.368
New value of Value function: 11.368
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2014
New value of Q matrix: 11.3655
New value of Value function: 11.3655
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2015
New value of Q matrix: 11.363
New value of Value function: 11.363
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2016
New value of Q matrix: 11.3604
New value of Value function: 11.3604
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 385
New value of Q matrix: 11.1609
New value of Value function: 11.3604
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 11.0621
New value of Value function: 11.3604
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2017
New value of Q matrix: 11.3579
New value of Value function: 11.3579
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2018
New value of Q matrix: 11.3554
New value of Value function: 11.3554
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2019
New value of Q matrix: 11.3529
New value of Value function: 11.3529
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 386
New value of Q matrix: 11.1649
New value of Value function: 11.3529
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2020
New value of Q matrix: 11.3503
New value of Value function: 11.3503
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2021
New value of Q matrix: 11.3478
New value of Value function: 11.3478
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2022
New value of Q matrix: 11.3453
New value of Value function: 11.3453
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2023
New value of Q matrix: 11.3428
New value of Value function: 11.3428
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2024
New value of Q matrix: 11.3402
New value of Value function: 11.3402
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 301
New value of Q matrix: 11.0694
New value of Value function: 11.3402
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2025
New value of Q matrix: 11.3377
New value of Value function: 11.3377
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2026
New value of Q matrix: 11.3352
New value of Value function: 11.3352
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 302
New value of Q matrix: 11.0782
New value of Value function: 11.3352
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2027
New value of Q matrix: 11.3327
New value of Value function: 11.3327
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2028
New value of Q matrix: 11.3302
New value of Value function: 11.3302
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2029
New value of Q matrix: 11.3276
New value of Value function: 11.3276
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 387
New value of Q matrix: 11.1674
New value of Value function: 11.3276
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2030
New value of Q matrix: 11.3251
New value of Value function: 11.3251
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2031
New value of Q matrix: 11.3226
New value of Value function: 11.3226
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2032
New value of Q matrix: 11.3201
New value of Value function: 11.3201
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2033
New value of Q matrix: 11.3176
New value of Value function: 11.3176
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2034
New value of Q matrix: 11.3151
New value of Value function: 11.3151
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 303
New value of Q matrix: 11.0853
New value of Value function: 11.3151
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2035
New value of Q matrix: 11.3126
New value of Value function: 11.3126
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2036
New value of Q matrix: 11.3101
New value of Value function: 11.3101
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2037
New value of Q matrix: 11.3076
New value of Value function: 11.3076
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2038
New value of Q matrix: 11.3051
New value of Value function: 11.3051
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 288
New value of Q matrix: 11.2146
New value of Value function: 11.3051
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2039
New value of Q matrix: 11.3026
New value of Value function: 11.3026
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 388
New value of Q matrix: 11.1685
New value of Value function: 11.3026
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2040
New value of Q matrix: 11.3001
New value of Value function: 11.3001
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2041
New value of Q matrix: 11.2976
New value of Value function: 11.2976
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2042
New value of Q matrix: 11.2951
New value of Value function: 11.2951
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2043
New value of Q matrix: 11.2926
New value of Value function: 11.2926
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2044
New value of Q matrix: 11.2901
New value of Value function: 11.2901
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2045
New value of Q matrix: 11.2876
New value of Value function: 11.2876
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 304
New value of Q matrix: 11.0904
New value of Value function: 11.2876
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2046
New value of Q matrix: 11.2851
New value of Value function: 11.2851
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2047
New value of Q matrix: 11.2826
New value of Value function: 11.2826
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 389
New value of Q matrix: 11.1686
New value of Value function: 11.2826
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 11.095
New value of Value function: 11.2826
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 289
New value of Q matrix: 11.212
New value of Value function: 11.2826
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2048
New value of Q matrix: 11.2801
New value of Value function: 11.2801
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 305
New value of Q matrix: 11.0681
New value of Value function: 11.2801
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2049
New value of Q matrix: 11.2776
New value of Value function: 11.2776
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 290
New value of Q matrix: 11.2092
New value of Value function: 11.2776
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2050
New value of Q matrix: 11.2751
New value of Value function: 11.2751
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2051
New value of Q matrix: 11.2726
New value of Value function: 11.2726
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2052
New value of Q matrix: 11.2701
New value of Value function: 11.2701
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2053
New value of Q matrix: 11.2676
New value of Value function: 11.2676
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2054
New value of Q matrix: 11.2651
New value of Value function: 11.2651
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 11.0982
New value of Value function: 11.2651
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 11.1013
New value of Value function: 11.2651
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 390
New value of Q matrix: 11.1677
New value of Value function: 11.2651
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 291
New value of Q matrix: 11.2059
New value of Value function: 11.2651
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2055
New value of Q matrix: 11.2627
New value of Value function: 11.2627
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 391
New value of Q matrix: 11.1669
New value of Value function: 11.2627
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2056
New value of Q matrix: 11.2602
New value of Value function: 11.2602
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2057
New value of Q matrix: 11.9271
New value of Value function: 11.9271
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 90
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 42.0248
New value of Value function: 42.0248
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 91
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 21.8145
New value of Value function: 48.7148
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 92
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 29.9684
New value of Value function: 29.9684
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 93
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 44.4132
New value of Value function: 44.4132
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 94
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 14.5412
New value of Value function: 48.7148
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 95
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 22
New value of Q matrix: 50.3861
New value of Value function: 50.3861
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 96
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 55.8419
New value of Value function: 55.8419
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 97
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 22.9797
New value of Value function: 50.3861
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 98
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 25
New value of Q matrix: 34.9512
New value of Value function: 34.9512
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 99
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 23
New value of Q matrix: 51.1988
New value of Value function: 51.1988
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 100
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 11
New value of Q matrix: 59.3594
New value of Value function: 59.3594
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 101
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 30
New value of Q matrix: 56.1487
New value of Value function: 56.1487
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 102
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 11
New value of Q matrix: 28.0018
New value of Value function: 28.0018
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 103
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 9
New value of Q matrix: 29.3344
New value of Value function: 29.3344
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 104
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -1
New value of Visit matrix: 3
New value of Q matrix: 26.7526
New value of Value function: 30.6598
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 105
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 10
New value of Q matrix: 29.9728
New value of Value function: 29.9728
New value of Policy matrix: 1

=======================================
Simulation: 66
Iteration: 106
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 32.9754
New value of Value function: 32.9754
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 107
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 27
New value of Q matrix: 41.1976
New value of Value function: 41.1976
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 108
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 20
New value of Q matrix: 47.7139
New value of Value function: 47.7139
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 109
----------
State: 1933
	Distance: 3
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 0.144351
New value of Value function: 7.70213
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 110
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 5.87834
New value of Value function: 5.87834
New value of Policy matrix: 4

=======================================
Simulation: 66
Iteration: 111
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 13.6246
New value of Value function: 13.6246
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 112
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 19
New value of Q matrix: 26.4807
New value of Value function: 26.4807
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 113
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 59.1789
New value of Value function: 59.1789
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 114
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 11
New value of Q matrix: 98.2611
New value of Value function: 98.2611
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 115
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.65579
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 66
Iteration: 116
----------
State: 1929
	Distance: 3
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -4
New value of Visit matrix: 2
New value of Q matrix: 7.2717
New value of Value function: 7.2717
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 117
----------
State: 2557
	Distance: 4
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 18.9925
New value of Value function: 18.9925
New value of Policy matrix: 3

=======================================
Simulation: 66
Iteration: 118
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 34.778
New value of Value function: 34.778
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 119
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 68.3678
New value of Value function: 68.3678
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 120
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 12
New value of Q matrix: 99.6291
New value of Value function: 99.6291
New value of Policy matrix: 2

=======================================
Simulation: 66
Iteration: 121
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1355
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 1
	Arm folded: 1
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 3
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

=======================================
Simulation: 67
Iteration: 1
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 9
New value of Q matrix: 33.7641
New value of Value function: 33.7641
New value of Policy matrix: 0

=======================================
Simulation: 67
Iteration: 2
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 6.1436
New value of Value function: 40.4696
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 3
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 31.2407
New value of Value function: 31.2407
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 4
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 41
New value of Q matrix: 38.1986
New value of Value function: 38.1986
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 5
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 1
New value of Q matrix: 40.4265
New value of Value function: 40.4265
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 6
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 10
New value of Q matrix: 33.5295
New value of Value function: 33.5295
New value of Policy matrix: 0

=======================================
Simulation: 67
Iteration: 7
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 2
New value of Q matrix: 40.2622
New value of Value function: 40.2622
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 8
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 11
New value of Q matrix: 33.3275
New value of Value function: 33.3275
New value of Policy matrix: 0

=======================================
Simulation: 67
Iteration: 9
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 3
New value of Q matrix: 40.1075
New value of Value function: 40.1075
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 10
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -7
New value of Visit matrix: 12
New value of Q matrix: 33.1482
New value of Value function: 33.1482
New value of Policy matrix: 0

=======================================
Simulation: 67
Iteration: 11
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 13.8169
New value of Value function: 40.1075
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 12
----------
State: 4969
	Distance: 8
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 4
New value of Q matrix: 39.9621
New value of Value function: 39.9621
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 13
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: 33.8883
New value of Value function: 33.8883
New value of Policy matrix: 0

=======================================
Simulation: 67
Iteration: 14
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 38.1397
New value of Value function: 38.1397
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 15
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 6
New value of Q matrix: 30.7797
New value of Value function: 38.1397
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 16
----------
State: 4345
	Distance: 7
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 14
New value of Q matrix: 34.3881
New value of Value function: 34.3881
New value of Policy matrix: 0

=======================================
Simulation: 67
Iteration: 17
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 24.3963
New value of Value function: 38.1397
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 18
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 40.1197
New value of Value function: 40.1197
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 19
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 63
New value of Q matrix: 45.0942
New value of Value function: 45.0942
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 20
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 33.2882
New value of Value function: 40.1197
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 21
----------
State: 4393
	Distance: 7
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 44
New value of Q matrix: 41.5555
New value of Value function: 41.5555
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 22
----------
State: 3817
	Distance: 6
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 64
New value of Q matrix: 47.5715
New value of Value function: 47.5715
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 23
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 60.3241
New value of Value function: 60.3241
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 24
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 25
New value of Q matrix: 61.1198
New value of Value function: 61.1198
New value of Policy matrix: 3

=======================================
Simulation: 67
Iteration: 25
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 76.4896
New value of Value function: 76.4896
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 26
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 43
New value of Q matrix: 79.8609
New value of Value function: 79.8609
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 27
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 33
New value of Q matrix: 95.7244
New value of Value function: 95.7244
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 28
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 3
New value of Visit matrix: 8
New value of Q matrix: 103.16
New value of Value function: 103.16
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 29
----------
State: 1505
	Distance: 2
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 4
New value of Q matrix: 100.386
New value of Value function: 100.386
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 30
----------
State: 1457
	Distance: 2
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -4
New value of Visit matrix: 9
New value of Q matrix: 99.5572
New value of Value function: 99.5572
New value of Policy matrix: 1

=======================================
Simulation: 67
Iteration: 31
----------
State: 1985
	Distance: 3
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 103.965
New value of Value function: 103.965
New value of Policy matrix: 2

=======================================
Simulation: 67
Iteration: 32
----------
State: 1409
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1410
	Distance: 2
	Angle: 5
	Height: 4
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 20
New value of Q matrix: 99.9778
New value of Value function: 99.9778
New value of Policy matrix: 4

=======================================
Simulation: 68
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2058
New value of Q matrix: 11.9245
New value of Value function: 11.9245
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2059
New value of Q matrix: 11.9219
New value of Value function: 11.9219
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2060
New value of Q matrix: 11.9192
New value of Value function: 11.9192
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2061
New value of Q matrix: 11.9166
New value of Value function: 11.9166
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 306
New value of Q matrix: 11.1098
New value of Value function: 11.9166
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 307
New value of Q matrix: 11.149
New value of Value function: 11.9166
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 11.141
New value of Value function: 11.9166
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2062
New value of Q matrix: 11.914
New value of Value function: 11.914
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2063
New value of Q matrix: 11.9114
New value of Value function: 11.9114
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 392
New value of Q matrix: 11.1984
New value of Value function: 11.9114
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2064
New value of Q matrix: 11.9087
New value of Value function: 11.9087
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2065
New value of Q matrix: 11.9061
New value of Value function: 11.9061
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2066
New value of Q matrix: 11.9035
New value of Value function: 11.9035
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2067
New value of Q matrix: 11.9009
New value of Value function: 11.9009
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 308
New value of Q matrix: 11.1851
New value of Value function: 11.9009
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2068
New value of Q matrix: 11.8983
New value of Value function: 11.8983
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2069
New value of Q matrix: 11.8956
New value of Value function: 11.8956
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2070
New value of Q matrix: 11.893
New value of Value function: 11.893
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2071
New value of Q matrix: 11.8904
New value of Value function: 11.8904
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2072
New value of Q matrix: 11.8878
New value of Value function: 11.8878
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2073
New value of Q matrix: 11.8852
New value of Value function: 11.8852
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2074
New value of Q matrix: 11.8826
New value of Value function: 11.8826
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2075
New value of Q matrix: 11.88
New value of Value function: 11.88
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 292
New value of Q matrix: 11.2384
New value of Value function: 11.88
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2076
New value of Q matrix: 11.8774
New value of Value function: 11.8774
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2077
New value of Q matrix: 11.8748
New value of Value function: 11.8748
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2078
New value of Q matrix: 11.8722
New value of Value function: 11.8722
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2079
New value of Q matrix: 11.8696
New value of Value function: 11.8696
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2080
New value of Q matrix: 11.867
New value of Value function: 11.867
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2081
New value of Q matrix: 11.8644
New value of Value function: 11.8644
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2082
New value of Q matrix: 11.8618
New value of Value function: 11.8618
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2083
New value of Q matrix: 11.8592
New value of Value function: 11.8592
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 11.2167
New value of Value function: 11.8592
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2084
New value of Q matrix: 11.8566
New value of Value function: 11.8566
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2085
New value of Q matrix: 11.854
New value of Value function: 11.854
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2086
New value of Q matrix: 11.8514
New value of Value function: 11.8514
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 309
New value of Q matrix: 11.1747
New value of Value function: 11.8514
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2087
New value of Q matrix: 11.8488
New value of Value function: 11.8488
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 11.2062
New value of Value function: 11.8488
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2088
New value of Q matrix: 11.8462
New value of Value function: 11.8462
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2089
New value of Q matrix: 11.8436
New value of Value function: 11.8436
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2090
New value of Q matrix: 11.841
New value of Value function: 11.841
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 293
New value of Q matrix: 11.2666
New value of Value function: 11.841
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2091
New value of Q matrix: 11.8384
New value of Value function: 11.8384
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2092
New value of Q matrix: 11.8358
New value of Value function: 11.8358
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2093
New value of Q matrix: 11.8332
New value of Value function: 11.8332
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2094
New value of Q matrix: 11.8306
New value of Value function: 11.8306
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2095
New value of Q matrix: 11.8281
New value of Value function: 11.8281
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2096
New value of Q matrix: 11.8255
New value of Value function: 11.8255
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2097
New value of Q matrix: 11.8229
New value of Value function: 11.8229
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2098
New value of Q matrix: 11.8203
New value of Value function: 11.8203
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2099
New value of Q matrix: 11.8177
New value of Value function: 11.8177
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2100
New value of Q matrix: 11.8152
New value of Value function: 11.8152
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2101
New value of Q matrix: 11.8126
New value of Value function: 11.8126
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2102
New value of Q matrix: 12.0812
New value of Value function: 12.0812
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 56
----------
State: 3957
	Distance: 6
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 10
New value of Q matrix: 27.1147
New value of Value function: 27.1147
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 57
----------
State: 3909
	Distance: 6
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 26
New value of Q matrix: 39.0178
New value of Value function: 39.0178
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 58
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -1
New value of Visit matrix: 24
New value of Q matrix: 52.5393
New value of Value function: 52.5393
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 59
----------
State: 3861
	Distance: 6
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 12
New value of Q matrix: 59.7138
New value of Value function: 59.7138
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 60
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 31
New value of Q matrix: 50.6839
New value of Value function: 50.6839
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 61
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 12
New value of Q matrix: 29.0616
New value of Value function: 29.0616
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 62
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 1
New value of Visit matrix: 11
New value of Q matrix: 31.0802
New value of Value function: 31.0802
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 63
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 20
New value of Q matrix: 35.8399
New value of Value function: 35.8399
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 64
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 39.9187
New value of Value function: 39.9187
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 65
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 21
New value of Q matrix: 32.9135
New value of Value function: 32.9135
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 66
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 32
New value of Q matrix: 20.3661
New value of Value function: 20.3661
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 67
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 14.2976
New value of Value function: 14.2976
New value of Policy matrix: 0

=======================================
Simulation: 68
Iteration: 68
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 33
New value of Q matrix: 18.9367
New value of Value function: 18.9367
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 69
----------
State: 2465
	Distance: 4
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 38
New value of Q matrix: 15.3439
New value of Value function: 15.3439
New value of Policy matrix: 0

=======================================
Simulation: 68
Iteration: 70
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 1
New value of Visit matrix: 12
New value of Q matrix: 28.0794
New value of Value function: 28.0794
New value of Policy matrix: 0

=======================================
Simulation: 68
Iteration: 71
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 8
New value of Q matrix: 14.0686
New value of Value function: 68.3678
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 72
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 22
New value of Q matrix: 41.3926
New value of Value function: 41.3926
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 73
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 2
New value of Visit matrix: 23
New value of Q matrix: 56.1401
New value of Value function: 56.1401
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 74
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: 4.44757
New value of Value function: 7.80393
New value of Policy matrix: 0

=======================================
Simulation: 68
Iteration: 75
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 9.44757
New value of Value function: 9.543
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 76
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 11.1344
New value of Value function: 11.1344
New value of Policy matrix: 2

=======================================
Simulation: 68
Iteration: 77
----------
State: 1841
	Distance: 3
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: 8.3436
New value of Value function: 8.3436
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2103
New value of Q matrix: 12.0785
New value of Value function: 12.0785
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2104
New value of Q matrix: 12.0759
New value of Value function: 12.0759
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 11.2487
New value of Value function: 12.0759
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2105
New value of Q matrix: 12.0733
New value of Value function: 12.0733
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2106
New value of Q matrix: 12.0706
New value of Value function: 12.0706
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 11.2884
New value of Value function: 12.0706
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2107
New value of Q matrix: 12.068
New value of Value function: 12.068
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2108
New value of Q matrix: 12.0654
New value of Value function: 12.0654
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2109
New value of Q matrix: 12.0627
New value of Value function: 12.0627
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2110
New value of Q matrix: 12.0601
New value of Value function: 12.0601
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2111
New value of Q matrix: 12.0575
New value of Value function: 12.0575
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 11.3251
New value of Value function: 12.0575
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2112
New value of Q matrix: 12.0549
New value of Value function: 12.0549
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2113
New value of Q matrix: 12.0522
New value of Value function: 12.0522
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2114
New value of Q matrix: 12.0496
New value of Value function: 12.0496
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2115
New value of Q matrix: 12.047
New value of Value function: 12.047
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 11.359
New value of Value function: 12.047
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2116
New value of Q matrix: 12.0444
New value of Value function: 12.0444
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2117
New value of Q matrix: 12.0418
New value of Value function: 12.0418
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2118
New value of Q matrix: 12.0391
New value of Value function: 12.0391
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2119
New value of Q matrix: 12.0365
New value of Value function: 12.0365
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 11.3904
New value of Value function: 12.0365
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2120
New value of Q matrix: 12.0339
New value of Value function: 12.0339
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 393
New value of Q matrix: 11.2345
New value of Value function: 12.0339
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2121
New value of Q matrix: 12.0313
New value of Value function: 12.0313
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 294
New value of Q matrix: 11.3042
New value of Value function: 12.0313
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2122
New value of Q matrix: 12.0287
New value of Value function: 12.0287
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 310
New value of Q matrix: 11.256
New value of Value function: 12.0287
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2123
New value of Q matrix: 12.0261
New value of Value function: 12.0261
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2124
New value of Q matrix: 12.0235
New value of Value function: 12.0235
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2125
New value of Q matrix: 12.0209
New value of Value function: 12.0209
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 11.4191
New value of Value function: 12.0209
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2126
New value of Q matrix: 12.0183
New value of Value function: 12.0183
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 394
New value of Q matrix: 11.2679
New value of Value function: 12.0183
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2127
New value of Q matrix: 12.0157
New value of Value function: 12.0157
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 295
New value of Q matrix: 11.3387
New value of Value function: 12.0157
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2128
New value of Q matrix: 12.013
New value of Value function: 12.013
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 296
New value of Q matrix: 11.3709
New value of Value function: 12.013
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2129
New value of Q matrix: 12.0104
New value of Value function: 12.0104
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2130
New value of Q matrix: 12.0078
New value of Value function: 12.0078
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 297
New value of Q matrix: 11.4009
New value of Value function: 12.0078
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 311
New value of Q matrix: 11.2918
New value of Value function: 12.0078
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2131
New value of Q matrix: 12.0052
New value of Value function: 12.0052
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 298
New value of Q matrix: 11.4289
New value of Value function: 12.0052
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2132
New value of Q matrix: 12.0026
New value of Value function: 12.0026
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2133
New value of Q matrix: 12
New value of Value function: 12
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2134
New value of Q matrix: 11.9974
New value of Value function: 11.9974
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2135
New value of Q matrix: 11.9948
New value of Value function: 11.9948
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2136
New value of Q matrix: 11.9923
New value of Value function: 11.9923
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2137
New value of Q matrix: 11.9897
New value of Value function: 11.9897
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 312
New value of Q matrix: 11.3245
New value of Value function: 11.9897
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2138
New value of Q matrix: 11.9871
New value of Value function: 11.9871
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2139
New value of Q matrix: 11.9845
New value of Value function: 11.9845
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2140
New value of Q matrix: 11.9819
New value of Value function: 11.9819
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 395
New value of Q matrix: 11.2978
New value of Value function: 11.9819
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2141
New value of Q matrix: 11.9793
New value of Value function: 11.9793
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2142
New value of Q matrix: 11.9767
New value of Value function: 11.9767
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2143
New value of Q matrix: 11.9741
New value of Value function: 11.9741
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2144
New value of Q matrix: 11.9715
New value of Value function: 11.9715
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 11.4434
New value of Value function: 11.9715
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2145
New value of Q matrix: 11.9689
New value of Value function: 11.9689
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2146
New value of Q matrix: 11.9664
New value of Value function: 11.9664
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2147
New value of Q matrix: 11.9638
New value of Value function: 11.9638
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2148
New value of Q matrix: 11.9612
New value of Value function: 11.9612
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2149
New value of Q matrix: 11.9586
New value of Value function: 11.9586
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2150
New value of Q matrix: 11.956
New value of Value function: 11.956
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2151
New value of Q matrix: 11.9535
New value of Value function: 11.9535
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2152
New value of Q matrix: 11.9509
New value of Value function: 11.9509
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2153
New value of Q matrix: 11.9483
New value of Value function: 11.9483
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 313
New value of Q matrix: 11.353
New value of Value function: 11.9483
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 396
New value of Q matrix: 11.3245
New value of Value function: 11.9483
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2154
New value of Q matrix: 11.9457
New value of Value function: 11.9457
New value of Policy matrix: 1

=======================================
Simulation: 68
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2155
New value of Q matrix: 11.9432
New value of Value function: 11.9432
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 1
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 7
New value of Q matrix: 26.7313
New value of Value function: 26.7313
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 2
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 16
New value of Q matrix: 25.5371
New value of Value function: 25.5371
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 3
----------
State: 4245
	Distance: 7
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 1
New value of Q matrix: 14.4839
New value of Value function: 26.7313
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 4
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 13.0503
New value of Value function: 13.0503
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 5
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: 7.06461
New value of Value function: 8.13163
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 6
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 7.45925
New value of Value function: 13.0503
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 7
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 13.0503
New value of Value function: 13.0503
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 8
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 12
New value of Q matrix: 7.51249
New value of Value function: 7.51249
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 9
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 9.03705
New value of Value function: 9.03705
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 10
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 6
New value of Q matrix: 11.8891
New value of Value function: 11.8891
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 11
----------
State: 2417
	Distance: 4
	Angle: 2
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: 7.36045
New value of Value function: 11.1344
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2156
New value of Q matrix: 11.9406
New value of Value function: 11.9406
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2157
New value of Q matrix: 11.938
New value of Value function: 11.938
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2158
New value of Q matrix: 11.9354
New value of Value function: 11.9354
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2159
New value of Q matrix: 11.9329
New value of Value function: 11.9329
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 314
New value of Q matrix: 11.379
New value of Value function: 11.9329
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2160
New value of Q matrix: 11.9303
New value of Value function: 11.9303
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2161
New value of Q matrix: 11.9277
New value of Value function: 11.9277
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2162
New value of Q matrix: 11.9252
New value of Value function: 11.9252
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2163
New value of Q matrix: 11.9226
New value of Value function: 11.9226
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2164
New value of Q matrix: 11.9201
New value of Value function: 11.9201
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2165
New value of Q matrix: 11.9175
New value of Value function: 11.9175
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2166
New value of Q matrix: 11.9149
New value of Value function: 11.9149
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2167
New value of Q matrix: 11.9124
New value of Value function: 11.9124
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2168
New value of Q matrix: 11.9098
New value of Value function: 11.9098
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 397
New value of Q matrix: 11.3479
New value of Value function: 11.9098
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2169
New value of Q matrix: 11.9073
New value of Value function: 11.9073
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 11.4627
New value of Value function: 11.9073
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 398
New value of Q matrix: 11.37
New value of Value function: 11.9073
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 299
New value of Q matrix: 11.4497
New value of Value function: 11.9073
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2170
New value of Q matrix: 11.9047
New value of Value function: 11.9047
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2171
New value of Q matrix: 11.9021
New value of Value function: 11.9021
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 33
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2172
New value of Q matrix: 11.8996
New value of Value function: 11.8996
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2173
New value of Q matrix: 11.897
New value of Value function: 11.897
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2174
New value of Q matrix: 11.8945
New value of Value function: 11.8945
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2175
New value of Q matrix: 11.8919
New value of Value function: 11.8919
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2176
New value of Q matrix: 11.8894
New value of Value function: 11.8894
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2177
New value of Q matrix: 11.8868
New value of Value function: 11.8868
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2178
New value of Q matrix: 11.8843
New value of Value function: 11.8843
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2179
New value of Q matrix: 11.8817
New value of Value function: 11.8817
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 399
New value of Q matrix: 11.3897
New value of Value function: 11.8817
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2180
New value of Q matrix: 11.8792
New value of Value function: 11.8792
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2181
New value of Q matrix: 11.8767
New value of Value function: 11.8767
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2182
New value of Q matrix: 11.8741
New value of Value function: 11.8741
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2183
New value of Q matrix: 11.8716
New value of Value function: 11.8716
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2184
New value of Q matrix: 11.869
New value of Value function: 11.869
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 319
New value of Q matrix: 11.4788
New value of Value function: 11.869
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2185
New value of Q matrix: 11.8665
New value of Value function: 11.8665
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 400
New value of Q matrix: 11.4076
New value of Value function: 11.8665
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 315
New value of Q matrix: 11.3998
New value of Value function: 11.8665
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2186
New value of Q matrix: 11.864
New value of Value function: 11.864
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2187
New value of Q matrix: 11.8614
New value of Value function: 11.8614
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2188
New value of Q matrix: 11.8589
New value of Value function: 11.8589
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 316
New value of Q matrix: 11.419
New value of Value function: 11.8589
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2189
New value of Q matrix: 11.8563
New value of Value function: 11.8563
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2190
New value of Q matrix: 11.8538
New value of Value function: 11.8538
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2191
New value of Q matrix: 11.8513
New value of Value function: 11.8513
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 317
New value of Q matrix: 11.4366
New value of Value function: 11.8513
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2192
New value of Q matrix: 11.8487
New value of Value function: 11.8487
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2193
New value of Q matrix: 11.8462
New value of Value function: 11.8462
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2194
New value of Q matrix: 11.8437
New value of Value function: 11.8437
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2195
New value of Q matrix: 11.8412
New value of Value function: 11.8412
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2196
New value of Q matrix: 11.8386
New value of Value function: 11.8386
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2197
New value of Q matrix: 11.8361
New value of Value function: 11.8361
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2198
New value of Q matrix: 11.8336
New value of Value function: 11.8336
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2199
New value of Q matrix: 11.8311
New value of Value function: 11.8311
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2200
New value of Q matrix: 11.8285
New value of Value function: 11.8285
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2201
New value of Q matrix: 11.826
New value of Value function: 11.826
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2202
New value of Q matrix: 11.8235
New value of Value function: 11.8235
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2203
New value of Q matrix: 11.821
New value of Value function: 11.821
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 318
New value of Q matrix: 11.4515
New value of Value function: 11.821
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2204
New value of Q matrix: 11.8185
New value of Value function: 11.8185
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 300
New value of Q matrix: 11.4642
New value of Value function: 11.8185
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 401
New value of Q matrix: 11.4222
New value of Value function: 11.8185
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2205
New value of Q matrix: 11.8159
New value of Value function: 11.8159
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2206
New value of Q matrix: 11.8134
New value of Value function: 11.8134
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 402
New value of Q matrix: 11.4358
New value of Value function: 11.8134
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2207
New value of Q matrix: 11.8109
New value of Value function: 11.8109
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2208
New value of Q matrix: 11.8084
New value of Value function: 11.8084
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2209
New value of Q matrix: 11.8059
New value of Value function: 11.8059
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2210
New value of Q matrix: 11.8034
New value of Value function: 11.8034
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 2211
New value of Q matrix: 12.5512
New value of Value function: 12.5512
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 83
----------
State: 3381
	Distance: 5
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 47.0407
New value of Value function: 47.0407
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 84
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 4
New value of Visit matrix: 25
New value of Q matrix: 52.8668
New value of Value function: 52.8668
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 85
----------
State: 3285
	Distance: 5
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 32
New value of Q matrix: 55.6409
New value of Value function: 55.6409
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 86
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 6
New value of Q matrix: 34.1419
New value of Value function: 76.4896
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 87
----------
State: 3813
	Distance: 6
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 7
New value of Visit matrix: 13
New value of Q matrix: 44.8707
New value of Value function: 44.8707
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 88
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 72.2156
New value of Value function: 72.2156
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 89
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: 27.3481
New value of Value function: 29.4421
New value of Policy matrix: 0

=======================================
Simulation: 69
Iteration: 90
----------
State: 3765
	Distance: 6
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 6
New value of Visit matrix: 12
New value of Q matrix: 35.2485
New value of Value function: 35.2485
New value of Policy matrix: 1

=======================================
Simulation: 69
Iteration: 91
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -5
New value of Visit matrix: 29
New value of Q matrix: 38.1662
New value of Value function: 38.1662
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 92
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 21
New value of Q matrix: 37.3553
New value of Value function: 37.3553
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 93
----------
State: 3141
	Distance: 5
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 30
New value of Q matrix: 42.2582
New value of Value function: 42.2582
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 94
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 9
New value of Q matrix: 21.3719
New value of Value function: 56.1401
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 95
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 23
New value of Q matrix: 45.3932
New value of Value function: 45.3932
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 96
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 24
New value of Q matrix: 65.8345
New value of Value function: 65.8345
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 97
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 4
New value of Visit matrix: 13
New value of Q matrix: 100.564
New value of Value function: 100.564
New value of Policy matrix: 2

=======================================
Simulation: 69
Iteration: 98
----------
State: 1353
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1354
	Distance: 2
	Angle: 4
	Height: 2
	Object picked: 1
	Arm folded: 0
Action: 4
	Move arm
Reward: 100
New value of Visit matrix: 4
New value of Q matrix: 100
New value of Value function: 100
New value of Policy matrix: 4

