=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 18
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 20
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 21
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 8
New value of Q matrix: 0.04
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.03928
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00072
New value of Value function: 0.04
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.03992
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 37
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0.00071856
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00142416
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 39
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00071856
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 40
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0.00142275
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00211424
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00279051
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0.00211285
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00345326
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00410276
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00278916
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00473926
New value of Value function: 0.03992
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.0398402
New value of Value function: 0.0398402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 49
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00142131
New value of Value function: 0.0398402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00211001
New value of Value function: 0.0398402
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.0397605
New value of Value function: 0.0397605
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 52
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00344906
New value of Value function: 0.0397605
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.039681
New value of Value function: 0.039681
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 54
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00409434
New value of Value function: 0.039681
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0.00141986
New value of Value function: 0.039681
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.0396016
New value of Value function: 0.0396016
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0.00210429
New value of Value function: 0.0396016
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0395224
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00277921
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 60
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00343503
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 61
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0.00277361
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00342954
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0.00472385
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00535588
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 65
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.00596016
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00534078
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00594537
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.00655236
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00653786
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.00713272
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 71
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.00770147
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 72
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00711851
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 73
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0.00407235
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 74
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0.00470231
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 75
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00407773
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.00470758
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.00825884
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.00768754
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0.00531966
New value of Value function: 0.0395224
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.0394433
New value of Value function: 0.0394433
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0393645
New value of Value function: 0.0393645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.00880223
New value of Value function: 0.0393645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.00532199
New value of Value function: 0.0393645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0.00592183
New value of Value function: 0.0393645
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0392857
New value of Value function: 0.0392857
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0392072
New value of Value function: 0.0392072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 87
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00823952
New value of Value function: 0.0392072
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0391287
New value of Value function: 0.0391287
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0390505
New value of Value function: 0.0390505
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.00591846
New value of Value function: 0.0390505
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 91
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.00877764
New value of Value function: 0.0390505
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.006503
New value of Value function: 0.0390505
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0389724
New value of Value function: 0.0389724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0.0065049
New value of Value function: 0.0389724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 95
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.00930359
New value of Value function: 0.0389724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 96
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.00981902
New value of Value function: 0.0389724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 97
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.00707444
New value of Value function: 0.0389724
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0388944
New value of Value function: 0.0388944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 99
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.00763305
New value of Value function: 0.0388944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.00932628
New value of Value function: 0.0388944
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0388167
New value of Value function: 0.0388167
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.0780403
New value of Value function: 0.0780403
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 103
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 104
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 105
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 106
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 107
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 108
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 109
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 110
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 111
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 112
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 113
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 114
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 115
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 116
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 117
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 118
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 119
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 120
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 121
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 122
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 123
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 124
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 125
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 126
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 127
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 128
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 129
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 130
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 131
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 132
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 133
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 134
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 135
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 136
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 137
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 138
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 139
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 140
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 141
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 142
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 143
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 144
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 145
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 146
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.0384944
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 147
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 148
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 149
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 4
New value of Q matrix: -0.0763198
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0.00777952
New value of Value function: 0.0780403
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 151
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 25
New value of Q matrix: 0.11648
New value of Value function: 0.11648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 152
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 153
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 154
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 155
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 156
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 157
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 158
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 159
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 160
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 161
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 162
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 163
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 164
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 165
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 166
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 167
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 168
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 169
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 170
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 171
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 172
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 173
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 174
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 175
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 176
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 177
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 178
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 179
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 180
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 181
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 182
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 183
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 184
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 185
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 186
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 187
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 188
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 189
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 190
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 191
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 192
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 193
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 194
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 195
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 196
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 197
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 198
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 199
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 200
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 201
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.112697
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 202
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0112364
New value of Value function: 0.11648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 203
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.00957702
New value of Value function: 0.11648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 204
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0114821
New value of Value function: 0.11648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 205
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0117193
New value of Value function: 0.11648
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 206
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.116247
New value of Value function: 0.116247
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 207
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 27
New value of Q matrix: 0.153922
New value of Value function: 0.153922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 208
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 209
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.110443
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 210
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 211
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.108234
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 212
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 213
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -2
New value of Visit matrix: 5
New value of Q matrix: -0.0372294
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 214
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 2
New value of Visit matrix: 24
New value of Q matrix: 0.0512525
New value of Value function: 0.153922
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 215
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 216
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 217
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: -0.0364848
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 218
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 219
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 220
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 221
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 222
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 223
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 224
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.106069
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 225
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 226
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 227
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.103948
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 228
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 229
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 230
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 231
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 232
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 233
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 234
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 235
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 236
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 237
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 238
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 239
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 240
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 241
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 242
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 243
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 244
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 245
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 246
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 247
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 248
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 249
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 250
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 251
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 252
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 253
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 254
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 255
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 256
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 257
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 258
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 259
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 260
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 261
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 262
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 263
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 264
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 265
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 266
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 267
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 268
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 269
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 270
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 271
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 272
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 273
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 274
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 275
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 276
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 277
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 278
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 279
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 280
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 281
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 282
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 283
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 284
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 285
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 286
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 287
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 288
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 289
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 290
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 291
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 292
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 293
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 294
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 295
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 296
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 297
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 298
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 299
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 300
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 301
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 302
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 303
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 304
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.101869
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 305
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 306
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 307
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 308
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0998316
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 309
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 310
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 311
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: -0.0357551
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 312
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: -0.03504
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 313
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 314
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 315
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 316
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 317
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 318
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 319
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 320
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 321
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 322
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 323
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 324
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 325
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 326
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 327
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 328
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 329
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 330
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 331
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 332
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 333
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 334
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 335
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: -0.0343392
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 336
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: -0.0336524
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 337
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 338
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 339
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: -0.0329794
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 340
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 341
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0978349
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 342
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 343
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 13
New value of Q matrix: -0.133108
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 344
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 28
New value of Q matrix: 0.190843
New value of Value function: 0.190843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 345
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 346
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: -0.0365648
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 347
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0536626
New value of Value function: 0.190843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 348
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 0.0110591
New value of Value function: 0.190843
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 349
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 0.227026
New value of Value function: 0.227026
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 350
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 351
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: -0.130445
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 352
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 15
New value of Q matrix: -0.16375
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 353
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0.0149244
New value of Value function: 0.227026
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 354
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 30
New value of Q matrix: 0.262486
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 355
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: -0.0358335
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 356
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -2
New value of Visit matrix: 16
New value of Q matrix: -0.19575
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 357
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0573141
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 358
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0157364
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 359
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0608926
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 360
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0.0193507
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 361
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0.0236884
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 362
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0643994
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 363
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0201464
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 364
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0244682
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 365
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0287036
New value of Value function: 0.262486
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 366
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.261961
New value of Value function: 0.261961
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 367
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.261437
New value of Value function: 0.261437
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 368
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.260914
New value of Value function: 0.260914
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 369
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0161813
New value of Value function: 0.260914
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 370
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0678079
New value of Value function: 0.260914
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 371
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 0.0279111
New value of Value function: 0.260914
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 372
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.260392
New value of Value function: 0.260392
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 373
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0711388
New value of Value function: 0.260392
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 374
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0328166
New value of Value function: 0.260392
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 375
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.259871
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 376
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0743937
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 377
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0775835
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 378
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0807095
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 379
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0320305
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 380
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0.0205354
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 381
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.083773
New value of Value function: 0.259871
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 382
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.259352
New value of Value function: 0.259352
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 383
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.024793
New value of Value function: 0.259352
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 384
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0.0360583
New value of Value function: 0.259352
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 385
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 2
New value of Visit matrix: 37
New value of Q matrix: 0.294165
New value of Value function: 0.294165
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 386
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: -0.0351169
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 387
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: -0.0344145
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 388
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 389
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 390
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 391
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 392
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 393
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: -0.0323198
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 394
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: -0.0316734
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 395
----------
State: 37
	Distance: 0
	Angle: 1
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 396
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 397
----------
State: 61
	Distance: 0
	Angle: 2
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 398
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 399
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 400
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 401
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 402
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 403
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 404
----------
State: 85
	Distance: 0
	Angle: 3
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 405
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 406
----------
State: 109
	Distance: 0
	Angle: 4
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 407
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 408
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 409
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 2
New value of Q matrix: -0.034705
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 410
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 2
New value of Visit matrix: 29
New value of Q matrix: 0.0721603
New value of Value function: 0.294165
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 411
----------
State: 133
	Distance: 0
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -2
New value of Visit matrix: 3
New value of Q matrix: -0.068716
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 412
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.293576
New value of Value function: 0.293576
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 413
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.292989
New value of Value function: 0.292989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 414
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.029571
New value of Value function: 0.292989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 415
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0759909
New value of Value function: 0.292989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 416
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0342533
New value of Value function: 0.292989
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 417
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.292403
New value of Value function: 0.292403
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 418
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.291818
New value of Value function: 0.291818
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 419
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.291235
New value of Value function: 0.291235
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 420
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.290652
New value of Value function: 0.290652
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 421
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.290071
New value of Value function: 0.290071
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 422
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 0.0405584
New value of Value function: 0.290071
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 423
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0796923
New value of Value function: 0.290071
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 424
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.289491
New value of Value function: 0.289491
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 425
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0833093
New value of Value function: 0.289491
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 426
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.288912
New value of Value function: 0.288912
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 427
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0868435
New value of Value function: 0.288912
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 428
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0903071
New value of Value function: 0.288912
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 429
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.288334
New value of Value function: 0.288334
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 430
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.093691
New value of Value function: 0.288334
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 431
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 0.0449372
New value of Value function: 0.288334
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 432
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 48
New value of Q matrix: 0.287757
New value of Value function: 0.287757
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 433
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 49
New value of Q matrix: 0.287182
New value of Value function: 0.287182
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 434
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0969864
New value of Value function: 0.287182
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 435
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 0.286607
New value of Value function: 0.286607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 436
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0387272
New value of Value function: 0.286607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 437
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 0.0491974
New value of Value function: 0.286607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 438
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0872565
New value of Value function: 0.286607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 439
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.100206
New value of Value function: 0.286607
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 440
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 0.286034
New value of Value function: 0.286034
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 441
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 0.285462
New value of Value function: 0.285462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 442
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.10334
New value of Value function: 0.285462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 443
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.106411
New value of Value function: 0.285462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 444
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.0533518
New value of Value function: 0.285462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 445
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 0.043091
New value of Value function: 0.285462
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 446
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 0.284891
New value of Value function: 0.284891
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 447
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0906394
New value of Value function: 0.284891
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 448
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0574128
New value of Value function: 0.284891
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 449
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0613926
New value of Value function: 0.284891
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 450
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0652928
New value of Value function: 0.284891
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 451
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.069115
New value of Value function: 0.284891
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 452
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 0.284321
New value of Value function: 0.284321
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 453
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 0.283753
New value of Value function: 0.283753
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 454
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 0.0728402
New value of Value function: 0.283753
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 455
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 0.283185
New value of Value function: 0.283185
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 456
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.093924
New value of Value function: 0.283185
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 457
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0971428
New value of Value function: 0.283185
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 458
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 0.282619
New value of Value function: 0.282619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 459
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 0.0473163
New value of Value function: 0.282619
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 460
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 0.282054
New value of Value function: 0.282054
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 461
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.10936
New value of Value function: 0.282054
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 462
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.11225
New value of Value function: 0.282054
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 463
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 0.28149
New value of Value function: 0.28149
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 464
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 0.0514368
New value of Value function: 0.28149
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 465
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 0.280927
New value of Value function: 0.280927
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 466
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.115062
New value of Value function: 0.280927
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 467
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 0.0764401
New value of Value function: 0.280927
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 468
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 0.0554647
New value of Value function: 0.280927
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 469
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 0.280365
New value of Value function: 0.280365
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 470
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 0.279804
New value of Value function: 0.279804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 471
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 0.0799477
New value of Value function: 0.279804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 472
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 0.100236
New value of Value function: 0.279804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 473
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.117797
New value of Value function: 0.279804
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 474
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 0.279244
New value of Value function: 0.279244
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 475
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 0.278686
New value of Value function: 0.278686
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 476
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 0.278129
New value of Value function: 0.278129
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 477
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 0.277572
New value of Value function: 0.277572
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 478
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 0.277017
New value of Value function: 0.277017
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 479
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 0.276463
New value of Value function: 0.276463
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 480
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.120417
New value of Value function: 0.276463
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 481
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 0.27591
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 482
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 0.103198
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 483
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.122975
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 484
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 0.106101
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 485
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 42
New value of Q matrix: 0.108945
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 486
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 0.0833152
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 487
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 0.0866153
New value of Value function: 0.27591
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 488
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 0.275358
New value of Value function: 0.275358
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 489
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 0.274808
New value of Value function: 0.274808
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 490
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 0.274258
New value of Value function: 0.274258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 491
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 0.125452
New value of Value function: 0.274258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 492
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 43
New value of Q matrix: 0.111703
New value of Value function: 0.274258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 493
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 0.114405
New value of Value function: 0.274258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 494
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 47
New value of Q matrix: 0.12788
New value of Value function: 0.274258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 495
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 0.0592921
New value of Value function: 0.274258
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 496
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 0.27371
New value of Value function: 0.27371
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 497
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 0.0898097
New value of Value function: 0.27371
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 498
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 0.0929403
New value of Value function: 0.27371
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 499
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 0.0960083
New value of Value function: 0.27371
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 500
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 0.273162
New value of Value function: 0.273162
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 501
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 45
New value of Q matrix: 0.117034
New value of Value function: 0.273162
New value of Policy matrix: 0

