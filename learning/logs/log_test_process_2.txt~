=======================================
Simulation: 1
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 4
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 5
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 6
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 7
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 9
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 1.68702
New value of Value function: 1.68702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 11
----------
State: 2805
	Distance: 4
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 12
----------
State: 3333
	Distance: 5
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 13
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 14
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 15
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 16
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 17
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 18
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.05
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 19
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95796
New value of Value function: 4.95796
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 20
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 4.9899
New value of Value function: 4.9899
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 21
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 22
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 23
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 24
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 25
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 26
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 27
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 28
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 29
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 30
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 31
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 32
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 33
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 34
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 35
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 36
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 2.6332
New value of Value function: 2.6332
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 37
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -2.80789
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 38
----------
State: 2565
	Distance: 4
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 2.6332
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 39
----------
State: 2517
	Distance: 4
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 4.20448
New value of Value function: 4.20448
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 40
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 41
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 42
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 43
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 44
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 45
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 46
----------
State: 1893
	Distance: 3
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 47
----------
State: 1989
	Distance: 3
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 48
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 49
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.79918
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 50
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -0.0584062
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 51
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 4
New value of Q matrix: 4.99704
New value of Value function: 4.99704
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 52
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 3
New value of Q matrix: -0.0542436
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 53
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.3437
New value of Value function: 4.99704
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 54
----------
State: 3769
	Distance: 6
	Angle: 6
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 55
----------
State: 3241
	Distance: 5
	Angle: 7
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 56
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 3.3437
New value of Value function: 3.3437
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 57
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 58
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 59
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 60
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 61
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 62
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 63
----------
State: 2709
	Distance: 4
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 64
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 65
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 66
----------
State: 2037
	Distance: 3
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 67
----------
State: 2085
	Distance: 3
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -4.20448
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 68
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0158876
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 69
----------
State: 2613
	Distance: 4
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 5
New value of Q matrix: -0.040658
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 70
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 2.11507
New value of Value function: 4.99704
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 71
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.1609
New value of Value function: 3.3437
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 72
----------
State: 3189
	Distance: 5
	Angle: 6
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 2.84986
New value of Value function: 4.99704
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 73
----------
State: 3237
	Distance: 5
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 7.40518
New value of Value function: 7.40518
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 74
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 75
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 76
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 77
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 78
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 79
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 80
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 81
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 82
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 83
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 84
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 85
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.027455
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 86
----------
State: 2661
	Distance: 4
	Angle: 7
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 3
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 87
----------
State: 2133
	Distance: 3
	Angle: 8
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 88
----------
State: 2181
	Distance: 3
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 89
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 90
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 91
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 92
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 1
Iteration: 93
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.940343
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 94
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 3
New value of Q matrix: 1.6473
New value of Value function: 1.68702
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 95
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.033437
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 96
----------
State: 2757
	Distance: 4
	Angle: 9
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 97
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 2
New value of Q matrix: -1.18921
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 98
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 3
New value of Visit matrix: 6
New value of Q matrix: 2.39247
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 99
----------
State: 2229
	Distance: 3
	Angle: 10
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -3
New value of Visit matrix: 3
New value of Q matrix: -0.846312
New value of Value function: 0
New value of Policy matrix: 2

=======================================
Simulation: 1
Iteration: 100
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.24737
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 101
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.22447
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 102
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.81707
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 103
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.79651
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 104
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.07822
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 105
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.21917
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 106
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.29071
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 107
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.32752
New value of Value function: 2.39247
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 108
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.38129
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 109
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.34135
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 110
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.34871
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 111
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.35267
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 112
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 11
New value of Q matrix: 2.35482
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 12
New value of Q matrix: 2.356
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 13
New value of Q matrix: 2.35665
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 14
New value of Q matrix: 2.35701
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 15
New value of Q matrix: 2.35721
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 117
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 16
New value of Q matrix: 2.35732
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0.999096
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 17
New value of Q matrix: 2.35739
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 18
New value of Q matrix: 2.35743
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 1.56163
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 19
New value of Q matrix: 2.35745
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.03769
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 20
New value of Q matrix: 2.35746
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 21
New value of Q matrix: 2.35747
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 22
New value of Q matrix: 2.35747
New value of Value function: 2.38129
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.37182
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 23
New value of Q matrix: 2.35377
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 1.87057
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 24
New value of Q matrix: 2.35156
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 25
New value of Q matrix: 2.35022
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 26
New value of Q matrix: 2.3494
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 27
New value of Q matrix: 2.3489
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 28
New value of Q matrix: 2.3486
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 29
New value of Q matrix: 2.34841
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 30
New value of Q matrix: 2.34829
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.15443
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.2269
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 31
New value of Q matrix: 2.34822
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 32
New value of Q matrix: 2.34818
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.27161
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 33
New value of Q matrix: 2.34815
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 34
New value of Q matrix: 2.34813
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 2.04436
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 35
New value of Q matrix: 2.34812
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 36
New value of Q matrix: 2.34812
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 37
New value of Q matrix: 2.34811
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 38
New value of Q matrix: 2.34811
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 39
New value of Q matrix: 2.34811
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 1
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 40
New value of Q matrix: 2.34811
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 1.89507
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 41
New value of Q matrix: 2.3481
New value of Value function: 2.37182
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 42
New value of Q matrix: 2.57682
New value of Value function: 2.57682
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 4
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 5
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 6
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 7
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.317456
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 8
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 43
New value of Q matrix: 2.72473
New value of Value function: 2.72473
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 9
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.202304
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 10
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 44
New value of Q matrix: 2.71524
New value of Value function: 2.71524
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 45
New value of Q matrix: 2.81404
New value of Value function: 2.81404
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 12
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.214096
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 46
New value of Q matrix: 2.80432
New value of Value function: 2.80432
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 14
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 47
New value of Q matrix: 2.87173
New value of Value function: 2.87173
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 15
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 16
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.20448
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 17
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 18
----------
State: 3669
	Distance: 6
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 2
New value of Q matrix: 4.20448
New value of Value function: 4.20448
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 19
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: -1.00977
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 20
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 21
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 22
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.79918
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 23
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 24
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 25
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 26
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 27
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 28
----------
State: 3717
	Distance: 6
	Angle: 5
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 29
----------
State: 3621
	Distance: 6
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 3.3437
New value of Value function: 3.3437
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 30
----------
State: 2997
	Distance: 5
	Angle: 2
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.100307
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 31
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 2.31854
New value of Value function: 2.87173
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 32
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 48
New value of Q matrix: 2.91561
New value of Value function: 2.91561
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 33
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: -0.295754
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 34
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 35
----------
State: 3045
	Distance: 5
	Angle: 3
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: -0.0979713
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 36
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 37
----------
State: 3093
	Distance: 5
	Angle: 4
	Height: 5
	Object picked: 0
	Arm folded: 1
State': 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 38
----------
State: 3041
	Distance: 5
	Angle: 3
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 39
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 40
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 41
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 42
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 43
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 5
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 44
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 45
----------
State: 3137
	Distance: 5
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 46
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 47
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 48
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 49
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 50
----------
State: 3185
	Distance: 5
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 3.3437
New value of Value function: 3.3437
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 51
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 52
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 4.20448
New value of Value function: 4.20448
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 53
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 54
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 55
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.113544
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 56
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.51217
New value of Value function: 2.91561
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 57
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 49
New value of Q matrix: 2.94429
New value of Value function: 2.94429
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 58
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 59
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 60
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 61
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 62
----------
State: 1301
	Distance: 2
	Angle: 3
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 63
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -3.79918
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 64
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 65
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.16244
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 66
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.72357
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 67
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 2
New value of Q matrix: -3.41692
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 68
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 69
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 70
----------
State: 2605
	Distance: 4
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 3.79918
New value of Value function: 3.79918
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 71
----------
State: 1445
	Distance: 2
	Angle: 6
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 72
----------
State: 1349
	Distance: 2
	Angle: 4
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 73
----------
State: 1397
	Distance: 2
	Angle: 5
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 74
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 2.94056
New value of Value function: 2.94056
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 75
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 76
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 77
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.68911
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 78
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.535155
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 79
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.16277
New value of Value function: 4.20448
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 80
----------
State: 2609
	Distance: 4
	Angle: 6
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 4.20448
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 81
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 82
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 83
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 84
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 85
----------
State: 2513
	Distance: 4
	Angle: 4
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 86
----------
State: 2561
	Distance: 4
	Angle: 5
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.01118
New value of Value function: 6.01118
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 87
----------
State: 1981
	Distance: 3
	Angle: 5
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 4.36145
New value of Value function: 4.36145
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 88
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 3.01277
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 89
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -4.20448
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 90
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 91
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 92
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 93
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 4
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 94
----------
State: 2657
	Distance: 4
	Angle: 7
	Height: 4
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 6.62086
New value of Value function: 6.62086
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 95
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.72357
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 96
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 3.53553
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 97
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 98
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 99
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 5
New value of Visit matrix: 1
New value of Q matrix: 5
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 100
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 101
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 102
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 103
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 104
----------
State: 1589
	Distance: 2
	Angle: 9
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 105
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 106
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 107
----------
State: 1541
	Distance: 2
	Angle: 8
	Height: 1
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -0.0635748
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 108
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 4.95
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 109
----------
State: 2029
	Distance: 3
	Angle: 6
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 3
New value of Q matrix: 4.13522
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 110
----------
State: 2077
	Distance: 3
	Angle: 7
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 3.16277
New value of Value function: 4.95
New value of Policy matrix: 1

=======================================
Simulation: 2
Iteration: 111
----------
State: 2125
	Distance: 3
	Angle: 8
	Height: 3
	Object picked: 0
	Arm folded: 1
State': 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 5
New value of Policy matrix: 2

=======================================
Simulation: 2
Iteration: 112
----------
State: 2169
	Distance: 3
	Angle: 9
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.0851553
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 113
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.64855
New value of Value function: 2.94429
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 114
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 50
New value of Q matrix: 2.93435
New value of Value function: 2.93435
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 115
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 51
New value of Q matrix: 2.92447
New value of Value function: 2.92447
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 116
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 3
New value of Visit matrix: 5
New value of Q matrix: 2.26569
New value of Value function: 2.92447
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 117
----------
State: 1641
	Distance: 2
	Angle: 10
	Height: 2
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.10477
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 118
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.48013
New value of Value function: 2.92447
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 119
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 9
New value of Q matrix: 2.54629
New value of Value function: 2.92447
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 120
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 52
New value of Q matrix: 2.91476
New value of Value function: 2.91476
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 121
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 53
New value of Q matrix: 2.9051
New value of Value function: 2.9051
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 122
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 54
New value of Q matrix: 2.8955
New value of Value function: 2.8955
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 123
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 55
New value of Q matrix: 2.88597
New value of Value function: 2.88597
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 124
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 56
New value of Q matrix: 2.87649
New value of Value function: 2.87649
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 125
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 57
New value of Q matrix: 2.86707
New value of Value function: 2.86707
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 126
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 58
New value of Q matrix: 2.85771
New value of Value function: 2.85771
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 127
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 6
New value of Q matrix: 2.44913
New value of Value function: 2.85771
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 128
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 59
New value of Q matrix: 2.84843
New value of Value function: 2.84843
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 129
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 60
New value of Q matrix: 2.83921
New value of Value function: 2.83921
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 130
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 61
New value of Q matrix: 2.83004
New value of Value function: 2.83004
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 131
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 62
New value of Q matrix: 2.82093
New value of Value function: 2.82093
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 132
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 63
New value of Q matrix: 2.81187
New value of Value function: 2.81187
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 133
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 64
New value of Q matrix: 2.80286
New value of Value function: 2.80286
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 134
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 65
New value of Q matrix: 2.79391
New value of Value function: 2.79391
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 135
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 66
New value of Q matrix: 2.78501
New value of Value function: 2.78501
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 136
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 67
New value of Q matrix: 2.77615
New value of Value function: 2.77615
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 137
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 68
New value of Q matrix: 2.76735
New value of Value function: 2.76735
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 138
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 69
New value of Q matrix: 2.7586
New value of Value function: 2.7586
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 139
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 70
New value of Q matrix: 2.7499
New value of Value function: 2.7499
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 140
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.60171
New value of Value function: 2.7499
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 141
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 71
New value of Q matrix: 2.74127
New value of Value function: 2.74127
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 142
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.669
New value of Value function: 2.74127
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 143
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: 0
New value of Visit matrix: 10
New value of Q matrix: 2.55315
New value of Value function: 2.74127
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 144
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 72
New value of Q matrix: 2.73273
New value of Value function: 2.73273
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 145
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 73
New value of Q matrix: 2.72423
New value of Value function: 2.72423
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 146
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 7
New value of Q matrix: 2.52602
New value of Value function: 2.72423
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 147
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 74
New value of Q matrix: 2.7158
New value of Value function: 2.7158
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 148
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 75
New value of Q matrix: 2.70741
New value of Value function: 2.70741
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 149
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: 0
New value of Visit matrix: 8
New value of Q matrix: 2.57356
New value of Value function: 2.70741
New value of Policy matrix: 0

=======================================
Simulation: 2
Iteration: 150
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 76
New value of Q matrix: 2.69909
New value of Value function: 2.69909
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 1
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 77
New value of Q matrix: 2.69081
New value of Value function: 2.69081
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 2
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 78
New value of Q matrix: 2.68258
New value of Value function: 2.68258
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 3
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 79
New value of Q matrix: 2.77951
New value of Value function: 2.77951
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 4
----------
State: 3577
	Distance: 6
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 1

=======================================
Simulation: 3
Iteration: 5
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 6
----------
State: 4297
	Distance: 7
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -5
New value of Visit matrix: 1
New value of Q matrix: -5
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 7
----------
State: 4873
	Distance: 8
	Angle: 5
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 1
	Turn right
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 8
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 9
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 2
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 10
----------
State: 4777
	Distance: 8
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 3
	Move back
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.188658
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 11
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 80
New value of Q matrix: 2.84669
New value of Value function: 2.84669
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 12
----------
State: 4153
	Distance: 7
	Angle: 2
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
Action: 2
	Move front
Reward: -3
New value of Visit matrix: 1
New value of Q matrix: -0.181773
New value of Value function: 0
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 13
----------
State: 1
	Distance: 0
	Angle: 0
	Height: 0
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 0
	Turn left
Reward: 3
New value of Visit matrix: 81
New value of Q matrix: 2.89331
New value of Value function: 2.89331
New value of Policy matrix: 0

=======================================
Simulation: 3
Iteration: 14
----------
State: 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
State': 4201
	Distance: 7
	Angle: 3
	Height: 6
	Object picked: 0
	Arm folded: 1
Action: 4
	Move arm
Reward: 0
New value of Visit matrix: 1
New value of Q matrix: 0
New value of Value function: 0
New value of Policy matrix: 0

